{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#arista-network-test-automation-anta-framework","title":"Arista Network Test Automation (ANTA) Framework","text":"Code License GitHub PyPi <p>ANTA is Python framework that automates tests for Arista devices.</p> <ul> <li>ANTA provides a set of tests to validate the state of your network</li> <li>ANTA can be used to:</li> <li>Automate NRFU (Network Ready For Use) test on a preproduction network</li> <li>Automate tests on a live network (periodically or on demand)</li> <li>ANTA can be used with:</li> <li>As a Python library in your own application</li> <li>The ANTA CLI</li> </ul> <p></p>"},{"location":"#install-anta-library","title":"Install ANTA library","text":"<p>The library will NOT install the necessary dependencies for the CLI.</p> <pre><code># Install ANTA as a library\npip install anta\n</code></pre>"},{"location":"#install-anta-cli","title":"Install ANTA CLI","text":"<p>If you plan to use ANTA only as a CLI tool you can use <code>pipx</code> to install it. <code>pipx</code>  is a tool to install and run python applications in isolated environments. Refer to <code>pipx</code> instructions to install on your system. <code>pipx</code> installs ANTA in an isolated python environment and makes it available globally.</p> <p>This is not recommended if you plan to contribute to ANTA</p> <pre><code># Install ANTA CLI with pipx\n$ pipx install anta[cli]\n\n# Run ANTA CLI\n$ anta --help\nUsage: anta [OPTIONS] COMMAND [ARGS]...\n\n  Arista Network Test Automation (ANTA) CLI\n\nOptions:\n  --version                       Show the version and exit.\n  --log-file FILE                 Send the logs to a file. If logging level is\n                                  DEBUG, only INFO or higher will be sent to\n                                  stdout.  [env var: ANTA_LOG_FILE]\n  -l, --log-level [CRITICAL|ERROR|WARNING|INFO|DEBUG]\n                                  ANTA logging level  [env var:\n                                  ANTA_LOG_LEVEL; default: INFO]\n  --help                          Show this message and exit.\n\nCommands:\n  check  Commands to validate configuration files\n  debug  Commands to execute EOS commands on remote devices\n  exec   Commands to execute various scripts on EOS devices\n  get    Commands to get information from or generate inventories\n  nrfu   Run ANTA tests on devices\n</code></pre> <p>You can also still choose to install it with directly with <code>pip</code>:</p> <pre><code>pip install anta[cli]\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>The documentation is published on ANTA package website.</p>"},{"location":"#contribution-guide","title":"Contribution guide","text":"<p>Contributions are welcome. Please refer to the contribution guide</p>"},{"location":"#credits","title":"Credits","text":"<p>Thank you to Jeremy Schulman for aio-eapi.</p> <p>Thank you to Ang\u00e9lique Phillipps, Colin MacGiollaE\u00e1in, Khelil Sator, Matthieu Tache, Onur Gashi, Paul Lavelle, Guillaume Mulocher and Thomas Grimonet for their contributions and guidances.</p>"},{"location":"contribution/","title":"Contributions","text":"<p>Contribution model is based on a fork-model. Don\u2019t push to aristanetworks/anta directly. Always do a branch in your forked repository and create a PR.</p> <p>To help development, open your PR as soon as possible even in draft mode. It helps other to know on what you are working on and avoid duplicate PRs.</p>"},{"location":"contribution/#create-a-development-environment","title":"Create a development environment","text":"<p>Run the following commands to create an ANTA development environment:</p> <pre><code># Clone repository\n$ git clone https://github.com/aristanetworks/anta.git\n$ cd anta\n\n# Install ANTA in editable mode and its development tools\n$ pip install -e .[dev]\n# To also install the CLI\n$ pip install -e .[dev,cli]\n\n# Verify installation\n$ pip list -e\nPackage Version Editable project location\n------- ------- -------------------------\nanta    1.3.0   /mnt/lab/projects/anta\n</code></pre> <p>Then, <code>tox</code> is configured with few environments to run CI locally:</p> <pre><code>$ tox list -d\ndefault environments:\nclean  -&gt; Erase previous coverage reports\nlint   -&gt; Check the code style\ntype   -&gt; Check typing\npy39   -&gt; Run pytest with py39\npy310  -&gt; Run pytest with py310\npy311  -&gt; Run pytest with py311\npy312  -&gt; Run pytest with py312\nreport -&gt; Generate coverage report\n</code></pre>"},{"location":"contribution/#code-linting","title":"Code linting","text":"<pre><code>tox -e lint\n[...]\nlint: commands[0]&gt; ruff check .\nAll checks passed!\nlint: commands[1]&gt; ruff format . --check\n158 files already formatted\nlint: commands[2]&gt; pylint anta\n\n--------------------------------------------------------------------\nYour code has been rated at 10.00/10 (previous run: 10.00/10, +0.00)\n\nlint: commands[3]&gt; pylint tests\n\n--------------------------------------------------------------------\nYour code has been rated at 10.00/10 (previous run: 10.00/10, +0.00)\n\n  lint: OK (22.69=setup[2.19]+cmd[0.02,0.02,9.71,10.75] seconds)\n  congratulations :) (22.72 seconds)\n</code></pre>"},{"location":"contribution/#code-typing","title":"Code Typing","text":"<pre><code>tox -e type\n\n[...]\ntype: commands[0]&gt; mypy --config-file=pyproject.toml anta\nSuccess: no issues found in 68 source files\ntype: commands[1]&gt; mypy --config-file=pyproject.toml tests\nSuccess: no issues found in 82 source files\n  type: OK (31.15=setup[14.62]+cmd[6.05,10.48] seconds)\n  congratulations :) (31.18 seconds)\n</code></pre> <p>NOTE: Typing is configured quite strictly, do not hesitate to reach out if you have any questions, struggles, nightmares.</p>"},{"location":"contribution/#unit-tests-with-pytest","title":"Unit tests with Pytest","text":"<p>To keep high quality code, we require to provide a Pytest for every tests implemented in ANTA.</p> <p>All submodule should have its own pytest section under <code>tests/units/anta_tests/&lt;submodule-name&gt;.py</code>.</p>"},{"location":"contribution/#how-to-write-a-unit-test-for-an-antatest-subclass","title":"How to write a unit test for an AntaTest subclass","text":"<p>The Python modules in the <code>tests/units/anta_tests</code> folder  define test parameters for AntaTest subclasses unit tests. A generic test function is written for all unit tests in <code>tests.units.anta_tests</code> module.</p> <p>The <code>pytest_generate_tests</code> function definition in <code>conftest.py</code> is called during test collection.</p> <p>The <code>pytest_generate_tests</code> function will parametrize the generic test function based on the <code>DATA</code> data structure defined in <code>tests.units.anta_tests</code> modules.</p> <p>See https://docs.pytest.org/en/7.3.x/how-to/parametrize.html#basic-pytest-generate-tests-example</p> <p>The <code>DATA</code> structure is a list of dictionaries used to parametrize the test. The list elements have the following keys:</p> <ul> <li><code>name</code> (str): Test name as displayed by Pytest.</li> <li><code>test</code> (AntaTest): An AntaTest subclass imported in the test module - e.g. VerifyUptime.</li> <li><code>eos_data</code> (list[dict]): List of data mocking EOS returned data to be passed to the test.</li> <li><code>inputs</code> (dict): Dictionary to instantiate the <code>test</code> inputs as defined in the class from <code>test</code>.</li> <li><code>expected</code> (dict): Expected test result structure, a dictionary containing a key     <code>result</code> containing one of the allowed status (<code>Literal['success', 'failure', 'unset', 'skipped', 'error']</code>) and optionally a key <code>messages</code> which is a list(str) and each message is expected to  be a substring of one of the actual messages in the TestResult object.</li> </ul> <p>In order for your unit tests to be correctly collected, you need to import the generic test function even if not used in the Python module.</p> <p>Test example for <code>anta.tests.system.VerifyUptime</code> AntaTest.</p> <pre><code># Import the generic test function\nfrom tests.units.anta_tests import test\n\n# Import your AntaTest\nfrom anta.tests.system import VerifyUptime\n\n# Define test parameters\nDATA: list[dict[str, Any]] = [\n   {\n        # Arbitrary test name\n        \"name\": \"success\",\n        # Must be an AntaTest definition\n        \"test\": VerifyUptime,\n        # Data returned by EOS on which the AntaTest is tested\n        \"eos_data\": [{\"upTime\": 1186689.15, \"loadAvg\": [0.13, 0.12, 0.09], \"users\": 1, \"currentTime\": 1683186659.139859}],\n        # Dictionary to instantiate VerifyUptime.Input\n        \"inputs\": {\"minimum\": 666},\n        # Expected test result\n        \"expected\": {\"result\": \"success\"},\n    },\n    {\n        \"name\": \"failure\",\n        \"test\": VerifyUptime,\n        \"eos_data\": [{\"upTime\": 665.15, \"loadAvg\": [0.13, 0.12, 0.09], \"users\": 1, \"currentTime\": 1683186659.139859}],\n        \"inputs\": {\"minimum\": 666},\n        # If the test returns messages, it needs to be expected otherwise test will fail.\n        # NB: expected messages only needs to be included in messages returned by the test. Exact match is not required.\n        \"expected\": {\"result\": \"failure\", \"messages\": [\"Device uptime is 665.15 seconds\"]},\n    },\n]\n</code></pre>"},{"location":"contribution/#git-pre-commit-hook","title":"Git Pre-commit hook","text":"<pre><code>pip install pre-commit\npre-commit install\n</code></pre> <p>When running a commit or a pre-commit check:</p> <pre><code>\u276f pre-commit\ntrim trailing whitespace.................................................Passed\nfix end of files.........................................................Passed\ncheck for added large files..............................................Passed\ncheck for merge conflicts................................................Passed\nCheck and insert license on Python files.................................Passed\nCheck and insert license on Markdown files...............................Passed\nRun Ruff linter..........................................................Passed\nRun Ruff formatter.......................................................Passed\nCheck code style with pylint.............................................Passed\nChecks for common misspellings in text files.............................Passed\nCheck typing with mypy...................................................Passed\nCheck Markdown files style...............................................Passed\n</code></pre>"},{"location":"contribution/#configure-mypypath","title":"Configure MYPYPATH","text":"<p>In some cases, mypy can complain about not having <code>MYPYPATH</code> configured in your shell. It is especially the case when you update both an anta test and its unit test. So you can configure this environment variable with:</p> <pre><code># Option 1: use local folder\nexport MYPYPATH=.\n\n# Option 2: use absolute path\nexport MYPYPATH=/path/to/your/local/anta/repository\n</code></pre>"},{"location":"contribution/#documentation","title":"Documentation","text":"<p><code>mkdocs</code> is used to generate the documentation. A PR should always update the documentation to avoid documentation debt.</p>"},{"location":"contribution/#install-documentation-requirements","title":"Install documentation requirements","text":"<p>Run pip to install the documentation requirements from the root of the repo:</p> <pre><code>pip install -e .[doc]\n</code></pre>"},{"location":"contribution/#testing-documentation","title":"Testing documentation","text":"<p>You can then check locally the documentation using the following command from the root of the repo:</p> <pre><code>mkdocs serve\n</code></pre> <p>By default, <code>mkdocs</code> listens to http://127.0.0.1:8000/, if you need to expose the documentation to another IP or port (for instance all IPs on port 8080), use the following command:</p> <pre><code>mkdocs serve --dev-addr=0.0.0.0:8080\n</code></pre>"},{"location":"contribution/#build-class-diagram","title":"Build class diagram","text":"<p>To build class diagram to use in API documentation, you can use <code>pyreverse</code> part of <code>pylint</code> with <code>graphviz</code> installed for jpeg generation.</p> <pre><code>pyreverse anta --colorized -a1 -s1 -o jpeg -m true -k --output-directory docs/imgs/uml/ -c &lt;FQDN anta class&gt;\n</code></pre> <p>Image will be generated under <code>docs/imgs/uml/</code> and can be inserted in your documentation.</p>"},{"location":"contribution/#checking-links","title":"Checking links","text":"<p>Writing documentation is crucial but managing links can be cumbersome. To be sure there is no dead links, you can use <code>muffet</code> with the following command:</p> <pre><code>muffet -c 2 --color=always http://127.0.0.1:8000 -e fonts.gstatic.com -b 8192\n</code></pre>"},{"location":"contribution/#continuous-integration","title":"Continuous Integration","text":"<p>GitHub actions is used to test git pushes and pull requests. The workflows are defined in this directory. The results can be viewed here.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#a-local-os-error-occurred-while-connecting-to-a-device","title":"A local OS error occurred while connecting to a device","text":"A local OS error occurred while connecting to a device <p>When running ANTA, you can receive <code>A local OS error occurred while connecting to &lt;device&gt;</code> errors. The underlying <code>OSError</code> exception can have various reasons: <code>[Errno 24] Too many open files</code> or <code>[Errno 16] Device or resource busy</code>.</p> <p>This usually means that the operating system refused to open a new file descriptor (or socket) for the ANTA process. This might be due to the hard limit for open file descriptors currently set for the ANTA process.</p> <p>At startup, ANTA sets the soft limit of its process to the hard limit up to 16384. This is because the soft limit is usually 1024 and the hard limit is usually higher (depends on the system). If the hard limit of the ANTA process is still lower than the number of selected tests in ANTA, the ANTA process may request to the operating system too many file descriptors and get an error, a WARNING is displayed at startup if this is the case.</p>"},{"location":"faq/#solution","title":"Solution","text":"<p>One solution could be to raise the hard limit for the user starting the ANTA process. You can get the current hard limit for a user using the command <code>ulimit -n -H</code> while logged in. Create the file <code>/etc/security/limits.d/10-anta.conf</code> with the following content: <pre><code>&lt;user&gt; hard nofile &lt;value&gt;\n</code></pre> The <code>user</code> is the one with which the ANTA process is started. The <code>value</code> is the new hard limit. The maximum value depends on the system. A hard limit of 16384 should be sufficient for ANTA to run in most high scale scenarios. After creating this file, log out the current session and log in again.</p>"},{"location":"faq/#timeout-error-in-the-logs","title":"<code>Timeout</code> error in the logs","text":"<code>Timeout</code> error in the logs <p>When running ANTA, you can receive <code>&lt;Foo&gt;Timeout</code> errors in the logs (could be ReadTimeout, WriteTimeout, ConnectTimeout or PoolTimeout). More details on the timeouts of the underlying library are available here: https://www.python-httpx.org/advanced/timeouts.</p> <p>This might be due to the time the host on which ANTA is run takes to reach the target devices (for instance if going through firewalls, NATs, \u2026) or when a lot of tests are being run at the same time on a device (eAPI has a queue mechanism to avoid exhausting EOS resources because of a high number of simultaneous eAPI requests).</p>"},{"location":"faq/#solution_1","title":"Solution","text":"<p>Use the <code>timeout</code> option. As an example for the <code>nrfu</code> command:</p> <pre><code>anta nrfu --enable --username username --password arista --inventory inventory.yml -c nrfu.yml --timeout 50 text\n</code></pre> <p>The previous command set a couple of options for ANTA NRFU, one them being the <code>timeout</code> command, by default, when running ANTA from CLI, it is set to 30s. The timeout is increased to 50s to allow ANTA to wait for API calls a little longer.</p>"},{"location":"faq/#importerror-related-to-urllib3","title":"<code>ImportError</code> related to <code>urllib3</code>","text":"<code>ImportError</code> related to <code>urllib3</code> when running ANTA <p>When running the <code>anta --help</code> command, some users might encounter the following error:</p> <pre><code>ImportError: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'OpenSSL 1.0.2k-fips  26 Jan 2017'. See: https://github.com/urllib3/urllib3/issues/2168\n</code></pre> <p>This error arises due to a compatibility issue between <code>urllib3</code> v2.0 and older versions of OpenSSL.</p>"},{"location":"faq/#solution_2","title":"Solution","text":"<ol> <li> <p>Workaround: Downgrade <code>urllib3</code></p> <p>If you need a quick fix, you can temporarily downgrade the <code>urllib3</code> package:</p> <pre><code>pip3 uninstall urllib3\n\npip3 install urllib3==1.26.15\n</code></pre> </li> <li> <p>Recommended: Upgrade System or Libraries:</p> <pre><code>As per the [urllib3 v2 migration guide](https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html), the root cause of this error is an incompatibility with older OpenSSL versions. For example, users on RHEL7 might consider upgrading to RHEL8, which supports the required OpenSSL version.\n</code></pre> </li> </ol>"},{"location":"faq/#attributeerror-module-lib-has-no-attribute-openssl_add_all_algorithms","title":"<code>AttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'</code>","text":"<code>AttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'</code> when running ANTA <p>When running the <code>anta</code> commands after installation, some users might encounter the following error:</p> <pre><code>AttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'\n</code></pre> <p>The error is a result of incompatibility between <code>cryptography</code> and <code>pyopenssl</code> when installing <code>asyncssh</code> which is a requirement of ANTA.</p>"},{"location":"faq/#solution_3","title":"Solution","text":"<ol> <li> <p>Upgrade <code>pyopenssl</code></p> <pre><code>pip install -U pyopenssl&gt;22.0\n</code></pre> </li> </ol>"},{"location":"faq/#caveat-running-on-non-posix-platforms-eg-windows","title":"Caveat running on non-POSIX platforms (e.g. Windows)","text":"Caveat running on non-POSIX platforms (e.g. Windows) <p>While ANTA should in general work on non-POSIX platforms (e.g. Windows), there are some known limitations:</p> <ul> <li>On non-Posix platforms, ANTA is not able to check and/or adjust the system limit of file descriptors.</li> </ul> <p>ANTA test suite is being run in the CI on a Windows runner.</p>"},{"location":"faq/#__nscfconstantstring-initialize-error-on-osx","title":"<code>__NSCFConstantString initialize</code> error on OSX","text":"<code>__NSCFConstantString initialize</code> error on OSX <p>This error occurs because of added security to restrict multithreading in macOS High Sierra and later versions of macOS. https://www.wefearchange.org/2018/11/forkmacos.rst.html</p>"},{"location":"faq/#solution_4","title":"Solution","text":"<ol> <li> <p>Set the following environment variable</p> <pre><code>export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\n</code></pre> </li> </ol>"},{"location":"faq/#eos-aaa-configuration-for-an-anta-only-user","title":"EOS AAA configuration for an ANTA-only user","text":"EOS AAA configuration for an ANTA-only user <p>Here is a starting guide to configure an ANTA-only user to run ANTA tests on a device.</p> <p>Warning</p> <p>This example is not using TACACS / RADIUS but only local AAA</p> <ol> <li> <p>Configure the following role.</p> <pre><code>role anta-users\n   10 permit command show\n   20 deny command .*\n</code></pre> <p>You can then add other commands if they are required for your test catalog (<code>ping</code> for example) and then tighten down the show commands to only those required for your tests.</p> </li> <li> <p>Configure the following authorization (You may need to adapt depending on your AAA setup).</p> <pre><code>aaa authorization commands all default local\n</code></pre> </li> <li> <p>Configure a user for the role.</p> <pre><code>user anta role anta-users secret &lt;secret&gt;\n</code></pre> </li> <li> <p>You can then use the credentials <code>anta</code> / <code>&lt;secret&gt;</code> to run ANTA against the device and adjust the role as required.</p> </li> </ol>"},{"location":"faq/#still-facing-issues","title":"Still facing issues?","text":"<p>If you\u2019ve tried the above solutions and continue to experience problems, please follow the troubleshooting instructions and report the issue in our GitHub repository.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This section shows how to use ANTA with basic configuration. All examples are based on Arista Test Drive (ATD) topology you can access by reaching out to your preferred SE.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>The easiest way to install ANTA package is to run Python (<code>&gt;=3.9</code>) and its pip package to install:</p> <pre><code>pip install anta[cli]\n</code></pre> <p>For more details about how to install package, please see the requirements and installation section.</p>"},{"location":"getting-started/#configure-arista-eos-devices","title":"Configure Arista EOS devices","text":"<p>For ANTA to be able to connect to your target devices, you need to configure your management interface</p> <pre><code>vrf instance MGMT\n!\ninterface Management0\n   description oob_management\n   vrf MGMT\n   ip address 192.168.0.10/24\n!\n</code></pre> <p>Then, configure access to eAPI:</p> <pre><code>!\nmanagement api http-commands\n   protocol https port 443\n   no shutdown\n   vrf MGMT\n      no shutdown\n   !\n!\n</code></pre>"},{"location":"getting-started/#create-your-inventory","title":"Create your inventory","text":"<p>ANTA uses an inventory to list the target devices for the tests. You can create a file manually with this format:</p> <pre><code>anta_inventory:\n  hosts:\n  - host: 192.168.0.10\n    name: s1-spine1\n    tags: ['fabric', 'spine']\n  - host: 192.168.0.11\n    name: s1-spine2\n    tags: ['fabric', 'spine']\n  - host: 192.168.0.12\n    name: s1-leaf1\n    tags: ['fabric', 'leaf']\n  - host: 192.168.0.13\n    name: s1-leaf2\n    tags: ['fabric', 'leaf']\n  - host: 192.168.0.14\n    name: s1-leaf3\n    tags: ['fabric', 'leaf']\n  - host: 192.168.0.15\n    name: s1-leaf3\n    tags: ['fabric', 'leaf']\n</code></pre> <p>You can read more details about how to build your inventory here</p>"},{"location":"getting-started/#test-catalog","title":"Test Catalog","text":"<p>To test your network, ANTA relies on a test catalog to list all the tests to run against your inventory. A test catalog references python functions into a yaml file.</p> <p>The structure to follow is like:</p> <pre><code>&lt;anta_tests_submodule&gt;:\n  - &lt;anta_tests_submodule function name&gt;:\n      &lt;test function option&gt;:\n        &lt;test function option value&gt;\n</code></pre> <p>You can read more details about how to build your catalog here</p> <p>Here is an example for basic tests:</p> <pre><code>---\nanta.tests.software:\n  - VerifyEOSVersion: # Verifies the device is running one of the allowed EOS version.\n      versions: # List of allowed EOS versions.\n        - 4.25.4M\n        - 4.26.1F\n        - '4.28.3M-28837868.4283M (engineering build)'\n  - VerifyTerminAttrVersion:\n      versions:\n        - v1.22.1\n\nanta.tests.system:\n  - VerifyUptime: # Verifies the device uptime is higher than a value.\n      minimum: 1\n  - VerifyNTP:\n\nanta.tests.mlag:\n  - VerifyMlagStatus:\n  - VerifyMlagInterfaces:\n  - VerifyMlagConfigSanity:\n\nanta.tests.configuration:\n  - VerifyZeroTouch: # Verifies ZeroTouch is disabled.\n  - VerifyRunningConfigDiffs:\n</code></pre>"},{"location":"getting-started/#test-your-network","title":"Test your network","text":""},{"location":"getting-started/#cli","title":"CLI","text":"<p>ANTA comes with a generic CLI entrypoint to run tests in your network. It requires an inventory file as well as a test catalog.</p> <p>This entrypoint has multiple options to manage test coverage and reporting.</p> <pre><code>$ anta --help\nUsage: anta [OPTIONS] COMMAND [ARGS]...\n\n  Arista Network Test Automation (ANTA) CLI.\n\nOptions:\n  --help                          Show this message and exit.\n  --version                       Show the version and exit.\n  --log-file FILE                 Send the logs to a file. If logging level is\n                                  DEBUG, only INFO or higher will be sent to\n                                  stdout.  [env var: ANTA_LOG_FILE]\n  -l, --log-level [CRITICAL|ERROR|WARNING|INFO|DEBUG]\n                                  ANTA logging level  [env var:\n                                  ANTA_LOG_LEVEL; default: INFO]\n\nCommands:\n  check  Commands to validate configuration files.\n  debug  Commands to execute EOS commands on remote devices.\n  exec   Commands to execute various scripts on EOS devices.\n  get    Commands to get information from or generate inventories.\n  nrfu   Run ANTA tests on selected inventory devices.\n</code></pre> <p>To run the NRFU, you need to select an output format amongst [<code>csv</code>, <code>json</code>, <code>md-report</code>, <code>table</code>, <code>text</code>, <code>tpl-report</code>].</p> <p>For a first usage, <code>table</code> is recommended.  By default all test results for all devices are rendered but it can be changed to a report per test case or per host</p> <pre><code>$ anta nrfu --help\nUsage: anta nrfu [OPTIONS] COMMAND [ARGS]...\n\n  Run ANTA tests on selected inventory devices.\n\nOptions:\n  -u, --username TEXT             Username to connect to EOS  [env var:\n                                  ANTA_USERNAME; required]\n  -p, --password TEXT             Password to connect to EOS that must be\n                                  provided. It can be prompted using '--\n                                  prompt' option.  [env var: ANTA_PASSWORD]\n  --enable-password TEXT          Password to access EOS Privileged EXEC mode.\n                                  It can be prompted using '--prompt' option.\n                                  Requires '--enable' option.  [env var:\n                                  ANTA_ENABLE_PASSWORD]\n  --enable                        Some commands may require EOS Privileged\n                                  EXEC mode. This option tries to access this\n                                  mode before sending a command to the device.\n                                  [env var: ANTA_ENABLE]\n  -P, --prompt                    Prompt for passwords if they are not\n                                  provided.  [env var: ANTA_PROMPT]\n  --timeout FLOAT                 Global API timeout. This value will be used\n                                  for all devices.  [env var: ANTA_TIMEOUT;\n                                  default: 30.0]\n  --insecure                      Disable SSH Host Key validation.  [env var:\n                                  ANTA_INSECURE]\n  --disable-cache                 Disable cache globally.  [env var:\n                                  ANTA_DISABLE_CACHE]\n  -i, --inventory FILE            Path to the inventory YAML file.  [env var:\n                                  ANTA_INVENTORY; required]\n  --inventory-format [yaml|json]  Format of the inventory file, either 'yaml'\n                                  or 'json'  [env var: ANTA_INVENTORY_FORMAT]\n  --tags TEXT                     List of tags using comma as separator:\n                                  tag1,tag2,tag3.  [env var: ANTA_TAGS]\n  -c, --catalog FILE              Path to the test catalog file  [env var:\n                                  ANTA_CATALOG; required]\n  --catalog-format [yaml|json]    Format of the catalog file, either 'yaml' or\n                                  'json'  [env var: ANTA_CATALOG_FORMAT]\n  -d, --device TEXT               Run tests on a specific device. Can be\n                                  provided multiple times.\n  -t, --test TEXT                 Run a specific test. Can be provided\n                                  multiple times.\n  --ignore-status                 Exit code will always be 0.  [env var:\n                                  ANTA_NRFU_IGNORE_STATUS]\n  --ignore-error                  Exit code will be 0 if all tests succeeded\n                                  or 1 if any test failed.  [env var:\n                                  ANTA_NRFU_IGNORE_ERROR]\n  --hide [success|failure|error|skipped]\n                                  Hide results by type: success / failure /\n                                  error / skipped'.\n  --dry-run                       Run anta nrfu command but stop before\n                                  starting to execute the tests. Considers all\n                                  devices as connected.  [env var:\n                                  ANTA_NRFU_DRY_RUN]\n  --help                          Show this message and exit.\n\nCommands:\n  csv         ANTA command to check network state with CSV report.\n  json        ANTA command to check network state with JSON results.\n  md-report   ANTA command to check network state with Markdown report.\n  table       ANTA command to check network state with table results.\n  text        ANTA command to check network state with text results.\n  tpl-report  ANTA command to check network state with templated report.\n</code></pre> <p>Note</p> <p>The following examples shows how to pass all the CLI options.</p> <p>See how to use environment variables instead in the CLI overview</p>"},{"location":"getting-started/#default-report-using-table","title":"Default report using table","text":"<pre><code>anta nrfu \\\n    --username arista \\\n    --password arista \\\n    --inventory ./inventory.yml \\\n    `# uncomment the next two lines if you have an enable password `\\\n    `# --enable` \\\n    `# --enable-password &lt;password&gt;` \\\n    --catalog ./catalog.yml \\\n    `# table is default if not provided` \\\n    table\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Settings \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 - ANTA Inventory contains 5 devices (AsyncEOSDevice) \u2502\n\u2502 - Tests catalog contains 9 tests                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n[10:53:01] INFO     Preparing ANTA NRFU Run ...                                                                                                     tools.py:294\n           INFO     Connecting to devices ...                                                                                                       tools.py:294\n           INFO     Connecting to devices completed in: 0:00:00.058.                                                                                tools.py:302\n           INFO     Preparing the tests ...                                                                                                         tools.py:294\n           INFO     Preparing the tests completed in: 0:00:00.001.                                                                                  tools.py:302\n           INFO     --- ANTA NRFU Run Information ---                                                                                              runner.py:276\n                    Number of devices: 5 (5 established)\n                    Total number of selected tests: 45\n                    Maximum number of open file descriptors for the current ANTA process: 16384\n                    ---------------------------------\n           INFO     Preparing ANTA NRFU Run completed in: 0:00:00.069.                                                                              tools.py:302\n           INFO     Running ANTA tests ...                                                                                                          tools.py:294\n[10:53:02] INFO     Running ANTA tests completed in: 0:00:00.969.                                                                                   tools.py:302\n           INFO     Cache statistics for 's1-spine1': 1 hits / 9 command(s) (11.11%)                                                                runner.py:75\n           INFO     Cache statistics for 's1-spine2': 1 hits / 9 command(s) (11.11%)                                                                runner.py:75\n           INFO     Cache statistics for 's1-leaf1': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n           INFO     Cache statistics for 's1-leaf2': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n           INFO     Cache statistics for 's1-leaf3': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n  \u2022 Running NRFU Tests...100% \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45/45 \u2022 0:00:00 \u2022 0:00:00\n\n                                                                       All tests results\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Device    \u2503 Test Name                \u2503 Test Status \u2503 Message(s)                                 \u2503 Test description                           \u2503 Test category \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 s1-spine1 \u2502 VerifyMlagConfigSanity   \u2502 skipped     \u2502 MLAG is disabled                           \u2502 Verifies there are no MLAG config-sanity   \u2502 MLAG          \u2502\n\u2502           \u2502                          \u2502             \u2502                                            \u2502 inconsistencies.                           \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 s1-spine1 \u2502 VerifyEOSVersion         \u2502 failure     \u2502 device is running version                  \u2502 Verifies the EOS version of the device.    \u2502 Software      \u2502\n\u2502           \u2502                          \u2502             \u2502 \"4.32.2F-38195967.4322F (engineering       \u2502                                            \u2502               \u2502\n\u2502           \u2502                          \u2502             \u2502 build)\" not in expected versions:          \u2502                                            \u2502               \u2502\n\u2502           \u2502                          \u2502             \u2502 ['4.25.4M', '4.26.1F',                     \u2502                                            \u2502               \u2502\n\u2502           \u2502                          \u2502             \u2502 '4.28.3M-28837868.4283M (engineering       \u2502                                            \u2502               \u2502\n\u2502           \u2502                          \u2502             \u2502 build)']                                   \u2502                                            \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n[...]\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 s1-leaf3  \u2502 VerifyTerminAttrVersion  \u2502 failure     \u2502 device is running TerminAttr version       \u2502 Verifies the TerminAttr version of the     \u2502 Software      \u2502\n\u2502           \u2502                          \u2502             \u2502 v1.34.0 and is not in the allowed list:    \u2502 device.                                    \u2502               \u2502\n\u2502           \u2502                          \u2502             \u2502 ['v1.22.1']                                \u2502                                            \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 s1-leaf3  \u2502 VerifyZeroTouch          \u2502 success     \u2502                                            \u2502 Verifies ZeroTouch is disabled             \u2502 Configuration \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/#report-in-text-mode","title":"Report in text mode","text":"<pre><code>anta nrfu \\\n    --username arista \\\n    --password arista \\\n    --inventory ./inventory.yml \\\n    `# uncomment the next two lines if you have an enable password `\\\n    `# --enable` \\\n    `# --enable-password &lt;password&gt;` \\\n    --catalog ./catalog.yml \\\n    text\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Settings \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 - ANTA Inventory contains 5 devices (AsyncEOSDevice) \u2502\n\u2502 - Tests catalog contains 9 tests                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n[10:52:39] INFO     Preparing ANTA NRFU Run ...                                                                                                     tools.py:294\n           INFO     Connecting to devices ...                                                                                                       tools.py:294\n           INFO     Connecting to devices completed in: 0:00:00.057.                                                                                tools.py:302\n           INFO     Preparing the tests ...                                                                                                         tools.py:294\n           INFO     Preparing the tests completed in: 0:00:00.001.                                                                                  tools.py:302\n           INFO     --- ANTA NRFU Run Information ---                                                                                              runner.py:276\n                    Number of devices: 5 (5 established)\n                    Total number of selected tests: 45\n                    Maximum number of open file descriptors for the current ANTA process: 16384\n                    ---------------------------------\n           INFO     Preparing ANTA NRFU Run completed in: 0:00:00.068.                                                                              tools.py:302\n           INFO     Running ANTA tests ...                                                                                                          tools.py:294\n[10:52:40] INFO     Running ANTA tests completed in: 0:00:00.863.                                                                                   tools.py:302\n           INFO     Cache statistics for 's1-spine1': 1 hits / 9 command(s) (11.11%)                                                                runner.py:75\n           INFO     Cache statistics for 's1-spine2': 1 hits / 9 command(s) (11.11%)                                                                runner.py:75\n           INFO     Cache statistics for 's1-leaf1': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n           INFO     Cache statistics for 's1-leaf2': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n           INFO     Cache statistics for 's1-leaf3': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n  \u2022 Running NRFU Tests...100% \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45/45 \u2022 0:00:00 \u2022 0:00:00\n\ns1-spine1 :: VerifyEOSVersion :: FAILURE(device is running version \"4.32.2F-38195967.4322F (engineering build)\" not in expected versions: ['4.25.4M', '4.26.1F',\n'4.28.3M-28837868.4283M (engineering build)'])\ns1-spine1 :: VerifyTerminAttrVersion :: FAILURE(device is running TerminAttr version v1.34.0 and is not in the allowed list: ['v1.22.1'])\ns1-spine1 :: VerifyZeroTouch :: SUCCESS()\ns1-spine1 :: VerifyMlagConfigSanity :: SKIPPED(MLAG is disabled)\n</code></pre>"},{"location":"getting-started/#report-in-json-format","title":"Report in JSON format","text":"<pre><code>anta nrfu \\\n    --username arista \\\n    --password arista \\\n    --inventory ./inventory.yml \\\n    `# uncomment the next two lines if you have an enable password `\\\n    `# --enable `\\\n    `# --enable-password &lt;password&gt; `\\\n    --catalog ./catalog.yml \\\n    json\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Settings \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 - ANTA Inventory contains 5 devices (AsyncEOSDevice) \u2502\n\u2502 - Tests catalog contains 9 tests                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n[10:53:11] INFO     Preparing ANTA NRFU Run ...                                                                                                     tools.py:294\n           INFO     Connecting to devices ...                                                                                                       tools.py:294\n           INFO     Connecting to devices completed in: 0:00:00.053.                                                                                tools.py:302\n           INFO     Preparing the tests ...                                                                                                         tools.py:294\n           INFO     Preparing the tests completed in: 0:00:00.001.                                                                                  tools.py:302\n           INFO     --- ANTA NRFU Run Information ---                                                                                              runner.py:276\n                    Number of devices: 5 (5 established)\n                    Total number of selected tests: 45\n                    Maximum number of open file descriptors for the current ANTA process: 16384\n                    ---------------------------------\n           INFO     Preparing ANTA NRFU Run completed in: 0:00:00.065.                                                                              tools.py:302\n           INFO     Running ANTA tests ...                                                                                                          tools.py:294\n[10:53:12] INFO     Running ANTA tests completed in: 0:00:00.857.                                                                                   tools.py:302\n           INFO     Cache statistics for 's1-spine1': 1 hits / 9 command(s) (11.11%)                                                                runner.py:75\n           INFO     Cache statistics for 's1-spine2': 1 hits / 9 command(s) (11.11%)                                                                runner.py:75\n           INFO     Cache statistics for 's1-leaf1': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n           INFO     Cache statistics for 's1-leaf2': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n           INFO     Cache statistics for 's1-leaf3': 1 hits / 9 command(s) (11.11%)                                                                 runner.py:75\n  \u2022 Running NRFU Tests...100% \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45/45 \u2022 0:00:00 \u2022 0:00:00\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 JSON results                                                                                                                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n[\n  {\n    \"name\": \"s1-spine1\",\n    \"test\": \"VerifyNTP\",\n    \"categories\": [\n      \"system\"\n    ],\n    \"description\": \"Verifies if NTP is synchronised.\",\n    \"result\": \"success\",\n    \"messages\": [],\n    \"custom_field\": null\n  },\n  {\n    \"name\": \"s1-spine1\",\n    \"test\": \"VerifyMlagConfigSanity\",\n    \"categories\": [\n      \"mlag\"\n    ],\n    \"description\": \"Verifies there are no MLAG config-sanity inconsistencies.\",\n    \"result\": \"skipped\",\n    \"messages\": [\n      \"MLAG is disabled\"\n    ],\n    \"custom_field\": null\n  },\n  [...]\n</code></pre>"},{"location":"getting-started/#basic-usage-in-a-python-script","title":"Basic usage in a Python script","text":"<pre><code># Copyright (c) 2023-2024 Arista Networks, Inc.\n# Use of this source code is governed by the Apache License 2.0\n# that can be found in the LICENSE file.\n\"\"\"Example script for ANTA.\n\nusage:\n\npython anta_runner.py\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport logging\nimport sys\nfrom pathlib import Path\n\nfrom anta.catalog import AntaCatalog\nfrom anta.cli.nrfu.utils import anta_progress_bar\nfrom anta.inventory import AntaInventory\nfrom anta.logger import Log, setup_logging\nfrom anta.models import AntaTest\nfrom anta.result_manager import ResultManager\nfrom anta.runner import main as anta_runner\n\n# setup logging\nsetup_logging(Log.INFO, Path(\"/tmp/anta.log\"))\nLOGGER = logging.getLogger()\nSCRIPT_LOG_PREFIX = \"[bold magenta][ANTA RUNNER SCRIPT][/] \"  # For convenience purpose - there are nicer way to do this.\n\n\n# NOTE: The inventory and catalog files are not delivered with this script\nUSERNAME = \"admin\"\nPASSWORD = \"admin\"\nCATALOG_PATH = Path(\"/tmp/anta_catalog.yml\")\nINVENTORY_PATH = Path(\"/tmp/anta_inventory.yml\")\n\n# Load catalog file\ntry:\n    catalog = AntaCatalog.parse(CATALOG_PATH)\nexcept Exception:\n    LOGGER.exception(\"%s Catalog failed to load!\", SCRIPT_LOG_PREFIX)\n    sys.exit(1)\nLOGGER.info(\"%s Catalog loaded!\", SCRIPT_LOG_PREFIX)\n\n# Load inventory\ntry:\n    inventory = AntaInventory.parse(INVENTORY_PATH, username=USERNAME, password=PASSWORD)\nexcept Exception:\n    LOGGER.exception(\"%s Inventory failed to load!\", SCRIPT_LOG_PREFIX)\n    sys.exit(1)\nLOGGER.info(\"%s Inventory loaded!\", SCRIPT_LOG_PREFIX)\n\n# Create result manager object\nmanager = ResultManager()\n\n# Launch ANTA\nLOGGER.info(\"%s  Starting ANTA runner...\", SCRIPT_LOG_PREFIX)\nwith anta_progress_bar() as AntaTest.progress:\n    # Set dry_run to True to avoid connecting to the devices\n    asyncio.run(anta_runner(manager, inventory, catalog, dry_run=False))\n\nLOGGER.info(\"%s ANTA run completed!\", SCRIPT_LOG_PREFIX)\n\n# Manipulate the test result object\nfor test_result in manager.results:\n    LOGGER.info(\"%s %s:%s:%s\", SCRIPT_LOG_PREFIX, test_result.name, test_result.test, test_result.result)\n</code></pre>"},{"location":"requirements-and-installation/","title":"Installation","text":""},{"location":"requirements-and-installation/#python-version","title":"Python version","text":"<p>Python 3 (<code>&gt;=3.9</code>) is required:</p> <pre><code>python --version\nPython 3.11.8\n</code></pre>"},{"location":"requirements-and-installation/#install-anta-package","title":"Install ANTA package","text":"<p>This installation will deploy tests collection, scripts and all their Python requirements.</p> <p>The ANTA package and the cli require some packages that are not part of the Python standard library. They are indicated in the pyproject.toml file, under dependencies.</p>"},{"location":"requirements-and-installation/#install-library-from-pypi-server","title":"Install library from Pypi server","text":"<pre><code>pip install anta\n</code></pre> <p>Warning</p> <p>This command alone will not install the ANTA CLI requirements.</p>"},{"location":"requirements-and-installation/#install-anta-cli-as-an-application-with-pipx","title":"Install ANTA CLI as an application with <code>pipx</code>","text":"<p><code>pipx</code> is a tool to install and run python applications in isolated environments. If you plan to use ANTA only as a CLI tool you can use <code>pipx</code> to install it. <code>pipx</code> installs ANTA in an isolated python environment and makes it available globally.</p> <pre><code>pipx install anta[cli]\n</code></pre> <p>Info</p> <p>Please take the time to read through the installation instructions of <code>pipx</code> before getting started.</p>"},{"location":"requirements-and-installation/#install-cli-from-pypi-server","title":"Install CLI from Pypi server","text":"<p>Alternatively, pip install with <code>cli</code> extra is enough to install the ANTA CLI.</p> <pre><code>pip install anta[cli]\n</code></pre>"},{"location":"requirements-and-installation/#install-anta-from-github","title":"Install ANTA from github","text":"<pre><code>pip install git+https://github.com/aristanetworks/anta.git\npip install git+https://github.com/aristanetworks/anta.git#egg=anta[cli]\n\n# You can even specify the branch, tag or commit:\npip install git+https://github.com/aristanetworks/anta.git@&lt;cool-feature-branch&gt;\npip install git+https://github.com/aristanetworks/anta.git@&lt;cool-feature-branch&gt;#egg=anta[cli]\n\npip install git+https://github.com/aristanetworks/anta.git@&lt;cool-tag&gt;\npip install git+https://github.com/aristanetworks/anta.git@&lt;cool-tag&gt;#egg=anta[cli]\n\npip install git+https://github.com/aristanetworks/anta.git@&lt;more-or-less-cool-hash&gt;\npip install git+https://github.com/aristanetworks/anta.git@&lt;more-or-less-cool-hash&gt;#egg=anta[cli]\n</code></pre>"},{"location":"requirements-and-installation/#check-installation","title":"Check installation","text":"<p>After installing ANTA, verify the installation with the following commands:</p> <pre><code># Check ANTA has been installed in your python path\npip list | grep anta\n\n# Check scripts are in your $PATH\n# Path may differ but it means CLI is in your path\nwhich anta\n/home/tom/.pyenv/shims/anta\n</code></pre> <p>Warning</p> <p>Before running the <code>anta --version</code> command, please be aware that some users have reported issues related to the <code>urllib3</code> package. If you encounter an error at this step, please refer to our FAQ page for guidance on resolving it.</p> <pre><code># Check ANTA version\nanta --version\nanta, version v1.3.0\n</code></pre>"},{"location":"requirements-and-installation/#eos-requirements","title":"EOS Requirements","text":"<p>To get ANTA working, the targeted Arista EOS devices must have eAPI enabled. They need to use the following configuration (assuming you connect to the device using Management interface in MGMT VRF):</p> <pre><code>configure\n!\nvrf instance MGMT\n!\ninterface Management1\n   description oob_management\n   vrf MGMT\n   ip address 10.73.1.105/24\n!\nend\n</code></pre> <p>Enable eAPI on the MGMT vrf:</p> <pre><code>configure\n!\nmanagement api http-commands\n   protocol https port 443\n   no shutdown\n   vrf MGMT\n      no shutdown\n!\nend\n</code></pre> <p>Now the switch accepts on port 443 in the MGMT VRF HTTPS requests containing a list of CLI commands.</p> <p>Run these EOS commands to verify:</p> <pre><code>show management http-server\nshow management api http-commands\n</code></pre>"},{"location":"troubleshooting/","title":"Troubleshooting ANTA","text":"<p>A couple of things to check when hitting an issue with ANTA:</p> <pre><code>flowchart LR\n    A&gt;Hitting an issue with ANTA] --&gt; B{Is my issue &lt;br &gt;listed in the FAQ?}\n    B -- Yes --&gt; C{Does the FAQ solution&lt;br /&gt;works for me?}\n    C -- Yes --&gt; V(((Victory)))\n    B --&gt;|No| E{Is my problem&lt;br /&gt;mentioned in one&lt;br /&gt;of the open issues?}\n    C --&gt;|No| E\n    E -- Yes --&gt; F{Has the issue been&lt;br /&gt;fixed in a newer&lt;br /&gt;release or in main?}\n    F -- Yes --&gt; U[Upgrade]\n    E -- No ---&gt; H((Follow the steps below&lt;br /&gt;and open a Github issue))\n    U --&gt; I{Did it fix&lt;br /&gt; your problem}\n    I -- Yes --&gt; V\n    I -- No --&gt; H\n    F -- No ----&gt; G((Add a comment on the &lt;br /&gt;issue indicating you&lt;br &gt;are hitting this and&lt;br /&gt;describing your setup&lt;br /&gt; and adding your logs.))\n\n    click B \"../faq\" \"FAQ\"\n    click E \"https://github.com/aristanetworks/anta/issues\"\n    click H \"https://github.com/aristanetworks/anta/issues\"\n style A stroke:#f00,stroke-width:2px</code></pre>"},{"location":"troubleshooting/#capturing-logs","title":"Capturing logs","text":"<p>To help document the issue in Github, it is important to capture some logs so the developers can understand what is affecting your system. No logs mean that the first question asked on the issue will probably be \u201cCan you share some logs please?\u201d.</p> <p>ANTA provides very verbose logs when using the <code>DEBUG</code> level.  When using DEBUG log level with a log file, the DEBUG logging level is not sent to stdout, but only to the file.</p> <p>Caution</p> <p>On real deployments, do not use DEBUG logging level without setting a log file at the same time.</p> <p>To save the logs to a file called <code>anta.log</code>, use the following flags:</p> <pre><code># Where ANTA_COMMAND is one of nrfu, debug, get, exec, check\nanta -l DEBUG \u2013log-file anta.log &lt;ANTA_COMMAND&gt;\n</code></pre> <p>See <code>anta --help</code> for more information.  These have to precede the <code>nrfu</code> cmd.</p> <p>Tip</p> <p>Remember that in ANTA, each level of command has its own options and they can only be set at this level.  so the <code>-l</code> and <code>--log-file</code> MUST be between <code>anta</code> and the <code>ANTA_COMMAND</code>.  similarly, all the <code>nrfu</code> options MUST be set between the <code>nrfu</code> and the <code>ANTA_NRFU_SUBCOMMAND</code> (<code>json</code>, <code>text</code>, <code>table</code> or <code>tpl-report</code>).</p> <p>As an example, for the <code>nrfu</code> command, it would look like:</p> <pre><code>anta -l DEBUG --log-file anta.log nrfu --enable --username username --password arista --inventory inventory.yml -c nrfu.yml text\n</code></pre>"},{"location":"troubleshooting/#anta_debug-environment-variable","title":"<code>ANTA_DEBUG</code> environment variable","text":"<p>Warning</p> <p>Do not use this if you do not know why. This produces a lot of logs and can create confusion if you do not know what to look for.</p> <p>The environment variable <code>ANTA_DEBUG=true</code> enable ANTA Debug Mode.</p> <p>This flag is used by various functions in ANTA: when set to true, the function will display or log more information. In particular, when an Exception occurs in the code and this variable is set, the logging function used by ANTA is different to also produce the Python traceback for debugging. This typically needs to be done when opening a GitHub issue and an Exception is seen at runtime.</p> <p>Example:</p> <pre><code>ANTA_DEBUG=true anta -l DEBUG --log-file anta.log nrfu --enable --username username --password arista --inventory inventory.yml -c nrfu.yml text\n</code></pre>"},{"location":"troubleshooting/#troubleshooting-on-eos","title":"Troubleshooting on EOS","text":"<p>ANTA is using a specific ID in eAPI requests towards EOS. This allows for easier eAPI requests debugging on the device using EOS configuration <code>trace CapiApp setting UwsgiRequestContext/4,CapiUwsgiServer/4</code> to set up CapiApp agent logs.</p> <p>Then, you can view agent logs using:</p> <pre><code>bash tail -f /var/log/agents/CapiApp-*\n\n2024-05-15 15:32:54.056166  1429 UwsgiRequestContext  4 request content b'{\"jsonrpc\": \"2.0\", \"method\": \"runCmds\", \"params\": {\"version\": \"latest\", \"cmds\": [{\"cmd\": \"show ip route vrf default 10.255.0.3\", \"revision\": 4}], \"format\": \"json\", \"autoComplete\": false, \"expandAliases\": false}, \"id\": \"ANTA-VerifyRoutingTableEntry-132366530677328\"}'\n</code></pre>"},{"location":"usage-inventory-catalog/","title":"Inventory and Test catalog","text":"<p>The ANTA framework needs 2 important inputs from the user to run:</p> <ol> <li>A device inventory</li> <li>A test catalog.</li> </ol> <p>Both inputs can be defined in a file or programmatically.</p>"},{"location":"usage-inventory-catalog/#device-inventory","title":"Device Inventory","text":"<p>A device inventory is an instance of the AntaInventory class.</p>"},{"location":"usage-inventory-catalog/#device-inventory-file","title":"Device Inventory File","text":"<p>The ANTA device inventory can easily be defined as a YAML file. The file must comply with the following structure:</p> <pre><code>anta_inventory:\n  hosts:\n    - host: &lt; ip address value &gt;\n      port: &lt; TCP port for eAPI. Default is 443 (Optional)&gt;\n      name: &lt; name to display in report. Default is host:port (Optional) &gt;\n      tags: &lt; list of tags to use to filter inventory during tests &gt;\n      disable_cache: &lt; Disable cache per hosts. Default is False. &gt;\n  networks:\n    - network: &lt; network using CIDR notation &gt;\n      tags: &lt; list of tags to use to filter inventory during tests &gt;\n      disable_cache: &lt; Disable cache per network. Default is False. &gt;\n  ranges:\n    - start: &lt; first ip address value of the range &gt;\n      end: &lt; last ip address value of the range &gt;\n      tags: &lt; list of tags to use to filter inventory during tests &gt;\n      disable_cache: &lt; Disable cache per range. Default is False. &gt;\n</code></pre> <p>The inventory file must start with the <code>anta_inventory</code> key then define one or multiple methods:</p> <ul> <li><code>hosts</code>: define each device individually</li> <li><code>networks</code>: scan a network for devices accessible via eAPI</li> <li><code>ranges</code>: scan a range for devices accessible via eAPI</li> </ul> <p>A full description of the inventory model is available in API documentation</p> <p>Info</p> <p>Caching can be disabled per device, network or range by setting the <code>disable_cache</code> key to <code>True</code> in the inventory file. For more details about how caching is implemented in ANTA, please refer to Caching in ANTA.</p>"},{"location":"usage-inventory-catalog/#example","title":"Example","text":"<pre><code>---\nanta_inventory:\n  hosts:\n  - host: 192.168.0.10\n    name: spine01\n    tags: ['fabric', 'spine']\n  - host: 192.168.0.11\n    name: spine02\n    tags: ['fabric', 'spine']\n  networks:\n  - network: '192.168.110.0/24'\n    tags: ['fabric', 'leaf']\n  ranges:\n  - start: 10.0.0.9\n    end: 10.0.0.11\n    tags: ['fabric', 'l2leaf']\n</code></pre>"},{"location":"usage-inventory-catalog/#test-catalog","title":"Test Catalog","text":"<p>A test catalog is an instance of the AntaCatalog class.</p>"},{"location":"usage-inventory-catalog/#test-catalog-file","title":"Test Catalog File","text":"<p>In addition to the inventory file, you also have to define a catalog of tests to execute against your devices. This catalog list all your tests, their inputs and their tags.</p> <p>A valid test catalog file must have the following structure in either YAML or JSON:</p> <pre><code>---\n&lt;Python module&gt;:\n    - &lt;AntaTest subclass&gt;:\n        &lt;AntaTest.Input compliant dictionary&gt;\n</code></pre> <pre><code>{\n  \"&lt;Python module&gt;\": [\n    {\n      \"&lt;AntaTest subclass&gt;\": &lt;AntaTest.Input compliant dictionary&gt;\n    }\n  ]\n}\n</code></pre>"},{"location":"usage-inventory-catalog/#example_1","title":"Example","text":"<pre><code>---\nanta.tests.connectivity:\n  - VerifyReachability:\n      hosts:\n        - source: Management0\n          destination: 1.1.1.1\n          vrf: MGMT\n        - source: Management0\n          destination: 8.8.8.8\n          vrf: MGMT\n      filters:\n        tags: ['leaf']\n      result_overwrite:\n        categories:\n          - \"Overwritten category 1\"\n        description: \"Test with overwritten description\"\n        custom_field: \"Test run by John Doe\"\n</code></pre> <p>or equivalent in JSON:</p> <pre><code>{\n  \"anta.tests.connectivity\": [\n    {\n      \"VerifyReachability\": {\n        \"result_overwrite\": {\n          \"description\": \"Test with overwritten description\",\n          \"categories\": [\n            \"Overwritten category 1\"\n          ],\n          \"custom_field\": \"Test run by John Doe\"\n        },\n        \"filters\": {\n          \"tags\": [\n            \"leaf\"\n          ]\n        },\n        \"hosts\": [\n          {\n            \"destination\": \"1.1.1.1\",\n            \"source\": \"Management0\",\n            \"vrf\": \"MGMT\"\n          },\n          {\n            \"destination\": \"8.8.8.8\",\n            \"source\": \"Management0\",\n            \"vrf\": \"MGMT\"\n          }\n        ]\n      }\n    }\n  ]\n}\n</code></pre> <p>It is also possible to nest Python module definition:</p> <pre><code>anta.tests:\n  connectivity:\n    - VerifyReachability:\n        hosts:\n          - source: Management0\n            destination: 1.1.1.1\n            vrf: MGMT\n          - source: Management0\n            destination: 8.8.8.8\n            vrf: MGMT\n        filters:\n          tags: ['leaf']\n        result_overwrite:\n          categories:\n            - \"Overwritten category 1\"\n          description: \"Test with overwritten description\"\n          custom_field: \"Test run by John Doe\"\n</code></pre> <p>This test catalog example is maintained with all the tests defined in the <code>anta.tests</code> Python module.</p>"},{"location":"usage-inventory-catalog/#test-tags","title":"Test tags","text":"<p>All tests can be defined with a list of user defined tags. These tags will be mapped with device tags: when at least one tag is defined for a test, this test will only be executed on devices with the same tag. If a test is defined in the catalog without any tags, the test will be executed on all devices.</p> <pre><code>anta.tests.system:\n  - VerifyUptime:\n      minimum: 10\n      filters:\n        tags: ['demo', 'leaf']\n  - VerifyReloadCause:\n  - VerifyCoredump:\n  - VerifyAgentLogs:\n  - VerifyCPUUtilization:\n      filters:\n        tags: ['leaf']\n</code></pre> <p>Info</p> <p>When using the CLI, you can filter the NRFU execution using tags. Refer to this section of the CLI documentation.</p>"},{"location":"usage-inventory-catalog/#tests-available-in-anta","title":"Tests available in ANTA","text":"<p>All tests available as part of the ANTA framework are defined under the <code>anta.tests</code> Python module and are categorised per family (Python submodule). The complete list of the tests and their respective inputs is available at the tests section of this website.</p> <p>To run test to verify the EOS software version, you can do:</p> <pre><code>anta.tests.software:\n  - VerifyEOSVersion:\n</code></pre> <p>It will load the test <code>VerifyEOSVersion</code> located in <code>anta.tests.software</code>. But since this test has mandatory inputs, we need to provide them as a dictionary in the YAML or JSON file:</p> <pre><code>anta.tests.software:\n  - VerifyEOSVersion:\n      # List of allowed EOS versions.\n      versions:\n        - 4.25.4M\n        - 4.26.1F\n</code></pre> <pre><code>{\n  \"anta.tests.software\": [\n    {\n      \"VerifyEOSVersion\": {\n        \"versions\": [\n          \"4.25.4M\",\n          \"4.31.1F\"\n        ]\n      }\n    }\n  ]\n}\n</code></pre> <p>The following example is a very minimal test catalog:</p> <pre><code>---\n# Load anta.tests.software\nanta.tests.software:\n  # Verifies the device is running one of the allowed EOS version.\n  - VerifyEOSVersion:\n      # List of allowed EOS versions.\n      versions:\n        - 4.25.4M\n        - 4.26.1F\n\n# Load anta.tests.system\nanta.tests.system:\n  # Verifies the device uptime is higher than a value.\n  - VerifyUptime:\n      minimum: 1\n\n# Load anta.tests.configuration\nanta.tests.configuration:\n  # Verifies ZeroTouch is disabled.\n  - VerifyZeroTouch:\n  - VerifyRunningConfigDiffs:\n</code></pre>"},{"location":"usage-inventory-catalog/#catalog-with-custom-tests","title":"Catalog with custom tests","text":"<p>In case you want to leverage your own tests collection, use your own Python package in the test catalog. So for instance, if my custom tests are defined in the <code>custom.tests.system</code> Python module, the test catalog will be:</p> <pre><code>custom.tests.system:\n  - VerifyPlatform:\n    type: ['cEOS-LAB']\n</code></pre> <p>Tip</p> <p>How to create custom tests</p> <p>To create your custom tests, you should refer to this documentation</p>"},{"location":"usage-inventory-catalog/#customize-test-description-and-categories","title":"Customize test description and categories","text":"<p>It might be interesting to use your own categories and customized test description to build a better report for your environment. ANTA comes with a handy feature to define your own <code>categories</code> and <code>description</code> in the report.</p> <p>In your test catalog, use <code>result_overwrite</code> dictionary with <code>categories</code> and <code>description</code> to just overwrite this values in your report:</p> <pre><code>anta.tests.configuration:\n  - VerifyZeroTouch: # Verifies ZeroTouch is disabled.\n      result_overwrite:\n        categories: ['demo', 'pr296']\n        description: A custom test\n  - VerifyRunningConfigDiffs:\nanta.tests.interfaces:\n  - VerifyInterfaceUtilization:\n</code></pre> <p>Once you run <code>anta nrfu table</code>, you will see following output:</p> <pre><code>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Device IP \u2503 Test Name                  \u2503 Test Status \u2503 Message(s) \u2503 Test description                              \u2503 Test category \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 spine01   \u2502 VerifyZeroTouch            \u2502 success     \u2502            \u2502 A custom test                                 \u2502 demo, pr296   \u2502\n\u2502 spine01   \u2502 VerifyRunningConfigDiffs   \u2502 success     \u2502            \u2502                                               \u2502 configuration \u2502\n\u2502 spine01   \u2502 VerifyInterfaceUtilization \u2502 success     \u2502            \u2502 Verifies interfaces utilization is below 75%. \u2502 interfaces    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage-inventory-catalog/#example-script-to-merge-catalogs","title":"Example script to merge catalogs","text":"<p>The following script reads all the files in <code>intended/test_catalogs/</code> with names <code>&lt;device_name&gt;-catalog.yml</code> and merge them together inside one big catalog <code>anta-catalog.yml</code> using the new <code>AntaCatalog.merge_catalogs()</code> class method.</p> <pre><code># Copyright (c) 2024 Arista Networks, Inc.\n# Use of this source code is governed by the Apache License 2.0\n# that can be found in the LICENSE file.\n\"\"\"Script that merge a collection of catalogs into one AntaCatalog.\"\"\"\n\nfrom pathlib import Path\n\nfrom anta.catalog import AntaCatalog\nfrom anta.models import AntaTest\n\nCATALOG_SUFFIX = \"-catalog.yml\"\nCATALOG_DIR = \"intended/test_catalogs/\"\n\nif __name__ == \"__main__\":\n    catalogs = []\n    for file in Path(CATALOG_DIR).glob(\"*\" + CATALOG_SUFFIX):\n        device = str(file).removesuffix(CATALOG_SUFFIX).removeprefix(CATALOG_DIR)\n        print(f\"Loading test catalog for device {device}\")\n        catalog = AntaCatalog.parse(file)\n        # Add the device name as a tag to all tests in the catalog\n        for test in catalog.tests:\n            test.inputs.filters = AntaTest.Input.Filters(tags={device})\n        catalogs.append(catalog)\n\n    # Merge all catalogs\n    merged_catalog = AntaCatalog.merge_catalogs(catalogs)\n\n    # Save the merged catalog to a file\n    with Path(\"anta-catalog.yml\").open(\"w\") as f:\n        f.write(merged_catalog.dump().yaml())\n</code></pre> <p>Warning</p> <p>The <code>AntaCatalog.merge()</code> method is deprecated and will be removed in ANTA v2.0. Please use the <code>AntaCatalog.merge_catalogs()</code> class method instead.</p>"},{"location":"advanced_usages/as-python-lib/","title":"ANTA as a Python Library","text":"<p>ANTA is a Python library that can be used in user applications. This section describes how you can leverage ANTA Python modules to help you create your own NRFU solution.</p> <p>Tip</p> <p>If you are unfamiliar with asyncio, refer to the Python documentation relevant to your Python version - https://docs.python.org/3/library/asyncio.html</p>"},{"location":"advanced_usages/as-python-lib/#antadevice-abstract-class","title":"AntaDevice Abstract Class","text":"<p>A device is represented in ANTA as a instance of a subclass of the AntaDevice abstract class. There are few abstract methods that needs to be implemented by child classes:</p> <ul> <li>The collect() coroutine is in charge of collecting outputs of AntaCommand instances.</li> <li>The refresh() coroutine is in charge of updating attributes of the AntaDevice instance. These attributes are used by AntaInventory to filter out unreachable devices or by AntaTest to skip devices based on their hardware models.</li> </ul> <p>The copy() coroutine is used to copy files to and from the device. It does not need to be implemented if tests are not using it.</p>"},{"location":"advanced_usages/as-python-lib/#asynceosdevice-class","title":"AsyncEOSDevice Class","text":"<p>The AsyncEOSDevice class is an implementation of AntaDevice for Arista EOS. It uses the aio-eapi eAPI client and the AsyncSSH library.</p> <ul> <li>The _collect() coroutine collects AntaCommand outputs using eAPI.</li> <li>The refresh() coroutine tries to open a TCP connection on the eAPI port and update the <code>is_online</code> attribute accordingly. If the TCP connection succeeds, it sends a <code>show version</code> command to gather the hardware model of the device and updates the <code>established</code> and <code>hw_model</code> attributes.</li> <li>The copy() coroutine copies files to and from the device using the SCP protocol.</li> </ul>"},{"location":"advanced_usages/as-python-lib/#antainventory-class","title":"AntaInventory Class","text":"<p>The AntaInventory class is a subclass of the standard Python type dict. The keys of this dictionary are the device names, the values are AntaDevice instances.</p> <p>AntaInventory provides methods to interact with the ANTA inventory:</p> <ul> <li>The add_device() method adds an AntaDevice instance to the inventory. Adding an entry to AntaInventory with a key different from the device name is not allowed.</li> <li>The get_inventory() returns a new AntaInventory instance with filtered out devices based on the method inputs.</li> <li>The connect_inventory() coroutine will execute the refresh() coroutines of all the devices in the inventory.</li> <li>The parse() static method creates an AntaInventory instance from a YAML file and returns it. The devices are AsyncEOSDevice instances.</li> </ul>"},{"location":"advanced_usages/as-python-lib/#examples","title":"Examples","text":""},{"location":"advanced_usages/as-python-lib/#parse-an-anta-inventory-file","title":"Parse an ANTA inventory file","text":"<pre><code># Copyright (c) 2024 Arista Networks, Inc.\n# Use of this source code is governed by the Apache License 2.0\n# that can be found in the LICENSE file.\n\"\"\"Script that parses an ANTA inventory file, connects to devices and print their status.\"\"\"\n\nimport asyncio\n\nfrom anta.inventory import AntaInventory\n\n\nasync def main(inv: AntaInventory) -&gt; None:\n    \"\"\"Read an AntaInventory and try to connect to every device in the inventory.\n\n    Print a message for every device connection status\n    \"\"\"\n    await inv.connect_inventory()\n\n    for device in inv.values():\n        if device.established:\n            print(f\"Device {device.name} is online\")\n        else:\n            print(f\"Could not connect to device {device.name}\")\n\n\nif __name__ == \"__main__\":\n    # Create the AntaInventory instance\n    inventory = AntaInventory.parse(\n        filename=\"inventory.yaml\",\n        username=\"arista\",\n        password=\"@rista123\",\n    )\n\n    # Run the main coroutine\n    res = asyncio.run(main(inventory))\n</code></pre> <p>Note</p> <p>How to create your inventory file</p> <p>Please visit this dedicated section for how to use inventory and catalog files.</p>"},{"location":"advanced_usages/as-python-lib/#run-eos-commands","title":"Run EOS commands","text":"<pre><code># Copyright (c) 2024 Arista Networks, Inc.\n# Use of this source code is governed by the Apache License 2.0\n# that can be found in the LICENSE file.\n\"\"\"Script that runs a list of EOS commands on reachable devices.\"\"\"\n\n# This is needed to run the script for python &lt; 3.10 for typing annotations\nfrom __future__ import annotations\n\nimport asyncio\nfrom pprint import pprint\n\nfrom anta.inventory import AntaInventory\nfrom anta.models import AntaCommand\n\n\nasync def main(inv: AntaInventory, commands: list[str]) -&gt; dict[str, list[AntaCommand]]:\n    \"\"\"Run a list of commands against each valid device in the inventory.\n\n    Take an AntaInventory and a list of commands as string\n    1. try to connect to every device in the inventory\n    2. collect the results of the commands from each device\n\n    Returns\n    -------\n    dict[str, list[AntaCommand]]\n        a dictionary where key is the device name and the value is the list of AntaCommand ran towards the device\n    \"\"\"\n    await inv.connect_inventory()\n\n    # Make a list of coroutine to run commands towards each connected device\n    coros = []\n    # dict to keep track of the commands per device\n    result_dict = {}\n    for name, device in inv.get_inventory(established_only=True).items():\n        anta_commands = [AntaCommand(command=command, ofmt=\"json\") for command in commands]\n        result_dict[name] = anta_commands\n        coros.append(device.collect_commands(anta_commands))\n\n    # Run the coroutines\n    await asyncio.gather(*coros)\n\n    return result_dict\n\n\nif __name__ == \"__main__\":\n    # Create the AntaInventory instance\n    inventory = AntaInventory.parse(\n        filename=\"inventory.yaml\",\n        username=\"arista\",\n        password=\"@rista123\",\n    )\n\n    # Create a list of commands with json output\n    command_list = [\"show version\", \"show ip bgp summary\"]\n\n    # Run the main asyncio  entry point\n    res = asyncio.run(main(inventory, command_list))\n\n    pprint(res)\n</code></pre>"},{"location":"advanced_usages/caching/","title":"Caching in ANTA","text":"<p>ANTA is a streamlined Python framework designed for efficient interaction with network devices. This section outlines how ANTA incorporates caching mechanisms to collect command outputs from network devices.</p>"},{"location":"advanced_usages/caching/#configuration","title":"Configuration","text":"<p>The <code>_init_cache()</code> method of the AntaDevice abstract class initializes the cache. Child classes can override this method to tweak the cache configuration:</p>"},{"location":"advanced_usages/caching/#cache-key-design","title":"Cache key design","text":"<p>The cache is initialized per <code>AntaDevice</code> and uses the following cache key design:</p> <p><code>&lt;device_name&gt;:&lt;uid&gt;</code></p> <p>The <code>uid</code> is an attribute of AntaCommand, which is a unique identifier generated from the command, version, revision and output format.</p> <p>Each UID has its own asyncio lock. This design allows coroutines that need to access the cache for different UIDs to do so concurrently. The locks are managed by the <code>AntaCache.locks</code> dictionary.</p>"},{"location":"advanced_usages/caching/#mechanisms","title":"Mechanisms","text":"<p>By default, once the cache is initialized, it is used in the <code>collect()</code> method of <code>AntaDevice</code>. The <code>collect()</code> method prioritizes retrieving the output of the command from the cache. If the output is not in the cache, the private <code>_collect()</code> method will retrieve and then store it for future access.</p>"},{"location":"advanced_usages/caching/#how-to-disable-caching","title":"How to disable caching","text":"<p>Caching is enabled by default in ANTA following the previous configuration and mechanisms.</p> <p>There might be scenarios where caching is not wanted. You can disable caching in multiple ways in ANTA:</p> <ol> <li>Caching can be disabled globally, for ALL commands on ALL devices, using the <code>--disable-cache</code> global flag when invoking anta at the CLI:</li> </ol> <pre><code>anta --disable-cache --username arista --password arista nrfu table\n</code></pre> <ol> <li>Caching can be disabled per device, network or range by setting the <code>disable_cache</code> key to <code>True</code> when defining the ANTA Inventory file:</li> </ol> <pre><code>anta_inventory:\n  hosts:\n    - host: 172.20.20.101\n      name: DC1-SPINE1\n      tags: [\"SPINE\", \"DC1\"]\n      disable_cache: True # Set this key to True\n    - host: 172.20.20.102\n      name: DC1-SPINE2\n      tags: [\"SPINE\", \"DC1\"]\n      disable_cache: False # Optional since it's the default\n\n  networks:\n    - network: \"172.21.21.0/24\"\n      disable_cache: True\n\n  ranges:\n    - start: 172.22.22.10\n      end: 172.22.22.19\n      disable_cache: True\n</code></pre> <p>This approach effectively disables caching for ALL commands sent to devices targeted by the <code>disable_cache</code> key.</p> <ol> <li>For tests developers, caching can be disabled for a specific <code>AntaCommand</code> or <code>AntaTemplate</code> by setting the <code>use_cache</code> attribute to <code>False</code>. That means the command output will always be collected on the device and therefore, never use caching.</li> </ol>"},{"location":"advanced_usages/caching/#disable-caching-in-a-child-class-of-antadevice","title":"Disable caching in a child class of <code>AntaDevice</code>","text":"<p>Since caching is implemented at the <code>AntaDevice</code> abstract class level, all subclasses will inherit that default behavior. As a result, if you need to disable caching in any custom implementation of <code>AntaDevice</code> outside of the ANTA framework, you must initialize <code>AntaDevice</code> with <code>disable_cache</code> set to <code>True</code>:</p> <pre><code>class AnsibleEOSDevice(AntaDevice):\n  \"\"\"\n  Implementation of an AntaDevice using Ansible HttpApi plugin for EOS.\n  \"\"\"\n  def __init__(self, name: str, connection: ConnectionBase, tags: set = None) -&gt; None:\n      super().__init__(name, tags, disable_cache=True)\n</code></pre>"},{"location":"advanced_usages/custom-tests/","title":"Developing ANTA tests","text":"<p>Info</p> <p>This documentation applies for both creating tests in ANTA or creating your own test package.</p> <p>ANTA is not only a Python library with a CLI and a collection of built-in tests, it is also a framework you can extend by building your own tests.</p>"},{"location":"advanced_usages/custom-tests/#generic-approach","title":"Generic approach","text":"<p>A test is a Python class where a test function is defined and will be run by the framework.</p> <p>ANTA provides an abstract class AntaTest. This class does the heavy lifting and provide the logic to define, collect and test data. The code below is an example of a simple test in ANTA, which is an AntaTest subclass:</p> <pre><code>from anta.models import AntaTest, AntaCommand\nfrom anta.decorators import skip_on_platforms\n\n\nclass VerifyTemperature(AntaTest):\n    \"\"\"Verifies if the device temperature is within acceptable limits.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device temperature is currently OK: 'temperatureOk'.\n    * Failure: The test will fail if the device temperature is NOT OK.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.hardware:\n      - VerifyTemperature:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"hardware\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show system environment temperature\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTemperature.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        temperature_status = command_output.get(\"systemStatus\", \"\")\n        if temperature_status == \"temperatureOk\":\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Device temperature exceeds acceptable limits. Current system status: '{temperature_status}'\")\n</code></pre> <p>AntaTest also provide more advanced capabilities like AntaCommand templating using the AntaTemplate class or test inputs definition and validation using AntaTest.Input pydantic model. This will be discussed in the sections below.</p>"},{"location":"advanced_usages/custom-tests/#antatest-structure","title":"AntaTest structure","text":"<p>Full AntaTest API documentation is available in the API documentation section</p>"},{"location":"advanced_usages/custom-tests/#class-attributes","title":"Class Attributes","text":"<ul> <li><code>name</code> (<code>str</code>, <code>optional</code>): Name of the test. Used during reporting. By default set to the Class name.</li> <li><code>description</code> (<code>str</code>, <code>optional</code>): A human readable description of your test. By default set to the first line of the docstring.</li> <li><code>categories</code> (<code>list[str]</code>): A list of categories in which the test belongs.</li> <li><code>commands</code> (<code>[list[AntaCommand | AntaTemplate]]</code>): A list of command to collect from devices. This list must be a list of AntaCommand or AntaTemplate instances. Rendering AntaTemplate instances will be discussed later.</li> </ul> <p>Info</p> <p>All these class attributes are mandatory. If any attribute is missing, a <code>NotImplementedError</code> exception will be raised during class instantiation.</p>"},{"location":"advanced_usages/custom-tests/#instance-attributes","title":"Instance Attributes","text":"<p>Attributes:</p> Name Type Description <code>device</code> <code>AntaDevice</code> <p>AntaDevice instance on which this test is run.</p> <code>inputs</code> <code>Input</code> <p>AntaTest.Input instance carrying the test inputs.</p> <code>instance_commands</code> <code>list[AntaCommand]</code> <p>List of AntaCommand instances of this test.</p> <code>result</code> <code>TestResult</code> <p>TestResult instance representing the result of this test.</p> <code>logger</code> <code>Logger</code> <p>Python logger for this test instance.</p> <p>Note</p> <ul> <li> <p>Logger object</p> <p>ANTA already provides comprehensive logging at every steps of a test execution. The AntaTest class also provides a <code>logger</code> attribute that is a Python logger specific to the test instance. See Python documentation for more information.</p> </li> <li> <p>AntaDevice object</p> <p>Even if <code>device</code> is not a private attribute, you should not need to access this object in your code.</p> </li> </ul>"},{"location":"advanced_usages/custom-tests/#test-inputs","title":"Test Inputs","text":"<p>AntaTest.Input is a pydantic model that allow test developers to define their test inputs. pydantic provides out of the box error handling for test input validation based on the type hints defined by the test developer.</p> <p>The base definition of AntaTest.Input provides common test inputs for all AntaTest instances:</p>"},{"location":"advanced_usages/custom-tests/#input-model","title":"Input model","text":"<p>Full <code>Input</code> model documentation is available in API documentation section</p> <p>Attributes:</p> Name Type Description <code>result_overwrite</code> <code>ResultOverwrite | None</code> <p>Define fields to overwrite in the TestResult object.</p>"},{"location":"advanced_usages/custom-tests/#resultoverwrite-model","title":"ResultOverwrite model","text":"<p>Full <code>ResultOverwrite</code> model documentation is available in API documentation section</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str | None</code> <p>Overwrite <code>TestResult.description</code>.</p> <code>categories</code> <code>list[str] | None</code> <p>Overwrite <code>TestResult.categories</code>.</p> <code>custom_field</code> <code>str | None</code> <p>A free string that will be included in the TestResult object.</p> <p>Note</p> <p>The pydantic model is configured using the <code>extra=forbid</code> that will fail input validation if extra fields are provided.</p>"},{"location":"advanced_usages/custom-tests/#methods","title":"Methods","text":"<ul> <li>test(self) -&gt; None: This is an abstract method that must be implemented. It contains the test logic that can access the collected command outputs using the <code>instance_commands</code> instance attribute, access the test inputs using the <code>inputs</code> instance attribute and must set the <code>result</code> instance attribute accordingly. It must be implemented using the <code>AntaTest.anta_test</code> decorator that provides logging and will collect commands before executing the <code>test()</code> method.</li> <li>render(self, template: AntaTemplate) -&gt; list[AntaCommand]: This method only needs to be implemented if AntaTemplate instances are present in the <code>commands</code> class attribute. It will be called for every AntaTemplate occurrence and must return a list of AntaCommand using the AntaTemplate.render() method. It can access test inputs using the <code>inputs</code> instance attribute.</li> </ul>"},{"location":"advanced_usages/custom-tests/#test-execution","title":"Test execution","text":"<p>Below is a high level description of the test execution flow in ANTA:</p> <ol> <li> <p>ANTA will parse the test catalog to get the list of AntaTest subclasses to instantiate and their associated input values. We consider a single AntaTest subclass in the following steps.</p> </li> <li> <p>ANTA will instantiate the AntaTest subclass and a single device will be provided to the test instance. The <code>Input</code> model defined in the class will also be instantiated at this moment. If any ValidationError is raised, the test execution will be stopped.</p> </li> <li> <p>If there is any AntaTemplate instance in the <code>commands</code> class attribute, render() will be called for every occurrence. At this moment, the <code>instance_commands</code> attribute has been initialized. If any rendering error occurs, the test execution will be stopped.</p> </li> <li> <p>The <code>AntaTest.anta_test</code> decorator will collect the commands from the device and update the <code>instance_commands</code> attribute with the outputs. If any collection error occurs, the test execution will be stopped.</p> </li> <li> <p>The test() method is executed.</p> </li> </ol>"},{"location":"advanced_usages/custom-tests/#writing-an-antatest-subclass","title":"Writing an AntaTest subclass","text":"<p>In this section, we will go into all the details of writing an AntaTest subclass.</p>"},{"location":"advanced_usages/custom-tests/#class-definition","title":"Class definition","text":"<p>Import anta.models.AntaTest and define your own class. Define the mandatory class attributes using anta.models.AntaCommand, anta.models.AntaTemplate or both.</p> <p>Note</p> <p>Caching can be disabled per <code>AntaCommand</code> or <code>AntaTemplate</code> by setting the <code>use_cache</code> argument to <code>False</code>. For more details about how caching is implemented in ANTA, please refer to Caching in ANTA.</p> <pre><code>from anta.models import AntaTest, AntaCommand, AntaTemplate\n\n\nclass &lt;YourTestName&gt;(AntaTest):\n    \"\"\"\n    &lt;a docstring description of your test, the first line is used as description of the test by default&gt;\n    \"\"\"\n\n    # name = &lt;override&gt;        # uncomment to override default behavior of name=Class Name\n    # description = &lt;override&gt; # uncomment to override default behavior of description=first line of docstring\n    categories = [\"&lt;arbitrary category&gt;\", \"&lt;another arbitrary category&gt;\"]\n    commands = [\n        AntaCommand(\n            command=\"&lt;EOS command to run&gt;\",\n            ofmt=\"&lt;command format output&gt;\",\n            version=\"&lt;eAPI version to use&gt;\",\n            revision=\"&lt;revision to use for the command&gt;\",           # revision has precedence over version\n            use_cache=\"&lt;Use cache for the command&gt;\",\n        ),\n        AntaTemplate(\n            template=\"&lt;Python f-string to render an EOS command&gt;\",\n            ofmt=\"&lt;command format output&gt;\",\n            version=\"&lt;eAPI version to use&gt;\",\n            revision=\"&lt;revision to use for the command&gt;\",           # revision has precedence over version\n            use_cache=\"&lt;Use cache for the command&gt;\",\n        )\n    ]\n</code></pre> <p>Tip</p> <p>Command revision and version</p> <ul> <li>Most of EOS commands return a JSON structure according to a model (some commands may not be modeled hence the necessity to use <code>text</code> outformat sometimes.</li> <li>The model can change across time (adding feature, \u2026 ) and when the model is changed in a non backward-compatible way, the revision number is bumped. The initial model starts with revision 1.</li> <li>A revision applies to a particular CLI command whereas a version is global to an eAPI call. The version is internally translated to a specific revision for each CLI command in the RPC call. The currently supported version values  are <code>1</code> and <code>latest</code>.</li> <li>A revision takes precedence over a version (e.g. if a command is run with version=\u201dlatest\u201d and revision=1, the first revision of the model is returned)</li> <li>By default, eAPI returns the first revision of each model to ensure that when upgrading, integrations with existing tools are not broken. This is done by using by default <code>version=1</code> in eAPI calls.</li> </ul> <p>By default, ANTA uses <code>version=\"latest\"</code> in AntaCommand, but when developing tests, the revision MUST be provided when the outformat of the command is <code>json</code>. As explained earlier, this is to ensure that the eAPI always returns the same output model and that the test remains always valid from the day it was created. For some commands, you may also want to run them with a different revision or version.</p> <p>For instance, the <code>VerifyBFDPeersHealth</code> test leverages the first revision of <code>show bfd peers</code>:</p> <pre><code># revision 1 as later revision introduce additional nesting for type\ncommands = [AntaCommand(command=\"show bfd peers\", revision=1)]\n</code></pre>"},{"location":"advanced_usages/custom-tests/#inputs-definition","title":"Inputs definition","text":"<p>If the user needs to provide inputs for your test, you need to define a pydantic model that defines the schema of the test inputs:</p> <pre><code>class &lt;YourTestName&gt;(AntaTest):\n    \"\"\"Verifies ...\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if ...\n    * Failure: The test will fail if ...\n\n    Examples\n    --------\n    ```yaml\n    your.module.path:\n      - YourTestName:\n        field_name: example_field_value\n    ```\n    \"\"\"\n    ...\n    class Input(AntaTest.Input):\n        \"\"\"Inputs for my awesome test.\"\"\"\n        &lt;input field name&gt;: &lt;input field type&gt;\n        \"\"\"&lt;input field docstring&gt;\"\"\"\n</code></pre> <p>To define an input field type, refer to the pydantic documentation about types. You can also leverage anta.custom_types that provides reusable types defined in ANTA tests.</p> <p>Regarding required, optional and nullable fields, refer to this documentation on how to define them.</p> <p>Note</p> <p>All the <code>pydantic</code> features are supported. For instance you can define validators for complex input validation.</p>"},{"location":"advanced_usages/custom-tests/#template-rendering","title":"Template rendering","text":"<p>Define the <code>render()</code> method if you have AntaTemplate instances in your <code>commands</code> class attribute:</p> <pre><code>class &lt;YourTestName&gt;(AntaTest):\n    ...\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        return [template.render(&lt;template param&gt;=input_value) for input_value in self.inputs.&lt;input_field&gt;]\n</code></pre> <p>You can access test inputs and render as many AntaCommand as desired.</p>"},{"location":"advanced_usages/custom-tests/#test-definition","title":"Test definition","text":"<p>Implement the <code>test()</code> method with your test logic:</p> <pre><code>class &lt;YourTestName&gt;(AntaTest):\n    ...\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        pass\n</code></pre> <p>The logic usually includes the following different stages:</p> <ol> <li>Parse the command outputs using the <code>self.instance_commands</code> instance attribute.</li> <li>If needed, access the test inputs using the <code>self.inputs</code> instance attribute and write your conditional logic.</li> <li>Set the <code>result</code> instance attribute to reflect the test result by either calling <code>self.result.is_success()</code> or <code>self.result.is_failure(\"&lt;FAILURE REASON&gt;\")</code>. Sometimes, setting the test result to <code>skipped</code> using <code>self.result.is_skipped(\"&lt;SKIPPED REASON&gt;\")</code> can make sense (e.g. testing the OSPF neighbor states but no neighbor was found). However, you should not need to catch any exception and set the test result to <code>error</code> since the error handling is done by the framework, see below.</li> </ol> <p>The example below is based on the VerifyTemperature test.</p> <pre><code>class VerifyTemperature(AntaTest):\n    ...\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        # Grab output of the collected command\n        command_output = self.instance_commands[0].json_output\n\n        # Do your test: In this example we check a specific field of the JSON output from EOS\n        temperature_status = command_output[\"systemStatus\"] if \"systemStatus\" in command_output.keys() else \"\"\n        if temperature_status == \"temperatureOk\":\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Device temperature exceeds acceptable limits. Current system status: '{temperature_status}'\")\n</code></pre> <p>As you can see there is no error handling to do in your code. Everything is packaged in the <code>AntaTest.anta_tests</code> decorator and below is a simple example of error captured when trying to access a dictionary with an incorrect key:</p> <pre><code>class VerifyTemperature(AntaTest):\n    ...\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        # Grab output of the collected command\n        command_output = self.instance_commands[0].json_output\n\n        # Access the dictionary with an incorrect key\n        command_output['incorrectKey']\n</code></pre> <pre><code>ERROR    Exception raised for test VerifyTemperature (on device 192.168.0.10) - KeyError ('incorrectKey')\n</code></pre> <p>Get stack trace for debugging</p> <p>If you want to access to the full exception stack, you can run ANTA in debug mode by setting the <code>ANTA_DEBUG</code> environment variable to <code>true</code>. Example: <pre><code>$ ANTA_DEBUG=true anta nrfu --catalog test_custom.yml text\n</code></pre></p>"},{"location":"advanced_usages/custom-tests/#test-decorators","title":"Test decorators","text":"<p>In addition to the required <code>AntaTest.anta_tests</code> decorator, ANTA offers a set of optional decorators for further test customization:</p> <ul> <li><code>anta.decorators.deprecated_test</code>: Use this to log a message of WARNING severity when a test is deprecated.</li> <li><code>anta.decorators.skip_on_platforms</code>: Use this to skip tests for functionalities that are not supported on specific platforms.</li> </ul> <pre><code>from anta.decorators import skip_on_platforms\n\nclass VerifyTemperature(AntaTest):\n    ...\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        pass\n</code></pre>"},{"location":"advanced_usages/custom-tests/#access-your-custom-tests-in-the-test-catalog","title":"Access your custom tests in the test catalog","text":"<p>Warning</p> <p>This section is required only if you are not merging your development into ANTA. Otherwise, just follow contribution guide.</p> <p>For that, you need to create your own Python package as described in this hitchhiker\u2019s guide to package Python code. We assume it is well known and we won\u2019t focus on this aspect. Thus, your package must be importable by ANTA hence available in the module search path <code>sys.path</code> (you can use <code>PYTHONPATH</code> for example).</p> <p>It is very similar to what is documented in catalog section but you have to use your own package name.2</p> <p>Let say the custom Python package is <code>anta_custom</code> and the test is defined in <code>anta_custom.dc_project</code> Python module, the test catalog would look like:</p> <pre><code>anta_custom.dc_project:\n  - VerifyFeatureX:\n      minimum: 1\n</code></pre> <p>And now you can run your NRFU tests with the CLI:</p> <pre><code>anta nrfu text --catalog test_custom.yml\nspine01 :: verify_dynamic_vlan :: FAILURE (Device has 0 configured, we expect at least 1)\nspine02 :: verify_dynamic_vlan :: FAILURE (Device has 0 configured, we expect at least 1)\nleaf01 :: verify_dynamic_vlan :: SUCCESS\nleaf02 :: verify_dynamic_vlan :: SUCCESS\nleaf03 :: verify_dynamic_vlan :: SUCCESS\nleaf04 :: verify_dynamic_vlan :: SUCCESS\n</code></pre>"},{"location":"api/catalog/","title":"Catalog","text":""},{"location":"api/catalog/#anta.catalog.AntaCatalog","title":"AntaCatalog","text":"<pre><code>AntaCatalog(\n    tests: list[AntaTestDefinition] | None = None,\n    filename: str | Path | None = None,\n)\n</code></pre> <p>Class representing an ANTA Catalog.</p> <p>It can be instantiated using its constructor or one of the static methods: <code>parse()</code>, <code>from_list()</code> or <code>from_dict()</code></p> <p>Parameters:</p> Name Type Description Default <code>tests</code> <code>list[AntaTestDefinition] | None</code> <p>A list of AntaTestDefinition instances.</p> <code>None</code> <code>filename</code> <code>str | Path | None</code> <p>The path from which the catalog is loaded.</p> <code>None</code>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.filename","title":"filename  <code>property</code>","text":"<pre><code>filename: Path | None\n</code></pre> <p>Path of the file used to create this AntaCatalog instance.</p>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.tests","title":"tests  <code>property</code> <code>writable</code>","text":"<pre><code>tests: list[AntaTestDefinition]\n</code></pre> <p>List of AntaTestDefinition in this catalog.</p>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.build_indexes","title":"build_indexes","text":"<pre><code>build_indexes(\n    filtered_tests: set[str] | None = None,\n) -&gt; None\n</code></pre> <p>Indexes tests by their tags for quick access during filtering operations.</p> <p>If a <code>filtered_tests</code> set is provided, only the tests in this set will be indexed.</p> <p>This method populates the tag_to_tests attribute, which is a dictionary mapping tags to sets of tests.</p> <p>Once the indexes are built, the <code>indexes_built</code> attribute is set to True.</p> Source code in <code>anta/catalog.py</code> <pre><code>def build_indexes(self, filtered_tests: set[str] | None = None) -&gt; None:\n    \"\"\"Indexes tests by their tags for quick access during filtering operations.\n\n    If a `filtered_tests` set is provided, only the tests in this set will be indexed.\n\n    This method populates the tag_to_tests attribute, which is a dictionary mapping tags to sets of tests.\n\n    Once the indexes are built, the `indexes_built` attribute is set to True.\n    \"\"\"\n    for test in self.tests:\n        # Skip tests that are not in the specified filtered_tests set\n        if filtered_tests and test.test.name not in filtered_tests:\n            continue\n\n        # Indexing by tag\n        if test.inputs.filters and (test_tags := test.inputs.filters.tags):\n            for tag in test_tags:\n                self.tag_to_tests[tag].add(test)\n        else:\n            self.tag_to_tests[None].add(test)\n\n    self.indexes_built = True\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.clear_indexes","title":"clear_indexes","text":"<pre><code>clear_indexes() -&gt; None\n</code></pre> <p>Clear this AntaCatalog instance indexes.</p> Source code in <code>anta/catalog.py</code> <pre><code>def clear_indexes(self) -&gt; None:\n    \"\"\"Clear this AntaCatalog instance indexes.\"\"\"\n    self._init_indexes()\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.dump","title":"dump","text":"<pre><code>dump() -&gt; AntaCatalogFile\n</code></pre> <p>Return an AntaCatalogFile instance from this AntaCatalog instance.</p> <p>Returns:</p> Type Description <code>AntaCatalogFile</code> <p>An AntaCatalogFile instance containing tests of this AntaCatalog instance.</p> Source code in <code>anta/catalog.py</code> <pre><code>def dump(self) -&gt; AntaCatalogFile:\n    \"\"\"Return an AntaCatalogFile instance from this AntaCatalog instance.\n\n    Returns\n    -------\n    AntaCatalogFile\n        An AntaCatalogFile instance containing tests of this AntaCatalog instance.\n    \"\"\"\n    root: dict[ImportString[Any], list[AntaTestDefinition]] = {}\n    for test in self.tests:\n        # Cannot use AntaTest.module property as the class is not instantiated\n        root.setdefault(test.test.__module__, []).append(test)\n    return AntaCatalogFile(root=root)\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(\n    data: RawCatalogInput,\n    filename: str | Path | None = None,\n) -&gt; AntaCatalog\n</code></pre> <p>Create an AntaCatalog instance from a dictionary data structure.</p> <p>See RawCatalogInput type alias for details. It is the data structure returned by <code>yaml.load()</code> function of a valid YAML Test Catalog file.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>RawCatalogInput</code> <p>Python dictionary used to instantiate the AntaCatalog instance.</p> required <code>filename</code> <code>str | Path | None</code> <p>value to be set as AntaCatalog instance attribute</p> <code>None</code> <p>Returns:</p> Type Description <code>AntaCatalog</code> <p>An AntaCatalog populated with the \u2018data\u2019 dictionary content.</p> Source code in <code>anta/catalog.py</code> <pre><code>@staticmethod\ndef from_dict(data: RawCatalogInput, filename: str | Path | None = None) -&gt; AntaCatalog:\n    \"\"\"Create an AntaCatalog instance from a dictionary data structure.\n\n    See RawCatalogInput type alias for details.\n    It is the data structure returned by `yaml.load()` function of a valid\n    YAML Test Catalog file.\n\n    Parameters\n    ----------\n    data\n        Python dictionary used to instantiate the AntaCatalog instance.\n    filename\n        value to be set as AntaCatalog instance attribute\n\n    Returns\n    -------\n    AntaCatalog\n        An AntaCatalog populated with the 'data' dictionary content.\n    \"\"\"\n    tests: list[AntaTestDefinition] = []\n    if data is None:\n        logger.warning(\"Catalog input data is empty\")\n        return AntaCatalog(filename=filename)\n\n    if not isinstance(data, dict):\n        msg = f\"Wrong input type for catalog data{f' (from {filename})' if filename is not None else ''}, must be a dict, got {type(data).__name__}\"\n        raise TypeError(msg)\n\n    try:\n        catalog_data = AntaCatalogFile(data)  # type: ignore[arg-type]\n    except ValidationError as e:\n        anta_log_exception(\n            e,\n            f\"Test catalog is invalid!{f' (from {filename})' if filename is not None else ''}\",\n            logger,\n        )\n        raise\n    for t in catalog_data.root.values():\n        tests.extend(t)\n    return AntaCatalog(tests, filename=filename)\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.from_list","title":"from_list  <code>staticmethod</code>","text":"<pre><code>from_list(data: ListAntaTestTuples) -&gt; AntaCatalog\n</code></pre> <p>Create an AntaCatalog instance from a list data structure.</p> <p>See ListAntaTestTuples type alias for details.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ListAntaTestTuples</code> <p>Python list used to instantiate the AntaCatalog instance.</p> required <p>Returns:</p> Type Description <code>AntaCatalog</code> <p>An AntaCatalog populated with the \u2018data\u2019 list content.</p> Source code in <code>anta/catalog.py</code> <pre><code>@staticmethod\ndef from_list(data: ListAntaTestTuples) -&gt; AntaCatalog:\n    \"\"\"Create an AntaCatalog instance from a list data structure.\n\n    See ListAntaTestTuples type alias for details.\n\n    Parameters\n    ----------\n    data\n        Python list used to instantiate the AntaCatalog instance.\n\n    Returns\n    -------\n    AntaCatalog\n        An AntaCatalog populated with the 'data' list content.\n    \"\"\"\n    tests: list[AntaTestDefinition] = []\n    try:\n        tests.extend(AntaTestDefinition(test=test, inputs=inputs) for test, inputs in data)\n    except ValidationError as e:\n        anta_log_exception(e, \"Test catalog is invalid!\", logger)\n        raise\n    return AntaCatalog(tests)\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.get_tests_by_tags","title":"get_tests_by_tags","text":"<pre><code>get_tests_by_tags(\n    tags: set[str], *, strict: bool = False\n) -&gt; set[AntaTestDefinition]\n</code></pre> <p>Return all tests that match a given set of tags, according to the specified strictness.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>set[str]</code> <p>The tags to filter tests by. If empty, return all tests without tags.</p> required <code>strict</code> <code>bool</code> <p>If True, returns only tests that contain all specified tags (intersection). If False, returns tests that contain any of the specified tags (union).</p> <code>False</code> <p>Returns:</p> Type Description <code>set[AntaTestDefinition]</code> <p>A set of tests that match the given tags.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the indexes have not been built prior to method call.</p> Source code in <code>anta/catalog.py</code> <pre><code>def get_tests_by_tags(self, tags: set[str], *, strict: bool = False) -&gt; set[AntaTestDefinition]:\n    \"\"\"Return all tests that match a given set of tags, according to the specified strictness.\n\n    Parameters\n    ----------\n    tags\n        The tags to filter tests by. If empty, return all tests without tags.\n    strict\n        If True, returns only tests that contain all specified tags (intersection).\n        If False, returns tests that contain any of the specified tags (union).\n\n    Returns\n    -------\n    set[AntaTestDefinition]\n        A set of tests that match the given tags.\n\n    Raises\n    ------\n    ValueError\n        If the indexes have not been built prior to method call.\n    \"\"\"\n    if not self.indexes_built:\n        msg = \"Indexes have not been built yet. Call build_indexes() first.\"\n        raise ValueError(msg)\n    if not tags:\n        return self.tag_to_tests[None]\n\n    filtered_sets = [self.tag_to_tests[tag] for tag in tags if tag in self.tag_to_tests]\n    if not filtered_sets:\n        return set()\n\n    if strict:\n        return set.intersection(*filtered_sets)\n    return set.union(*filtered_sets)\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.merge","title":"merge  <code>deprecated</code>","text":"<pre><code>merge(catalog: AntaCatalog) -&gt; AntaCatalog\n</code></pre> Deprecated <p>This method is deprecated, use <code>AntaCatalogs.merge_catalogs</code> class method instead. This will be removed in ANTA v2.0.0.</p> <p>Merge two AntaCatalog instances.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>AntaCatalog</code> <p>AntaCatalog instance to merge to this instance.</p> required <p>Returns:</p> Type Description <code>AntaCatalog</code> <p>A new AntaCatalog instance containing the tests of the two instances.</p> Source code in <code>anta/catalog.py</code> <pre><code>@deprecated(\n    \"This method is deprecated, use `AntaCatalogs.merge_catalogs` class method instead. This will be removed in ANTA v2.0.0.\", category=DeprecationWarning\n)\ndef merge(self, catalog: AntaCatalog) -&gt; AntaCatalog:\n    \"\"\"Merge two AntaCatalog instances.\n\n    Parameters\n    ----------\n    catalog\n        AntaCatalog instance to merge to this instance.\n\n    Returns\n    -------\n    AntaCatalog\n        A new AntaCatalog instance containing the tests of the two instances.\n    \"\"\"\n    return self.merge_catalogs([self, catalog])\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.merge_catalogs","title":"merge_catalogs  <code>classmethod</code>","text":"<pre><code>merge_catalogs(catalogs: list[AntaCatalog]) -&gt; AntaCatalog\n</code></pre> <p>Merge multiple AntaCatalog instances.</p> <p>Parameters:</p> Name Type Description Default <code>catalogs</code> <code>list[AntaCatalog]</code> <p>A list of AntaCatalog instances to merge.</p> required <p>Returns:</p> Type Description <code>AntaCatalog</code> <p>A new AntaCatalog instance containing the tests of all the input catalogs.</p> Source code in <code>anta/catalog.py</code> <pre><code>@classmethod\ndef merge_catalogs(cls, catalogs: list[AntaCatalog]) -&gt; AntaCatalog:\n    \"\"\"Merge multiple AntaCatalog instances.\n\n    Parameters\n    ----------\n    catalogs\n        A list of AntaCatalog instances to merge.\n\n    Returns\n    -------\n    AntaCatalog\n        A new AntaCatalog instance containing the tests of all the input catalogs.\n    \"\"\"\n    combined_tests = list(chain(*(catalog.tests for catalog in catalogs)))\n    return cls(tests=combined_tests)\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalog.parse","title":"parse  <code>staticmethod</code>","text":"<pre><code>parse(\n    filename: str | Path,\n    file_format: Literal[\"yaml\", \"json\"] = \"yaml\",\n) -&gt; AntaCatalog\n</code></pre> <p>Create an AntaCatalog instance from a test catalog file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to test catalog YAML or JSON file.</p> required <code>file_format</code> <code>Literal['yaml', 'json']</code> <p>Format of the file, either \u2018yaml\u2019 or \u2018json\u2019.</p> <code>'yaml'</code> <p>Returns:</p> Type Description <code>AntaCatalog</code> <p>An AntaCatalog populated with the file content.</p> Source code in <code>anta/catalog.py</code> <pre><code>@staticmethod\ndef parse(filename: str | Path, file_format: Literal[\"yaml\", \"json\"] = \"yaml\") -&gt; AntaCatalog:\n    \"\"\"Create an AntaCatalog instance from a test catalog file.\n\n    Parameters\n    ----------\n    filename\n        Path to test catalog YAML or JSON file.\n    file_format\n        Format of the file, either 'yaml' or 'json'.\n\n    Returns\n    -------\n    AntaCatalog\n        An AntaCatalog populated with the file content.\n    \"\"\"\n    if file_format not in [\"yaml\", \"json\"]:\n        message = f\"'{file_format}' is not a valid format for an AntaCatalog file. Only 'yaml' and 'json' are supported.\"\n        raise ValueError(message)\n\n    try:\n        file: Path = filename if isinstance(filename, Path) else Path(filename)\n        with file.open(encoding=\"UTF-8\") as f:\n            data = safe_load(f) if file_format == \"yaml\" else json_load(f)\n    except (TypeError, YAMLError, OSError, ValueError) as e:\n        message = f\"Unable to parse ANTA Test Catalog file '{filename}'\"\n        anta_log_exception(e, message, logger)\n        raise\n\n    return AntaCatalog.from_dict(data, filename=filename)\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaTestDefinition","title":"AntaTestDefinition","text":"<pre><code>AntaTestDefinition(\n    **data: type[AntaTest] | Input | dict[str, Any] | None,\n)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Define a test with its associated inputs.</p> <p>Attributes:</p> Name Type Description <code>test</code> <code>type[AntaTest]</code> <p>An AntaTest concrete subclass.</p> <code>inputs</code> <code>Input</code> <p>The associated AntaTest.Input subclass instance.</p> <p>https://docs.pydantic.dev/2.0/usage/validators/#using-validation-context-with-basemodel-initialization.</p>"},{"location":"api/catalog/#anta.catalog.AntaTestDefinition.check_inputs","title":"check_inputs","text":"<pre><code>check_inputs() -&gt; Self\n</code></pre> <p>Check the <code>inputs</code> field typing.</p> <p>The <code>inputs</code> class attribute needs to be an instance of the AntaTest.Input subclass defined in the class <code>test</code>.</p> Source code in <code>anta/catalog.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_inputs(self) -&gt; Self:\n    \"\"\"Check the `inputs` field typing.\n\n    The `inputs` class attribute needs to be an instance of the AntaTest.Input subclass defined in the class `test`.\n    \"\"\"\n    if not isinstance(self.inputs, self.test.Input):\n        msg = f\"Test input has type {self.inputs.__class__.__qualname__} but expected type {self.test.Input.__qualname__}\"\n        raise ValueError(msg)  # noqa: TRY004 pydantic catches ValueError or AssertionError, no TypeError\n    return self\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaTestDefinition.instantiate_inputs","title":"instantiate_inputs  <code>classmethod</code>","text":"<pre><code>instantiate_inputs(\n    data: Input | dict[str, Any] | None,\n    info: ValidationInfo,\n) -&gt; Input\n</code></pre> <p>Ensure the test inputs can be instantiated and thus are valid.</p> <p>If the test has no inputs, allow the user to omit providing the <code>inputs</code> field. If the test has inputs, allow the user to provide a valid dictionary of the input fields. This model validator will instantiate an Input class from the <code>test</code> class field.</p> Source code in <code>anta/catalog.py</code> <pre><code>@field_validator(\"inputs\", mode=\"before\")\n@classmethod\ndef instantiate_inputs(\n    cls: type[AntaTestDefinition],\n    data: AntaTest.Input | dict[str, Any] | None,\n    info: ValidationInfo,\n) -&gt; AntaTest.Input:\n    \"\"\"Ensure the test inputs can be instantiated and thus are valid.\n\n    If the test has no inputs, allow the user to omit providing the `inputs` field.\n    If the test has inputs, allow the user to provide a valid dictionary of the input fields.\n    This model validator will instantiate an Input class from the `test` class field.\n    \"\"\"\n    if info.context is None:\n        msg = \"Could not validate inputs as no test class could be identified\"\n        raise ValueError(msg)\n    # Pydantic guarantees at this stage that test_class is a subclass of AntaTest because of the ordering\n    # of fields in the class definition - so no need to check for this\n    test_class = info.context[\"test\"]\n    if not (isclass(test_class) and issubclass(test_class, AntaTest)):\n        msg = f\"Could not validate inputs as no test class {test_class} is not a subclass of AntaTest\"\n        raise ValueError(msg)\n\n    if isinstance(data, AntaTest.Input):\n        return data\n    try:\n        if data is None:\n            return test_class.Input()\n        if isinstance(data, dict):\n            return test_class.Input(**data)\n    except ValidationError as e:\n        inputs_msg = str(e).replace(\"\\n\", \"\\n\\t\")\n        err_type = \"wrong_test_inputs\"\n        raise PydanticCustomError(\n            err_type,\n            f\"{test_class.name} test inputs are not valid: {inputs_msg}\\n\",\n            {\"errors\": e.errors()},\n        ) from e\n    msg = f\"Could not instantiate inputs as type {type(data).__name__} is not valid\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaTestDefinition.serialize_model","title":"serialize_model","text":"<pre><code>serialize_model() -&gt; dict[str, Input]\n</code></pre> <p>Serialize the AntaTestDefinition model.</p> <p>The dictionary representing the model will be look like: <pre><code>&lt;AntaTest subclass name&gt;:\n        &lt;AntaTest.Input compliant dictionary&gt;\n</code></pre></p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary representing the model.</p> Source code in <code>anta/catalog.py</code> <pre><code>@model_serializer()\ndef serialize_model(self) -&gt; dict[str, AntaTest.Input]:\n    \"\"\"Serialize the AntaTestDefinition model.\n\n    The dictionary representing the model will be look like:\n    ```\n    &lt;AntaTest subclass name&gt;:\n            &lt;AntaTest.Input compliant dictionary&gt;\n    ```\n\n    Returns\n    -------\n    dict\n        A dictionary representing the model.\n    \"\"\"\n    return {self.test.__name__: self.inputs}\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalogFile","title":"AntaCatalogFile","text":"<p>               Bases: <code>RootModel[dict[ImportString[Any], list[AntaTestDefinition]]]</code></p> <p>Represents an ANTA Test Catalog File.</p> Example <p>A valid test catalog file must have the following structure: <pre><code>&lt;Python module&gt;:\n    - &lt;AntaTest subclass&gt;:\n        &lt;AntaTest.Input compliant dictionary&gt;\n</code></pre></p>"},{"location":"api/catalog/#anta.catalog.AntaCatalogFile.check_tests","title":"check_tests  <code>classmethod</code>","text":"<pre><code>check_tests(data: Any) -&gt; Any\n</code></pre> <p>Allow the user to provide a Python data structure that only has string values.</p> <p>This validator will try to flatten and import Python modules, check if the tests classes are actually defined in their respective Python module and instantiate Input instances with provided value to validate test inputs.</p> Source code in <code>anta/catalog.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_tests(cls: type[AntaCatalogFile], data: Any) -&gt; Any:  # noqa: ANN401\n    \"\"\"Allow the user to provide a Python data structure that only has string values.\n\n    This validator will try to flatten and import Python modules, check if the tests classes\n    are actually defined in their respective Python module and instantiate Input instances\n    with provided value to validate test inputs.\n    \"\"\"\n    if isinstance(data, dict):\n        if not data:\n            return data\n        typed_data: dict[ModuleType, list[Any]] = AntaCatalogFile.flatten_modules(data)\n        for module, tests in typed_data.items():\n            test_definitions: list[AntaTestDefinition] = []\n            for test_definition in tests:\n                if isinstance(test_definition, AntaTestDefinition):\n                    test_definitions.append(test_definition)\n                    continue\n                if not isinstance(test_definition, dict):\n                    msg = f\"Syntax error when parsing: {test_definition}\\nIt must be a dictionary. Check the test catalog.\"\n                    raise ValueError(msg)  # noqa: TRY004 pydantic catches ValueError or AssertionError, no TypeError\n                if len(test_definition) != 1:\n                    msg = (\n                        f\"Syntax error when parsing: {test_definition}\\nIt must be a dictionary with a single entry. Check the indentation in the test catalog.\"\n                    )\n                    raise ValueError(msg)\n                for test_name, test_inputs in test_definition.copy().items():\n                    test: type[AntaTest] | None = getattr(module, test_name, None)\n                    if test is None:\n                        msg = (\n                            f\"{test_name} is not defined in Python module {module.__name__}{f' (from {module.__file__})' if module.__file__ is not None else ''}\"\n                        )\n                        raise ValueError(msg)\n                    test_definitions.append(AntaTestDefinition(test=test, inputs=test_inputs))\n            typed_data[module] = test_definitions\n        return typed_data\n    return data\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalogFile.flatten_modules","title":"flatten_modules  <code>staticmethod</code>","text":"<pre><code>flatten_modules(\n    data: dict[str, Any], package: str | None = None\n) -&gt; dict[ModuleType, list[Any]]\n</code></pre> <p>Allow the user to provide a data structure with nested Python modules.</p> Example <p><pre><code>anta.tests.routing:\n  generic:\n    - &lt;AntaTestDefinition&gt;\n  bgp:\n    - &lt;AntaTestDefinition&gt;\n</code></pre> <code>anta.tests.routing.generic</code> and <code>anta.tests.routing.bgp</code> are importable Python modules.</p> Source code in <code>anta/catalog.py</code> <pre><code>@staticmethod\ndef flatten_modules(data: dict[str, Any], package: str | None = None) -&gt; dict[ModuleType, list[Any]]:\n    \"\"\"Allow the user to provide a data structure with nested Python modules.\n\n    Example\n    -------\n    ```\n    anta.tests.routing:\n      generic:\n        - &lt;AntaTestDefinition&gt;\n      bgp:\n        - &lt;AntaTestDefinition&gt;\n    ```\n    `anta.tests.routing.generic` and `anta.tests.routing.bgp` are importable Python modules.\n\n    \"\"\"\n    modules: dict[ModuleType, list[Any]] = {}\n    for module_name, tests in data.items():\n        if package and not module_name.startswith(\".\"):\n            # PLW2901 - we redefine the loop variable on purpose here.\n            module_name = f\".{module_name}\"  # noqa: PLW2901\n        try:\n            module: ModuleType = importlib.import_module(name=module_name, package=package)\n        except Exception as e:\n            # A test module is potentially user-defined code.\n            # We need to catch everything if we want to have meaningful logs\n            module_str = f\"{module_name.removeprefix('.')}{f' from package {package}' if package else ''}\"\n            message = f\"Module named {module_str} cannot be imported. Verify that the module exists and there is no Python syntax issues.\"\n            anta_log_exception(e, message, logger)\n            raise ValueError(message) from e\n        if isinstance(tests, dict):\n            # This is an inner Python module\n            modules.update(AntaCatalogFile.flatten_modules(data=tests, package=module.__name__))\n        elif isinstance(tests, list):\n            # This is a list of AntaTestDefinition\n            modules[module] = tests\n        else:\n            msg = f\"Syntax error when parsing: {tests}\\nIt must be a list of ANTA tests. Check the test catalog.\"\n            raise ValueError(msg)  # noqa: TRY004 pydantic catches ValueError or AssertionError, no TypeError\n    return modules\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalogFile.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Return a JSON representation string of this model.</p> <p>Returns:</p> Type Description <code>str</code> <p>The JSON representation string of this model.</p> Source code in <code>anta/catalog.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Return a JSON representation string of this model.\n\n    Returns\n    -------\n    str\n        The JSON representation string of this model.\n    \"\"\"\n    return self.model_dump_json(serialize_as_any=True, exclude_unset=True, indent=2)\n</code></pre>"},{"location":"api/catalog/#anta.catalog.AntaCatalogFile.yaml","title":"yaml","text":"<pre><code>yaml() -&gt; str\n</code></pre> <p>Return a YAML representation string of this model.</p> <p>Returns:</p> Type Description <code>str</code> <p>The YAML representation string of this model.</p> Source code in <code>anta/catalog.py</code> <pre><code>def yaml(self) -&gt; str:\n    \"\"\"Return a YAML representation string of this model.\n\n    Returns\n    -------\n    str\n        The YAML representation string of this model.\n    \"\"\"\n    # TODO: Pydantic and YAML serialization/deserialization is not supported natively.\n    # This could be improved.\n    # https://github.com/pydantic/pydantic/issues/1043\n    # Explore if this worth using this: https://github.com/NowanIlfideme/pydantic-yaml\n    return safe_dump(safe_load(self.model_dump_json(serialize_as_any=True, exclude_unset=True)), width=math.inf)\n</code></pre>"},{"location":"api/class-diagram/","title":"Class Diagram","text":"<p>Info</p> <p>The classes colored in pink  are  pydantic models.</p> <pre><code>classDiagram\n  class AntaDevice {\n    &lt;&lt;Abstract&gt;&gt;\n    name : str\n    tags : Optional[set[str]]\n    hw_model : str | None\n    established : bool\n    is_online : bool\n    cache_statistics : dict[str, Any]\n    collect(command: AntaCommand) None\n    collect_commands(commands: list[AntaCommand]) None\n    copy(sources: list[Path], destination: Path, direction: Literal['to', 'from']) None\n    refresh()* None\n    _collect(command: AntaCommand)* None\n  }\n  class AntaTest {\n    &lt;&lt;Abstract&gt;&gt;\n    name : str$\n    description : str$\n    categories : list[str]$\n    commands : list[AntaTemplate | AntaCommand]$\n    device : AntaDevice\n    inputs : Input\n    result : TestResult\n    instance_commands : list[AntaCommand]\n    failed_commands : list[AntaCommand]\n    collected : bool\n    blocked : bool\n    module : str\n    logger : Logger\n    anta_test(function: F) Callable[..., Coroutine[Any, Any, TestResult]]$\n    save_commands_data(eos_data: list[dict[str, Any] | str]) None\n    render(template: AntaTemplate) list[AntaCommand]\n    test() None*\n  }\n  class AntaCommand:::pydantic {\n    command : str\n    version : Literal[1, 'latest']\n    revision : Revision | None\n    ofmt : Literal['json', 'text']\n    output : dict[str, Any] | str | None\n    json_output : dict[str, Any]\n    text_output : str\n    uid : str\n    template : AntaTemplate | None\n    params : AntaParamsBaseModel\n    errors : list[str]\n    error : bool\n    use_cache : bool\n    collected : bool\n    requires_privileges : bool\n    returned_known_eos_error : bool\n    supported : bool\n  }\n  class AntaTemplate {\n    template : str\n    version : Literal[1, 'latest']\n    revision : Revision | None\n    ofmt : Literal['json', 'text']\n    use_cache : bool\n    render() AntaCommand\n  }\n  class AntaTestStatus {\n    &lt;&lt;Enumeration&gt;&gt;\n    UNSET\n    SUCCESS\n    FAILURE\n    ERROR\n    SKIPPED\n  }\n  class Input:::pydantic {\n    filters : Filters | None\n    result_overwrite : ResultOverwrite | None\n  }\n  class ResultManager {\n    results : list[TestResult]\n    status: AntaTestStatus\n    error_status : bool\n    results_by_status: dict[AntaTestStatus, list[TestResult]]\n    sorted_category_stats: dict[str, CategoryStats]\n    dump: list[dict[str, Any]]\n    json : str\n    test_stats: dict[str, TestStats]\n    device_stats: dict[str, DeviceStats]\n    category_stats: dict[str, CategoryStats]\n    add(result: TestResult) None\n    filter(hide: set[AntaTestStatus]) ResultManager\n    filter_by_devices(devices: set[str]) ResultManager\n    filter_by_tests(tests: set[str]) ResultManager\n    get_results(status: set[AntaTestStatus] | None, sort_by: list[str] | None) list[TestResult]\n    get_total_results(status: set[AntaTestStatus] | None) int\n    get_status() str\n    get_tests() set[str]\n    get_devices() set[str]\n    reset() None\n  }\n  class AsyncEOSDevice {\n    enable : bool\n    copy(sources: list[Path], destination: Path, direction: Literal['to', 'from']) None\n    refresh() None\n    _collect(command: AntaCommand) None\n  }\n  class TestResult:::pydantic {\n    name : str\n    test : str\n    categories : list[str]\n    description : str\n    messages : list[str]\n    result : AntaTestStatus\n    custom_field : str | None\n    is_error(message: str | None) None\n    is_failure(message: str | None) None\n    is_skipped(message: str | None) None\n    is_success(message: str | None) None\n  }\nclass AntaCatalog {\n    tests : list[AntaTestDefinition]\n    filename: Path | None\n    indexes_built : bool\n    tag_to_tests : defaultdict[str | None, set[AntaTestDefinition]]\n    parse(filename: str | Path, file_format: Literal['yaml', 'json']) AntaCatalog$\n    from_dict(data: RawCatalogInput, filename: str | Path | None) AntaCatalog$\n    from_list(data: ListAntaTestTuples) AntaCatalog$\n    build_indexes(filtered_tests: set[str] | None) None\n    clear_indexes() None\n    get_tests_by_tags(tags: set[str]) set[AntaTestDefinition]\n    merge_catalogs(catalogs: list[AntaCatalog]) AntaCatalog\n    dump() AntaCatalogFile\n  }\n  class AntaCatalogFile:::pydantic {\n    root : dict[ImportString[Any], list[AntaTestDefinition]]\n    yaml() str\n  }\n  class AntaTestDefinition:::pydantic {\n    inputs : Input\n    test : type[AntaTest]\n    check_inputs() Self\n    instantiate_inputs(data: AntaTest.Input | dict[str, Any] | None, info: ValidationInfo) AntaTest.Input\n    serialize_model() dict[str, AntaTest.Input]\n  }\n  class AntaInventory {\n    devices : list[AntaDevice]\n    parse(filename: str | Path, username: str, password: str, enable_password: str | None, timeout: float | None) AntaInventory$\n    add_device(device: AntaDevice) None\n    connect_inventory() None\n    get_inventory() AntaInventory\n  }\n  class AntaInventoryHost:::pydantic {\n    disable_cache : bool\n    host : Hostname | IPvAnyAddress\n    name : str | None\n    port : Port | None\n    tags : set[str] | None\n  }\n  class AntaInventoryInput:::pydantic {\n    hosts : list[AntaInventoryHost] | None\n    networks : list[AntaInventoryNetwork] | None\n    ranges : list[AntaInventoryRange] | None\n    yaml() str\n  }\n  class AntaInventoryNetwork:::pydantic {\n    disable_cache : bool\n    network : IPvAnyNetwork, str\n    tags : set[str] | None\n  }\n  class AntaInventoryRange:::pydantic {\n    disable_cache : bool\n    end : IPvAnyAddress, str\n    start : IPvAnyAddress, str\n    tags : set[str] | None\n  }\n  AsyncEOSDevice --|&gt; AntaDevice\n  Input --* AntaTestDefinition : inputs\n  Input --* AntaTest : inputs\n  AntaTestStatus --* ResultManager : status\n  AntaTestStatus --* TestResult : result\n  TestResult --* AntaTest : result\n  AntaDevice --o AntaTest : device\n  AntaTestDefinition --o AntaCatalog : tests\n  AntaCommand --o AntaTest : commands\n  AntaTemplate ..&gt; AntaCommand : render()\n  AntaTemplate --o AntaTest : commands\n  AntaDevice --o AntaInventory : devices\n  AntaCatalog ..&gt; AntaCatalogFile\n  AntaInventory ..&gt; AntaInventoryInput\n  AntaInventoryInput ..&gt; AntaInventoryHost\n  AntaInventoryInput ..&gt; AntaInventoryNetwork\n  AntaInventoryInput ..&gt; AntaInventoryRange\n  classDef pydantic fill:#D63965\n</code></pre>"},{"location":"api/commands/","title":"Commands","text":""},{"location":"api/commands/#anta.models.AntaCommand","title":"AntaCommand","text":"<p>               Bases: <code>BaseModel</code></p> <p>Class to define a command.</p> <p>Info</p> <p>eAPI models are revisioned, this means that if a model is modified in a non-backwards compatible way, then its revision will be bumped up (revisions are numbers, default value is 1).</p> <p>By default an eAPI request will return revision 1 of the model instance, this ensures that older management software will not suddenly stop working when a switch is upgraded. A revision applies to a particular CLI command whereas a version is global and is internally translated to a specific revision for each CLI command in the RPC.</p> <p>Revision has precedence over version.</p> <p>Attributes:</p> Name Type Description <code>command</code> <code>str</code> <p>Device command.</p> <code>version</code> <code>Literal[1, 'latest']</code> <p>eAPI version - valid values are 1 or \u201clatest\u201d.</p> <code>revision</code> <code>Revision | None</code> <p>eAPI revision of the command. Valid values are 1 to 99. Revision has precedence over version.</p> <code>ofmt</code> <code>Literal['json', 'text']</code> <p>eAPI output - json or text.</p> <code>output</code> <code>dict[str, Any] | str | None</code> <p>Output of the command. Only defined if there was no errors.</p> <code>template</code> <code>AntaTemplate | None</code> <p>AntaTemplate object used to render this command.</p> <code>errors</code> <code>list[str]</code> <p>If the command execution fails, eAPI returns a list of strings detailing the error(s).</p> <code>params</code> <code>AntaParamsBaseModel</code> <p>Pydantic Model containing the variables values used to render the template.</p> <code>use_cache</code> <code>bool</code> <p>Enable or disable caching for this AntaCommand if the AntaDevice supports it.</p>"},{"location":"api/commands/#anta.models.AntaCommand.collected","title":"collected  <code>property</code>","text":"<pre><code>collected: bool\n</code></pre> <p>Return True if the command has been collected, False otherwise.</p> <p>A command that has not been collected could have returned an error. See error property.</p>"},{"location":"api/commands/#anta.models.AntaCommand.error","title":"error  <code>property</code>","text":"<pre><code>error: bool\n</code></pre> <p>Return True if the command returned an error, False otherwise.</p>"},{"location":"api/commands/#anta.models.AntaCommand.json_output","title":"json_output  <code>property</code>","text":"<pre><code>json_output: dict[str, Any]\n</code></pre> <p>Get the command output as JSON.</p>"},{"location":"api/commands/#anta.models.AntaCommand.requires_privileges","title":"requires_privileges  <code>property</code>","text":"<pre><code>requires_privileges: bool\n</code></pre> <p>Return True if the command requires privileged mode, False otherwise.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the command has not been collected and has not returned an error. AntaDevice.collect() must be called before this property.</p>"},{"location":"api/commands/#anta.models.AntaCommand.returned_known_eos_error","title":"returned_known_eos_error  <code>property</code>","text":"<pre><code>returned_known_eos_error: bool\n</code></pre> <p>Return True if the command returned a known_eos_error on the device, False otherwise.</p> <p>RuntimeError     If the command has not been collected and has not returned an error.     AntaDevice.collect() must be called before this property.</p>"},{"location":"api/commands/#anta.models.AntaCommand.supported","title":"supported  <code>property</code>","text":"<pre><code>supported: bool\n</code></pre> <p>Indicates if the command is supported on the device.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the command is supported on the device hardware platform, False otherwise.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the command has not been collected and has not returned an error. AntaDevice.collect() must be called before this property.</p>"},{"location":"api/commands/#anta.models.AntaCommand.text_output","title":"text_output  <code>property</code>","text":"<pre><code>text_output: str\n</code></pre> <p>Get the command output as a string.</p>"},{"location":"api/commands/#anta.models.AntaCommand.uid","title":"uid  <code>property</code>","text":"<pre><code>uid: str\n</code></pre> <p>Generate a unique identifier for this command.</p>"},{"location":"api/commands/#anta.models.AntaTemplate","title":"AntaTemplate","text":"<pre><code>AntaTemplate(\n    template: str,\n    version: Literal[1, \"latest\"] = \"latest\",\n    revision: Revision | None = None,\n    ofmt: Literal[\"json\", \"text\"] = \"json\",\n    *,\n    use_cache: bool = True\n)\n</code></pre> <p>Class to define a command template as Python f-string.</p> <p>Can render a command from parameters.</p> <p>Attributes:</p> Name Type Description <code>template</code> <p>Python f-string. Example: \u2018show vlan {vlan_id}\u2019.</p> <code>version</code> <p>eAPI version - valid values are 1 or \u201clatest\u201d.</p> <code>revision</code> <p>Revision of the command. Valid values are 1 to 99. Revision has precedence over version.</p> <code>ofmt</code> <p>eAPI output - json or text.</p> <code>use_cache</code> <p>Enable or disable caching for this AntaTemplate if the AntaDevice supports it.</p>"},{"location":"api/commands/#anta.models.AntaTemplate.render","title":"render","text":"<pre><code>render(**params: str | int | bool) -&gt; AntaCommand\n</code></pre> <p>Render an AntaCommand from an AntaTemplate instance.</p> <p>Keep the parameters used in the AntaTemplate instance.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>str | int | bool</code> <p>Dictionary of variables with string values to render the Python f-string.</p> <code>{}</code> <p>Returns:</p> Type Description <code>AntaCommand</code> <p>The rendered AntaCommand. This AntaCommand instance have a template attribute that references this AntaTemplate instance.</p> <p>Raises:</p> Type Description <code>AntaTemplateRenderError</code> <p>If a parameter is missing to render the AntaTemplate instance.</p> Source code in <code>anta/models.py</code> <pre><code>def render(self, **params: str | int | bool) -&gt; AntaCommand:\n    \"\"\"Render an AntaCommand from an AntaTemplate instance.\n\n    Keep the parameters used in the AntaTemplate instance.\n\n    Parameters\n    ----------\n    params\n        Dictionary of variables with string values to render the Python f-string.\n\n    Returns\n    -------\n    AntaCommand\n        The rendered AntaCommand.\n        This AntaCommand instance have a template attribute that references this\n        AntaTemplate instance.\n\n    Raises\n    ------\n    AntaTemplateRenderError\n        If a parameter is missing to render the AntaTemplate instance.\n    \"\"\"\n    try:\n        command = self.template.format(**params)\n    except (KeyError, SyntaxError) as e:\n        raise AntaTemplateRenderError(self, e.args[0]) from e\n    return AntaCommand(\n        command=command,\n        ofmt=self.ofmt,\n        version=self.version,\n        revision=self.revision,\n        template=self,\n        params=self.params_schema(**params),\n        use_cache=self.use_cache,\n    )\n</code></pre>"},{"location":"api/commands/#eos-commands-error-handling","title":"EOS Commands Error Handling","text":"UNSUPPORTED_PLATFORM_ERRORS \u00b6 <pre><code>UNSUPPORTED_PLATFORM_ERRORS = [\n    \"not supported on this hardware platform\",\n    \"Invalid input (at token 2: 'trident')\",\n]\n</code></pre> <p>Error messages indicating platform or hardware unsupported commands. Includes both general hardware platform errors and specific ASIC family limitations.</p> <p>Running EOS commands unsupported by hardware</p> <p>When catching these errors, ANTA will skip the affected test and raise a warning. The test catalog must be updated to remove execution of the affected test on unsupported devices.</p> <code></code> EOS_BLACKLIST_CMDS \u00b6 <pre><code>EOS_BLACKLIST_CMDS = ['^reload.*', '^conf.*', '^wr.*']\n</code></pre> <p>List of blacklisted EOS commands.</p> <p>Disruptive commands safeguard</p> <p>ANTA implements a mechanism to prevent the execution of disruptive commands such as <code>reload</code>, <code>write erase</code> or <code>configure terminal</code>.</p> <code></code> KNOWN_EOS_ERRORS \u00b6 <pre><code>KNOWN_EOS_ERRORS = [\n    \"BGP inactive\",\n    \"VRF '.*' is not active\",\n    \".* does not support IP\",\n    \"IS-IS (.*) is disabled because: .*\",\n    \"No source interface .*\",\n    \".*controller\\\\snot\\\\sready.*\",\n]\n</code></pre> <p>List of known EOS errors.</p> <p>Generic EOS Error Handling</p> <p>When catching these errors, ANTA will fail the affected test and reported the error message.</p>"},{"location":"api/device/","title":"Device","text":""},{"location":"api/device/#anta.device.AntaDevice","title":"AntaDevice","text":"<pre><code>AntaDevice(\n    name: str,\n    tags: set[str] | None = None,\n    *,\n    disable_cache: bool = False\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract class representing a device in ANTA.</p> <p>An implementation of this class must override the abstract coroutines <code>_collect()</code> and <code>refresh()</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Device name.</p> <code>is_online</code> <code>bool</code> <p>True if the device IP is reachable and a port can be open.</p> <code>established</code> <code>bool</code> <p>True if remote command execution succeeds.</p> <code>hw_model</code> <code>str</code> <p>Hardware model of the device.</p> <code>tags</code> <code>set[str]</code> <p>Tags for this device.</p> <code>cache</code> <code>AntaCache | None</code> <p>In-memory cache for this device (None if cache is disabled).</p> <code>cache_locks</code> <code>dict</code> <p>Dictionary mapping keys to asyncio locks to guarantee exclusive access to the cache if not disabled. Deprecated, will be removed in ANTA v2.0.0, use self.cache.locks instead.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Device name.</p> required <code>tags</code> <code>set[str] | None</code> <p>Tags for this device.</p> <code>None</code> <code>disable_cache</code> <code>bool</code> <p>Disable caching for all commands for this device.</p> <code>False</code>"},{"location":"api/device/#anta.device.AntaDevice.cache_statistics","title":"cache_statistics  <code>property</code>","text":"<pre><code>cache_statistics: dict[str, Any] | None\n</code></pre> <p>Return the device cache statistics for logging purposes.</p>"},{"location":"api/device/#anta.device.AntaDevice._collect","title":"_collect  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>_collect(\n    command: AntaCommand,\n    *,\n    collection_id: str | None = None\n) -&gt; None\n</code></pre> <p>Collect device command output.</p> <p>This abstract coroutine can be used to implement any command collection method for a device in ANTA.</p> <p>The <code>_collect()</code> implementation needs to populate the <code>output</code> attribute of the <code>AntaCommand</code> object passed as argument.</p> <p>If a failure occurs, the <code>_collect()</code> implementation is expected to catch the exception and implement proper logging, the <code>output</code> attribute of the <code>AntaCommand</code> object passed as argument would be <code>None</code> in this case.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>AntaCommand</code> <p>The command to collect.</p> required <code>collection_id</code> <code>str | None</code> <p>An identifier used to build the eAPI request ID.</p> <code>None</code> Source code in <code>anta/device.py</code> <pre><code>@abstractmethod\nasync def _collect(self, command: AntaCommand, *, collection_id: str | None = None) -&gt; None:\n    \"\"\"Collect device command output.\n\n    This abstract coroutine can be used to implement any command collection method\n    for a device in ANTA.\n\n    The `_collect()` implementation needs to populate the `output` attribute\n    of the `AntaCommand` object passed as argument.\n\n    If a failure occurs, the `_collect()` implementation is expected to catch the\n    exception and implement proper logging, the `output` attribute of the\n    `AntaCommand` object passed as argument would be `None` in this case.\n\n    Parameters\n    ----------\n    command\n        The command to collect.\n    collection_id\n        An identifier used to build the eAPI request ID.\n    \"\"\"\n</code></pre>"},{"location":"api/device/#anta.device.AntaDevice.collect","title":"collect  <code>async</code>","text":"<pre><code>collect(\n    command: AntaCommand,\n    *,\n    collection_id: str | None = None\n) -&gt; None\n</code></pre> <p>Collect the output for a specified command.</p> <p>When caching is activated on both the device and the command, this method prioritizes retrieving the output from the cache. In cases where the output isn\u2019t cached yet, it will be freshly collected and then stored in the cache for future access. The method employs asynchronous locks based on the command\u2019s UID to guarantee exclusive access to the cache.</p> <p>When caching is NOT enabled, either at the device or command level, the method directly collects the output via the private <code>_collect</code> method without interacting with the cache.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>AntaCommand</code> <p>The command to collect.</p> required <code>collection_id</code> <code>str | None</code> <p>An identifier used to build the eAPI request ID.</p> <code>None</code> Source code in <code>anta/device.py</code> <pre><code>async def collect(self, command: AntaCommand, *, collection_id: str | None = None) -&gt; None:\n    \"\"\"Collect the output for a specified command.\n\n    When caching is activated on both the device and the command,\n    this method prioritizes retrieving the output from the cache. In cases where the output isn't cached yet,\n    it will be freshly collected and then stored in the cache for future access.\n    The method employs asynchronous locks based on the command's UID to guarantee exclusive access to the cache.\n\n    When caching is NOT enabled, either at the device or command level, the method directly collects the output\n    via the private `_collect` method without interacting with the cache.\n\n    Parameters\n    ----------\n    command\n        The command to collect.\n    collection_id\n        An identifier used to build the eAPI request ID.\n    \"\"\"\n    if self.cache is not None and command.use_cache:\n        async with self.cache.locks[command.uid]:\n            cached_output = await self.cache.get(command.uid)\n\n            if cached_output is not None:\n                logger.debug(\"Cache hit for %s on %s\", command.command, self.name)\n                command.output = cached_output\n            else:\n                await self._collect(command=command, collection_id=collection_id)\n                await self.cache.set(command.uid, command.output)\n    else:\n        await self._collect(command=command, collection_id=collection_id)\n</code></pre>"},{"location":"api/device/#anta.device.AntaDevice.collect_commands","title":"collect_commands  <code>async</code>","text":"<pre><code>collect_commands(\n    commands: list[AntaCommand],\n    *,\n    collection_id: str | None = None\n) -&gt; None\n</code></pre> <p>Collect multiple commands.</p> <p>Parameters:</p> Name Type Description Default <code>commands</code> <code>list[AntaCommand]</code> <p>The commands to collect.</p> required <code>collection_id</code> <code>str | None</code> <p>An identifier used to build the eAPI request ID.</p> <code>None</code> Source code in <code>anta/device.py</code> <pre><code>async def collect_commands(self, commands: list[AntaCommand], *, collection_id: str | None = None) -&gt; None:\n    \"\"\"Collect multiple commands.\n\n    Parameters\n    ----------\n    commands\n        The commands to collect.\n    collection_id\n        An identifier used to build the eAPI request ID.\n    \"\"\"\n    await asyncio.gather(*(self.collect(command=command, collection_id=collection_id) for command in commands))\n</code></pre>"},{"location":"api/device/#anta.device.AntaDevice.copy","title":"copy  <code>async</code>","text":"<pre><code>copy(\n    sources: list[Path],\n    destination: Path,\n    direction: Literal[\"to\", \"from\"] = \"from\",\n) -&gt; None\n</code></pre> <p>Copy files to and from the device, usually through SCP.</p> <p>It is not mandatory to implement this for a valid AntaDevice subclass.</p> <p>Parameters:</p> Name Type Description Default <code>sources</code> <code>list[Path]</code> <p>List of files to copy to or from the device.</p> required <code>destination</code> <code>Path</code> <p>Local or remote destination when copying the files. Can be a folder.</p> required <code>direction</code> <code>Literal['to', 'from']</code> <p>Defines if this coroutine copies files to or from the device.</p> <code>'from'</code> Source code in <code>anta/device.py</code> <pre><code>async def copy(self, sources: list[Path], destination: Path, direction: Literal[\"to\", \"from\"] = \"from\") -&gt; None:\n    \"\"\"Copy files to and from the device, usually through SCP.\n\n    It is not mandatory to implement this for a valid AntaDevice subclass.\n\n    Parameters\n    ----------\n    sources\n        List of files to copy to or from the device.\n    destination\n        Local or remote destination when copying the files. Can be a folder.\n    direction\n        Defines if this coroutine copies files to or from the device.\n\n    \"\"\"\n    _ = (sources, destination, direction)\n    msg = f\"copy() method has not been implemented in {self.__class__.__name__} definition\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/device/#anta.device.AntaDevice.refresh","title":"refresh  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>refresh() -&gt; None\n</code></pre> <p>Update attributes of an AntaDevice instance.</p> <p>This coroutine must update the following attributes of AntaDevice:</p> <ul> <li> <p><code>is_online</code>: When the device IP is reachable and a port can be open.</p> </li> <li> <p><code>established</code>: When a command execution succeeds.</p> </li> <li> <p><code>hw_model</code>: The hardware model of the device.</p> </li> </ul> Source code in <code>anta/device.py</code> <pre><code>@abstractmethod\nasync def refresh(self) -&gt; None:\n    \"\"\"Update attributes of an AntaDevice instance.\n\n    This coroutine must update the following attributes of AntaDevice:\n\n    - `is_online`: When the device IP is reachable and a port can be open.\n\n    - `established`: When a command execution succeeds.\n\n    - `hw_model`: The hardware model of the device.\n    \"\"\"\n</code></pre>"},{"location":"api/device/#anta.device.AsyncEOSDevice","title":"AsyncEOSDevice","text":"<pre><code>AsyncEOSDevice(\n    host: str,\n    username: str,\n    password: str,\n    name: str | None = None,\n    enable_password: str | None = None,\n    port: int | None = None,\n    ssh_port: int | None = 22,\n    tags: set[str] | None = None,\n    timeout: float | None = None,\n    proto: Literal[\"http\", \"https\"] = \"https\",\n    *,\n    enable: bool = False,\n    insecure: bool = False,\n    disable_cache: bool = False\n)\n</code></pre> <p>               Bases: <code>AntaDevice</code></p> <p>Implementation of AntaDevice for EOS using aio-eapi.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Device name.</p> <code>is_online</code> <code>bool</code> <p>True if the device IP is reachable and a port can be open.</p> <code>established</code> <code>bool</code> <p>True if remote command execution succeeds.</p> <code>hw_model</code> <code>str</code> <p>Hardware model of the device.</p> <code>tags</code> <code>set[str]</code> <p>Tags for this device.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Device FQDN or IP.</p> required <code>username</code> <code>str</code> <p>Username to connect to eAPI and SSH.</p> required <code>password</code> <code>str</code> <p>Password to connect to eAPI and SSH.</p> required <code>name</code> <code>str | None</code> <p>Device name.</p> <code>None</code> <code>enable</code> <code>bool</code> <p>Collect commands using privileged mode.</p> <code>False</code> <code>enable_password</code> <code>str | None</code> <p>Password used to gain privileged access on EOS.</p> <code>None</code> <code>port</code> <code>int | None</code> <p>eAPI port. Defaults to 80 is proto is \u2018http\u2019 or 443 if proto is \u2018https\u2019.</p> <code>None</code> <code>ssh_port</code> <code>int | None</code> <p>SSH port.</p> <code>22</code> <code>tags</code> <code>set[str] | None</code> <p>Tags for this device.</p> <code>None</code> <code>timeout</code> <code>float | None</code> <p>Timeout value in seconds for outgoing API calls.</p> <code>None</code> <code>insecure</code> <code>bool</code> <p>Disable SSH Host Key validation.</p> <code>False</code> <code>proto</code> <code>Literal['http', 'https']</code> <p>eAPI protocol. Value can be \u2018http\u2019 or \u2018https\u2019.</p> <code>'https'</code> <code>disable_cache</code> <code>bool</code> <p>Disable caching for all commands for this device.</p> <code>False</code>"},{"location":"api/device/#anta.device.AsyncEOSDevice._collect","title":"_collect  <code>async</code>","text":"<pre><code>_collect(\n    command: AntaCommand,\n    *,\n    collection_id: str | None = None\n) -&gt; None\n</code></pre> <p>Collect device command output from EOS using aio-eapi.</p> <p>Supports outformat <code>json</code> and <code>text</code> as output structure. Gain privileged access using the <code>enable_password</code> attribute of the <code>AntaDevice</code> instance if populated.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>AntaCommand</code> <p>The command to collect.</p> required <code>collection_id</code> <code>str | None</code> <p>An identifier used to build the eAPI request ID.</p> <code>None</code> Source code in <code>anta/device.py</code> <pre><code>async def _collect(self, command: AntaCommand, *, collection_id: str | None = None) -&gt; None:\n    \"\"\"Collect device command output from EOS using aio-eapi.\n\n    Supports outformat `json` and `text` as output structure.\n    Gain privileged access using the `enable_password` attribute\n    of the `AntaDevice` instance if populated.\n\n    Parameters\n    ----------\n    command\n        The command to collect.\n    collection_id\n        An identifier used to build the eAPI request ID.\n    \"\"\"\n    semaphore = await self._get_semaphore()\n\n    async with semaphore:\n        commands: list[EapiComplexCommand | EapiSimpleCommand] = []\n        if self.enable and self._enable_password is not None:\n            commands.append(\n                {\n                    \"cmd\": \"enable\",\n                    \"input\": str(self._enable_password),\n                },\n            )\n        elif self.enable:\n            # No password\n            commands.append({\"cmd\": \"enable\"})\n        commands += [{\"cmd\": command.command, \"revision\": command.revision}] if command.revision else [{\"cmd\": command.command}]\n        try:\n            response = await self._session.cli(\n                commands=commands,\n                ofmt=command.ofmt,\n                version=command.version,\n                req_id=f\"ANTA-{collection_id}-{id(command)}\" if collection_id else f\"ANTA-{id(command)}\",\n            )\n            # Do not keep response of 'enable' command\n            command.output = response[-1]\n        except asynceapi.EapiCommandError as e:\n            # This block catches exceptions related to EOS issuing an error.\n            self._log_eapi_command_error(command, e)\n        except TimeoutException as e:\n            # This block catches Timeout exceptions.\n            command.errors = [exc_to_str(e)]\n            timeouts = self._session.timeout.as_dict()\n            logger.error(\n                \"%s occurred while sending a command to %s. Consider increasing the timeout.\\nCurrent timeouts: Connect: %s | Read: %s | Write: %s | Pool: %s\",\n                exc_to_str(e),\n                self.name,\n                timeouts[\"connect\"],\n                timeouts[\"read\"],\n                timeouts[\"write\"],\n                timeouts[\"pool\"],\n            )\n        except (ConnectError, OSError) as e:\n            # This block catches OSError and socket issues related exceptions.\n            command.errors = [exc_to_str(e)]\n            # pylint: disable=no-member\n            if (isinstance(exc := e.__cause__, httpcore.ConnectError) and isinstance(os_error := exc.__context__, OSError)) or isinstance(\n                os_error := e, OSError\n            ):\n                if isinstance(os_error.__cause__, OSError):\n                    os_error = os_error.__cause__\n                logger.error(\"A local OS error occurred while connecting to %s: %s.\", self.name, os_error)\n            else:\n                anta_log_exception(e, f\"An error occurred while issuing an eAPI request to {self.name}\", logger)\n        except HTTPError as e:\n            # This block catches most of the httpx Exceptions and logs a general message.\n            command.errors = [exc_to_str(e)]\n            anta_log_exception(e, f\"An error occurred while issuing an eAPI request to {self.name}\", logger)\n        logger.debug(\"%s: %s\", self.name, command)\n</code></pre>"},{"location":"api/device/#anta.device.AsyncEOSDevice.copy","title":"copy  <code>async</code>","text":"<pre><code>copy(\n    sources: list[Path],\n    destination: Path,\n    direction: Literal[\"to\", \"from\"] = \"from\",\n) -&gt; None\n</code></pre> <p>Copy files to and from the device using asyncssh.scp().</p> <p>Parameters:</p> Name Type Description Default <code>sources</code> <code>list[Path]</code> <p>List of files to copy to or from the device.</p> required <code>destination</code> <code>Path</code> <p>Local or remote destination when copying the files. Can be a folder.</p> required <code>direction</code> <code>Literal['to', 'from']</code> <p>Defines if this coroutine copies files to or from the device.</p> <code>'from'</code> Source code in <code>anta/device.py</code> <pre><code>async def copy(self, sources: list[Path], destination: Path, direction: Literal[\"to\", \"from\"] = \"from\") -&gt; None:\n    \"\"\"Copy files to and from the device using asyncssh.scp().\n\n    Parameters\n    ----------\n    sources\n        List of files to copy to or from the device.\n    destination\n        Local or remote destination when copying the files. Can be a folder.\n    direction\n        Defines if this coroutine copies files to or from the device.\n\n    \"\"\"\n    async with asyncssh.connect(\n        host=self._ssh_opts.host,\n        port=self._ssh_opts.port,\n        tunnel=self._ssh_opts.tunnel,\n        family=self._ssh_opts.family,\n        local_addr=self._ssh_opts.local_addr,\n        options=self._ssh_opts,\n    ) as conn:\n        src: list[tuple[SSHClientConnection, Path]] | list[Path]\n        dst: tuple[SSHClientConnection, Path] | Path\n        if direction == \"from\":\n            src = [(conn, file) for file in sources]\n            dst = destination\n            for file in sources:\n                message = f\"Copying '{file}' from device {self.name} to '{destination}' locally\"\n                logger.info(message)\n\n        elif direction == \"to\":\n            src = sources\n            dst = conn, destination\n            for file in src:\n                message = f\"Copying '{file}' to device {self.name} to '{destination}' remotely\"\n                logger.info(message)\n\n        else:\n            logger.critical(\"'direction' argument to copy() function is invalid: %s\", direction)\n\n            return\n        await asyncssh.scp(src, dst)\n</code></pre>"},{"location":"api/device/#anta.device.AsyncEOSDevice.refresh","title":"refresh  <code>async</code>","text":"<pre><code>refresh() -&gt; None\n</code></pre> <p>Update attributes of an AsyncEOSDevice instance.</p> <p>This coroutine must update the following attributes of AsyncEOSDevice: - is_online: When a device IP is reachable and a port can be open - established: When a command execution succeeds - hw_model: The hardware model of the device</p> Source code in <code>anta/device.py</code> <pre><code>async def refresh(self) -&gt; None:\n    \"\"\"Update attributes of an AsyncEOSDevice instance.\n\n    This coroutine must update the following attributes of AsyncEOSDevice:\n    - is_online: When a device IP is reachable and a port can be open\n    - established: When a command execution succeeds\n    - hw_model: The hardware model of the device\n    \"\"\"\n    logger.debug(\"Refreshing device %s\", self.name)\n    self.is_online = await self._session.check_connection()\n    if self.is_online:\n        show_version = AntaCommand(command=\"show version\")\n        await self._collect(show_version)\n        if not show_version.collected:\n            logger.warning(\"Cannot get hardware information from device %s\", self.name)\n        else:\n            self.hw_model = show_version.json_output.get(\"modelName\", None)\n            if self.hw_model is None:\n                logger.critical(\"Cannot parse 'show version' returned by device %s\", self.name)\n            # in some cases it is possible that 'modelName' comes back empty\n            # and it is nice to get a meaninfule error message\n            elif self.hw_model == \"\":\n                logger.critical(\"Got an empty 'modelName' in the 'show version' returned by device %s\", self.name)\n    else:\n        logger.warning(\"Could not connect to device %s: cannot open eAPI port\", self.name)\n\n    self.established = bool(self.is_online and self.hw_model)\n</code></pre>"},{"location":"api/inventory/","title":"Inventory","text":""},{"location":"api/inventory/#anta.inventory.AntaInventory","title":"AntaInventory","text":"<p>               Bases: <code>dict[str, AntaDevice]</code></p> <p>Inventory abstraction for ANTA framework.</p>"},{"location":"api/inventory/#anta.inventory.AntaInventory.devices","title":"devices  <code>property</code>","text":"<pre><code>devices: list[AntaDevice]\n</code></pre> <p>List of AntaDevice in this inventory.</p>"},{"location":"api/inventory/#anta.inventory.AntaInventory.add_device","title":"add_device","text":"<pre><code>add_device(device: AntaDevice) -&gt; None\n</code></pre> <p>Add a device to final inventory.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>AntaDevice</code> <p>Device object to be added.</p> required Source code in <code>anta/inventory/__init__.py</code> <pre><code>def add_device(self, device: AntaDevice) -&gt; None:\n    \"\"\"Add a device to final inventory.\n\n    Parameters\n    ----------\n    device\n        Device object to be added.\n\n    \"\"\"\n    self[device.name] = device\n</code></pre>"},{"location":"api/inventory/#anta.inventory.AntaInventory.connect_inventory","title":"connect_inventory  <code>async</code>","text":"<pre><code>connect_inventory() -&gt; None\n</code></pre> <p>Run <code>refresh()</code> coroutines for all AntaDevice objects in this inventory.</p> Source code in <code>anta/inventory/__init__.py</code> <pre><code>async def connect_inventory(self) -&gt; None:\n    \"\"\"Run `refresh()` coroutines for all AntaDevice objects in this inventory.\"\"\"\n    logger.debug(\"Refreshing devices...\")\n    results = await asyncio.gather(\n        *(device.refresh() for device in self.values()),\n        return_exceptions=True,\n    )\n    for r in results:\n        if isinstance(r, Exception):\n            message = \"Error when refreshing inventory\"\n            anta_log_exception(r, message, logger)\n</code></pre>"},{"location":"api/inventory/#anta.inventory.AntaInventory.dump","title":"dump","text":"<pre><code>dump() -&gt; AntaInventoryInput\n</code></pre> <p>Dump the AntaInventory to an AntaInventoryInput.</p> <p>Each hosts is dumped individually.</p> Source code in <code>anta/inventory/__init__.py</code> <pre><code>def dump(self) -&gt; AntaInventoryInput:\n    \"\"\"Dump the AntaInventory to an AntaInventoryInput.\n\n    Each hosts is dumped individually.\n    \"\"\"\n    hosts = [\n        AntaInventoryHost(\n            name=device.name,\n            host=device.host if hasattr(device, \"host\") else device.name,\n            port=device.port if hasattr(device, \"port\") else None,\n            tags=device.tags,\n            disable_cache=device.cache is None,\n        )\n        for device in self.devices\n    ]\n    return AntaInventoryInput(hosts=hosts)\n</code></pre>"},{"location":"api/inventory/#anta.inventory.AntaInventory.get_inventory","title":"get_inventory","text":"<pre><code>get_inventory(\n    *,\n    established_only: bool = False,\n    tags: set[str] | None = None,\n    devices: set[str] | None = None\n) -&gt; AntaInventory\n</code></pre> <p>Return a filtered inventory.</p> <p>Parameters:</p> Name Type Description Default <code>established_only</code> <code>bool</code> <p>Whether or not to include only established devices.</p> <code>False</code> <code>tags</code> <code>set[str] | None</code> <p>Tags to filter devices.</p> <code>None</code> <code>devices</code> <code>set[str] | None</code> <p>Names to filter devices.</p> <code>None</code> <p>Returns:</p> Type Description <code>AntaInventory</code> <p>An inventory with filtered AntaDevice objects.</p> Source code in <code>anta/inventory/__init__.py</code> <pre><code>def get_inventory(self, *, established_only: bool = False, tags: set[str] | None = None, devices: set[str] | None = None) -&gt; AntaInventory:\n    \"\"\"Return a filtered inventory.\n\n    Parameters\n    ----------\n    established_only\n        Whether or not to include only established devices.\n    tags\n        Tags to filter devices.\n    devices\n        Names to filter devices.\n\n    Returns\n    -------\n    AntaInventory\n        An inventory with filtered AntaDevice objects.\n    \"\"\"\n\n    def _filter_devices(device: AntaDevice) -&gt; bool:\n        \"\"\"Select the devices based on the inputs `tags`, `devices` and `established_only`.\"\"\"\n        if tags is not None and all(tag not in tags for tag in device.tags):\n            return False\n        if devices is None or device.name in devices:\n            return bool(not established_only or device.established)\n        return False\n\n    filtered_devices: list[AntaDevice] = list(filter(_filter_devices, self.values()))\n    result = AntaInventory()\n    for device in filtered_devices:\n        result.add_device(device)\n    return result\n</code></pre>"},{"location":"api/inventory/#anta.inventory.AntaInventory.parse","title":"parse  <code>staticmethod</code>","text":"<pre><code>parse(\n    filename: str | Path,\n    username: str,\n    password: str,\n    enable_password: str | None = None,\n    timeout: float | None = None,\n    file_format: Literal[\"yaml\", \"json\"] = \"yaml\",\n    *,\n    enable: bool = False,\n    insecure: bool = False,\n    disable_cache: bool = False\n) -&gt; AntaInventory\n</code></pre> <p>Create an AntaInventory instance from an inventory file.</p> <p>The inventory devices are AsyncEOSDevice instances.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to device inventory YAML file.</p> required <code>username</code> <code>str</code> <p>Username to use to connect to devices.</p> required <code>password</code> <code>str</code> <p>Password to use to connect to devices.</p> required <code>enable_password</code> <code>str | None</code> <p>Enable password to use if required.</p> <code>None</code> <code>timeout</code> <code>float | None</code> <p>Timeout value in seconds for outgoing API calls.</p> <code>None</code> <code>file_format</code> <code>Literal['yaml', 'json']</code> <p>Whether the inventory file is in JSON or YAML.</p> <code>'yaml'</code> <code>enable</code> <code>bool</code> <p>Whether or not the commands need to be run in enable mode towards the devices.</p> <code>False</code> <code>insecure</code> <code>bool</code> <p>Disable SSH Host Key validation.</p> <code>False</code> <code>disable_cache</code> <code>bool</code> <p>Disable cache globally.</p> <code>False</code> <p>Raises:</p> Type Description <code>InventoryRootKeyError</code> <p>Root key of inventory is missing.</p> <code>InventoryIncorrectSchemaError</code> <p>Inventory file is not following AntaInventory Schema.</p> Source code in <code>anta/inventory/__init__.py</code> <pre><code>@staticmethod\ndef parse(\n    filename: str | Path,\n    username: str,\n    password: str,\n    enable_password: str | None = None,\n    timeout: float | None = None,\n    file_format: Literal[\"yaml\", \"json\"] = \"yaml\",\n    *,\n    enable: bool = False,\n    insecure: bool = False,\n    disable_cache: bool = False,\n) -&gt; AntaInventory:\n    \"\"\"Create an AntaInventory instance from an inventory file.\n\n    The inventory devices are AsyncEOSDevice instances.\n\n    Parameters\n    ----------\n    filename\n        Path to device inventory YAML file.\n    username\n        Username to use to connect to devices.\n    password\n        Password to use to connect to devices.\n    enable_password\n        Enable password to use if required.\n    timeout\n        Timeout value in seconds for outgoing API calls.\n    file_format\n        Whether the inventory file is in JSON or YAML.\n    enable\n        Whether or not the commands need to be run in enable mode towards the devices.\n    insecure\n        Disable SSH Host Key validation.\n    disable_cache\n        Disable cache globally.\n\n    Raises\n    ------\n    InventoryRootKeyError\n        Root key of inventory is missing.\n    InventoryIncorrectSchemaError\n        Inventory file is not following AntaInventory Schema.\n\n    \"\"\"\n    if file_format not in [\"yaml\", \"json\"]:\n        message = f\"'{file_format}' is not a valid format for an AntaInventory file. Only 'yaml' and 'json' are supported.\"\n        raise ValueError(message)\n\n    inventory = AntaInventory()\n    kwargs: dict[str, Any] = {\n        \"username\": username,\n        \"password\": password,\n        \"enable\": enable,\n        \"enable_password\": enable_password,\n        \"timeout\": timeout,\n        \"insecure\": insecure,\n        \"disable_cache\": disable_cache,\n    }\n\n    try:\n        filename = Path(filename)\n        with filename.open(encoding=\"UTF-8\") as file:\n            data = safe_load(file) if file_format == \"yaml\" else json_load(file)\n    except (TypeError, YAMLError, OSError, ValueError) as e:\n        message = f\"Unable to parse ANTA Device Inventory file '{filename}'\"\n        anta_log_exception(e, message, logger)\n        raise\n\n    if AntaInventory.INVENTORY_ROOT_KEY not in data:\n        exc = InventoryRootKeyError(f\"Inventory root key ({AntaInventory.INVENTORY_ROOT_KEY}) is not defined in your inventory\")\n        anta_log_exception(exc, f\"Device inventory is invalid! (from {filename})\", logger)\n        raise exc\n\n    try:\n        inventory_input = AntaInventoryInput(**data[AntaInventory.INVENTORY_ROOT_KEY])\n    except ValidationError as e:\n        anta_log_exception(e, f\"Device inventory is invalid! (from {filename})\", logger)\n        raise\n\n    # Read data from input\n    AntaInventory._parse_hosts(inventory_input, inventory, **kwargs)\n    AntaInventory._parse_networks(inventory_input, inventory, **kwargs)\n    AntaInventory._parse_ranges(inventory_input, inventory, **kwargs)\n\n    return inventory\n</code></pre>"},{"location":"api/inventory/#anta.inventory.models.AntaInventoryInput","title":"AntaInventoryInput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Device inventory input model.</p>"},{"location":"api/inventory/#anta.inventory.models.AntaInventoryInput.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Return a JSON representation string of this model.</p> <p>Returns:</p> Type Description <code>    The JSON representation string of this model.</code> Source code in <code>anta/inventory/models.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Return a JSON representation string of this model.\n\n    Returns\n    -------\n        The JSON representation string of this model.\n    \"\"\"\n    return self.model_dump_json(serialize_as_any=True, exclude_unset=True, indent=2)\n</code></pre>"},{"location":"api/inventory/#anta.inventory.models.AntaInventoryInput.yaml","title":"yaml","text":"<pre><code>yaml() -&gt; str\n</code></pre> <p>Return a YAML representation string of this model.</p> <p>Returns:</p> Type Description <code>str</code> <p>The YAML representation string of this model.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>def yaml(self) -&gt; str:\n    \"\"\"Return a YAML representation string of this model.\n\n    Returns\n    -------\n    str\n        The YAML representation string of this model.\n    \"\"\"\n    # TODO: Pydantic and YAML serialization/deserialization is not supported natively.\n    # This could be improved.\n    # https://github.com/pydantic/pydantic/issues/1043\n    # Explore if this worth using this: https://github.com/NowanIlfideme/pydantic-yaml\n    return yaml.safe_dump(yaml.safe_load(self.model_dump_json(serialize_as_any=True, exclude_unset=True)), width=math.inf)\n</code></pre>"},{"location":"api/inventory/#anta.inventory.models.AntaInventoryHost","title":"AntaInventoryHost","text":"<p>               Bases: <code>AntaInventoryBaseModel</code></p> <p>Host entry of AntaInventoryInput.</p> <p>Attributes:</p> Name Type Description <code>host</code> <code>Hostname | IPvAnyAddress</code> <p>IP Address or FQDN of the device.</p> <code>port</code> <code>Port | None</code> <p>Custom eAPI port to use.</p> <code>name</code> <code>str | None</code> <p>Custom name of the device.</p> <code>tags</code> <code>set[str]</code> <p>Tags of the device.</p> <code>disable_cache</code> <code>bool</code> <p>Disable cache for this device.</p>"},{"location":"api/inventory/#anta.inventory.models.AntaInventoryNetwork","title":"AntaInventoryNetwork","text":"<p>               Bases: <code>AntaInventoryBaseModel</code></p> <p>Network entry of AntaInventoryInput.</p> <p>Attributes:</p> Name Type Description <code>network</code> <code>IPvAnyNetwork</code> <p>Subnet to use for scanning.</p> <code>tags</code> <code>set[str]</code> <p>Tags of the devices in this network.</p> <code>disable_cache</code> <code>bool</code> <p>Disable cache for all devices in this network.</p>"},{"location":"api/inventory/#anta.inventory.models.AntaInventoryRange","title":"AntaInventoryRange","text":"<p>               Bases: <code>AntaInventoryBaseModel</code></p> <p>IP Range entry of AntaInventoryInput.</p> <p>Attributes:</p> Name Type Description <code>start</code> <code>IPvAnyAddress</code> <p>IPv4 or IPv6 address for the beginning of the range.</p> <code>stop</code> <code>IPvAnyAddress</code> <p>IPv4 or IPv6 address for the end of the range.</p> <code>tags</code> <code>set[str]</code> <p>Tags of the devices in this IP range.</p> <code>disable_cache</code> <code>bool</code> <p>Disable cache for all devices in this IP range.</p>"},{"location":"api/inventory/#anta.inventory.exceptions","title":"exceptions","text":"<p>Manage Exception in Inventory module.</p>"},{"location":"api/inventory/#anta.inventory.exceptions.InventoryIncorrectSchemaError","title":"InventoryIncorrectSchemaError","text":"<p>               Bases: <code>Exception</code></p> <p>Error when user data does not follow ANTA schema.</p>"},{"location":"api/inventory/#anta.inventory.exceptions.InventoryRootKeyError","title":"InventoryRootKeyError","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when inventory root key is not found.</p>"},{"location":"api/result/","title":"Result","text":""},{"location":"api/result/#anta.result_manager.ResultManager","title":"ResultManager","text":"<pre><code>ResultManager()\n</code></pre> <p>Manager of ANTA Results.</p> <p>The status of the class is initialized to \u201cunset\u201d</p> <p>Then when adding a test with a status that is NOT \u2018error\u2019 the following table shows the updated status:</p> Current Status Added test Status Updated Status unset Any Any skipped unset, skipped skipped skipped success success skipped failure failure success unset, skipped, success success success failure failure failure unset, skipped success, failure failure <p>If the status of the added test is error, the status is untouched and the <code>error_status</code> attribute is set to True.</p> <p>Attributes:</p> Name Type Description <code>results</code> <code>list[TestResult]</code> <code>dump</code> <code>list[dict[str, Any]]</code> <code>status</code> <code>AntaTestStatus</code> <p>Status rerpesenting all the results.</p> <code>error_status</code> <code>bool</code> <p>Will be <code>True</code> if a test returned an error.</p> <code>results_by_status</code> <code>dict[AntaTestStatus, list[TestResult]]</code> <code>dump</code> <code>list[dict[str, Any]]</code> <code>json</code> <code>str</code> <code>device_stats</code> <code>dict[str, DeviceStats]</code> <code>category_stats</code> <code>dict[str, CategoryStats]</code> <code>test_stats</code> <code>dict[str, TestStats]</code>"},{"location":"api/result/#anta.result_manager.ResultManager.category_stats","title":"category_stats  <code>property</code>","text":"<pre><code>category_stats: dict[str, CategoryStats]\n</code></pre> <p>Get the category statistics.</p>"},{"location":"api/result/#anta.result_manager.ResultManager.device_stats","title":"device_stats  <code>property</code>","text":"<pre><code>device_stats: dict[str, DeviceStats]\n</code></pre> <p>Get the device statistics.</p>"},{"location":"api/result/#anta.result_manager.ResultManager.dump","title":"dump  <code>property</code>","text":"<pre><code>dump: list[dict[str, Any]]\n</code></pre> <p>Get a list of dictionary of the results.</p>"},{"location":"api/result/#anta.result_manager.ResultManager.json","title":"json  <code>property</code>","text":"<pre><code>json: str\n</code></pre> <p>Get a JSON representation of the results.</p>"},{"location":"api/result/#anta.result_manager.ResultManager.results","title":"results  <code>property</code> <code>writable</code>","text":"<pre><code>results: list[TestResult]\n</code></pre> <p>Get the list of TestResult.</p>"},{"location":"api/result/#anta.result_manager.ResultManager.results_by_status","title":"results_by_status  <code>cached</code> <code>property</code>","text":"<pre><code>results_by_status: dict[AntaTestStatus, list[TestResult]]\n</code></pre> <p>A cached property that returns the results grouped by status.</p>"},{"location":"api/result/#anta.result_manager.ResultManager.sorted_category_stats","title":"sorted_category_stats  <code>property</code>","text":"<pre><code>sorted_category_stats: dict[str, CategoryStats]\n</code></pre> <p>A property that returns the category_stats dictionary sorted by key name.</p>"},{"location":"api/result/#anta.result_manager.ResultManager.test_stats","title":"test_stats  <code>property</code>","text":"<pre><code>test_stats: dict[str, TestStats]\n</code></pre> <p>Get the test statistics.</p>"},{"location":"api/result/#anta.result_manager.ResultManager.add","title":"add","text":"<pre><code>add(result: TestResult) -&gt; None\n</code></pre> <p>Add a result to the ResultManager instance.</p> <p>The result is added to the internal list of results and the overall status of the ResultManager instance is updated based on the added test status.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>TestResult</code> <p>TestResult to add to the ResultManager instance.</p> required Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def add(self, result: TestResult) -&gt; None:\n    \"\"\"Add a result to the ResultManager instance.\n\n    The result is added to the internal list of results and the overall status\n    of the ResultManager instance is updated based on the added test status.\n\n    Parameters\n    ----------\n    result\n        TestResult to add to the ResultManager instance.\n    \"\"\"\n    self._result_entries.append(result)\n    self._update_status(result.result)\n    self._stats_in_sync = False\n\n    # Every time a new result is added, we need to clear the cached property\n    self.__dict__.pop(\"results_by_status\", None)\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.filter","title":"filter","text":"<pre><code>filter(hide: set[AntaTestStatus]) -&gt; ResultManager\n</code></pre> <p>Get a filtered ResultManager based on test status.</p> <p>Parameters:</p> Name Type Description Default <code>hide</code> <code>set[AntaTestStatus]</code> <p>Set of AntaTestStatus enum members to select tests to hide based on their status.</p> required <p>Returns:</p> Type Description <code>ResultManager</code> <p>A filtered <code>ResultManager</code>.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def filter(self, hide: set[AntaTestStatus]) -&gt; ResultManager:\n    \"\"\"Get a filtered ResultManager based on test status.\n\n    Parameters\n    ----------\n    hide\n        Set of AntaTestStatus enum members to select tests to hide based on their status.\n\n    Returns\n    -------\n    ResultManager\n        A filtered `ResultManager`.\n    \"\"\"\n    possible_statuses = set(AntaTestStatus)\n    manager = ResultManager()\n    manager.results = self.get_results(possible_statuses - hide)\n    return manager\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.filter_by_devices","title":"filter_by_devices  <code>deprecated</code>","text":"<pre><code>filter_by_devices(devices: set[str]) -&gt; ResultManager\n</code></pre> Deprecated <p>This method is deprecated. This will be removed in ANTA v2.0.0.</p> <p>Get a filtered ResultManager that only contains specific devices.</p> <p>Parameters:</p> Name Type Description Default <code>devices</code> <code>set[str]</code> <p>Set of device names to filter the results.</p> required <p>Returns:</p> Type Description <code>ResultManager</code> <p>A filtered <code>ResultManager</code>.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>@deprecated(\"This method is deprecated. This will be removed in ANTA v2.0.0.\", category=DeprecationWarning)\ndef filter_by_devices(self, devices: set[str]) -&gt; ResultManager:\n    \"\"\"Get a filtered ResultManager that only contains specific devices.\n\n    Parameters\n    ----------\n    devices\n        Set of device names to filter the results.\n\n    Returns\n    -------\n    ResultManager\n        A filtered `ResultManager`.\n    \"\"\"\n    manager = ResultManager()\n    manager.results = [result for result in self._result_entries if result.name in devices]\n    return manager\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.filter_by_tests","title":"filter_by_tests  <code>deprecated</code>","text":"<pre><code>filter_by_tests(tests: set[str]) -&gt; ResultManager\n</code></pre> Deprecated <p>This method is deprecated. This will be removed in ANTA v2.0.0.</p> <p>Get a filtered ResultManager that only contains specific tests.</p> <p>Parameters:</p> Name Type Description Default <code>tests</code> <code>set[str]</code> <p>Set of test names to filter the results.</p> required <p>Returns:</p> Type Description <code>ResultManager</code> <p>A filtered <code>ResultManager</code>.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>@deprecated(\"This method is deprecated. This will be removed in ANTA v2.0.0.\", category=DeprecationWarning)\ndef filter_by_tests(self, tests: set[str]) -&gt; ResultManager:\n    \"\"\"Get a filtered ResultManager that only contains specific tests.\n\n    Parameters\n    ----------\n    tests\n        Set of test names to filter the results.\n\n    Returns\n    -------\n    ResultManager\n        A filtered `ResultManager`.\n    \"\"\"\n    manager = ResultManager()\n    manager.results = [result for result in self._result_entries if result.test in tests]\n    return manager\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.get_devices","title":"get_devices  <code>deprecated</code>","text":"<pre><code>get_devices() -&gt; set[str]\n</code></pre> Deprecated <p>This method is deprecated. This will be removed in ANTA v2.0.0.</p> <p>Get the set of all the device names.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of device names.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>@deprecated(\"This method is deprecated. This will be removed in ANTA v2.0.0.\", category=DeprecationWarning)\ndef get_devices(self) -&gt; set[str]:\n    \"\"\"Get the set of all the device names.\n\n    Returns\n    -------\n    set[str]\n        Set of device names.\n    \"\"\"\n    return {str(result.name) for result in self._result_entries}\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.get_results","title":"get_results","text":"<pre><code>get_results(\n    status: set[AntaTestStatus] | None = None,\n    sort_by: list[str] | None = None,\n) -&gt; list[TestResult]\n</code></pre> <p>Get the results, optionally filtered by status and sorted by TestResult fields.</p> <p>If no status is provided, all results are returned.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>set[AntaTestStatus] | None</code> <p>Optional set of AntaTestStatus enum members to filter the results.</p> <code>None</code> <code>sort_by</code> <code>list[str] | None</code> <p>Optional list of TestResult fields to sort the results.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[TestResult]</code> <p>List of results.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def get_results(self, status: set[AntaTestStatus] | None = None, sort_by: list[str] | None = None) -&gt; list[TestResult]:\n    \"\"\"Get the results, optionally filtered by status and sorted by TestResult fields.\n\n    If no status is provided, all results are returned.\n\n    Parameters\n    ----------\n    status\n        Optional set of AntaTestStatus enum members to filter the results.\n    sort_by\n        Optional list of TestResult fields to sort the results.\n\n    Returns\n    -------\n    list[TestResult]\n        List of results.\n    \"\"\"\n    # Return all results if no status is provided, otherwise return results for multiple statuses\n    results = self._result_entries if status is None else list(chain.from_iterable(self.results_by_status.get(status, []) for status in status))\n\n    if sort_by:\n        accepted_fields = TestResult.model_fields.keys()\n        if not set(sort_by).issubset(set(accepted_fields)):\n            msg = f\"Invalid sort_by fields: {sort_by}. Accepted fields are: {list(accepted_fields)}\"\n            raise ValueError(msg)\n        results = sorted(results, key=lambda result: [getattr(result, field) or \"\" for field in sort_by])\n\n    return results\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.get_status","title":"get_status","text":"<pre><code>get_status(*, ignore_error: bool = False) -&gt; str\n</code></pre> <p>Return the current status including error_status if ignore_error is False.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def get_status(self, *, ignore_error: bool = False) -&gt; str:\n    \"\"\"Return the current status including error_status if ignore_error is False.\"\"\"\n    return \"error\" if self.error_status and not ignore_error else self.status\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.get_tests","title":"get_tests  <code>deprecated</code>","text":"<pre><code>get_tests() -&gt; set[str]\n</code></pre> Deprecated <p>This method is deprecated. This will be removed in ANTA v2.0.0.</p> <p>Get the set of all the test names.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of test names.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>@deprecated(\"This method is deprecated. This will be removed in ANTA v2.0.0.\", category=DeprecationWarning)\ndef get_tests(self) -&gt; set[str]:\n    \"\"\"Get the set of all the test names.\n\n    Returns\n    -------\n    set[str]\n        Set of test names.\n    \"\"\"\n    return {str(result.test) for result in self._result_entries}\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.get_total_results","title":"get_total_results","text":"<pre><code>get_total_results(\n    status: set[AntaTestStatus] | None = None,\n) -&gt; int\n</code></pre> <p>Get the total number of results, optionally filtered by status.</p> <p>If no status is provided, the total number of results is returned.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>set[AntaTestStatus] | None</code> <p>Optional set of AntaTestStatus enum members to filter the results.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Total number of results.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def get_total_results(self, status: set[AntaTestStatus] | None = None) -&gt; int:\n    \"\"\"Get the total number of results, optionally filtered by status.\n\n    If no status is provided, the total number of results is returned.\n\n    Parameters\n    ----------\n    status\n        Optional set of AntaTestStatus enum members to filter the results.\n\n    Returns\n    -------\n    int\n        Total number of results.\n    \"\"\"\n    if status is None:\n        # Return the total number of results\n        return sum(len(results) for results in self.results_by_status.values())\n\n    # Return the total number of results for multiple statuses\n    return sum(len(self.results_by_status.get(status, [])) for status in status)\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Create or reset the attributes of the ResultManager instance.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Create or reset the attributes of the ResultManager instance.\"\"\"\n    self._result_entries: list[TestResult] = []\n    self.status: AntaTestStatus = AntaTestStatus.UNSET\n    self.error_status = False\n\n    # Initialize the statistics attributes\n    self._reset_stats()\n</code></pre>"},{"location":"api/result/#anta.result_manager.ResultManager.sort","title":"sort","text":"<pre><code>sort(sort_by: list[str]) -&gt; ResultManager\n</code></pre> <p>Sort the ResultManager results based on TestResult fields.</p> <p>Parameters:</p> Name Type Description Default <code>sort_by</code> <code>list[str]</code> <p>List of TestResult fields to sort the results.</p> required Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def sort(self, sort_by: list[str]) -&gt; ResultManager:\n    \"\"\"Sort the ResultManager results based on TestResult fields.\n\n    Parameters\n    ----------\n    sort_by\n        List of TestResult fields to sort the results.\n    \"\"\"\n    accepted_fields = TestResult.model_fields.keys()\n    if not set(sort_by).issubset(set(accepted_fields)):\n        msg = f\"Invalid sort_by fields: {sort_by}. Accepted fields are: {list(accepted_fields)}\"\n        raise ValueError(msg)\n    self._result_entries.sort(key=lambda result: [getattr(result, field) or \"\" for field in sort_by])\n    return self\n</code></pre>"},{"location":"api/result/#anta.result_manager.models.TestResult","title":"TestResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Describe the result of a test from a single device.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the device where the test was run.</p> <code>test</code> <code>str</code> <p>Name of the test run on the device.</p> <code>categories</code> <code>list[str]</code> <p>List of categories the TestResult belongs to. Defaults to the AntaTest categories.</p> <code>description</code> <code>str</code> <p>Description of the TestResult. Defaults to the AntaTest description.</p> <code>result</code> <code>AntaTestStatus</code> <p>Result of the test. Must be one of the AntaTestStatus Enum values: unset, success, failure, error or skipped.</p> <code>messages</code> <code>list[str]</code> <p>Messages to report after the test, if any.</p> <code>custom_field</code> <code>str | None</code> <p>Custom field to store a string for flexibility in integrating with ANTA.</p>"},{"location":"api/result/#anta.result_manager.models.TestResult.is_error","title":"is_error","text":"<pre><code>is_error(message: str | None = None) -&gt; None\n</code></pre> <p>Set status to error.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str | None</code> <p>Optional message related to the test.</p> <code>None</code> Source code in <code>anta/result_manager/models.py</code> <pre><code>def is_error(self, message: str | None = None) -&gt; None:\n    \"\"\"Set status to error.\n\n    Parameters\n    ----------\n    message\n        Optional message related to the test.\n\n    \"\"\"\n    self._set_status(AntaTestStatus.ERROR, message)\n</code></pre>"},{"location":"api/result/#anta.result_manager.models.TestResult.is_failure","title":"is_failure","text":"<pre><code>is_failure(message: str | None = None) -&gt; None\n</code></pre> <p>Set status to failure.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str | None</code> <p>Optional message related to the test.</p> <code>None</code> Source code in <code>anta/result_manager/models.py</code> <pre><code>def is_failure(self, message: str | None = None) -&gt; None:\n    \"\"\"Set status to failure.\n\n    Parameters\n    ----------\n    message\n        Optional message related to the test.\n\n    \"\"\"\n    self._set_status(AntaTestStatus.FAILURE, message)\n</code></pre>"},{"location":"api/result/#anta.result_manager.models.TestResult.is_skipped","title":"is_skipped","text":"<pre><code>is_skipped(message: str | None = None) -&gt; None\n</code></pre> <p>Set status to skipped.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str | None</code> <p>Optional message related to the test.</p> <code>None</code> Source code in <code>anta/result_manager/models.py</code> <pre><code>def is_skipped(self, message: str | None = None) -&gt; None:\n    \"\"\"Set status to skipped.\n\n    Parameters\n    ----------\n    message\n        Optional message related to the test.\n\n    \"\"\"\n    self._set_status(AntaTestStatus.SKIPPED, message)\n</code></pre>"},{"location":"api/result/#anta.result_manager.models.TestResult.is_success","title":"is_success","text":"<pre><code>is_success(message: str | None = None) -&gt; None\n</code></pre> <p>Set status to success.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str | None</code> <p>Optional message related to the test.</p> <code>None</code> Source code in <code>anta/result_manager/models.py</code> <pre><code>def is_success(self, message: str | None = None) -&gt; None:\n    \"\"\"Set status to success.\n\n    Parameters\n    ----------\n    message\n        Optional message related to the test.\n\n    \"\"\"\n    self._set_status(AntaTestStatus.SUCCESS, message)\n</code></pre>"},{"location":"api/runner/","title":"Runner","text":"<p>Refer to the Getting started - Basic usage in a Python script section for a usage example.</p>"},{"location":"api/runner/#anta.runner","title":"anta.runner","text":"<p>ANTA runner module.</p>"},{"location":"api/runner/#anta.runner.adjust_rlimit_nofile","title":"adjust_rlimit_nofile","text":"<pre><code>adjust_rlimit_nofile() -&gt; tuple[int, int]\n</code></pre> <p>Adjust the maximum number of open file descriptors for the ANTA process.</p> <p>The limit is set to the lower of the current hard limit and the value of the ANTA_NOFILE environment variable.</p> <p>If the <code>ANTA_NOFILE</code> environment variable is not set or is invalid, <code>DEFAULT_NOFILE</code> is used.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>The new soft and hard limits for open file descriptors.</p> Source code in <code>anta/runner.py</code> <pre><code>def adjust_rlimit_nofile() -&gt; tuple[int, int]:\n    \"\"\"Adjust the maximum number of open file descriptors for the ANTA process.\n\n    The limit is set to the lower of the current hard limit and the value of the ANTA_NOFILE environment variable.\n\n    If the `ANTA_NOFILE` environment variable is not set or is invalid, `DEFAULT_NOFILE` is used.\n\n    Returns\n    -------\n    tuple[int, int]\n        The new soft and hard limits for open file descriptors.\n    \"\"\"\n    try:\n        nofile = int(os.environ.get(\"ANTA_NOFILE\", DEFAULT_NOFILE))\n    except ValueError as exception:\n        logger.warning(\"The ANTA_NOFILE environment variable value is invalid: %s\\nDefault to %s.\", exc_to_str(exception), DEFAULT_NOFILE)\n        nofile = DEFAULT_NOFILE\n\n    limits = resource.getrlimit(resource.RLIMIT_NOFILE)\n    logger.debug(\"Initial limit numbers for open file descriptors for the current ANTA process: Soft Limit: %s | Hard Limit: %s\", limits[0], limits[1])\n    nofile = min(limits[1], nofile)\n    logger.debug(\"Setting soft limit for open file descriptors for the current ANTA process to %s\", nofile)\n    resource.setrlimit(resource.RLIMIT_NOFILE, (nofile, limits[1]))\n    return resource.getrlimit(resource.RLIMIT_NOFILE)\n</code></pre>"},{"location":"api/runner/#anta.runner.get_coroutines","title":"get_coroutines","text":"<pre><code>get_coroutines(\n    selected_tests: defaultdict[\n        AntaDevice, set[AntaTestDefinition]\n    ],\n    manager: ResultManager | None = None,\n) -&gt; list[Coroutine[Any, Any, TestResult]]\n</code></pre> <p>Get the coroutines for the ANTA run.</p> <p>Parameters:</p> Name Type Description Default <code>selected_tests</code> <code>defaultdict[AntaDevice, set[AntaTestDefinition]]</code> <p>A mapping of devices to the tests to run. The selected tests are generated by the <code>prepare_tests</code> function.</p> required <code>manager</code> <code>ResultManager | None</code> <p>An optional ResultManager object to pre-populate with the test results. Used in dry-run mode.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Coroutine[Any, Any, TestResult]]</code> <p>The list of coroutines to run.</p> Source code in <code>anta/runner.py</code> <pre><code>def get_coroutines(selected_tests: defaultdict[AntaDevice, set[AntaTestDefinition]], manager: ResultManager | None = None) -&gt; list[Coroutine[Any, Any, TestResult]]:\n    \"\"\"Get the coroutines for the ANTA run.\n\n    Parameters\n    ----------\n    selected_tests\n        A mapping of devices to the tests to run. The selected tests are generated by the `prepare_tests` function.\n    manager\n        An optional ResultManager object to pre-populate with the test results. Used in dry-run mode.\n\n    Returns\n    -------\n    list[Coroutine[Any, Any, TestResult]]\n        The list of coroutines to run.\n    \"\"\"\n    coros = []\n    for device, test_definitions in selected_tests.items():\n        for test in test_definitions:\n            try:\n                test_instance = test.test(device=device, inputs=test.inputs)\n                if manager is not None:\n                    manager.add(test_instance.result)\n                coros.append(test_instance.test())\n            except Exception as e:  # noqa: PERF203, BLE001\n                # An AntaTest instance is potentially user-defined code.\n                # We need to catch everything and exit gracefully with an error message.\n                message = \"\\n\".join(\n                    [\n                        f\"There is an error when creating test {test.test.__module__}.{test.test.__name__}.\",\n                        f\"If this is not a custom test implementation: {GITHUB_SUGGESTION}\",\n                    ],\n                )\n                anta_log_exception(e, message, logger)\n    return coros\n</code></pre>"},{"location":"api/runner/#anta.runner.log_cache_statistics","title":"log_cache_statistics","text":"<pre><code>log_cache_statistics(devices: list[AntaDevice]) -&gt; None\n</code></pre> <p>Log cache statistics for each device in the inventory.</p> <p>Parameters:</p> Name Type Description Default <code>devices</code> <code>list[AntaDevice]</code> <p>List of devices in the inventory.</p> required Source code in <code>anta/runner.py</code> <pre><code>def log_cache_statistics(devices: list[AntaDevice]) -&gt; None:\n    \"\"\"Log cache statistics for each device in the inventory.\n\n    Parameters\n    ----------\n    devices\n        List of devices in the inventory.\n    \"\"\"\n    for device in devices:\n        if device.cache_statistics is not None:\n            msg = (\n                f\"Cache statistics for '{device.name}': \"\n                f\"{device.cache_statistics['cache_hits']} hits / {device.cache_statistics['total_commands_sent']} \"\n                f\"command(s) ({device.cache_statistics['cache_hit_ratio']})\"\n            )\n            logger.info(msg)\n        else:\n            logger.info(\"Caching is not enabled on %s\", device.name)\n</code></pre>"},{"location":"api/runner/#anta.runner.main","title":"main  <code>async</code>","text":"<pre><code>main(\n    manager: ResultManager,\n    inventory: AntaInventory,\n    catalog: AntaCatalog,\n    devices: set[str] | None = None,\n    tests: set[str] | None = None,\n    tags: set[str] | None = None,\n    *,\n    established_only: bool = True,\n    dry_run: bool = False\n) -&gt; None\n</code></pre> <p>Run ANTA.</p> <p>Use this as an entrypoint to the test framework in your script. ResultManager object gets updated with the test results.</p> <p>Parameters:</p> Name Type Description Default <code>manager</code> <code>ResultManager</code> <p>ResultManager object to populate with the test results.</p> required <code>inventory</code> <code>AntaInventory</code> <p>AntaInventory object that includes the device(s).</p> required <code>catalog</code> <code>AntaCatalog</code> <p>AntaCatalog object that includes the list of tests.</p> required <code>devices</code> <code>set[str] | None</code> <p>Devices on which to run tests. None means all devices. These may come from the <code>--device / -d</code> CLI option in NRFU.</p> <code>None</code> <code>tests</code> <code>set[str] | None</code> <p>Tests to run against devices. None means all tests. These may come from the <code>--test / -t</code> CLI option in NRFU.</p> <code>None</code> <code>tags</code> <code>set[str] | None</code> <p>Tags to filter devices from the inventory. These may come from the <code>--tags</code> CLI option in NRFU.</p> <code>None</code> <code>established_only</code> <code>bool</code> <p>Include only established device(s).</p> <code>True</code> <code>dry_run</code> <code>bool</code> <p>Build the list of coroutine to run and stop before test execution.</p> <code>False</code> Source code in <code>anta/runner.py</code> <pre><code>@cprofile()\nasync def main(\n    manager: ResultManager,\n    inventory: AntaInventory,\n    catalog: AntaCatalog,\n    devices: set[str] | None = None,\n    tests: set[str] | None = None,\n    tags: set[str] | None = None,\n    *,\n    established_only: bool = True,\n    dry_run: bool = False,\n) -&gt; None:\n    \"\"\"Run ANTA.\n\n    Use this as an entrypoint to the test framework in your script.\n    ResultManager object gets updated with the test results.\n\n    Parameters\n    ----------\n    manager\n        ResultManager object to populate with the test results.\n    inventory\n        AntaInventory object that includes the device(s).\n    catalog\n        AntaCatalog object that includes the list of tests.\n    devices\n        Devices on which to run tests. None means all devices. These may come from the `--device / -d` CLI option in NRFU.\n    tests\n        Tests to run against devices. None means all tests. These may come from the `--test / -t` CLI option in NRFU.\n    tags\n        Tags to filter devices from the inventory. These may come from the `--tags` CLI option in NRFU.\n    established_only\n        Include only established device(s).\n    dry_run\n        Build the list of coroutine to run and stop before test execution.\n    \"\"\"\n    if not catalog.tests:\n        logger.info(\"The list of tests is empty, exiting\")\n        return\n\n    with Catchtime(logger=logger, message=\"Preparing ANTA NRFU Run\"):\n        # Setup the inventory\n        selected_inventory = inventory if dry_run else await setup_inventory(inventory, tags, devices, established_only=established_only)\n        if selected_inventory is None:\n            return\n\n        with Catchtime(logger=logger, message=\"Preparing the tests\"):\n            selected_tests = prepare_tests(selected_inventory, catalog, tests, tags)\n            if selected_tests is None:\n                return\n            final_tests_count = sum(len(tests) for tests in selected_tests.values())\n\n        run_info = (\n            \"--- ANTA NRFU Run Information ---\\n\"\n            f\"Number of devices: {len(inventory)} ({len(selected_inventory)} established)\\n\"\n            f\"Total number of selected tests: {final_tests_count}\\n\"\n        )\n\n        if os.name == \"posix\":\n            # Adjust the maximum number of open file descriptors for the ANTA process\n            limits = adjust_rlimit_nofile()\n            run_info += f\"Maximum number of open file descriptors for the current ANTA process: {limits[0]}\\n\"\n        else:\n            # Running on non-Posix system, cannot manage the resource.\n            limits = (sys.maxsize, sys.maxsize)\n            run_info += \"Running on a non-POSIX system, cannot adjust the maximum number of file descriptors.\\n\"\n\n        run_info += \"---------------------------------\"\n\n        logger.info(run_info)\n\n        if final_tests_count &gt; limits[0]:\n            logger.warning(\n                \"The number of concurrent tests is higher than the open file descriptors limit for this ANTA process.\\n\"\n                \"Errors may occur while running the tests.\\n\"\n                \"Please consult the ANTA FAQ.\"\n            )\n\n        coroutines = get_coroutines(selected_tests, manager if dry_run else None)\n\n    if dry_run:\n        logger.info(\"Dry-run mode, exiting before running the tests.\")\n        for coro in coroutines:\n            coro.close()\n        return\n\n    if AntaTest.progress is not None:\n        AntaTest.nrfu_task = AntaTest.progress.add_task(\"Running NRFU Tests...\", total=len(coroutines))\n\n    with Catchtime(logger=logger, message=\"Running ANTA tests\"):\n        results = await asyncio.gather(*coroutines)\n        for result in results:\n            manager.add(result)\n\n    log_cache_statistics(selected_inventory.devices)\n</code></pre>"},{"location":"api/runner/#anta.runner.prepare_tests","title":"prepare_tests","text":"<pre><code>prepare_tests(\n    inventory: AntaInventory,\n    catalog: AntaCatalog,\n    tests: set[str] | None,\n    tags: set[str] | None,\n) -&gt; (\n    defaultdict[AntaDevice, set[AntaTestDefinition]] | None\n)\n</code></pre> <p>Prepare the tests to run.</p> <p>Parameters:</p> Name Type Description Default <code>inventory</code> <code>AntaInventory</code> <p>AntaInventory object that includes the device(s).</p> required <code>catalog</code> <code>AntaCatalog</code> <p>AntaCatalog object that includes the list of tests.</p> required <code>tests</code> <code>set[str] | None</code> <p>Tests to run against devices. None means all tests.</p> required <code>tags</code> <code>set[str] | None</code> <p>Tags to filter devices from the inventory.</p> required <p>Returns:</p> Type Description <code>defaultdict[AntaDevice, set[AntaTestDefinition]] | None</code> <p>A mapping of devices to the tests to run or None if there are no tests to run.</p> Source code in <code>anta/runner.py</code> <pre><code>def prepare_tests(\n    inventory: AntaInventory, catalog: AntaCatalog, tests: set[str] | None, tags: set[str] | None\n) -&gt; defaultdict[AntaDevice, set[AntaTestDefinition]] | None:\n    \"\"\"Prepare the tests to run.\n\n    Parameters\n    ----------\n    inventory\n        AntaInventory object that includes the device(s).\n    catalog\n        AntaCatalog object that includes the list of tests.\n    tests\n        Tests to run against devices. None means all tests.\n    tags\n        Tags to filter devices from the inventory.\n\n    Returns\n    -------\n    defaultdict[AntaDevice, set[AntaTestDefinition]] | None\n        A mapping of devices to the tests to run or None if there are no tests to run.\n    \"\"\"\n    # Build indexes for the catalog. If `tests` is set, filter the indexes based on these tests\n    catalog.build_indexes(filtered_tests=tests)\n\n    # Using a set to avoid inserting duplicate tests\n    device_to_tests: defaultdict[AntaDevice, set[AntaTestDefinition]] = defaultdict(set)\n\n    total_test_count = 0\n\n    # Create the device to tests mapping from the tags\n    for device in inventory.devices:\n        if tags:\n            # If there are CLI tags, execute tests with matching tags for this device\n            if not (matching_tags := tags.intersection(device.tags)):\n                # The device does not have any selected tag, skipping\n                continue\n            device_to_tests[device].update(catalog.get_tests_by_tags(matching_tags))\n        else:\n            # If there is no CLI tags, execute all tests that do not have any tags\n            device_to_tests[device].update(catalog.tag_to_tests[None])\n\n            # Then add the tests with matching tags from device tags\n            device_to_tests[device].update(catalog.get_tests_by_tags(device.tags))\n\n        total_test_count += len(device_to_tests[device])\n\n    if total_test_count == 0:\n        msg = (\n            f\"There are no tests{f' matching the tags {tags} ' if tags else ' '}to run in the current test catalog and device inventory, please verify your inputs.\"\n        )\n        logger.warning(msg)\n        return None\n\n    return device_to_tests\n</code></pre>"},{"location":"api/runner/#anta.runner.setup_inventory","title":"setup_inventory  <code>async</code>","text":"<pre><code>setup_inventory(\n    inventory: AntaInventory,\n    tags: set[str] | None,\n    devices: set[str] | None,\n    *,\n    established_only: bool\n) -&gt; AntaInventory | None\n</code></pre> <p>Set up the inventory for the ANTA run.</p> <p>Parameters:</p> Name Type Description Default <code>inventory</code> <code>AntaInventory</code> <p>AntaInventory object that includes the device(s).</p> required <code>tags</code> <code>set[str] | None</code> <p>Tags to filter devices from the inventory.</p> required <code>devices</code> <code>set[str] | None</code> <p>Devices on which to run tests. None means all devices.</p> required <code>established_only</code> <code>bool</code> <p>If True use return only devices where a connection is established.</p> required <p>Returns:</p> Type Description <code>AntaInventory | None</code> <p>The filtered inventory or None if there are no devices to run tests on.</p> Source code in <code>anta/runner.py</code> <pre><code>async def setup_inventory(inventory: AntaInventory, tags: set[str] | None, devices: set[str] | None, *, established_only: bool) -&gt; AntaInventory | None:\n    \"\"\"Set up the inventory for the ANTA run.\n\n    Parameters\n    ----------\n    inventory\n        AntaInventory object that includes the device(s).\n    tags\n        Tags to filter devices from the inventory.\n    devices\n        Devices on which to run tests. None means all devices.\n    established_only\n        If True use return only devices where a connection is established.\n\n    Returns\n    -------\n    AntaInventory | None\n        The filtered inventory or None if there are no devices to run tests on.\n    \"\"\"\n    if len(inventory) == 0:\n        logger.info(\"The inventory is empty, exiting\")\n        return None\n\n    # Filter the inventory based on the CLI provided tags and devices if any\n    selected_inventory = inventory.get_inventory(tags=tags, devices=devices) if tags or devices else inventory\n\n    with Catchtime(logger=logger, message=\"Connecting to devices\"):\n        # Connect to the devices\n        await selected_inventory.connect_inventory()\n\n    # Remove devices that are unreachable\n    selected_inventory = selected_inventory.get_inventory(established_only=established_only)\n\n    # If there are no devices in the inventory after filtering, exit\n    if not selected_inventory.devices:\n        msg = f\"No reachable device {f'matching the tags {tags} ' if tags else ''}was found.{f' Selected devices: {devices} ' if devices is not None else ''}\"\n        logger.warning(msg)\n        return None\n\n    return selected_inventory\n</code></pre>"},{"location":"api/tests/","title":"Overview","text":"<p>This section describes all the available tests provided by the ANTA package.</p>"},{"location":"api/tests/#available-tests","title":"Available Tests","text":"<p>Here are the tests that we currently provide:</p> <ul> <li>AAA</li> <li>Adaptive Virtual Topology</li> <li>BFD</li> <li>Configuration</li> <li>Connectivity</li> <li>CVX</li> <li>Field Notices</li> <li>Flow Tracking</li> <li>GreenT</li> <li>Hardware</li> <li>Interfaces</li> <li>LANZ</li> <li>Logging</li> <li>MLAG</li> <li>Multicast</li> <li>Profiles</li> <li>PTP</li> <li>Router Path Selection</li> <li>Routing Generic</li> <li>Routing BGP</li> <li>Routing ISIS</li> <li>Routing OSPF</li> <li>Security</li> <li>Services</li> <li>SNMP</li> <li>Software</li> <li>STP</li> <li>STUN</li> <li>System</li> <li>VLAN</li> <li>VXLAN</li> </ul> <p>Tip</p> <p>You can use <code>anta get tests</code> from the CLI to list all the tests available with an example. Refer to documentation for more options.</p>"},{"location":"api/tests/#using-the-tests","title":"Using the Tests","text":"<p>All these tests can be imported in a catalog to be used by the ANTA CLI or in your own framework.</p>"},{"location":"api/reporter/csv/","title":"CSV","text":"<p>CSV Report management for ANTA.</p>"},{"location":"api/reporter/csv/#anta.reporter.csv_reporter.ReportCsv","title":"ReportCsv","text":"<p>Build a CSV report.</p>"},{"location":"api/reporter/csv/#anta.reporter.csv_reporter.ReportCsv.Headers","title":"Headers  <code>dataclass</code>","text":"<pre><code>Headers(\n    device: str = \"Device\",\n    test_name: str = \"Test Name\",\n    test_status: str = \"Test Status\",\n    messages: str = \"Message(s)\",\n    description: str = \"Test description\",\n    categories: str = \"Test category\",\n)\n</code></pre> <p>Headers for the CSV report.</p>"},{"location":"api/reporter/csv/#anta.reporter.csv_reporter.ReportCsv.convert_to_list","title":"convert_to_list  <code>classmethod</code>","text":"<pre><code>convert_to_list(result: TestResult) -&gt; list[str]\n</code></pre> <p>Convert a TestResult into a list of string for creating file content.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>TestResult</code> <p>A TestResult to convert into list.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>TestResult converted into a list.</p> Source code in <code>anta/reporter/csv_reporter.py</code> <pre><code>@classmethod\ndef convert_to_list(cls, result: TestResult) -&gt; list[str]:\n    \"\"\"Convert a TestResult into a list of string for creating file content.\n\n    Parameters\n    ----------\n    result\n        A TestResult to convert into list.\n\n    Returns\n    -------\n    list[str]\n        TestResult converted into a list.\n    \"\"\"\n    message = cls.split_list_to_txt_list(result.messages) if len(result.messages) &gt; 0 else \"\"\n    categories = cls.split_list_to_txt_list(convert_categories(result.categories)) if len(result.categories) &gt; 0 else \"None\"\n    return [\n        str(result.name),\n        result.test,\n        result.result,\n        message,\n        result.description,\n        categories,\n    ]\n</code></pre>"},{"location":"api/reporter/csv/#anta.reporter.csv_reporter.ReportCsv.generate","title":"generate  <code>classmethod</code>","text":"<pre><code>generate(\n    results: ResultManager, csv_filename: Path\n) -&gt; None\n</code></pre> <p>Build CSV flle with tests results.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>ResultManager</code> <p>A ResultManager instance.</p> required <code>csv_filename</code> <code>Path</code> <p>File path where to save CSV data.</p> required <p>Raises:</p> Type Description <code>OSError</code> <p>if any is raised while writing the CSV file.</p> Source code in <code>anta/reporter/csv_reporter.py</code> <pre><code>@classmethod\ndef generate(cls, results: ResultManager, csv_filename: pathlib.Path) -&gt; None:\n    \"\"\"Build CSV flle with tests results.\n\n    Parameters\n    ----------\n    results\n        A ResultManager instance.\n    csv_filename\n        File path where to save CSV data.\n\n    Raises\n    ------\n    OSError\n        if any is raised while writing the CSV file.\n    \"\"\"\n    headers = [\n        cls.Headers.device,\n        cls.Headers.test_name,\n        cls.Headers.test_status,\n        cls.Headers.messages,\n        cls.Headers.description,\n        cls.Headers.categories,\n    ]\n\n    try:\n        with csv_filename.open(mode=\"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n            csvwriter = csv.writer(\n                csvfile,\n                delimiter=\",\",\n                lineterminator=os.linesep,\n            )\n            csvwriter.writerow(headers)\n            for entry in results.results:\n                csvwriter.writerow(cls.convert_to_list(entry))\n    except OSError as exc:\n        message = f\"OSError caught while writing the CSV file '{csv_filename.resolve()}'.\"\n        anta_log_exception(exc, message, logger)\n        raise\n</code></pre>"},{"location":"api/reporter/csv/#anta.reporter.csv_reporter.ReportCsv.split_list_to_txt_list","title":"split_list_to_txt_list  <code>classmethod</code>","text":"<pre><code>split_list_to_txt_list(\n    usr_list: list[str], delimiter: str = \" - \"\n) -&gt; str\n</code></pre> <p>Split list to multi-lines string.</p> <p>Parameters:</p> Name Type Description Default <code>usr_list</code> <code>list[str]</code> <p>List of string to concatenate.</p> required <code>delimiter</code> <code>str</code> <p>A delimiter to use to start string. Defaults to None.</p> <code>' - '</code> <p>Returns:</p> Type Description <code>str</code> <p>Multi-lines string.</p> Source code in <code>anta/reporter/csv_reporter.py</code> <pre><code>@classmethod\ndef split_list_to_txt_list(cls, usr_list: list[str], delimiter: str = \" - \") -&gt; str:\n    \"\"\"Split list to multi-lines string.\n\n    Parameters\n    ----------\n    usr_list\n        List of string to concatenate.\n    delimiter\n        A delimiter to use to start string. Defaults to None.\n\n    Returns\n    -------\n    str\n        Multi-lines string.\n\n    \"\"\"\n    return f\"{delimiter}\".join(f\"{line}\" for line in usr_list)\n</code></pre>"},{"location":"api/reporter/jinja/","title":"Jinja","text":""},{"location":"api/reporter/jinja/#anta.reporter.ReportJinja","title":"ReportJinja","text":"<pre><code>ReportJinja(template_path: Path)\n</code></pre> <p>Report builder based on a Jinja2 template.</p>"},{"location":"api/reporter/jinja/#anta.reporter.ReportJinja.render","title":"render","text":"<pre><code>render(\n    data: list[dict[str, Any]],\n    *,\n    trim_blocks: bool = True,\n    lstrip_blocks: bool = True\n) -&gt; str\n</code></pre> <p>Build a report based on a Jinja2 template.</p> <p>Report is built based on a J2 template provided by user. Data structure sent to template is:</p> Example <pre><code>&gt;&gt;&gt; print(ResultManager.json)\n[\n    {\n        name: ...,\n        test: ...,\n        result: ...,\n        messages: [...]\n        categories: ...,\n        description: ...,\n    }\n]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list[dict[str, Any]]</code> <p>List of results from <code>ResultManager.results</code>.</p> required <code>trim_blocks</code> <code>bool</code> <p>enable trim_blocks for J2 rendering.</p> <code>True</code> <code>lstrip_blocks</code> <code>bool</code> <p>enable lstrip_blocks for J2 rendering.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Rendered template</p> Source code in <code>anta/reporter/__init__.py</code> <pre><code>def render(self, data: list[dict[str, Any]], *, trim_blocks: bool = True, lstrip_blocks: bool = True) -&gt; str:\n    \"\"\"Build a report based on a Jinja2 template.\n\n    Report is built based on a J2 template provided by user.\n    Data structure sent to template is:\n\n    Example\n    -------\n    ```\n    &gt;&gt;&gt; print(ResultManager.json)\n    [\n        {\n            name: ...,\n            test: ...,\n            result: ...,\n            messages: [...]\n            categories: ...,\n            description: ...,\n        }\n    ]\n    ```\n\n    Parameters\n    ----------\n    data\n        List of results from `ResultManager.results`.\n    trim_blocks\n        enable trim_blocks for J2 rendering.\n    lstrip_blocks\n        enable lstrip_blocks for J2 rendering.\n\n    Returns\n    -------\n    str\n        Rendered template\n\n    \"\"\"\n    with self.template_path.open(encoding=\"utf-8\") as file_:\n        template = Template(file_.read(), trim_blocks=trim_blocks, lstrip_blocks=lstrip_blocks)\n\n    return template.render({\"data\": data})\n</code></pre>"},{"location":"api/reporter/markdown/","title":"Markdown","text":"<p>Markdown report generator for ANTA test results.</p>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.ANTAReport","title":"ANTAReport","text":"<pre><code>ANTAReport(mdfile: TextIO, results: ResultManager)\n</code></pre> <p>               Bases: <code>MDReportBase</code></p> <p>Generate the <code># ANTA Report</code> section of the markdown report.</p>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.ANTAReport.generate_section","title":"generate_section","text":"<pre><code>generate_section() -&gt; None\n</code></pre> <p>Generate the <code># ANTA Report</code> section of the markdown report.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_section(self) -&gt; None:\n    \"\"\"Generate the `# ANTA Report` section of the markdown report.\"\"\"\n    self.write_heading(heading_level=1)\n    toc = MD_REPORT_TOC\n    self.mdfile.write(toc + \"\\n\\n\")\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportBase","title":"MDReportBase","text":"<pre><code>MDReportBase(mdfile: TextIO, results: ResultManager)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for all sections subclasses.</p> <p>Every subclasses must implement the <code>generate_section</code> method that uses the <code>ResultManager</code> object to generate and write content to the provided markdown file.</p> <p>Parameters:</p> Name Type Description Default <code>mdfile</code> <code>TextIO</code> <p>An open file object to write the markdown data into.</p> required <code>results</code> <code>ResultManager</code> <p>The ResultsManager instance containing all test results.</p> required"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportBase.generate_heading_name","title":"generate_heading_name","text":"<pre><code>generate_heading_name() -&gt; str\n</code></pre> <p>Generate a formatted heading name based on the class name.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted header name.</p> Example <ul> <li><code>ANTAReport</code> will become <code>ANTA Report</code>.</li> <li><code>TestResultsSummary</code> will become <code>Test Results Summary</code>.</li> </ul> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_heading_name(self) -&gt; str:\n    \"\"\"Generate a formatted heading name based on the class name.\n\n    Returns\n    -------\n    str\n        Formatted header name.\n\n    Example\n    -------\n    - `ANTAReport` will become `ANTA Report`.\n    - `TestResultsSummary` will become `Test Results Summary`.\n    \"\"\"\n    class_name = self.__class__.__name__\n\n    # Split the class name into words, keeping acronyms together\n    words = re.findall(r\"[A-Z]?[a-z]+|[A-Z]+(?=[A-Z][a-z]|\\d|\\W|$)|\\d+\", class_name)\n\n    # Capitalize each word, but keep acronyms in all caps\n    formatted_words = [word if word.isupper() else word.capitalize() for word in words]\n\n    return \" \".join(formatted_words)\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportBase.generate_rows","title":"generate_rows","text":"<pre><code>generate_rows() -&gt; Generator[str, None, None]\n</code></pre> <p>Generate the rows of a markdown table for a specific report section.</p> <p>Subclasses can implement this method to generate the content of the table rows.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_rows(self) -&gt; Generator[str, None, None]:\n    \"\"\"Generate the rows of a markdown table for a specific report section.\n\n    Subclasses can implement this method to generate the content of the table rows.\n    \"\"\"\n    msg = \"Subclasses should implement this method\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportBase.generate_section","title":"generate_section  <code>abstractmethod</code>","text":"<pre><code>generate_section() -&gt; None\n</code></pre> <p>Abstract method to generate a specific section of the markdown report.</p> <p>Must be implemented by subclasses.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>@abstractmethod\ndef generate_section(self) -&gt; None:\n    \"\"\"Abstract method to generate a specific section of the markdown report.\n\n    Must be implemented by subclasses.\n    \"\"\"\n    msg = \"Must be implemented by subclasses\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportBase.safe_markdown","title":"safe_markdown","text":"<pre><code>safe_markdown(text: str | None) -&gt; str\n</code></pre> <p>Escape markdown characters in the text to prevent markdown rendering issues.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to escape markdown characters from.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The text with escaped markdown characters.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def safe_markdown(self, text: str | None) -&gt; str:\n    \"\"\"Escape markdown characters in the text to prevent markdown rendering issues.\n\n    Parameters\n    ----------\n    text\n        The text to escape markdown characters from.\n\n    Returns\n    -------\n    str\n        The text with escaped markdown characters.\n    \"\"\"\n    # Custom field from a TestResult object can be None\n    if text is None:\n        return \"\"\n\n    # Replace newlines with &lt;br&gt; to preserve line breaks in HTML\n    text = text.replace(\"\\n\", \"&lt;br&gt;\")\n\n    # Replace backticks with single quotes\n    return text.replace(\"`\", \"'\")\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportBase.write_heading","title":"write_heading","text":"<pre><code>write_heading(heading_level: int) -&gt; None\n</code></pre> <p>Write a markdown heading to the markdown file.</p> <p>The heading name used is the class name.</p> <p>Parameters:</p> Name Type Description Default <code>heading_level</code> <code>int</code> <p>The level of the heading (1-6).</p> required Example <p><code>## Test Results Summary</code></p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def write_heading(self, heading_level: int) -&gt; None:\n    \"\"\"Write a markdown heading to the markdown file.\n\n    The heading name used is the class name.\n\n    Parameters\n    ----------\n    heading_level\n        The level of the heading (1-6).\n\n    Example\n    -------\n    `## Test Results Summary`\n    \"\"\"\n    # Ensure the heading level is within the valid range of 1 to 6\n    heading_level = max(1, min(heading_level, 6))\n    heading_name = self.generate_heading_name()\n    heading = \"#\" * heading_level + \" \" + heading_name\n    self.mdfile.write(f\"{heading}\\n\\n\")\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportBase.write_table","title":"write_table","text":"<pre><code>write_table(\n    table_heading: list[str], *, last_table: bool = False\n) -&gt; None\n</code></pre> <p>Write a markdown table with a table heading and multiple rows to the markdown file.</p> <p>Parameters:</p> Name Type Description Default <code>table_heading</code> <code>list[str]</code> <p>List of strings to join for the table heading.</p> required <code>last_table</code> <code>bool</code> <p>Flag to determine if it\u2019s the last table of the markdown file to avoid unnecessary new line. Defaults to False.</p> <code>False</code> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def write_table(self, table_heading: list[str], *, last_table: bool = False) -&gt; None:\n    \"\"\"Write a markdown table with a table heading and multiple rows to the markdown file.\n\n    Parameters\n    ----------\n    table_heading\n        List of strings to join for the table heading.\n    last_table\n        Flag to determine if it's the last table of the markdown file to avoid unnecessary new line. Defaults to False.\n    \"\"\"\n    self.mdfile.write(\"\\n\".join(table_heading) + \"\\n\")\n    for row in self.generate_rows():\n        self.mdfile.write(row)\n    if not last_table:\n        self.mdfile.write(\"\\n\")\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportGenerator","title":"MDReportGenerator","text":"<p>Class responsible for generating a Markdown report based on the provided <code>ResultManager</code> object.</p> <p>It aggregates different report sections, each represented by a subclass of <code>MDReportBase</code>, and sequentially generates their content into a markdown file.</p> <p>The <code>generate</code> class method will loop over all the section subclasses and call their <code>generate_section</code> method. The final report will be generated in the same order as the <code>sections</code> list of the method.</p>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.MDReportGenerator.generate","title":"generate  <code>classmethod</code>","text":"<pre><code>generate(results: ResultManager, md_filename: Path) -&gt; None\n</code></pre> <p>Generate and write the various sections of the markdown report.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>ResultManager</code> <p>The ResultsManager instance containing all test results.</p> required <code>md_filename</code> <code>Path</code> <p>The path to the markdown file to write the report into.</p> required Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>@classmethod\ndef generate(cls, results: ResultManager, md_filename: Path) -&gt; None:\n    \"\"\"Generate and write the various sections of the markdown report.\n\n    Parameters\n    ----------\n    results\n        The ResultsManager instance containing all test results.\n    md_filename\n        The path to the markdown file to write the report into.\n    \"\"\"\n    try:\n        with md_filename.open(\"w\", encoding=\"utf-8\") as mdfile:\n            sections: list[MDReportBase] = [\n                ANTAReport(mdfile, results),\n                TestResultsSummary(mdfile, results),\n                SummaryTotals(mdfile, results),\n                SummaryTotalsDeviceUnderTest(mdfile, results),\n                SummaryTotalsPerCategory(mdfile, results),\n                TestResults(mdfile, results),\n            ]\n            for section in sections:\n                section.generate_section()\n    except OSError as exc:\n        message = f\"OSError caught while writing the Markdown file '{md_filename.resolve()}'.\"\n        anta_log_exception(exc, message, logger)\n        raise\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotals","title":"SummaryTotals","text":"<pre><code>SummaryTotals(mdfile: TextIO, results: ResultManager)\n</code></pre> <p>               Bases: <code>MDReportBase</code></p> <p>Generate the <code>### Summary Totals</code> section of the markdown report.</p>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotals.generate_rows","title":"generate_rows","text":"<pre><code>generate_rows() -&gt; Generator[str, None, None]\n</code></pre> <p>Generate the rows of the summary totals table.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_rows(self) -&gt; Generator[str, None, None]:\n    \"\"\"Generate the rows of the summary totals table.\"\"\"\n    yield (\n        f\"| {self.results.get_total_results()} \"\n        f\"| {self.results.get_total_results({AntaTestStatus.SUCCESS})} \"\n        f\"| {self.results.get_total_results({AntaTestStatus.SKIPPED})} \"\n        f\"| {self.results.get_total_results({AntaTestStatus.FAILURE})} \"\n        f\"| {self.results.get_total_results({AntaTestStatus.ERROR})} |\\n\"\n    )\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotals.generate_section","title":"generate_section","text":"<pre><code>generate_section() -&gt; None\n</code></pre> <p>Generate the <code>### Summary Totals</code> section of the markdown report.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_section(self) -&gt; None:\n    \"\"\"Generate the `### Summary Totals` section of the markdown report.\"\"\"\n    self.write_heading(heading_level=3)\n    self.write_table(table_heading=self.TABLE_HEADING)\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotalsDeviceUnderTest","title":"SummaryTotalsDeviceUnderTest","text":"<pre><code>SummaryTotalsDeviceUnderTest(\n    mdfile: TextIO, results: ResultManager\n)\n</code></pre> <p>               Bases: <code>MDReportBase</code></p> <p>Generate the <code>### Summary Totals Devices Under Tests</code> section of the markdown report.</p>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotalsDeviceUnderTest.generate_rows","title":"generate_rows","text":"<pre><code>generate_rows() -&gt; Generator[str, None, None]\n</code></pre> <p>Generate the rows of the summary totals device under test table.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_rows(self) -&gt; Generator[str, None, None]:\n    \"\"\"Generate the rows of the summary totals device under test table.\"\"\"\n    for device, stat in self.results.device_stats.items():\n        total_tests = stat.tests_success_count + stat.tests_skipped_count + stat.tests_failure_count + stat.tests_error_count + stat.tests_unset_count\n        categories_skipped = \", \".join(sorted(convert_categories(list(stat.categories_skipped))))\n        categories_failed = \", \".join(sorted(convert_categories(list(stat.categories_failed))))\n        yield (\n            f\"| {device} | {total_tests} | {stat.tests_success_count} | {stat.tests_skipped_count} | {stat.tests_failure_count} | {stat.tests_error_count} \"\n            f\"| {categories_skipped or '-'} | {categories_failed or '-'} |\\n\"\n        )\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotalsDeviceUnderTest.generate_section","title":"generate_section","text":"<pre><code>generate_section() -&gt; None\n</code></pre> <p>Generate the <code>### Summary Totals Devices Under Tests</code> section of the markdown report.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_section(self) -&gt; None:\n    \"\"\"Generate the `### Summary Totals Devices Under Tests` section of the markdown report.\"\"\"\n    self.write_heading(heading_level=3)\n    self.write_table(table_heading=self.TABLE_HEADING)\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotalsPerCategory","title":"SummaryTotalsPerCategory","text":"<pre><code>SummaryTotalsPerCategory(\n    mdfile: TextIO, results: ResultManager\n)\n</code></pre> <p>               Bases: <code>MDReportBase</code></p> <p>Generate the <code>### Summary Totals Per Category</code> section of the markdown report.</p>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotalsPerCategory.generate_rows","title":"generate_rows","text":"<pre><code>generate_rows() -&gt; Generator[str, None, None]\n</code></pre> <p>Generate the rows of the summary totals per category table.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_rows(self) -&gt; Generator[str, None, None]:\n    \"\"\"Generate the rows of the summary totals per category table.\"\"\"\n    for category, stat in self.results.category_stats.items():\n        converted_category = convert_categories([category])[0]\n        total_tests = stat.tests_success_count + stat.tests_skipped_count + stat.tests_failure_count + stat.tests_error_count + stat.tests_unset_count\n        yield (\n            f\"| {converted_category} | {total_tests} | {stat.tests_success_count} | {stat.tests_skipped_count} | {stat.tests_failure_count} \"\n            f\"| {stat.tests_error_count} |\\n\"\n        )\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.SummaryTotalsPerCategory.generate_section","title":"generate_section","text":"<pre><code>generate_section() -&gt; None\n</code></pre> <p>Generate the <code>### Summary Totals Per Category</code> section of the markdown report.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_section(self) -&gt; None:\n    \"\"\"Generate the `### Summary Totals Per Category` section of the markdown report.\"\"\"\n    self.write_heading(heading_level=3)\n    self.write_table(table_heading=self.TABLE_HEADING)\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.TestResults","title":"TestResults","text":"<pre><code>TestResults(mdfile: TextIO, results: ResultManager)\n</code></pre> <p>               Bases: <code>MDReportBase</code></p> <p>Generates the <code>## Test Results</code> section of the markdown report.</p>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.TestResults.generate_rows","title":"generate_rows","text":"<pre><code>generate_rows() -&gt; Generator[str, None, None]\n</code></pre> <p>Generate the rows of the all test results table.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_rows(self) -&gt; Generator[str, None, None]:\n    \"\"\"Generate the rows of the all test results table.\"\"\"\n    for result in self.results.results:\n        messages = self.safe_markdown(result.messages[0]) if len(result.messages) == 1 else self.safe_markdown(\"&lt;br&gt;\".join(result.messages))\n        categories = \", \".join(sorted(convert_categories(result.categories)))\n        yield (\n            f\"| {result.name or '-'} | {categories or '-'} | {result.test or '-'} \"\n            f\"| {result.description or '-'} | {self.safe_markdown(result.custom_field) or '-'} | {result.result or '-'} | {messages or '-'} |\\n\"\n        )\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.TestResults.generate_section","title":"generate_section","text":"<pre><code>generate_section() -&gt; None\n</code></pre> <p>Generate the <code>## Test Results</code> section of the markdown report.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_section(self) -&gt; None:\n    \"\"\"Generate the `## Test Results` section of the markdown report.\"\"\"\n    self.write_heading(heading_level=2)\n    self.write_table(table_heading=self.TABLE_HEADING, last_table=True)\n</code></pre>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.TestResultsSummary","title":"TestResultsSummary","text":"<pre><code>TestResultsSummary(mdfile: TextIO, results: ResultManager)\n</code></pre> <p>               Bases: <code>MDReportBase</code></p> <p>Generate the <code>## Test Results Summary</code> section of the markdown report.</p>"},{"location":"api/reporter/markdown/#anta.reporter.md_reporter.TestResultsSummary.generate_section","title":"generate_section","text":"<pre><code>generate_section() -&gt; None\n</code></pre> <p>Generate the <code>## Test Results Summary</code> section of the markdown report.</p> Source code in <code>anta/reporter/md_reporter.py</code> <pre><code>def generate_section(self) -&gt; None:\n    \"\"\"Generate the `## Test Results Summary` section of the markdown report.\"\"\"\n    self.write_heading(heading_level=2)\n</code></pre>"},{"location":"api/reporter/table/","title":"Table","text":""},{"location":"api/reporter/table/#anta.reporter.ReportTable","title":"ReportTable","text":"<p>TableReport Generate a Table based on TestResult.</p>"},{"location":"api/reporter/table/#anta.reporter.ReportTable.Headers","title":"Headers  <code>dataclass</code>","text":"<pre><code>Headers(\n    device: str = \"Device\",\n    test_case: str = \"Test Name\",\n    number_of_success: str = \"# of success\",\n    number_of_failure: str = \"# of failure\",\n    number_of_skipped: str = \"# of skipped\",\n    number_of_errors: str = \"# of errors\",\n    list_of_error_nodes: str = \"List of failed or error nodes\",\n    list_of_error_tests: str = \"List of failed or error test cases\",\n)\n</code></pre> <p>Headers for the table report.</p>"},{"location":"api/reporter/table/#anta.reporter.ReportTable.report_all","title":"report_all","text":"<pre><code>report_all(\n    manager: ResultManager, title: str = \"All tests results\"\n) -&gt; Table\n</code></pre> <p>Create a table report with all tests for one or all devices.</p> <p>Create table with full output: Device | Test Name | Test Status | Message(s) | Test description | Test category</p> <p>Parameters:</p> Name Type Description Default <code>manager</code> <code>ResultManager</code> <p>A ResultManager instance.</p> required <code>title</code> <code>str</code> <p>Title for the report. Defaults to \u2018All tests results\u2019.</p> <code>'All tests results'</code> <p>Returns:</p> Type Description <code>Table</code> <p>A fully populated rich <code>Table</code>.</p> Source code in <code>anta/reporter/__init__.py</code> <pre><code>def report_all(self, manager: ResultManager, title: str = \"All tests results\") -&gt; Table:\n    \"\"\"Create a table report with all tests for one or all devices.\n\n    Create table with full output: Device | Test Name | Test Status | Message(s) | Test description | Test category\n\n    Parameters\n    ----------\n    manager\n        A ResultManager instance.\n    title\n        Title for the report. Defaults to 'All tests results'.\n\n    Returns\n    -------\n    Table\n        A fully populated rich `Table`.\n    \"\"\"\n    table = Table(title=title, show_lines=True)\n    headers = [\"Device\", \"Test Name\", \"Test Status\", \"Message(s)\", \"Test description\", \"Test category\"]\n    table = self._build_headers(headers=headers, table=table)\n\n    def add_line(result: TestResult) -&gt; None:\n        state = self._color_result(result.result)\n        message = self._split_list_to_txt_list(result.messages) if len(result.messages) &gt; 0 else \"\"\n        categories = \", \".join(convert_categories(result.categories))\n        table.add_row(str(result.name), result.test, state, message, result.description, categories)\n\n    for result in manager.results:\n        add_line(result)\n    return table\n</code></pre>"},{"location":"api/reporter/table/#anta.reporter.ReportTable.report_summary_devices","title":"report_summary_devices","text":"<pre><code>report_summary_devices(\n    manager: ResultManager,\n    devices: list[str] | None = None,\n    title: str = \"Summary per device\",\n) -&gt; Table\n</code></pre> <p>Create a table report with result aggregated per device.</p> <p>Create table with full output: Device | # of success | # of skipped | # of failure | # of errors | List of failed or error test cases</p> <p>Parameters:</p> Name Type Description Default <code>manager</code> <code>ResultManager</code> <p>A ResultManager instance.</p> required <code>devices</code> <code>list[str] | None</code> <p>List of device names to include. None to select all devices.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the report.</p> <code>'Summary per device'</code> <p>Returns:</p> Type Description <code>Table</code> <p>A fully populated rich <code>Table</code>.</p> Source code in <code>anta/reporter/__init__.py</code> <pre><code>def report_summary_devices(\n    self,\n    manager: ResultManager,\n    devices: list[str] | None = None,\n    title: str = \"Summary per device\",\n) -&gt; Table:\n    \"\"\"Create a table report with result aggregated per device.\n\n    Create table with full output: Device | # of success | # of skipped | # of failure | # of errors | List of failed or error test cases\n\n    Parameters\n    ----------\n    manager\n        A ResultManager instance.\n    devices\n        List of device names to include. None to select all devices.\n    title\n        Title of the report.\n\n    Returns\n    -------\n    Table\n        A fully populated rich `Table`.\n    \"\"\"\n    table = Table(title=title, show_lines=True)\n    headers = [\n        self.Headers.device,\n        self.Headers.number_of_success,\n        self.Headers.number_of_skipped,\n        self.Headers.number_of_failure,\n        self.Headers.number_of_errors,\n        self.Headers.list_of_error_tests,\n    ]\n    table = self._build_headers(headers=headers, table=table)\n    for device, stats in manager.device_stats.items():\n        if devices is None or device in devices:\n            table.add_row(\n                device,\n                str(stats.tests_success_count),\n                str(stats.tests_skipped_count),\n                str(stats.tests_failure_count),\n                str(stats.tests_error_count),\n                \", \".join(stats.tests_failure),\n            )\n    return table\n</code></pre>"},{"location":"api/reporter/table/#anta.reporter.ReportTable.report_summary_tests","title":"report_summary_tests","text":"<pre><code>report_summary_tests(\n    manager: ResultManager,\n    tests: list[str] | None = None,\n    title: str = \"Summary per test\",\n) -&gt; Table\n</code></pre> <p>Create a table report with result aggregated per test.</p> <p>Create table with full output: Test Name | # of success | # of skipped | # of failure | # of errors | List of failed or error nodes</p> <p>Parameters:</p> Name Type Description Default <code>manager</code> <code>ResultManager</code> <p>A ResultManager instance.</p> required <code>tests</code> <code>list[str] | None</code> <p>List of test names to include. None to select all tests.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the report.</p> <code>'Summary per test'</code> <p>Returns:</p> Type Description <code>Table</code> <p>A fully populated rich <code>Table</code>.</p> Source code in <code>anta/reporter/__init__.py</code> <pre><code>def report_summary_tests(\n    self,\n    manager: ResultManager,\n    tests: list[str] | None = None,\n    title: str = \"Summary per test\",\n) -&gt; Table:\n    \"\"\"Create a table report with result aggregated per test.\n\n    Create table with full output:\n    Test Name | # of success | # of skipped | # of failure | # of errors | List of failed or error nodes\n\n    Parameters\n    ----------\n    manager\n        A ResultManager instance.\n    tests\n        List of test names to include. None to select all tests.\n    title\n        Title of the report.\n\n    Returns\n    -------\n    Table\n        A fully populated rich `Table`.\n    \"\"\"\n    table = Table(title=title, show_lines=True)\n    headers = [\n        self.Headers.test_case,\n        self.Headers.number_of_success,\n        self.Headers.number_of_skipped,\n        self.Headers.number_of_failure,\n        self.Headers.number_of_errors,\n        self.Headers.list_of_error_nodes,\n    ]\n    table = self._build_headers(headers=headers, table=table)\n    for test, stats in manager.test_stats.items():\n        if tests is None or test in tests:\n            table.add_row(\n                test,\n                str(stats.devices_success_count),\n                str(stats.devices_skipped_count),\n                str(stats.devices_failure_count),\n                str(stats.devices_error_count),\n                \", \".join(stats.devices_failure),\n            )\n    return table\n</code></pre>"},{"location":"api/tests/aaa/","title":"AAA","text":"<p>Module related to the EOS various AAA tests.</p>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyAcctConsoleMethods","title":"VerifyAcctConsoleMethods","text":"<p>Verifies the AAA accounting console method lists for different accounting types (system, exec, commands, dot1x).</p> Expected Results <ul> <li>Success: The test will pass if the provided AAA accounting console method list is matching in the configured accounting types.</li> <li>Failure: The test will fail if the provided AAA accounting console method list is NOT matching in the configured accounting types.</li> </ul> Examples <pre><code>anta.tests.aaa:\n  - VerifyAcctConsoleMethods:\n      methods:\n        - local\n        - none\n        - logging\n      types:\n        - system\n        - exec\n        - commands\n        - dot1x\n</code></pre> Source code in <code>anta/tests/aaa.py</code> <pre><code>class VerifyAcctConsoleMethods(AntaTest):\n    \"\"\"Verifies the AAA accounting console method lists for different accounting types (system, exec, commands, dot1x).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided AAA accounting console method list is matching in the configured accounting types.\n    * Failure: The test will fail if the provided AAA accounting console method list is NOT matching in the configured accounting types.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.aaa:\n      - VerifyAcctConsoleMethods:\n          methods:\n            - local\n            - none\n            - logging\n          types:\n            - system\n            - exec\n            - commands\n            - dot1x\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"aaa\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show aaa methods accounting\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyAcctConsoleMethods test.\"\"\"\n\n        methods: list[AAAAuthMethod]\n        \"\"\"List of AAA accounting console methods. Methods should be in the right order.\"\"\"\n        types: set[Literal[\"commands\", \"exec\", \"system\", \"dot1x\"]]\n        \"\"\"List of accounting console types to verify.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAcctConsoleMethods.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        not_matching = []\n        not_configured = []\n        for k, v in command_output.items():\n            acct_type = k.replace(\"AcctMethods\", \"\")\n            if acct_type not in self.inputs.types:\n                # We do not need to verify this accounting type\n                continue\n            for methods in v.values():\n                if \"consoleAction\" not in methods:\n                    not_configured.append(acct_type)\n                if methods[\"consoleMethods\"] != self.inputs.methods:\n                    not_matching.append(acct_type)\n        if not_configured:\n            self.result.is_failure(f\"AAA console accounting is not configured for {', '.join(not_configured)}\")\n            return\n        if not not_matching:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"AAA accounting console methods {', '.join(self.inputs.methods)} are not matching for {', '.join(not_matching)}\")\n</code></pre>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyAcctConsoleMethods-attributes","title":"Inputs","text":"Name Type Description Default <code>methods</code> <code>list[AAAAuthMethod]</code>                      List of AAA accounting console methods. Methods should be in the right order.                    - <code>types</code> <code>set[Literal['commands', 'exec', 'system', 'dot1x']]</code>                      List of accounting console types to verify.                    -"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyAcctDefaultMethods","title":"VerifyAcctDefaultMethods","text":"<p>Verifies the AAA accounting default method lists for different accounting types (system, exec, commands, dot1x).</p> Expected Results <ul> <li>Success: The test will pass if the provided AAA accounting default method list is matching in the configured accounting types.</li> <li>Failure: The test will fail if the provided AAA accounting default method list is NOT matching in the configured accounting types.</li> </ul> Examples <pre><code>anta.tests.aaa:\n  - VerifyAcctDefaultMethods:\n      methods:\n        - local\n        - none\n        - logging\n      types:\n        - system\n        - exec\n        - commands\n        - dot1x\n</code></pre> Source code in <code>anta/tests/aaa.py</code> <pre><code>class VerifyAcctDefaultMethods(AntaTest):\n    \"\"\"Verifies the AAA accounting default method lists for different accounting types (system, exec, commands, dot1x).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided AAA accounting default method list is matching in the configured accounting types.\n    * Failure: The test will fail if the provided AAA accounting default method list is NOT matching in the configured accounting types.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.aaa:\n      - VerifyAcctDefaultMethods:\n          methods:\n            - local\n            - none\n            - logging\n          types:\n            - system\n            - exec\n            - commands\n            - dot1x\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"aaa\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show aaa methods accounting\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyAcctDefaultMethods test.\"\"\"\n\n        methods: list[AAAAuthMethod]\n        \"\"\"List of AAA accounting methods. Methods should be in the right order.\"\"\"\n        types: set[Literal[\"commands\", \"exec\", \"system\", \"dot1x\"]]\n        \"\"\"List of accounting types to verify.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAcctDefaultMethods.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        not_matching = []\n        not_configured = []\n        for k, v in command_output.items():\n            acct_type = k.replace(\"AcctMethods\", \"\")\n            if acct_type not in self.inputs.types:\n                # We do not need to verify this accounting type\n                continue\n            for methods in v.values():\n                if \"defaultAction\" not in methods:\n                    not_configured.append(acct_type)\n                if methods[\"defaultMethods\"] != self.inputs.methods:\n                    not_matching.append(acct_type)\n        if not_configured:\n            self.result.is_failure(f\"AAA default accounting is not configured for {', '.join(not_configured)}\")\n            return\n        if not not_matching:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"AAA accounting default methods {', '.join(self.inputs.methods)} are not matching for {', '.join(not_matching)}\")\n</code></pre>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyAcctDefaultMethods-attributes","title":"Inputs","text":"Name Type Description Default <code>methods</code> <code>list[AAAAuthMethod]</code>                      List of AAA accounting methods. Methods should be in the right order.                    - <code>types</code> <code>set[Literal['commands', 'exec', 'system', 'dot1x']]</code>                      List of accounting types to verify.                    -"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyAuthenMethods","title":"VerifyAuthenMethods","text":"<p>Verifies the AAA authentication method lists for different authentication types (login, enable, dot1x).</p> Expected Results <ul> <li>Success: The test will pass if the provided AAA authentication method list is matching in the configured authentication types.</li> <li>Failure: The test will fail if the provided AAA authentication method list is NOT matching in the configured authentication types.</li> </ul> Examples <pre><code>anta.tests.aaa:\n  - VerifyAuthenMethods:\n      methods:\n        - local\n        - none\n        - logging\n      types:\n        - login\n        - enable\n        - dot1x\n</code></pre> Source code in <code>anta/tests/aaa.py</code> <pre><code>class VerifyAuthenMethods(AntaTest):\n    \"\"\"Verifies the AAA authentication method lists for different authentication types (login, enable, dot1x).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided AAA authentication method list is matching in the configured authentication types.\n    * Failure: The test will fail if the provided AAA authentication method list is NOT matching in the configured authentication types.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.aaa:\n      - VerifyAuthenMethods:\n          methods:\n            - local\n            - none\n            - logging\n          types:\n            - login\n            - enable\n            - dot1x\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"aaa\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show aaa methods authentication\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyAuthenMethods test.\"\"\"\n\n        methods: list[AAAAuthMethod]\n        \"\"\"List of AAA authentication methods. Methods should be in the right order.\"\"\"\n        types: set[Literal[\"login\", \"enable\", \"dot1x\"]]\n        \"\"\"List of authentication types to verify.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAuthenMethods.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        not_matching: list[str] = []\n        for k, v in command_output.items():\n            auth_type = k.replace(\"AuthenMethods\", \"\")\n            if auth_type not in self.inputs.types:\n                # We do not need to verify this accounting type\n                continue\n            if auth_type == \"login\":\n                if \"login\" not in v:\n                    self.result.is_failure(\"AAA authentication methods are not configured for login console\")\n                    return\n                if v[\"login\"][\"methods\"] != self.inputs.methods:\n                    self.result.is_failure(f\"AAA authentication methods {', '.join(self.inputs.methods)} are not matching for login console\")\n                    return\n            not_matching.extend(auth_type for methods in v.values() if methods[\"methods\"] != self.inputs.methods)\n\n        if not not_matching:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"AAA authentication methods {', '.join(self.inputs.methods)} are not matching for {', '.join(not_matching)}\")\n</code></pre>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyAuthenMethods-attributes","title":"Inputs","text":"Name Type Description Default <code>methods</code> <code>list[AAAAuthMethod]</code>                      List of AAA authentication methods. Methods should be in the right order.                    - <code>types</code> <code>set[Literal['login', 'enable', 'dot1x']]</code>                      List of authentication types to verify.                    -"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyAuthzMethods","title":"VerifyAuthzMethods","text":"<p>Verifies the AAA authorization method lists for different authorization types (commands, exec).</p> Expected Results <ul> <li>Success: The test will pass if the provided AAA authorization method list is matching in the configured authorization types.</li> <li>Failure: The test will fail if the provided AAA authorization method list is NOT matching in the configured authorization types.</li> </ul> Examples <pre><code>anta.tests.aaa:\n  - VerifyAuthzMethods:\n      methods:\n        - local\n        - none\n        - logging\n      types:\n        - commands\n        - exec\n</code></pre> Source code in <code>anta/tests/aaa.py</code> <pre><code>class VerifyAuthzMethods(AntaTest):\n    \"\"\"Verifies the AAA authorization method lists for different authorization types (commands, exec).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided AAA authorization method list is matching in the configured authorization types.\n    * Failure: The test will fail if the provided AAA authorization method list is NOT matching in the configured authorization types.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.aaa:\n      - VerifyAuthzMethods:\n          methods:\n            - local\n            - none\n            - logging\n          types:\n            - commands\n            - exec\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"aaa\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show aaa methods authorization\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyAuthzMethods test.\"\"\"\n\n        methods: list[AAAAuthMethod]\n        \"\"\"List of AAA authorization methods. Methods should be in the right order.\"\"\"\n        types: set[Literal[\"commands\", \"exec\"]]\n        \"\"\"List of authorization types to verify.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAuthzMethods.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        not_matching: list[str] = []\n        for k, v in command_output.items():\n            authz_type = k.replace(\"AuthzMethods\", \"\")\n            if authz_type not in self.inputs.types:\n                # We do not need to verify this accounting type\n                continue\n            not_matching.extend(authz_type for methods in v.values() if methods[\"methods\"] != self.inputs.methods)\n\n        if not not_matching:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"AAA authorization methods {', '.join(self.inputs.methods)} are not matching for {', '.join(not_matching)}\")\n</code></pre>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyAuthzMethods-attributes","title":"Inputs","text":"Name Type Description Default <code>methods</code> <code>list[AAAAuthMethod]</code>                      List of AAA authorization methods. Methods should be in the right order.                    - <code>types</code> <code>set[Literal['commands', 'exec']]</code>                      List of authorization types to verify.                    -"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyTacacsServerGroups","title":"VerifyTacacsServerGroups","text":"<p>Verifies if the provided TACACS server group(s) are configured.</p> Expected Results <ul> <li>Success: The test will pass if the provided TACACS server group(s) are configured.</li> <li>Failure: The test will fail if one or all the provided TACACS server group(s) are NOT configured.</li> </ul> Examples <pre><code>anta.tests.aaa:\n  - VerifyTacacsServerGroups:\n      groups:\n        - TACACS-GROUP1\n        - TACACS-GROUP2\n</code></pre> Source code in <code>anta/tests/aaa.py</code> <pre><code>class VerifyTacacsServerGroups(AntaTest):\n    \"\"\"Verifies if the provided TACACS server group(s) are configured.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided TACACS server group(s) are configured.\n    * Failure: The test will fail if one or all the provided TACACS server group(s) are NOT configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.aaa:\n      - VerifyTacacsServerGroups:\n          groups:\n            - TACACS-GROUP1\n            - TACACS-GROUP2\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"aaa\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show tacacs\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyTacacsServerGroups test.\"\"\"\n\n        groups: list[str]\n        \"\"\"List of TACACS server groups.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTacacsServerGroups.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        tacacs_groups = command_output[\"groups\"]\n        if not tacacs_groups:\n            self.result.is_failure(\"No TACACS server group(s) are configured\")\n            return\n        not_configured = [group for group in self.inputs.groups if group not in tacacs_groups]\n        if not not_configured:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"TACACS server group(s) {', '.join(not_configured)} are not configured\")\n</code></pre>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyTacacsServerGroups-attributes","title":"Inputs","text":"Name Type Description Default <code>groups</code> <code>list[str]</code>                      List of TACACS server groups.                    -"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyTacacsServers","title":"VerifyTacacsServers","text":"<p>Verifies TACACS servers are configured for a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if the provided TACACS servers are configured in the specified VRF.</li> <li>Failure: The test will fail if the provided TACACS servers are NOT configured in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.aaa:\n  - VerifyTacacsServers:\n      servers:\n        - 10.10.10.21\n        - 10.10.10.22\n      vrf: MGMT\n</code></pre> Source code in <code>anta/tests/aaa.py</code> <pre><code>class VerifyTacacsServers(AntaTest):\n    \"\"\"Verifies TACACS servers are configured for a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided TACACS servers are configured in the specified VRF.\n    * Failure: The test will fail if the provided TACACS servers are NOT configured in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.aaa:\n      - VerifyTacacsServers:\n          servers:\n            - 10.10.10.21\n            - 10.10.10.22\n          vrf: MGMT\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"aaa\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show tacacs\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyTacacsServers test.\"\"\"\n\n        servers: list[IPv4Address]\n        \"\"\"List of TACACS servers.\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF to transport TACACS messages. Defaults to `default`.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTacacsServers.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        tacacs_servers = command_output[\"tacacsServers\"]\n        if not tacacs_servers:\n            self.result.is_failure(\"No TACACS servers are configured\")\n            return\n        not_configured = [\n            str(server)\n            for server in self.inputs.servers\n            if not any(\n                str(server) == tacacs_server[\"serverInfo\"][\"hostname\"] and self.inputs.vrf == tacacs_server[\"serverInfo\"][\"vrf\"] for tacacs_server in tacacs_servers\n            )\n        ]\n        if not not_configured:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"TACACS servers {', '.join(not_configured)} are not configured in VRF {self.inputs.vrf}\")\n</code></pre>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyTacacsServers-attributes","title":"Inputs","text":"Name Type Description Default <code>servers</code> <code>list[IPv4Address]</code>                      List of TACACS servers.                    - <code>vrf</code> <code>str</code>                      The name of the VRF to transport TACACS messages. Defaults to `default`.                    <code>'default'</code>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyTacacsSourceIntf","title":"VerifyTacacsSourceIntf","text":"<p>Verifies TACACS source-interface for a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if the provided TACACS source-interface is configured in the specified VRF.</li> <li>Failure: The test will fail if the provided TACACS source-interface is NOT configured in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.aaa:\n  - VerifyTacacsSourceIntf:\n      intf: Management0\n      vrf: MGMT\n</code></pre> Source code in <code>anta/tests/aaa.py</code> <pre><code>class VerifyTacacsSourceIntf(AntaTest):\n    \"\"\"Verifies TACACS source-interface for a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided TACACS source-interface is configured in the specified VRF.\n    * Failure: The test will fail if the provided TACACS source-interface is NOT configured in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.aaa:\n      - VerifyTacacsSourceIntf:\n          intf: Management0\n          vrf: MGMT\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"aaa\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show tacacs\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyTacacsSourceIntf test.\"\"\"\n\n        intf: str\n        \"\"\"Source-interface to use as source IP of TACACS messages.\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF to transport TACACS messages. Defaults to `default`.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTacacsSourceIntf.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        try:\n            if (src_interface := command_output[\"srcIntf\"][self.inputs.vrf]) == self.inputs.intf:\n                self.result.is_success()\n            else:\n                self.result.is_failure(f\"VRF: {self.inputs.vrf} - Source interface mismatch - Expected: {self.inputs.intf} Actual: {src_interface}\")\n        except KeyError:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} Source Interface: {self.inputs.intf} - Not configured\")\n</code></pre>"},{"location":"api/tests/aaa/#anta.tests.aaa.VerifyTacacsSourceIntf-attributes","title":"Inputs","text":"Name Type Description Default <code>intf</code> <code>str</code>                      Source-interface to use as source IP of TACACS messages.                    - <code>vrf</code> <code>str</code>                      The name of the VRF to transport TACACS messages. Defaults to `default`.                    <code>'default'</code>"},{"location":"api/tests/anta_test/","title":"AntaTest","text":""},{"location":"api/tests/anta_test/#anta.models.AntaTest","title":"AntaTest","text":"<pre><code>AntaTest(\n    device: AntaDevice,\n    inputs: dict[str, Any] | Input | None = None,\n    eos_data: list[dict[Any, Any] | str] | None = None,\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract class defining a test in ANTA.</p> <p>The goal of this class is to handle the heavy lifting and make writing a test as simple as possible.</p> Examples <p>The following is an example of an AntaTest subclass implementation:     <pre><code>    class VerifyReachability(AntaTest):\n        '''Test the network reachability to one or many destination IP(s).'''\n        categories = [\"connectivity\"]\n        commands = [AntaTemplate(template=\"ping vrf {vrf} {dst} source {src} repeat 2\")]\n\n        class Input(AntaTest.Input):\n            hosts: list[Host]\n            class Host(BaseModel):\n                dst: IPv4Address\n                src: IPv4Address\n                vrf: str = \"default\"\n\n        def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n            return [template.render(dst=host.dst, src=host.src, vrf=host.vrf) for host in self.inputs.hosts]\n\n        @AntaTest.anta_test\n        def test(self) -&gt; None:\n            failures = []\n            for command in self.instance_commands:\n                src, dst = command.params.src, command.params.dst\n                if \"2 received\" not in command.json_output[\"messages\"][0]:\n                    failures.append((str(src), str(dst)))\n            if not failures:\n                self.result.is_success()\n            else:\n                self.result.is_failure(f\"Connectivity test failed for the following source-destination pairs: {failures}\")\n</code></pre></p> <p>Attributes:</p> Name Type Description <code>device</code> <code>AntaDevice</code> <p>AntaDevice instance on which this test is run.</p> <code>inputs</code> <code>Input</code> <p>AntaTest.Input instance carrying the test inputs.</p> <code>instance_commands</code> <code>list[AntaCommand]</code> <p>List of AntaCommand instances of this test.</p> <code>result</code> <code>TestResult</code> <p>TestResult instance representing the result of this test.</p> <code>logger</code> <code>Logger</code> <p>Python logger for this test instance.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>AntaDevice</code> <p>AntaDevice instance on which the test will be run.</p> required <code>inputs</code> <code>dict[str, Any] | Input | None</code> <p>Dictionary of attributes used to instantiate the AntaTest.Input instance.</p> <code>None</code> <code>eos_data</code> <code>list[dict[Any, Any] | str] | None</code> <p>Populate outputs of the test commands instead of collecting from devices. This list must have the same length and order than the <code>instance_commands</code> instance attribute.</p> <code>None</code>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.blocked","title":"blocked  <code>property</code>","text":"<pre><code>blocked: bool\n</code></pre> <p>Check if CLI commands contain a blocked keyword.</p>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.collected","title":"collected  <code>property</code>","text":"<pre><code>collected: bool\n</code></pre> <p>Return True if all commands for this test have been collected.</p>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.failed_commands","title":"failed_commands  <code>property</code>","text":"<pre><code>failed_commands: list[AntaCommand]\n</code></pre> <p>Return a list of all the commands that have failed.</p>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.module","title":"module  <code>property</code>","text":"<pre><code>module: str\n</code></pre> <p>Return the Python module in which this AntaTest class is defined.</p>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.Input","title":"Input","text":"<p>               Bases: <code>BaseModel</code></p> <p>Class defining inputs for a test in ANTA.</p> Examples <p>A valid test catalog will look like the following:     <pre><code>&lt;Python module&gt;:\n- &lt;AntaTest subclass&gt;:\n    result_overwrite:\n        categories:\n        - \"Overwritten category 1\"\n        description: \"Test with overwritten description\"\n        custom_field: \"Test run by John Doe\"\n</code></pre></p> <p>Attributes:</p> Name Type Description <code>result_overwrite</code> <code>ResultOverwrite | None</code> <p>Define fields to overwrite in the TestResult object.</p>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.Input.Filters","title":"Filters","text":"<p>               Bases: <code>BaseModel</code></p> <p>Runtime filters to map tests with list of tags or devices.</p> <p>Attributes:</p> Name Type Description <code>tags</code> <code>set[str] | None</code> <p>Tag of devices on which to run the test.</p>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.Input.ResultOverwrite","title":"ResultOverwrite","text":"<p>               Bases: <code>BaseModel</code></p> <p>Test inputs model to overwrite result fields.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str | None</code> <p>Overwrite <code>TestResult.description</code>.</p> <code>categories</code> <code>list[str] | None</code> <p>Overwrite <code>TestResult.categories</code>.</p> <code>custom_field</code> <code>str | None</code> <p>A free string that will be included in the TestResult object.</p>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.anta_test","title":"anta_test  <code>staticmethod</code>","text":"<pre><code>anta_test(\n    function: F,\n) -&gt; Callable[..., Coroutine[Any, Any, TestResult]]\n</code></pre> <p>Decorate the <code>test()</code> method in child classes.</p> <p>This decorator implements (in this order):</p> <ol> <li>Instantiate the command outputs if <code>eos_data</code> is provided to the <code>test()</code> method</li> <li>Collect the commands from the device</li> <li>Run the <code>test()</code> method</li> <li>Catches any exception in <code>test()</code> user code and set the <code>result</code> instance attribute</li> </ol> Source code in <code>anta/models.py</code> <pre><code>@staticmethod\ndef anta_test(function: F) -&gt; Callable[..., Coroutine[Any, Any, TestResult]]:\n    \"\"\"Decorate the `test()` method in child classes.\n\n    This decorator implements (in this order):\n\n    1. Instantiate the command outputs if `eos_data` is provided to the `test()` method\n    2. Collect the commands from the device\n    3. Run the `test()` method\n    4. Catches any exception in `test()` user code and set the `result` instance attribute\n    \"\"\"\n\n    @wraps(function)\n    async def wrapper(\n        self: AntaTest,\n        eos_data: list[dict[Any, Any] | str] | None = None,\n        **kwargs: dict[str, Any],\n    ) -&gt; TestResult:\n        \"\"\"Inner function for the anta_test decorator.\n\n        Parameters\n        ----------\n        self\n            The test instance.\n        eos_data\n            Populate outputs of the test commands instead of collecting from devices.\n            This list must have the same length and order than the `instance_commands` instance attribute.\n        kwargs\n            Any keyword argument to pass to the test.\n\n        Returns\n        -------\n        TestResult\n            The TestResult instance attribute populated with error status if any.\n\n        \"\"\"\n        if self.result.result != \"unset\":\n            return self.result\n\n        # Data\n        if eos_data is not None:\n            self.save_commands_data(eos_data)\n            self.logger.debug(\"Test %s initialized with input data %s\", self.name, eos_data)\n\n        # If some data is missing, try to collect\n        if not self.collected:\n            await self.collect()\n            if self.result.result != \"unset\":\n                AntaTest.update_progress()\n                return self.result\n\n            if self.failed_commands:\n                self._handle_failed_commands()\n\n                AntaTest.update_progress()\n                return self.result\n\n        try:\n            function(self, **kwargs)\n        except Exception as e:  # noqa: BLE001\n            # test() is user-defined code.\n            # We need to catch everything if we want the AntaTest object\n            # to live until the reporting\n            message = f\"Exception raised for test {self.name} (on device {self.device.name})\"\n            anta_log_exception(e, message, self.logger)\n            self.result.is_error(message=exc_to_str(e))\n\n        # TODO: find a correct way to time test execution\n        AntaTest.update_progress()\n        return self.result\n\n    return wrapper\n</code></pre>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.collect","title":"collect  <code>async</code>","text":"<pre><code>collect() -&gt; None\n</code></pre> <p>Collect outputs of all commands of this test class from the device of this test instance.</p> Source code in <code>anta/models.py</code> <pre><code>async def collect(self) -&gt; None:\n    \"\"\"Collect outputs of all commands of this test class from the device of this test instance.\"\"\"\n    try:\n        if self.blocked is False:\n            await self.device.collect_commands(self.instance_commands, collection_id=self.name)\n    except Exception as e:  # noqa: BLE001\n        # device._collect() is user-defined code.\n        # We need to catch everything if we want the AntaTest object\n        # to live until the reporting\n        message = f\"Exception raised while collecting commands for test {self.name} (on device {self.device.name})\"\n        anta_log_exception(e, message, self.logger)\n        self.result.is_error(message=exc_to_str(e))\n</code></pre>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.render","title":"render","text":"<pre><code>render(template: AntaTemplate) -&gt; list[AntaCommand]\n</code></pre> <p>Render an AntaTemplate instance of this AntaTest using the provided AntaTest.Input instance at self.inputs.</p> <p>This is not an abstract method because it does not need to be implemented if there is no AntaTemplate for this test.</p> Source code in <code>anta/models.py</code> <pre><code>def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n    \"\"\"Render an AntaTemplate instance of this AntaTest using the provided AntaTest.Input instance at self.inputs.\n\n    This is not an abstract method because it does not need to be implemented if there is\n    no AntaTemplate for this test.\n    \"\"\"\n    _ = template\n    msg = f\"AntaTemplate are provided but render() method has not been implemented for {self.module}.{self.__class__.__name__}\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.save_commands_data","title":"save_commands_data","text":"<pre><code>save_commands_data(\n    eos_data: list[dict[str, Any] | str],\n) -&gt; None\n</code></pre> <p>Populate output of all AntaCommand instances in <code>instance_commands</code>.</p> Source code in <code>anta/models.py</code> <pre><code>def save_commands_data(self, eos_data: list[dict[str, Any] | str]) -&gt; None:\n    \"\"\"Populate output of all AntaCommand instances in `instance_commands`.\"\"\"\n    if len(eos_data) &gt; len(self.instance_commands):\n        self.result.is_error(message=\"Test initialization error: Trying to save more data than there are commands for the test\")\n        return\n    if len(eos_data) &lt; len(self.instance_commands):\n        self.result.is_error(message=\"Test initialization error: Trying to save less data than there are commands for the test\")\n        return\n    for index, data in enumerate(eos_data or []):\n        self.instance_commands[index].output = data\n</code></pre>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.test","title":"test  <code>abstractmethod</code>","text":"<pre><code>test() -&gt; Coroutine[Any, Any, TestResult]\n</code></pre> <p>Core of the test logic.</p> <p>This is an abstractmethod that must be implemented by child classes. It must set the correct status of the <code>result</code> instance attribute with the appropriate outcome of the test.</p> Examples <p>It must be implemented using the <code>AntaTest.anta_test</code> decorator:     <pre><code>@AntaTest.anta_test\ndef test(self) -&gt; None:\n    self.result.is_success()\n    for command in self.instance_commands:\n        if not self._test_command(command): # _test_command() is an arbitrary test logic\n            self.result.is_failure(\"Failure reason\")\n</code></pre></p> Source code in <code>anta/models.py</code> <pre><code>@abstractmethod\ndef test(self) -&gt; Coroutine[Any, Any, TestResult]:\n    \"\"\"Core of the test logic.\n\n    This is an abstractmethod that must be implemented by child classes.\n    It must set the correct status of the `result` instance attribute with the appropriate outcome of the test.\n\n    Examples\n    --------\n    It must be implemented using the `AntaTest.anta_test` decorator:\n        ```python\n        @AntaTest.anta_test\n        def test(self) -&gt; None:\n            self.result.is_success()\n            for command in self.instance_commands:\n                if not self._test_command(command): # _test_command() is an arbitrary test logic\n                    self.result.is_failure(\"Failure reason\")\n        ```\n\n    \"\"\"\n</code></pre>"},{"location":"api/tests/anta_test/#anta.models.AntaTest.update_progress","title":"update_progress  <code>classmethod</code>","text":"<pre><code>update_progress() -&gt; None\n</code></pre> <p>Update progress bar for all AntaTest objects if it exists.</p> Source code in <code>anta/models.py</code> <pre><code>@classmethod\ndef update_progress(cls: type[AntaTest]) -&gt; None:\n    \"\"\"Update progress bar for all AntaTest objects if it exists.\"\"\"\n    if cls.progress and (cls.nrfu_task is not None):\n        cls.progress.update(cls.nrfu_task, advance=1)\n</code></pre>"},{"location":"api/tests/avt/","title":"Adaptive Virtual Topology","text":""},{"location":"api/tests/avt/#tests","title":"Tests","text":"<p>Module related to Adaptive virtual topology tests.</p>"},{"location":"api/tests/avt/#anta.tests.avt.VerifyAVTPathHealth","title":"VerifyAVTPathHealth","text":"<p>Verifies the status of all Adaptive Virtual Topology (AVT) paths for all VRFs.</p> Expected Results <ul> <li>Success: The test will pass if all AVT paths for all VRFs are active and valid.</li> <li>Failure: The test will fail if the AVT path is not configured or if any AVT path under any VRF is either inactive or invalid.</li> </ul> Examples <pre><code>anta.tests.avt:\n  - VerifyAVTPathHealth:\n</code></pre> Source code in <code>anta/tests/avt.py</code> <pre><code>class VerifyAVTPathHealth(AntaTest):\n    \"\"\"Verifies the status of all Adaptive Virtual Topology (AVT) paths for all VRFs.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all AVT paths for all VRFs are active and valid.\n    * Failure: The test will fail if the AVT path is not configured or if any AVT path under any VRF is either inactive or invalid.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.avt:\n      - VerifyAVTPathHealth:\n    ```\n    \"\"\"\n\n    description = \"Verifies the status of all AVT paths for all VRFs.\"\n    categories: ClassVar[list[str]] = [\"avt\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show adaptive-virtual-topology path\")]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAVTPathHealth.\"\"\"\n        # Initialize the test result as success\n        self.result.is_success()\n\n        # Get the command output\n        command_output = self.instance_commands[0].json_output.get(\"vrfs\", {})\n\n        # Check if AVT is configured\n        if not command_output:\n            self.result.is_failure(\"Adaptive virtual topology paths are not configured\")\n            return\n\n        # Iterate over each VRF\n        for vrf, vrf_data in command_output.items():\n            # Iterate over each AVT path\n            for profile, avt_path in vrf_data.get(\"avts\", {}).items():\n                for path, flags in avt_path.get(\"avtPaths\", {}).items():\n                    # Get the status of the AVT path\n                    valid = flags[\"flags\"][\"valid\"]\n                    active = flags[\"flags\"][\"active\"]\n\n                    # Check the status of the AVT path\n                    if not valid and not active:\n                        self.result.is_failure(f\"VRF: {vrf} Profile: {profile} AVT path: {path} - Invalid and not active\")\n                    elif not valid:\n                        self.result.is_failure(f\"VRF: {vrf} Profile: {profile} AVT path: {path} - Invalid\")\n                    elif not active:\n                        self.result.is_failure(f\"VRF: {vrf} Profile: {profile} AVT path: {path} - Not active\")\n</code></pre>"},{"location":"api/tests/avt/#anta.tests.avt.VerifyAVTRole","title":"VerifyAVTRole","text":"<p>Verifies the Adaptive Virtual Topology (AVT) role of a device.</p> Expected Results <ul> <li>Success: The test will pass if the AVT role of the device matches the expected role.</li> <li>Failure: The test will fail if the AVT is not configured or if the AVT role does not match the expected role.</li> </ul> Examples <pre><code>anta.tests.avt:\n  - VerifyAVTRole:\n      role: edge\n</code></pre> Source code in <code>anta/tests/avt.py</code> <pre><code>class VerifyAVTRole(AntaTest):\n    \"\"\"Verifies the Adaptive Virtual Topology (AVT) role of a device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the AVT role of the device matches the expected role.\n    * Failure: The test will fail if the AVT is not configured or if the AVT role does not match the expected role.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.avt:\n      - VerifyAVTRole:\n          role: edge\n    ```\n    \"\"\"\n\n    description = \"Verifies the AVT role of a device.\"\n    categories: ClassVar[list[str]] = [\"avt\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show adaptive-virtual-topology path\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyAVTRole test.\"\"\"\n\n        role: str\n        \"\"\"Expected AVT role of the device.\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAVTRole.\"\"\"\n        # Initialize the test result as success\n        self.result.is_success()\n\n        # Get the command output\n        command_output = self.instance_commands[0].json_output\n\n        # Check if the AVT role matches the expected role\n        if self.inputs.role != command_output.get(\"role\"):\n            self.result.is_failure(f\"AVT role mismatch - Expected: {self.inputs.role} Actual: {command_output.get('role')}\")\n</code></pre>"},{"location":"api/tests/avt/#anta.tests.avt.VerifyAVTRole-attributes","title":"Inputs","text":"Name Type Description Default <code>role</code> <code>str</code>                      Expected AVT role of the device.                    -"},{"location":"api/tests/avt/#anta.tests.avt.VerifyAVTSpecificPath","title":"VerifyAVTSpecificPath","text":"<p>Verifies the Adaptive Virtual Topology (AVT) path.</p> <p>This test performs the following checks for each specified LLDP neighbor:</p> <ol> <li>Confirming that the AVT paths are associated with the specified VRF.</li> <li>Verifying that each AVT path is active and valid.</li> <li>Ensuring that the AVT path matches the specified type (direct/multihop) if provided.</li> </ol> Expected Results <ul> <li>Success: The test will pass if all of the following conditions are met:<ul> <li>All AVT paths for the specified VRF are active, valid, and match the specified path type (direct/multihop), if provided.</li> <li>If multiple paths are configured, the test will pass only if all paths meet these criteria.</li> </ul> </li> <li>Failure: The test will fail if any of the following conditions are met:<ul> <li>No AVT paths are configured for the specified VRF.</li> <li>Any configured path is inactive, invalid, or does not match the specified type.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.avt:\n  - VerifyAVTSpecificPath:\n      avt_paths:\n        - avt_name: CONTROL-PLANE-PROFILE\n          vrf: default\n          destination: 10.101.255.2\n          next_hop: 10.101.255.1\n          path_type: direct\n</code></pre> Source code in <code>anta/tests/avt.py</code> <pre><code>class VerifyAVTSpecificPath(AntaTest):\n    \"\"\"Verifies the Adaptive Virtual Topology (AVT) path.\n\n    This test performs the following checks for each specified LLDP neighbor:\n\n      1. Confirming that the AVT paths are associated with the specified VRF.\n      2. Verifying that each AVT path is active and valid.\n      3. Ensuring that the AVT path matches the specified type (direct/multihop) if provided.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all of the following conditions are met:\n        - All AVT paths for the specified VRF are active, valid, and match the specified path type (direct/multihop), if provided.\n        - If multiple paths are configured, the test will pass only if all paths meet these criteria.\n    * Failure: The test will fail if any of the following conditions are met:\n        - No AVT paths are configured for the specified VRF.\n        - Any configured path is inactive, invalid, or does not match the specified type.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.avt:\n      - VerifyAVTSpecificPath:\n          avt_paths:\n            - avt_name: CONTROL-PLANE-PROFILE\n              vrf: default\n              destination: 10.101.255.2\n              next_hop: 10.101.255.1\n              path_type: direct\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"avt\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show adaptive-virtual-topology path\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyAVTSpecificPath test.\"\"\"\n\n        avt_paths: list[AVTPath]\n        \"\"\"List of AVT paths to verify.\"\"\"\n        AVTPaths: ClassVar[type[AVTPath]] = AVTPath\n        \"\"\"To maintain backward compatibility.\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAVTSpecificPath.\"\"\"\n        # Assume the test is successful until a failure is detected\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output\n        for avt_path in self.inputs.avt_paths:\n            if (path_output := get_value(command_output, f\"vrfs.{avt_path.vrf}.avts.{avt_path.avt_name}.avtPaths\")) is None:\n                self.result.is_failure(f\"{avt_path} - No AVT path configured\")\n                return\n\n            path_found = path_type_found = False\n\n            # Check each AVT path\n            for path, path_data in path_output.items():\n                dest = path_data.get(\"destination\")\n                nexthop = path_data.get(\"nexthopAddr\")\n                path_type = \"direct\" if get_value(path_data, \"flags.directPath\") else \"multihop\"\n\n                if not avt_path.path_type:\n                    path_found = all([dest == str(avt_path.destination), nexthop == str(avt_path.next_hop)])\n\n                else:\n                    path_type_found = all([dest == str(avt_path.destination), nexthop == str(avt_path.next_hop), path_type == avt_path.path_type])\n                    if path_type_found:\n                        path_found = True\n                        # Check the path status and type against the expected values\n                        valid = get_value(path_data, \"flags.valid\")\n                        active = get_value(path_data, \"flags.active\")\n                        if not all([valid, active]):\n                            self.result.is_failure(f\"{avt_path} - Incorrect path {path} - Valid: {valid} Active: {active}\")\n\n            # If no matching path found, mark the test as failed\n            if not path_found:\n                if avt_path.path_type and not path_type_found:\n                    self.result.is_failure(f\"{avt_path} Path Type: {avt_path.path_type} - Path not found\")\n                else:\n                    self.result.is_failure(f\"{avt_path} - Path not found\")\n</code></pre>"},{"location":"api/tests/avt/#anta.tests.avt.VerifyAVTSpecificPath-attributes","title":"Inputs","text":"Name Type Description Default <code>avt_paths</code> <code>list[AVTPath]</code>                      List of AVT paths to verify.                    - <code>AVTPaths</code> <code>type[AVTPath]</code>                      To maintain backward compatibility.                    <code>AVTPath</code>"},{"location":"api/tests/avt/#input-models","title":"Input models","text":"<p>Module containing input models for AVT tests.</p>"},{"location":"api/tests/avt/#anta.input_models.avt.AVTPath","title":"AVTPath","text":"<p>AVT (Adaptive Virtual Topology) model representing path details and associated information.</p> Name Type Description Default <code>vrf</code> <code>str</code>                      VRF context. Defaults to `default`.                    <code>'default'</code> <code>avt_name</code> <code>str</code>                      The name of the Adaptive Virtual Topology (AVT).                    - <code>destination</code> <code>IPv4Address</code>                      The IPv4 address of the destination peer in the AVT.                    - <code>next_hop</code> <code>IPv4Address</code>                      The IPv4 address of the next hop used to reach the AVT peer.                    - <code>path_type</code> <code>str | None</code>                      Specifies the type of path for the AVT. If not specified, both types 'direct' and 'multihop' are considered.                    <code>None</code> Source code in <code>anta/input_models/avt.py</code> <pre><code>class AVTPath(BaseModel):\n    \"\"\"AVT (Adaptive Virtual Topology) model representing path details and associated information.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    vrf: str = \"default\"\n    \"\"\"VRF context. Defaults to `default`.\"\"\"\n    avt_name: str\n    \"\"\"The name of the Adaptive Virtual Topology (AVT).\"\"\"\n    destination: IPv4Address\n    \"\"\"The IPv4 address of the destination peer in the AVT.\"\"\"\n    next_hop: IPv4Address\n    \"\"\"The IPv4 address of the next hop used to reach the AVT peer.\"\"\"\n    path_type: str | None = None\n    \"\"\"Specifies the type of path for the AVT. If not specified, both types 'direct' and 'multihop' are considered.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the AVTPath for reporting.\n\n        Examples\n        --------\n        AVT CONTROL-PLANE-PROFILE VRF: default (Destination: 10.101.255.2, Next-hop: 10.101.255.1)\n\n        \"\"\"\n        return f\"AVT: {self.avt_name} VRF: {self.vrf} Destination: {self.destination} Next-hop: {self.next_hop}\"\n</code></pre>"},{"location":"api/tests/bfd/","title":"BFD","text":""},{"location":"api/tests/bfd/#tests","title":"Tests","text":"<p>Module related to BFD tests.</p>"},{"location":"api/tests/bfd/#anta.tests.bfd.VerifyBFDPeersHealth","title":"VerifyBFDPeersHealth","text":"<p>Verifies the health of IPv4 BFD peers across all VRFs.</p> <p>This test performs the following checks for BFD peers across all VRFs:</p> <ol> <li>Validates that the state is <code>up</code>.</li> <li>Confirms that the remote discriminator identifier (disc) is non-zero.</li> <li>Optionally verifies that the peer have not been down before a specified threshold of hours.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All BFD peers across the VRFs are up and remote disc is non-zero.</li> <li>Last downtime of each peer is above the defined threshold, if specified.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>Any BFD peer session is not up or the remote discriminator identifier is zero.</li> <li>Last downtime of any peer is below the defined threshold, if specified.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.bfd:\n  - VerifyBFDPeersHealth:\n      down_threshold: 2\n</code></pre> Source code in <code>anta/tests/bfd.py</code> <pre><code>class VerifyBFDPeersHealth(AntaTest):\n    \"\"\"Verifies the health of IPv4 BFD peers across all VRFs.\n\n    This test performs the following checks for BFD peers across all VRFs:\n\n      1. Validates that the state is `up`.\n      2. Confirms that the remote discriminator identifier (disc) is non-zero.\n      3. Optionally verifies that the peer have not been down before a specified threshold of hours.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All BFD peers across the VRFs are up and remote disc is non-zero.\n        - Last downtime of each peer is above the defined threshold, if specified.\n    * Failure: If any of the following occur:\n        - Any BFD peer session is not up or the remote discriminator identifier is zero.\n        - Last downtime of any peer is below the defined threshold, if specified.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.bfd:\n      - VerifyBFDPeersHealth:\n          down_threshold: 2\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bfd\"]\n    # revision 1 as later revision introduces additional nesting for type\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaCommand(command=\"show bfd peers\", revision=1),\n        AntaCommand(command=\"show clock\", revision=1),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBFDPeersHealth test.\"\"\"\n\n        down_threshold: int | None = Field(default=None, gt=0)\n        \"\"\"Optional down threshold in hours to check if a BFD peer was down before those hours or not.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBFDPeersHealth.\"\"\"\n        self.result.is_success()\n\n        # Extract the current timestamp and command output\n        clock_output = self.instance_commands[1].json_output\n        current_timestamp = clock_output[\"utcTime\"]\n        bfd_output = self.instance_commands[0].json_output\n\n        # Check if any IPv4 BFD peer is configured\n        ipv4_neighbors_exist = any(vrf_data[\"ipv4Neighbors\"] for vrf_data in bfd_output[\"vrfs\"].values())\n        if not ipv4_neighbors_exist:\n            self.result.is_failure(\"No IPv4 BFD peers are configured for any VRF\")\n            return\n\n        # Iterate over IPv4 BFD peers\n        for vrf, vrf_data in bfd_output[\"vrfs\"].items():\n            for peer, neighbor_data in vrf_data[\"ipv4Neighbors\"].items():\n                for peer_data in neighbor_data[\"peerStats\"].values():\n                    peer_status = peer_data[\"status\"]\n                    remote_disc = peer_data[\"remoteDisc\"]\n                    last_down = peer_data[\"lastDown\"]\n                    hours_difference = (\n                        datetime.fromtimestamp(current_timestamp, tz=timezone.utc) - datetime.fromtimestamp(last_down, tz=timezone.utc)\n                    ).total_seconds() / 3600\n\n                    if not (peer_status == \"up\" and remote_disc != 0):\n                        self.result.is_failure(\n                            f\"Peer: {peer} VRF: {vrf} - Session not properly established - State: {peer_status} Remote Discriminator: {remote_disc}\"\n                        )\n\n                    # Check if the last down is within the threshold\n                    if self.inputs.down_threshold and hours_difference &lt; self.inputs.down_threshold:\n                        self.result.is_failure(\n                            f\"Peer: {peer} VRF: {vrf} - Session failure detected within the expected uptime threshold ({round(hours_difference)} hours ago)\"\n                        )\n</code></pre>"},{"location":"api/tests/bfd/#anta.tests.bfd.VerifyBFDPeersHealth-attributes","title":"Inputs","text":"Name Type Description Default <code>down_threshold</code> <code>int | None</code>                      Optional down threshold in hours to check if a BFD peer was down before those hours or not.                    <code>Field(default=None, gt=0)</code>"},{"location":"api/tests/bfd/#anta.tests.bfd.VerifyBFDPeersIntervals","title":"VerifyBFDPeersIntervals","text":"<p>Verifies the timers of IPv4 BFD peer sessions.</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Confirms that the specified VRF is configured.</li> <li>Verifies that the peer exists in the BFD configuration.</li> <li>Confirms that BFD peer is correctly configured with the <code>Transmit interval, Receive interval and Multiplier</code>.</li> <li>Verifies that BFD peer is correctly configured with the <code>Detection time</code>, if provided.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BFD configuration within the specified VRF.</li> <li>All BFD peers are correctly configured with the <code>Transmit interval, Receive interval and Multiplier</code>.</li> <li>If provided, the <code>Detection time</code> is correctly configured.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BFD configuration within the specified VRF.</li> <li>Any BFD peer not correctly configured with the <code>Transmit interval, Receive interval and Multiplier</code>.</li> <li>Any BFD peer is not correctly configured with <code>Detection time</code>, if provided.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.bfd:\n  - VerifyBFDPeersIntervals:\n      bfd_peers:\n        - peer_address: 192.0.255.8\n          vrf: default\n          tx_interval: 1200\n          rx_interval: 1200\n          multiplier: 3\n        - peer_address: 192.0.255.7\n          vrf: default\n          tx_interval: 1200\n          rx_interval: 1200\n          multiplier: 3\n          detection_time: 3600\n</code></pre> Source code in <code>anta/tests/bfd.py</code> <pre><code>class VerifyBFDPeersIntervals(AntaTest):\n    \"\"\"Verifies the timers of IPv4 BFD peer sessions.\n\n    This test performs the following checks for each specified peer:\n\n      1. Confirms that the specified VRF is configured.\n      2. Verifies that the peer exists in the BFD configuration.\n      3. Confirms that BFD peer is correctly configured with the `Transmit interval, Receive interval and Multiplier`.\n      4. Verifies that BFD peer is correctly configured with the `Detection time`, if provided.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BFD configuration within the specified VRF.\n        - All BFD peers are correctly configured with the `Transmit interval, Receive interval and Multiplier`.\n        - If provided, the `Detection time` is correctly configured.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BFD configuration within the specified VRF.\n        - Any BFD peer not correctly configured with the `Transmit interval, Receive interval and Multiplier`.\n        - Any BFD peer is not correctly configured with `Detection time`, if provided.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.bfd:\n      - VerifyBFDPeersIntervals:\n          bfd_peers:\n            - peer_address: 192.0.255.8\n              vrf: default\n              tx_interval: 1200\n              rx_interval: 1200\n              multiplier: 3\n            - peer_address: 192.0.255.7\n              vrf: default\n              tx_interval: 1200\n              rx_interval: 1200\n              multiplier: 3\n              detection_time: 3600\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bfd\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bfd peers detail\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBFDPeersIntervals test.\"\"\"\n\n        bfd_peers: list[BFDPeer]\n        \"\"\"List of IPv4 BFD\"\"\"\n        BFDPeer: ClassVar[type[BFDPeer]] = BFDPeer\n        \"\"\"To maintain backward compatibility\"\"\"\n\n        @field_validator(\"bfd_peers\")\n        @classmethod\n        def validate_bfd_peers(cls, bfd_peers: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'tx_interval', 'rx_interval' and 'multiplier' fields are provided in each BFD peer.\"\"\"\n            for peer in bfd_peers:\n                missing_fileds = []\n                if peer.tx_interval is None:\n                    missing_fileds.append(\"tx_interval\")\n                if peer.rx_interval is None:\n                    missing_fileds.append(\"rx_interval\")\n                if peer.multiplier is None:\n                    missing_fileds.append(\"multiplier\")\n                if missing_fileds:\n                    msg = f\"{peer} {', '.join(missing_fileds)} field(s) are missing in the input\"\n                    raise ValueError(msg)\n            return bfd_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBFDPeersIntervals.\"\"\"\n        self.result.is_success()\n\n        # Iterating over BFD peers\n        for bfd_peer in self.inputs.bfd_peers:\n            peer = str(bfd_peer.peer_address)\n            vrf = bfd_peer.vrf\n            tx_interval = bfd_peer.tx_interval\n            rx_interval = bfd_peer.rx_interval\n            multiplier = bfd_peer.multiplier\n            detect_time = bfd_peer.detection_time\n\n            # Check if BFD peer configured\n            bfd_output = get_value(\n                self.instance_commands[0].json_output,\n                f\"vrfs..{vrf}..ipv4Neighbors..{peer}..peerStats..\",\n                separator=\"..\",\n            )\n            if not bfd_output:\n                self.result.is_failure(f\"{bfd_peer} - Not found\")\n                continue\n\n            # Convert interval timer(s) into milliseconds to be consistent with the inputs.\n            bfd_details = bfd_output.get(\"peerStatsDetail\", {})\n            op_tx_interval = bfd_details.get(\"operTxInterval\") // 1000\n            op_rx_interval = bfd_details.get(\"operRxInterval\") // 1000\n            op_detection_time = bfd_details.get(\"detectTime\") // 1000\n            detect_multiplier = bfd_details.get(\"detectMult\")\n\n            if op_tx_interval != tx_interval:\n                self.result.is_failure(f\"{bfd_peer} - Incorrect Transmit interval - Expected: {tx_interval} Actual: {op_tx_interval}\")\n\n            if op_rx_interval != rx_interval:\n                self.result.is_failure(f\"{bfd_peer} - Incorrect Receive interval - Expected: {rx_interval} Actual: {op_rx_interval}\")\n\n            if detect_multiplier != multiplier:\n                self.result.is_failure(f\"{bfd_peer} - Incorrect Multiplier - Expected: {multiplier} Actual: {detect_multiplier}\")\n\n            if detect_time and op_detection_time != detect_time:\n                self.result.is_failure(f\"{bfd_peer} - Incorrect Detection Time - Expected: {detect_time} Actual: {op_detection_time}\")\n</code></pre>"},{"location":"api/tests/bfd/#anta.tests.bfd.VerifyBFDPeersIntervals-attributes","title":"Inputs","text":"Name Type Description Default <code>bfd_peers</code> <code>list[BFDPeer]</code>                      List of IPv4 BFD                    - <code>BFDPeer</code> <code>type[BFDPeer]</code>                      To maintain backward compatibility                    <code>BFDPeer</code>"},{"location":"api/tests/bfd/#anta.tests.bfd.VerifyBFDPeersRegProtocols","title":"VerifyBFDPeersRegProtocols","text":"<p>Verifies the registered routing protocol of IPv4 BFD peer sessions.</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Confirms that the specified VRF is configured.</li> <li>Verifies that the peer exists in the BFD configuration.</li> <li>Confirms that BFD peer is correctly configured with the <code>routing protocol</code>.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BFD configuration within the specified VRF.</li> <li>All BFD peers are correctly configured with the <code>routing protocol</code>.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BFD configuration within the specified VRF.</li> <li>Any BFD peer not correctly configured with the <code>routing protocol</code>.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.bfd:\n  - VerifyBFDPeersRegProtocols:\n      bfd_peers:\n        - peer_address: 192.0.255.7\n          vrf: default\n          protocols:\n            - bgp\n</code></pre> Source code in <code>anta/tests/bfd.py</code> <pre><code>class VerifyBFDPeersRegProtocols(AntaTest):\n    \"\"\"Verifies the registered routing protocol of IPv4 BFD peer sessions.\n\n    This test performs the following checks for each specified peer:\n\n      1. Confirms that the specified VRF is configured.\n      2. Verifies that the peer exists in the BFD configuration.\n      3. Confirms that BFD peer is correctly configured with the `routing protocol`.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BFD configuration within the specified VRF.\n        - All BFD peers are correctly configured with the `routing protocol`.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BFD configuration within the specified VRF.\n        - Any BFD peer not correctly configured with the `routing protocol`.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.bfd:\n      - VerifyBFDPeersRegProtocols:\n          bfd_peers:\n            - peer_address: 192.0.255.7\n              vrf: default\n              protocols:\n                - bgp\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bfd\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bfd peers detail\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBFDPeersRegProtocols test.\"\"\"\n\n        bfd_peers: list[BFDPeer]\n        \"\"\"List of IPv4 BFD\"\"\"\n        BFDPeer: ClassVar[type[BFDPeer]] = BFDPeer\n        \"\"\"To maintain backward compatibility\"\"\"\n\n        @field_validator(\"bfd_peers\")\n        @classmethod\n        def validate_bfd_peers(cls, bfd_peers: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'protocols' field is provided in each BFD peer.\"\"\"\n            for peer in bfd_peers:\n                if peer.protocols is None:\n                    msg = f\"{peer} 'protocols' field missing in the input\"\n                    raise ValueError(msg)\n            return bfd_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBFDPeersRegProtocols.\"\"\"\n        self.result.is_success()\n\n        # Iterating over BFD peers, extract the parameters and command output\n        for bfd_peer in self.inputs.bfd_peers:\n            peer = str(bfd_peer.peer_address)\n            vrf = bfd_peer.vrf\n            protocols = bfd_peer.protocols\n            bfd_output = get_value(\n                self.instance_commands[0].json_output,\n                f\"vrfs..{vrf}..ipv4Neighbors..{peer}..peerStats..\",\n                separator=\"..\",\n            )\n\n            # Check if BFD peer configured\n            if not bfd_output:\n                self.result.is_failure(f\"{bfd_peer} - Not found\")\n                continue\n\n            # Check registered protocols\n            difference = sorted(set(protocols) - set(get_value(bfd_output, \"peerStatsDetail.apps\")))\n            if difference:\n                failures = \", \".join(f\"`{item}`\" for item in difference)\n                self.result.is_failure(f\"{bfd_peer} - {failures} routing protocol(s) not configured\")\n</code></pre>"},{"location":"api/tests/bfd/#anta.tests.bfd.VerifyBFDPeersRegProtocols-attributes","title":"Inputs","text":"Name Type Description Default <code>bfd_peers</code> <code>list[BFDPeer]</code>                      List of IPv4 BFD                    - <code>BFDPeer</code> <code>type[BFDPeer]</code>                      To maintain backward compatibility                    <code>BFDPeer</code>"},{"location":"api/tests/bfd/#anta.tests.bfd.VerifyBFDSpecificPeers","title":"VerifyBFDSpecificPeers","text":"<p>Verifies the state of IPv4 BFD peer sessions.</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Confirms that the specified VRF is configured.</li> <li>Verifies that the peer exists in the BFD configuration.</li> <li>For each specified BFD peer:<ul> <li>Validates that the state is <code>up</code></li> <li>Confirms that the remote discriminator identifier (disc) is non-zero.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BFD configuration within the specified VRF.</li> <li>All BFD peers are <code>up</code> and remote disc is non-zero.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BFD configuration within the specified VRF.</li> <li>Any BFD peer session is not <code>up</code> or the remote discriminator identifier is zero.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.bfd:\n  - VerifyBFDSpecificPeers:\n      bfd_peers:\n        - peer_address: 192.0.255.8\n          vrf: default\n        - peer_address: 192.0.255.7\n          vrf: default\n</code></pre> Source code in <code>anta/tests/bfd.py</code> <pre><code>class VerifyBFDSpecificPeers(AntaTest):\n    \"\"\"Verifies the state of IPv4 BFD peer sessions.\n\n    This test performs the following checks for each specified peer:\n\n      1. Confirms that the specified VRF is configured.\n      2. Verifies that the peer exists in the BFD configuration.\n      3. For each specified BFD peer:\n        - Validates that the state is `up`\n        - Confirms that the remote discriminator identifier (disc) is non-zero.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BFD configuration within the specified VRF.\n        - All BFD peers are `up` and remote disc is non-zero.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BFD configuration within the specified VRF.\n        - Any BFD peer session is not `up` or the remote discriminator identifier is zero.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.bfd:\n      - VerifyBFDSpecificPeers:\n          bfd_peers:\n            - peer_address: 192.0.255.8\n              vrf: default\n            - peer_address: 192.0.255.7\n              vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bfd\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bfd peers\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBFDSpecificPeers test.\"\"\"\n\n        bfd_peers: list[BFDPeer]\n        \"\"\"List of IPv4 BFD\"\"\"\n        BFDPeer: ClassVar[type[BFDPeer]] = BFDPeer\n        \"\"\"To maintain backward compatibility.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBFDSpecificPeers.\"\"\"\n        self.result.is_success()\n\n        # Iterating over BFD peers\n        for bfd_peer in self.inputs.bfd_peers:\n            peer = str(bfd_peer.peer_address)\n            vrf = bfd_peer.vrf\n            bfd_output = get_value(\n                self.instance_commands[0].json_output,\n                f\"vrfs..{vrf}..ipv4Neighbors..{peer}..peerStats..\",\n                separator=\"..\",\n            )\n\n            # Check if BFD peer configured\n            if not bfd_output:\n                self.result.is_failure(f\"{bfd_peer} - Not found\")\n                continue\n\n            # Check BFD peer status and remote disc\n            state = bfd_output.get(\"status\")\n            remote_disc = bfd_output.get(\"remoteDisc\")\n            if not (state == \"up\" and remote_disc != 0):\n                self.result.is_failure(f\"{bfd_peer} - Session not properly established - State: {state} Remote Discriminator: {remote_disc}\")\n</code></pre>"},{"location":"api/tests/bfd/#anta.tests.bfd.VerifyBFDSpecificPeers-attributes","title":"Inputs","text":"Name Type Description Default <code>bfd_peers</code> <code>list[BFDPeer]</code>                      List of IPv4 BFD                    - <code>BFDPeer</code> <code>type[BFDPeer]</code>                      To maintain backward compatibility.                    <code>BFDPeer</code>"},{"location":"api/tests/bfd/#input-models","title":"Input models","text":"<p>Module containing input models for BFD tests.</p>"},{"location":"api/tests/bfd/#anta.input_models.bfd.BFDPeer","title":"BFDPeer","text":"<p>BFD (Bidirectional Forwarding Detection) model representing the peer details.</p> <p>Only IPv4 peers are supported for now.</p> Name Type Description Default <code>peer_address</code> <code>IPv4Address</code>                      IPv4 address of a BFD peer.                    - <code>vrf</code> <code>str</code>                      Optional VRF for the BFD peer. Defaults to `default`.                    <code>'default'</code> <code>tx_interval</code> <code>BfdInterval | None</code>                      Tx interval of BFD peer in milliseconds. Required field in the `VerifyBFDPeersIntervals` test.                    <code>None</code> <code>rx_interval</code> <code>BfdInterval | None</code>                      Rx interval of BFD peer in milliseconds. Required field in the `VerifyBFDPeersIntervals` test.                    <code>None</code> <code>multiplier</code> <code>BfdMultiplier | None</code>                      Multiplier of BFD peer. Required field in the `VerifyBFDPeersIntervals` test.                    <code>None</code> <code>protocols</code> <code>list[BfdProtocol] | None</code>                      List of protocols to be verified. Required field in the `VerifyBFDPeersRegProtocols` test.                    <code>None</code> <code>detection_time</code> <code>int | None</code>                      Detection time of BFD peer in milliseconds. Defines how long to wait without receiving BFD packets before declaring the peer session as down.  Optional field in the `VerifyBFDPeersIntervals` test.                    <code>None</code> Source code in <code>anta/input_models/bfd.py</code> <pre><code>class BFDPeer(BaseModel):\n    \"\"\"BFD (Bidirectional Forwarding Detection) model representing the peer details.\n\n    Only IPv4 peers are supported for now.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    peer_address: IPv4Address\n    \"\"\"IPv4 address of a BFD peer.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"Optional VRF for the BFD peer. Defaults to `default`.\"\"\"\n    tx_interval: BfdInterval | None = None\n    \"\"\"Tx interval of BFD peer in milliseconds. Required field in the `VerifyBFDPeersIntervals` test.\"\"\"\n    rx_interval: BfdInterval | None = None\n    \"\"\"Rx interval of BFD peer in milliseconds. Required field in the `VerifyBFDPeersIntervals` test.\"\"\"\n    multiplier: BfdMultiplier | None = None\n    \"\"\"Multiplier of BFD peer. Required field in the `VerifyBFDPeersIntervals` test.\"\"\"\n    protocols: list[BfdProtocol] | None = None\n    \"\"\"List of protocols to be verified. Required field in the `VerifyBFDPeersRegProtocols` test.\"\"\"\n    detection_time: int | None = None\n    \"\"\"Detection time of BFD peer in milliseconds. Defines how long to wait without receiving BFD packets before declaring the peer session as down.\n\n    Optional field in the `VerifyBFDPeersIntervals` test.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the BFDPeer for reporting.\"\"\"\n        return f\"Peer: {self.peer_address} VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/configuration/","title":"Configuration","text":"<p>Module related to the device configuration tests.</p>"},{"location":"api/tests/configuration/#anta.tests.configuration.VerifyRunningConfigDiffs","title":"VerifyRunningConfigDiffs","text":"<p>Verifies there is no difference between the running-config and the startup-config.</p> Expected Results <ul> <li>Success: The test will pass if there is no difference between the running-config and the startup-config.</li> <li>Failure: The test will fail if there is a difference between the running-config and the startup-config.</li> </ul> Examples <pre><code>anta.tests.configuration:\n  - VerifyRunningConfigDiffs:\n</code></pre> Source code in <code>anta/tests/configuration.py</code> <pre><code>class VerifyRunningConfigDiffs(AntaTest):\n    \"\"\"Verifies there is no difference between the running-config and the startup-config.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there is no difference between the running-config and the startup-config.\n    * Failure: The test will fail if there is a difference between the running-config and the startup-config.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.configuration:\n      - VerifyRunningConfigDiffs:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"configuration\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show running-config diffs\", ofmt=\"text\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyRunningConfigDiffs.\"\"\"\n        command_output = self.instance_commands[0].text_output\n        if command_output == \"\":\n            self.result.is_success()\n        else:\n            self.result.is_failure(command_output)\n</code></pre>"},{"location":"api/tests/configuration/#anta.tests.configuration.VerifyRunningConfigLines","title":"VerifyRunningConfigLines","text":"<p>Verifies the given regular expression patterns are present in the running-config.</p> <p>Warning</p> <p>Since this uses regular expression searches on the whole running-config, it can drastically impact performance and should only be used if no other test is available.</p> <p>If possible, try using another ANTA test that is more specific.</p> Expected Results <ul> <li>Success: The test will pass if all the patterns are found in the running-config.</li> <li>Failure: The test will fail if any of the patterns are NOT found in the running-config.</li> </ul> Examples <pre><code>anta.tests.configuration:\n  - VerifyRunningConfigLines:\n      regex_patterns:\n        - \"^enable password.*$\"\n        - \"bla bla\"\n</code></pre> Source code in <code>anta/tests/configuration.py</code> <pre><code>class VerifyRunningConfigLines(AntaTest):\n    \"\"\"Verifies the given regular expression patterns are present in the running-config.\n\n    !!! warning\n        Since this uses regular expression searches on the whole running-config, it can\n        drastically impact performance and should only be used if no other test is available.\n\n        If possible, try using another ANTA test that is more specific.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all the patterns are found in the running-config.\n    * Failure: The test will fail if any of the patterns are NOT found in the running-config.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.configuration:\n      - VerifyRunningConfigLines:\n          regex_patterns:\n            - \"^enable password.*$\"\n            - \"bla bla\"\n    ```\n    \"\"\"\n\n    description = \"Search the Running-Config for the given RegEx patterns.\"\n    categories: ClassVar[list[str]] = [\"configuration\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show running-config\", ofmt=\"text\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyRunningConfigLines test.\"\"\"\n\n        regex_patterns: list[RegexString]\n        \"\"\"List of regular expressions.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyRunningConfigLines.\"\"\"\n        failure_msgs = []\n        command_output = self.instance_commands[0].text_output\n\n        for pattern in self.inputs.regex_patterns:\n            re_search = re.compile(pattern, flags=re.MULTILINE)\n\n            if not re_search.search(command_output):\n                failure_msgs.append(f\"'{pattern}'\")\n\n        if not failure_msgs:\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"Following patterns were not found: \" + \", \".join(failure_msgs))\n</code></pre>"},{"location":"api/tests/configuration/#anta.tests.configuration.VerifyRunningConfigLines-attributes","title":"Inputs","text":"Name Type Description Default <code>regex_patterns</code> <code>list[RegexString]</code>                      List of regular expressions.                    -"},{"location":"api/tests/configuration/#anta.tests.configuration.VerifyZeroTouch","title":"VerifyZeroTouch","text":"<p>Verifies ZeroTouch is disabled.</p> Expected Results <ul> <li>Success: The test will pass if ZeroTouch is disabled.</li> <li>Failure: The test will fail if ZeroTouch is enabled.</li> </ul> Examples <pre><code>anta.tests.configuration:\n  - VerifyZeroTouch:\n</code></pre> Source code in <code>anta/tests/configuration.py</code> <pre><code>class VerifyZeroTouch(AntaTest):\n    \"\"\"Verifies ZeroTouch is disabled.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if ZeroTouch is disabled.\n    * Failure: The test will fail if ZeroTouch is enabled.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.configuration:\n      - VerifyZeroTouch:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"configuration\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show zerotouch\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyZeroTouch.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        if command_output[\"mode\"] == \"disabled\":\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"ZTP is NOT disabled\")\n</code></pre>"},{"location":"api/tests/connectivity/","title":"Connectivity","text":""},{"location":"api/tests/connectivity/#tests","title":"Tests","text":"<p>Module related to various connectivity tests.</p>"},{"location":"api/tests/connectivity/#anta.tests.connectivity.VerifyLLDPNeighbors","title":"VerifyLLDPNeighbors","text":"<p>Verifies the connection status of the specified LLDP (Link Layer Discovery Protocol) neighbors.</p> <p>This test performs the following checks for each specified LLDP neighbor:</p> <ol> <li>Confirming matching ports on both local and neighboring devices.</li> <li>Ensuring compatibility of device names and interface identifiers.</li> <li>Verifying neighbor configurations match expected values per interface; extra neighbors are ignored.</li> </ol> Expected Results <ul> <li>Success: The test will pass if all the provided LLDP neighbors are present and correctly connected to the specified port and device.</li> <li>Failure: The test will fail if any of the following conditions are met:<ul> <li>The provided LLDP neighbor is not found in the LLDP table.</li> <li>The system name or port of the LLDP neighbor does not match the expected information.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.connectivity:\n  - VerifyLLDPNeighbors:\n      neighbors:\n        - port: Ethernet1\n          neighbor_device: DC1-SPINE1\n          neighbor_port: Ethernet1\n        - port: Ethernet2\n          neighbor_device: DC1-SPINE2\n          neighbor_port: Ethernet1\n</code></pre> Source code in <code>anta/tests/connectivity.py</code> <pre><code>class VerifyLLDPNeighbors(AntaTest):\n    \"\"\"Verifies the connection status of the specified LLDP (Link Layer Discovery Protocol) neighbors.\n\n    This test performs the following checks for each specified LLDP neighbor:\n\n      1. Confirming matching ports on both local and neighboring devices.\n      2. Ensuring compatibility of device names and interface identifiers.\n      3. Verifying neighbor configurations match expected values per interface; extra neighbors are ignored.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all the provided LLDP neighbors are present and correctly connected to the specified port and device.\n    * Failure: The test will fail if any of the following conditions are met:\n        - The provided LLDP neighbor is not found in the LLDP table.\n        - The system name or port of the LLDP neighbor does not match the expected information.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.connectivity:\n      - VerifyLLDPNeighbors:\n          neighbors:\n            - port: Ethernet1\n              neighbor_device: DC1-SPINE1\n              neighbor_port: Ethernet1\n            - port: Ethernet2\n              neighbor_device: DC1-SPINE2\n              neighbor_port: Ethernet1\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"connectivity\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show lldp neighbors detail\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLLDPNeighbors test.\"\"\"\n\n        neighbors: list[LLDPNeighbor]\n        \"\"\"List of LLDP neighbors.\"\"\"\n        Neighbor: ClassVar[type[Neighbor]] = Neighbor\n        \"\"\"To maintain backward compatibility.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLLDPNeighbors.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output[\"lldpNeighbors\"]\n        for neighbor in self.inputs.neighbors:\n            if neighbor.port not in output:\n                self.result.is_failure(f\"{neighbor} - Port not found\")\n                continue\n\n            if len(lldp_neighbor_info := output[neighbor.port][\"lldpNeighborInfo\"]) == 0:\n                self.result.is_failure(f\"{neighbor} - No LLDP neighbors\")\n                continue\n\n            # Check if the system name and neighbor port matches\n            match_found = any(\n                info[\"systemName\"] == neighbor.neighbor_device and info[\"neighborInterfaceInfo\"][\"interfaceId_v2\"] == neighbor.neighbor_port\n                for info in lldp_neighbor_info\n            )\n            if not match_found:\n                failure_msg = [f\"{info['systemName']}/{info['neighborInterfaceInfo']['interfaceId_v2']}\" for info in lldp_neighbor_info]\n                self.result.is_failure(f\"{neighbor} - Wrong LLDP neighbors: {', '.join(failure_msg)}\")\n</code></pre>"},{"location":"api/tests/connectivity/#anta.tests.connectivity.VerifyLLDPNeighbors-attributes","title":"Inputs","text":"Name Type Description Default <code>neighbors</code> <code>list[LLDPNeighbor]</code>                      List of LLDP neighbors.                    - <code>Neighbor</code> <code>type[Neighbor]</code>                      To maintain backward compatibility.                    <code>Neighbor</code>"},{"location":"api/tests/connectivity/#anta.tests.connectivity.VerifyReachability","title":"VerifyReachability","text":"<p>Test network reachability to one or many destination IP(s).</p> Expected Results <ul> <li>Success: The test will pass if all destination IP(s) are reachable.</li> <li>Failure: The test will fail if one or many destination IP(s) are unreachable.</li> </ul> Examples <pre><code>anta.tests.connectivity:\n  - VerifyReachability:\n      hosts:\n        - source: Management0\n          destination: 1.1.1.1\n          vrf: MGMT\n          df_bit: True\n          size: 100\n          reachable: true\n        - destination: 8.8.8.8\n          vrf: MGMT\n          df_bit: True\n          size: 100\n        - source: fd12:3456:789a:1::1\n          destination: fd12:3456:789a:1::2\n          vrf: default\n          df_bit: True\n          size: 100\n          reachable: false\n</code></pre> Source code in <code>anta/tests/connectivity.py</code> <pre><code>class VerifyReachability(AntaTest):\n    \"\"\"Test network reachability to one or many destination IP(s).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all destination IP(s) are reachable.\n    * Failure: The test will fail if one or many destination IP(s) are unreachable.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.connectivity:\n      - VerifyReachability:\n          hosts:\n            - source: Management0\n              destination: 1.1.1.1\n              vrf: MGMT\n              df_bit: True\n              size: 100\n              reachable: true\n            - destination: 8.8.8.8\n              vrf: MGMT\n              df_bit: True\n              size: 100\n            - source: fd12:3456:789a:1::1\n              destination: fd12:3456:789a:1::2\n              vrf: default\n              df_bit: True\n              size: 100\n              reachable: false\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"connectivity\"]\n    # Template uses '{size}{df_bit}' without space since df_bit includes leading space when enabled\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaTemplate(template=\"ping vrf {vrf} {destination}{source} size {size}{df_bit} repeat {repeat}\", revision=1)\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyReachability test.\"\"\"\n\n        hosts: list[Host]\n        \"\"\"List of host to ping.\"\"\"\n        Host: ClassVar[type[Host]] = Host\n        \"\"\"To maintain backward compatibility.\"\"\"\n\n        @field_validator(\"hosts\")\n        @classmethod\n        def validate_hosts(cls, hosts: list[T]) -&gt; list[T]:\n            \"\"\"Validate the 'destination' and 'source' IP address family in each host.\"\"\"\n            for host in hosts:\n                if host.source and not isinstance(host.source, str) and host.destination.version != host.source.version:\n                    msg = f\"{host} IP address family for destination does not match source\"\n                    raise ValueError(msg)\n            return hosts\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for each host in the input list.\"\"\"\n        return [\n            template.render(\n                destination=host.destination,\n                source=f\" source {host.source}\" if host.source else \"\",\n                vrf=host.vrf,\n                repeat=host.repeat,\n                size=host.size,\n                df_bit=\" df-bit\" if host.df_bit else \"\",\n            )\n            for host in self.inputs.hosts\n        ]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyReachability.\"\"\"\n        self.result.is_success()\n\n        for command, host in zip(self.instance_commands, self.inputs.hosts):\n            # Verifies the network is reachable\n            if host.reachable and f\"{host.repeat} received\" not in command.json_output[\"messages\"][0]:\n                self.result.is_failure(f\"{host} - Unreachable\")\n\n            # Verifies the network is unreachable.\n            if not host.reachable and f\"{host.repeat} received\" in command.json_output[\"messages\"][0]:\n                self.result.is_failure(f\"{host} - Destination is expected to be unreachable but found reachable\")\n</code></pre>"},{"location":"api/tests/connectivity/#anta.tests.connectivity.VerifyReachability-attributes","title":"Inputs","text":"Name Type Description Default <code>hosts</code> <code>list[Host]</code>                      List of host to ping.                    - <code>Host</code> <code>type[Host]</code>                      To maintain backward compatibility.                    <code>Host</code>"},{"location":"api/tests/connectivity/#input-models","title":"Input models","text":"<p>Module containing input models for connectivity tests.</p>"},{"location":"api/tests/connectivity/#anta.input_models.connectivity.Host","title":"Host","text":"<p>Model for a remote host to ping.</p> Name Type Description Default <code>destination</code> <code>IPv4Address | IPv6Address</code>                      Destination address to ping.                    - <code>source</code> <code>IPv4Address | IPv6Address | Interface | None</code>                      Source address IP or egress interface to use. Can be provided in the `VerifyReachability` test.                    <code>None</code> <code>vrf</code> <code>str</code>                      VRF context.                    <code>'default'</code> <code>repeat</code> <code>int</code>                      Number of ping repetition.                    <code>2</code> <code>size</code> <code>int</code>                      Specify datagram size.                    <code>100</code> <code>df_bit</code> <code>bool</code>                      Enable do not fragment bit in IP header.                    <code>False</code> <code>reachable</code> <code>bool</code>                      Indicates whether the destination should be reachable.                    <code>True</code> Source code in <code>anta/input_models/connectivity.py</code> <pre><code>class Host(BaseModel):\n    \"\"\"Model for a remote host to ping.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    destination: IPv4Address | IPv6Address\n    \"\"\"Destination address to ping.\"\"\"\n    source: IPv4Address | IPv6Address | Interface | None = None\n    \"\"\"Source address IP or egress interface to use. Can be provided in the `VerifyReachability` test.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"VRF context.\"\"\"\n    repeat: int = 2\n    \"\"\"Number of ping repetition.\"\"\"\n    size: int = 100\n    \"\"\"Specify datagram size.\"\"\"\n    df_bit: bool = False\n    \"\"\"Enable do not fragment bit in IP header.\"\"\"\n    reachable: bool = True\n    \"\"\"Indicates whether the destination should be reachable.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the Host for reporting.\n\n        Examples\n        --------\n        - Host: 10.1.1.1 Source: 10.2.2.2 VRF: mgmt\n        - Host: 10.1.1.1 VRF: mgmt\n\n        \"\"\"\n        base_string = f\"Host: {self.destination}\"\n        if self.source:\n            base_string += f\" Source: {self.source}\"\n        base_string += f\" VRF: {self.vrf}\"\n        return base_string\n</code></pre>"},{"location":"api/tests/connectivity/#anta.input_models.connectivity.LLDPNeighbor","title":"LLDPNeighbor","text":"<p>LLDP (Link Layer Discovery Protocol) model representing the port details and neighbor information.</p> Name Type Description Default <code>port</code> <code>Interface</code>                      The LLDP port for the local device.                    - <code>neighbor_device</code> <code>str</code>                      The system name of the LLDP neighbor device.                    - <code>neighbor_port</code> <code>Interface</code>                      The LLDP port on the neighboring device.                    - Source code in <code>anta/input_models/connectivity.py</code> <pre><code>class LLDPNeighbor(BaseModel):\n    \"\"\"LLDP (Link Layer Discovery Protocol) model representing the port details and neighbor information.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    port: Interface\n    \"\"\"The LLDP port for the local device.\"\"\"\n    neighbor_device: str\n    \"\"\"The system name of the LLDP neighbor device.\"\"\"\n    neighbor_port: Interface\n    \"\"\"The LLDP port on the neighboring device.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the LLDPNeighbor for reporting.\n\n        Examples\n        --------\n        Port: Ethernet1 Neighbor: DC1-SPINE2 Neighbor Port: Ethernet2\n\n        \"\"\"\n        return f\"Port: {self.port} Neighbor: {self.neighbor_device} Neighbor Port: {self.neighbor_port}\"\n</code></pre>"},{"location":"api/tests/connectivity/#anta.input_models.connectivity.Neighbor","title":"Neighbor","text":"<p>Alias for the LLDPNeighbor model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the LLDPNeighbor model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/connectivity.py</code> <pre><code>class Neighbor(LLDPNeighbor):  # pragma: no cover\n    \"\"\"Alias for the LLDPNeighbor model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the LLDPNeighbor model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the LLDPNeighbor class, emitting a depreciation warning.\"\"\"\n        warn(\n            message=\"Neighbor model is deprecated and will be removed in ANTA v2.0.0. Use the LLDPNeighbor model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/connectivity/#anta.input_models.connectivity.Neighbor.__init__","title":"__init__","text":"<pre><code>__init__(**data: Any) -&gt; None\n</code></pre> Source code in <code>anta/input_models/connectivity.py</code> <pre><code>def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n    \"\"\"Initialize the LLDPNeighbor class, emitting a depreciation warning.\"\"\"\n    warn(\n        message=\"Neighbor model is deprecated and will be removed in ANTA v2.0.0. Use the LLDPNeighbor model instead.\",\n        category=DeprecationWarning,\n        stacklevel=2,\n    )\n    super().__init__(**data)\n</code></pre>"},{"location":"api/tests/cvx/","title":"CVX","text":""},{"location":"api/tests/cvx/#test","title":"Test","text":"<p>Module related to the CVX tests.</p>"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyActiveCVXConnections","title":"VerifyActiveCVXConnections","text":"<p>Verifies the number of active CVX Connections.</p> Expected Results <ul> <li>Success: The test will pass if number of connections is equal to the expected number of connections.</li> <li>Failure: The test will fail otherwise.</li> </ul> Examples <pre><code>anta.tests.cvx:\n  - VerifyActiveCVXConnections:\n      connections_count: 100\n</code></pre> Source code in <code>anta/tests/cvx.py</code> <pre><code>class VerifyActiveCVXConnections(AntaTest):\n    \"\"\"Verifies the number of active CVX Connections.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if number of connections is equal to the expected number of connections.\n    * Failure: The test will fail otherwise.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.cvx:\n      - VerifyActiveCVXConnections:\n          connections_count: 100\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"cvx\"]\n    # TODO: @gmuloc - cover \"% Unavailable command (controller not ready)\"\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show cvx connections brief\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyActiveCVXConnections test.\"\"\"\n\n        connections_count: PositiveInteger\n        \"\"\"The expected number of active CVX Connections.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyActiveCVXConnections.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n\n        if not (connections := command_output.get(\"connections\")):\n            self.result.is_failure(\"CVX connections are not available\")\n            return\n\n        active_count = len([connection for connection in connections if connection.get(\"oobConnectionActive\")])\n\n        if self.inputs.connections_count != active_count:\n            self.result.is_failure(f\"Incorrect CVX active connections count - Expected: {self.inputs.connections_count} Actual: {active_count}\")\n</code></pre>"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyActiveCVXConnections-attributes","title":"Inputs","text":"Name Type Description Default <code>connections_count</code> <code>PositiveInteger</code>                      The expected number of active CVX Connections.                    -"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyCVXClusterStatus","title":"VerifyCVXClusterStatus","text":"<p>Verifies the CVX Server Cluster status.</p> Expected Results <ul> <li>Success: The test will pass if all of the following conditions is met:<ul> <li>CVX Enabled state is true</li> <li>Cluster Mode is true</li> <li>Role is either Master or Standby.</li> <li>peer_status matches defined state</li> </ul> </li> <li>Failure: The test will fail if any of the success conditions is not met.</li> </ul> Examples <pre><code>anta.tests.cvx:\n  - VerifyCVXClusterStatus:\n      role: Master\n      peer_status:\n        - peer_name : cvx-red-2\n          registration_state: Registration complete\n        - peer_name: cvx-red-3\n          registration_state: Registration error\n</code></pre> Source code in <code>anta/tests/cvx.py</code> <pre><code>class VerifyCVXClusterStatus(AntaTest):\n    \"\"\"Verifies the CVX Server Cluster status.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all of the following conditions is met:\n        - CVX Enabled state is true\n        - Cluster Mode is true\n        - Role is either Master or Standby.\n        - peer_status matches defined state\n    * Failure: The test will fail if any of the success conditions is not met.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.cvx:\n      - VerifyCVXClusterStatus:\n          role: Master\n          peer_status:\n            - peer_name : cvx-red-2\n              registration_state: Registration complete\n            - peer_name: cvx-red-3\n              registration_state: Registration error\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"cvx\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show cvx\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyCVXClusterStatus test.\"\"\"\n\n        role: Literal[\"Master\", \"Standby\", \"Disconnected\"] = \"Master\"\n        peer_status: list[CVXPeers]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Run the main test for VerifyCVXClusterStatus.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n\n        # Validate Server enabled status\n        if not command_output.get(\"enabled\"):\n            self.result.is_failure(\"CVX Server status is not enabled\")\n\n        # Validate cluster status and mode\n        if not (cluster_status := command_output.get(\"clusterStatus\")) or not command_output.get(\"clusterMode\"):\n            self.result.is_failure(\"CVX Server is not a cluster\")\n            return\n\n        # Check cluster role\n        if (cluster_role := cluster_status.get(\"role\")) != self.inputs.role:\n            self.result.is_failure(f\"CVX Role is not valid: Expected: {self.inputs.role} Actual: {cluster_role}\")\n            return\n\n        # Validate peer status\n        peer_cluster = cluster_status.get(\"peerStatus\", {})\n\n        # Check peer count\n        if (num_of_peers := len(peer_cluster)) != (expected_num_of_peers := len(self.inputs.peer_status)):\n            self.result.is_failure(f\"Unexpected number of peers - Expected: {expected_num_of_peers} Actual: {num_of_peers}\")\n\n        # Check each peer\n        for peer in self.inputs.peer_status:\n            # Retrieve the peer status from the peer cluster\n            if (eos_peer_status := get_value(peer_cluster, peer.peer_name, separator=\"..\")) is None:\n                self.result.is_failure(f\"{peer.peer_name} - Not present\")\n                continue\n\n            # Validate the registration state of the peer\n            if (peer_reg_state := eos_peer_status.get(\"registrationState\")) != peer.registration_state:\n                self.result.is_failure(f\"{peer.peer_name} - Invalid registration state - Expected: {peer.registration_state} Actual: {peer_reg_state}\")\n</code></pre>"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyCVXClusterStatus-attributes","title":"Inputs","text":"Name Type Description Default"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyManagementCVX","title":"VerifyManagementCVX","text":"<p>Verifies the management CVX global status.</p> Expected Results <ul> <li>Success: The test will pass if the management CVX global status matches the expected status.</li> <li>Failure: The test will fail if the management CVX global status does not match the expected status.</li> </ul> Examples <pre><code>anta.tests.cvx:\n  - VerifyManagementCVX:\n      enabled: true\n</code></pre> Source code in <code>anta/tests/cvx.py</code> <pre><code>class VerifyManagementCVX(AntaTest):\n    \"\"\"Verifies the management CVX global status.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the management CVX global status matches the expected status.\n    * Failure: The test will fail if the management CVX global status does not match the expected status.\n\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.cvx:\n      - VerifyManagementCVX:\n          enabled: true\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"cvx\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management cvx\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyManagementCVX test.\"\"\"\n\n        enabled: bool\n        \"\"\"Whether management CVX must be enabled (True) or disabled (False).\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyManagementCVX.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        if (cluster_state := get_value(command_output, \"clusterStatus.enabled\")) != self.inputs.enabled:\n            if cluster_state is None:\n                self.result.is_failure(\"Management CVX status - Not configured\")\n                return\n            cluster_state = \"enabled\" if cluster_state else \"disabled\"\n            self.inputs.enabled = \"enabled\" if self.inputs.enabled else \"disabled\"\n            self.result.is_failure(f\"Management CVX status is not valid: Expected: {self.inputs.enabled} Actual: {cluster_state}\")\n</code></pre>"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyManagementCVX-attributes","title":"Inputs","text":"Name Type Description Default <code>enabled</code> <code>bool</code>                      Whether management CVX must be enabled (True) or disabled (False).                    -"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyMcsClientMounts","title":"VerifyMcsClientMounts","text":"<p>Verify if all MCS client mounts are in mountStateMountComplete.</p> Expected Results <ul> <li>Success: The test will pass if the MCS mount status on MCS Clients are mountStateMountComplete.</li> <li>Failure: The test will fail even if one switch\u2019s MCS client mount status is not  mountStateMountComplete.</li> </ul> Examples <pre><code>anta.tests.cvx:\n- VerifyMcsClientMounts:\n</code></pre> Source code in <code>anta/tests/cvx.py</code> <pre><code>class VerifyMcsClientMounts(AntaTest):\n    \"\"\"Verify if all MCS client mounts are in mountStateMountComplete.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the MCS mount status on MCS Clients are mountStateMountComplete.\n    * Failure: The test will fail even if one switch's MCS client mount status is not  mountStateMountComplete.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.cvx:\n    - VerifyMcsClientMounts:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"cvx\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management cvx mounts\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMcsClientMounts.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        mount_states = command_output[\"mountStates\"]\n        mcs_mount_state_detected = False\n        for mount_state in mount_states:\n            if not mount_state[\"type\"].startswith(\"Mcs\"):\n                continue\n            mcs_mount_state_detected = True\n            if (state := mount_state[\"state\"]) != \"mountStateMountComplete\":\n                self.result.is_failure(f\"MCS Client mount states are not valid - Expected: mountStateMountComplete Actual: {state}\")\n\n        if not mcs_mount_state_detected:\n            self.result.is_failure(\"MCS Client mount states are not present\")\n</code></pre>"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyMcsServerMounts","title":"VerifyMcsServerMounts","text":"<p>Verify if all MCS server mounts are in a MountComplete state.</p> Expected Results <ul> <li>Success: The test will pass if all the MCS mount status on MCS server are mountStateMountComplete.</li> <li>Failure: The test will fail even if any MCS server mount status is not mountStateMountComplete.</li> </ul> Examples <pre><code>anta.tests.cvx:\n\n- VerifyMcsServerMounts:\n    connections_count: 100\n</code></pre> Source code in <code>anta/tests/cvx.py</code> <pre><code>class VerifyMcsServerMounts(AntaTest):\n    \"\"\"Verify if all MCS server mounts are in a MountComplete state.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all the MCS mount status on MCS server are mountStateMountComplete.\n    * Failure: The test will fail even if any MCS server mount status is not mountStateMountComplete.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.cvx:\n\n    - VerifyMcsServerMounts:\n        connections_count: 100\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"cvx\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show cvx mounts\", revision=1)]\n\n    mcs_path_types: ClassVar[list[str]] = [\"Mcs::ApiConfigRedundancyStatus\", \"Mcs::ActiveFlows\", \"Mcs::Client::Status\"]\n    \"\"\"The list of expected MCS path types to verify.\"\"\"\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyMcsServerMounts test.\"\"\"\n\n        connections_count: int\n        \"\"\"The expected number of active CVX Connections with mountStateMountComplete\"\"\"\n\n    def validate_mount_states(self, mount: dict[str, Any], hostname: str) -&gt; None:\n        \"\"\"Validate the mount states of a given mount.\"\"\"\n        mount_states = mount[\"mountStates\"][0]\n\n        if (num_path_states := len(mount_states[\"pathStates\"])) != (expected_num := len(self.mcs_path_types)):\n            self.result.is_failure(f\"Host: {hostname} - Incorrect number of mount path states - Expected: {expected_num} Actual: {num_path_states}\")\n\n        for path in mount_states[\"pathStates\"]:\n            if (path_type := path.get(\"type\")) not in self.mcs_path_types:\n                self.result.is_failure(f\"Host: {hostname} - Unexpected MCS path type - Expected: {', '.join(self.mcs_path_types)} Actual: {path_type}\")\n            if (path_state := path.get(\"state\")) != \"mountStateMountComplete\":\n                self.result.is_failure(\n                    f\"Host: {hostname} Path Type: {path_type} - MCS server mount state is not valid - Expected: mountStateMountComplete Actual:{path_state}\"\n                )\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMcsServerMounts.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        active_count = 0\n\n        if not (connections := command_output.get(\"connections\")):\n            self.result.is_failure(\"CVX connections are not available\")\n            return\n\n        for connection in connections:\n            mounts = connection.get(\"mounts\", [])\n            hostname = connection[\"hostname\"]\n\n            mcs_mounts = [mount for mount in mounts if mount[\"service\"] == \"Mcs\"]\n\n            if not mounts:\n                self.result.is_failure(f\"Host: {hostname} - No mount status found\")\n                continue\n\n            if not mcs_mounts:\n                self.result.is_failure(f\"Host: {hostname} - MCS mount state not detected\")\n            else:\n                for mount in mcs_mounts:\n                    self.validate_mount_states(mount, hostname)\n                    active_count += 1\n\n        if active_count != self.inputs.connections_count:\n            self.result.is_failure(f\"Incorrect CVX successful connections count - Expected: {self.inputs.connections_count} Actual: {active_count}\")\n</code></pre>"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyMcsServerMounts.mcs_path_types","title":"mcs_path_types  <code>class-attribute</code>","text":"<pre><code>mcs_path_types: list[str] = [\n    \"Mcs::ApiConfigRedundancyStatus\",\n    \"Mcs::ActiveFlows\",\n    \"Mcs::Client::Status\",\n]\n</code></pre> <p>The list of expected MCS path types to verify.</p>"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyMcsServerMounts-attributes","title":"Inputs","text":"Name Type Description Default <code>connections_count</code> <code>int</code>                      The expected number of active CVX Connections with mountStateMountComplete                    -"},{"location":"api/tests/cvx/#anta.tests.cvx.VerifyMcsServerMounts.validate_mount_states","title":"validate_mount_states","text":"<pre><code>validate_mount_states(\n    mount: dict[str, Any], hostname: str\n) -&gt; None\n</code></pre> <p>Validate the mount states of a given mount.</p> Source code in <code>anta/tests/cvx.py</code> <pre><code>def validate_mount_states(self, mount: dict[str, Any], hostname: str) -&gt; None:\n    \"\"\"Validate the mount states of a given mount.\"\"\"\n    mount_states = mount[\"mountStates\"][0]\n\n    if (num_path_states := len(mount_states[\"pathStates\"])) != (expected_num := len(self.mcs_path_types)):\n        self.result.is_failure(f\"Host: {hostname} - Incorrect number of mount path states - Expected: {expected_num} Actual: {num_path_states}\")\n\n    for path in mount_states[\"pathStates\"]:\n        if (path_type := path.get(\"type\")) not in self.mcs_path_types:\n            self.result.is_failure(f\"Host: {hostname} - Unexpected MCS path type - Expected: {', '.join(self.mcs_path_types)} Actual: {path_type}\")\n        if (path_state := path.get(\"state\")) != \"mountStateMountComplete\":\n            self.result.is_failure(\n                f\"Host: {hostname} Path Type: {path_type} - MCS server mount state is not valid - Expected: mountStateMountComplete Actual:{path_state}\"\n            )\n</code></pre>"},{"location":"api/tests/cvx/#input-models","title":"Input models","text":"<p>Module containing input models for CVX tests.</p>"},{"location":"api/tests/cvx/#anta.input_models.cvx.CVXPeers","title":"CVXPeers","text":"<p>Model for a CVX Cluster Peer.</p> Name Type Description Default <code>peer_name</code> <code>Hostname</code>                      The CVX Peer used communicate with a CVX server.                    - <code>registration_state</code> <code>Literal['Connecting', 'Connected', 'Registration error', 'Registration complete', 'Unexpected peer state']</code>                      The CVX registration state.                    <code>'Registration complete'</code> Source code in <code>anta/input_models/cvx.py</code> <pre><code>class CVXPeers(BaseModel):\n    \"\"\"Model for a CVX Cluster Peer.\"\"\"\n\n    peer_name: Hostname\n    \"\"\"The CVX Peer used communicate with a CVX server.\"\"\"\n    registration_state: Literal[\"Connecting\", \"Connected\", \"Registration error\", \"Registration complete\", \"Unexpected peer state\"] = \"Registration complete\"\n    \"\"\"The CVX registration state.\"\"\"\n</code></pre>"},{"location":"api/tests/field_notices/","title":"Field Notices","text":"<p>Module related to field notices tests.</p>"},{"location":"api/tests/field_notices/#anta.tests.field_notices.VerifyFieldNotice44Resolution","title":"VerifyFieldNotice44Resolution","text":"<p>Verifies if the device is using an Aboot version that fixes the bug discussed in the Field Notice 44.</p> <p>Aboot manages system settings prior to EOS initialization.</p> <p>Reference: https://www.arista.com/en/support/advisories-notices/field-notice/8756-field-notice-44</p> Expected Results <ul> <li>Success: The test will pass if the device is using an Aboot version that fixes the bug discussed in the Field Notice 44.</li> <li>Failure: The test will fail if the device is not using an Aboot version that fixes the bug discussed in the Field Notice 44.</li> </ul> Examples <pre><code>anta.tests.field_notices:\n  - VerifyFieldNotice44Resolution:\n</code></pre> Source code in <code>anta/tests/field_notices.py</code> <pre><code>class VerifyFieldNotice44Resolution(AntaTest):\n    \"\"\"Verifies if the device is using an Aboot version that fixes the bug discussed in the Field Notice 44.\n\n    Aboot manages system settings prior to EOS initialization.\n\n    Reference: https://www.arista.com/en/support/advisories-notices/field-notice/8756-field-notice-44\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device is using an Aboot version that fixes the bug discussed in the Field Notice 44.\n    * Failure: The test will fail if the device is not using an Aboot version that fixes the bug discussed in the Field Notice 44.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.field_notices:\n      - VerifyFieldNotice44Resolution:\n    ```\n    \"\"\"\n\n    description = \"Verifies that the device is using the correct Aboot version per FN0044.\"\n    categories: ClassVar[list[str]] = [\"field notices\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show version detail\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyFieldNotice44Resolution.\"\"\"\n        command_output = self.instance_commands[0].json_output\n\n        devices = [\n            \"DCS-7010T-48\",\n            \"DCS-7010T-48-DC\",\n            \"DCS-7050TX-48\",\n            \"DCS-7050TX-64\",\n            \"DCS-7050TX-72\",\n            \"DCS-7050TX-72Q\",\n            \"DCS-7050TX-96\",\n            \"DCS-7050TX2-128\",\n            \"DCS-7050SX-64\",\n            \"DCS-7050SX-72\",\n            \"DCS-7050SX-72Q\",\n            \"DCS-7050SX2-72Q\",\n            \"DCS-7050SX-96\",\n            \"DCS-7050SX2-128\",\n            \"DCS-7050QX-32S\",\n            \"DCS-7050QX2-32S\",\n            \"DCS-7050SX3-48YC12\",\n            \"DCS-7050CX3-32S\",\n            \"DCS-7060CX-32S\",\n            \"DCS-7060CX2-32S\",\n            \"DCS-7060SX2-48YC6\",\n            \"DCS-7160-48YC6\",\n            \"DCS-7160-48TC6\",\n            \"DCS-7160-32CQ\",\n            \"DCS-7280SE-64\",\n            \"DCS-7280SE-68\",\n            \"DCS-7280SE-72\",\n            \"DCS-7150SC-24-CLD\",\n            \"DCS-7150SC-64-CLD\",\n            \"DCS-7020TR-48\",\n            \"DCS-7020TRA-48\",\n            \"DCS-7020SR-24C2\",\n            \"DCS-7020SRG-24C2\",\n            \"DCS-7280TR-48C6\",\n            \"DCS-7280TRA-48C6\",\n            \"DCS-7280SR-48C6\",\n            \"DCS-7280SRA-48C6\",\n            \"DCS-7280SRAM-48C6\",\n            \"DCS-7280SR2K-48C6-M\",\n            \"DCS-7280SR2-48YC6\",\n            \"DCS-7280SR2A-48YC6\",\n            \"DCS-7280SRM-40CX2\",\n            \"DCS-7280QR-C36\",\n            \"DCS-7280QRA-C36S\",\n        ]\n        variants = [\"-SSD-F\", \"-SSD-R\", \"-M-F\", \"-M-R\", \"-F\", \"-R\"]\n\n        model = command_output[\"modelName\"]\n        for variant in variants:\n            model = model.replace(variant, \"\")\n        if model not in devices:\n            self.result.is_skipped(\"Device is not impacted by FN044\")\n            return\n\n        for component in command_output[\"details\"][\"components\"]:\n            if component[\"name\"] == \"Aboot\":\n                aboot_version = component[\"version\"].split(\"-\")[2]\n                break\n        else:\n            self.result.is_failure(\"Aboot component not found\")\n            return\n\n        self.result.is_success()\n        incorrect_aboot_version = (\n            (aboot_version.startswith(\"4.0.\") and int(aboot_version.split(\".\")[2]) &lt; 7)\n            or (aboot_version.startswith(\"4.1.\") and int(aboot_version.split(\".\")[2]) &lt; 1)\n            or (\n                (aboot_version.startswith(\"6.0.\") and int(aboot_version.split(\".\")[2]) &lt; 9)\n                or (aboot_version.startswith(\"6.1.\") and int(aboot_version.split(\".\")[2]) &lt; 7)\n            )\n        )\n        if incorrect_aboot_version:\n            self.result.is_failure(f\"Device is running incorrect version of aboot {aboot_version}\")\n</code></pre>"},{"location":"api/tests/field_notices/#anta.tests.field_notices.VerifyFieldNotice72Resolution","title":"VerifyFieldNotice72Resolution","text":"<p>Verifies if the device is potentially exposed to Field Notice 72, and if the issue has been mitigated.</p> <p>Reference: https://www.arista.com/en/support/advisories-notices/field-notice/17410-field-notice-0072</p> Expected Results <ul> <li>Success: The test will pass if the device is not exposed to FN72 and the issue has been mitigated.</li> <li>Failure: The test will fail if the device is exposed to FN72 and the issue has not been mitigated.</li> </ul> Examples <pre><code>anta.tests.field_notices:\n  - VerifyFieldNotice72Resolution:\n</code></pre> Source code in <code>anta/tests/field_notices.py</code> <pre><code>class VerifyFieldNotice72Resolution(AntaTest):\n    \"\"\"Verifies if the device is potentially exposed to Field Notice 72, and if the issue has been mitigated.\n\n    Reference: https://www.arista.com/en/support/advisories-notices/field-notice/17410-field-notice-0072\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device is not exposed to FN72 and the issue has been mitigated.\n    * Failure: The test will fail if the device is exposed to FN72 and the issue has not been mitigated.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.field_notices:\n      - VerifyFieldNotice72Resolution:\n    ```\n    \"\"\"\n\n    description = \"Verifies if the device is exposed to FN0072, and if the issue has been mitigated.\"\n    categories: ClassVar[list[str]] = [\"field notices\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show version detail\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyFieldNotice72Resolution.\"\"\"\n        command_output = self.instance_commands[0].json_output\n\n        devices = [\"DCS-7280SR3-48YC8\", \"DCS-7280SR3K-48YC8\"]\n        variants = [\"-SSD-F\", \"-SSD-R\", \"-M-F\", \"-M-R\", \"-F\", \"-R\"]\n        model = command_output[\"modelName\"]\n\n        for variant in variants:\n            model = model.replace(variant, \"\")\n        if model not in devices:\n            self.result.is_skipped(\"Platform is not impacted by FN072\")\n            return\n\n        serial = command_output[\"serialNumber\"]\n        number = int(serial[3:7])\n\n        if \"JPE\" not in serial and \"JAS\" not in serial:\n            self.result.is_skipped(\"Device not exposed\")\n            return\n\n        if model == \"DCS-7280SR3-48YC8\" and \"JPE\" in serial and number &gt;= 2131:\n            self.result.is_skipped(\"Device not exposed\")\n            return\n\n        if model == \"DCS-7280SR3-48YC8\" and \"JAS\" in serial and number &gt;= 2041:\n            self.result.is_skipped(\"Device not exposed\")\n            return\n\n        if model == \"DCS-7280SR3K-48YC8\" and \"JPE\" in serial and number &gt;= 2134:\n            self.result.is_skipped(\"Device not exposed\")\n            return\n\n        if model == \"DCS-7280SR3K-48YC8\" and \"JAS\" in serial and number &gt;= 2041:\n            self.result.is_skipped(\"Device not exposed\")\n            return\n\n        # Because each of the if checks above will return if taken, we only run the long check if we get this far\n        for entry in command_output[\"details\"][\"components\"]:\n            if entry[\"name\"] == \"FixedSystemvrm1\":\n                if int(entry[\"version\"]) &lt; 7:\n                    self.result.is_failure(\"Device is exposed to FN72\")\n                else:\n                    self.result.is_success(\"FN72 is mitigated\")\n                return\n        # We should never hit this point\n        self.result.is_failure(\"Error in running test - Component FixedSystemvrm1 not found in 'show version'\")\n</code></pre>"},{"location":"api/tests/flow_tracking/","title":"Flow Tracking","text":""},{"location":"api/tests/flow_tracking/#tests","title":"Tests","text":"<p>Module related to the flow tracking tests.</p>"},{"location":"api/tests/flow_tracking/#anta.tests.flow_tracking.VerifyHardwareFlowTrackerStatus","title":"VerifyHardwareFlowTrackerStatus","text":"<p>Verifies the hardware flow tracking state.</p> <p>This test performs the following checks:</p> <ol> <li>Confirms that hardware flow tracking is running.</li> <li>For each specified flow tracker:<ul> <li>Confirms that the tracker is active.</li> <li>Optionally, checks the tracker interval/timeout configuration.</li> <li>Optionally, verifies the tracker exporter configuration</li> </ul> </li> </ol> Expected Results <ul> <li>Success: The test will pass if all of the following conditions are met:<ul> <li>Hardware flow tracking is running.</li> <li>For each specified flow tracker:<ul> <li>The flow tracker is active.</li> <li>The tracker interval/timeout matches the expected values, if provided.</li> <li>The exporter configuration matches the expected values, if provided.</li> </ul> </li> </ul> </li> <li>Failure: The test will fail if any of the following conditions are met:<ul> <li>Hardware flow tracking is not running.</li> <li>For any specified flow tracker:<ul> <li>The flow tracker is not active.</li> <li>The tracker interval/timeout does not match the expected values, if provided.</li> <li>The exporter configuration does not match the expected values, if provided.</li> </ul> </li> </ul> </li> </ul> Examples <pre><code>anta.tests.flow_tracking:\n  - VerifyHardwareFlowTrackerStatus:\n      trackers:\n        - name: FLOW-TRACKER\n          record_export:\n            on_inactive_timeout: 70000\n            on_interval: 300000\n          exporters:\n            - name: CV-TELEMETRY\n              local_interface: Loopback0\n              template_interval: 3600000\n</code></pre> Source code in <code>anta/tests/flow_tracking.py</code> <pre><code>class VerifyHardwareFlowTrackerStatus(AntaTest):\n    \"\"\"Verifies the hardware flow tracking state.\n\n    This test performs the following checks:\n\n      1. Confirms that hardware flow tracking is running.\n      2. For each specified flow tracker:\n        - Confirms that the tracker is active.\n        - Optionally, checks the tracker interval/timeout configuration.\n        - Optionally, verifies the tracker exporter configuration\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all of the following conditions are met:\n        - Hardware flow tracking is running.\n        - For each specified flow tracker:\n            - The flow tracker is active.\n            - The tracker interval/timeout matches the expected values, if provided.\n            - The exporter configuration matches the expected values, if provided.\n    * Failure: The test will fail if any of the following conditions are met:\n        - Hardware flow tracking is not running.\n        - For any specified flow tracker:\n            - The flow tracker is not active.\n            - The tracker interval/timeout does not match the expected values, if provided.\n            - The exporter configuration does not match the expected values, if provided.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.flow_tracking:\n      - VerifyHardwareFlowTrackerStatus:\n          trackers:\n            - name: FLOW-TRACKER\n              record_export:\n                on_inactive_timeout: 70000\n                on_interval: 300000\n              exporters:\n                - name: CV-TELEMETRY\n                  local_interface: Loopback0\n                  template_interval: 3600000\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"flow tracking\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show flow tracking hardware\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyHardwareFlowTrackerStatus test.\"\"\"\n\n        trackers: list[FlowTracker]\n        \"\"\"List of flow trackers to verify.\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyHardwareFlowTrackerStatus.\"\"\"\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output\n        # Check if hardware flow tracking is configured\n        if not command_output.get(\"running\"):\n            self.result.is_failure(\"Hardware flow tracking is not running\")\n            return\n\n        for tracker in self.inputs.trackers:\n            # Check if the input hardware tracker is configured\n            if not (tracker_info := get_value(command_output[\"trackers\"], f\"{tracker.name}\")):\n                self.result.is_failure(f\"{tracker} - Not found\")\n                continue\n\n            # Check if the input hardware tracker is active\n            if not tracker_info.get(\"active\"):\n                self.result.is_failure(f\"{tracker} - Disabled\")\n                continue\n\n            # Check the input hardware tracker timeouts\n            if tracker.record_export:\n                inactive_interval = tracker.record_export.on_inactive_timeout\n                on_interval = tracker.record_export.on_interval\n                act_inactive = tracker_info.get(\"inactiveTimeout\")\n                act_interval = tracker_info.get(\"activeInterval\")\n                if not all([inactive_interval == act_inactive, on_interval == act_interval]):\n                    self.result.is_failure(\n                        f\"{tracker} {tracker.record_export} - Incorrect timers - Inactive Timeout: {act_inactive} OnActive Interval: {act_interval}\"\n                    )\n\n            # Check the input hardware tracker exporters configuration\n            if tracker.exporters:\n                failure_messages = validate_exporters(tracker.exporters, tracker_info)\n                for message in failure_messages:\n                    self.result.is_failure(f\"{tracker} {message}\")\n</code></pre>"},{"location":"api/tests/flow_tracking/#anta.tests.flow_tracking.VerifyHardwareFlowTrackerStatus-attributes","title":"Inputs","text":"Name Type Description Default <code>trackers</code> <code>list[FlowTracker]</code>                      List of flow trackers to verify.                    -"},{"location":"api/tests/flow_tracking/#input-models","title":"Input models","text":"<p>Module containing input models for flow tracking tests.</p>"},{"location":"api/tests/flow_tracking/#anta.input_models.flow_tracking.Exporter","title":"Exporter","text":"<p>Model representing the exporter used for flow record export.</p> Name Type Description Default <code>name</code> <code>str</code>                      The name of the exporter.                    - <code>local_interface</code> <code>str</code>                      The local interface used by the exporter to send flow records.                    - <code>template_interval</code> <code>int</code>                      The template interval, in milliseconds, for the exporter to refresh the flow template.                    - Source code in <code>anta/input_models/flow_tracking.py</code> <pre><code>class Exporter(BaseModel):\n    \"\"\"Model representing the exporter used for flow record export.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    name: str\n    \"\"\"The name of the exporter.\"\"\"\n    local_interface: str\n    \"\"\"The local interface used by the exporter to send flow records.\"\"\"\n    template_interval: int\n    \"\"\"The template interval, in milliseconds, for the exporter to refresh the flow template.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the Exporter for reporting.\n\n        Examples\n        --------\n        Exporter: CVP-TELEMETRY\n\n        \"\"\"\n        return f\"Exporter: {self.name}\"\n</code></pre>"},{"location":"api/tests/flow_tracking/#anta.input_models.flow_tracking.FlowTracker","title":"FlowTracker","text":"<p>Flow Tracking model representing the tracker details.</p> Name Type Description Default <code>name</code> <code>str</code>                      The name of the flow tracker.                    - <code>record_export</code> <code>RecordExport | None</code>                      Configuration for record export, specifying details about timeouts.                    <code>None</code> <code>exporters</code> <code>list[Exporter] | None</code>                      A list of exporters associated with the flow tracker.                    <code>None</code> Source code in <code>anta/input_models/flow_tracking.py</code> <pre><code>class FlowTracker(BaseModel):\n    \"\"\"Flow Tracking model representing the tracker details.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    name: str\n    \"\"\"The name of the flow tracker.\"\"\"\n    record_export: RecordExport | None = None\n    \"\"\"Configuration for record export, specifying details about timeouts.\"\"\"\n    exporters: list[Exporter] | None = None\n    \"\"\"A list of exporters associated with the flow tracker.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the FlowTracker for reporting.\n\n        Examples\n        --------\n        Flow Tracker: FLOW-TRACKER\n\n        \"\"\"\n        return f\"Flow Tracker: {self.name}\"\n</code></pre>"},{"location":"api/tests/flow_tracking/#anta.input_models.flow_tracking.RecordExport","title":"RecordExport","text":"<p>Model representing the record export configuration for a flow tracker.</p> Name Type Description Default <code>on_inactive_timeout</code> <code>int</code>                      The timeout in milliseconds for exporting flow records when the flow becomes inactive.                    - <code>on_interval</code> <code>int</code>                      The interval in milliseconds for exporting flow records.                    - Source code in <code>anta/input_models/flow_tracking.py</code> <pre><code>class RecordExport(BaseModel):\n    \"\"\"Model representing the record export configuration for a flow tracker.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    on_inactive_timeout: int\n    \"\"\"The timeout in milliseconds for exporting flow records when the flow becomes inactive.\"\"\"\n    on_interval: int\n    \"\"\"The interval in milliseconds for exporting flow records.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the RecordExport for reporting.\n\n        Examples\n        --------\n        Inactive Timeout: 60000, Active Interval: 300000\n\n        \"\"\"\n        return f\"Inactive Timeout: {self.on_inactive_timeout} Active Interval: {self.on_interval}\"\n</code></pre>"},{"location":"api/tests/greent/","title":"GreenT","text":"<p>Module related to GreenT (Postcard Telemetry) tests.</p>"},{"location":"api/tests/greent/#anta.tests.greent.VerifyGreenT","title":"VerifyGreenT","text":"<p>Verifies if a GreenT (GRE Encapsulated Telemetry) policy other than the default is created.</p> Expected Results <ul> <li>Success: The test will pass if a GreenT policy is created other than the default one.</li> <li>Failure: The test will fail if no other GreenT policy is created.</li> </ul> Examples <pre><code>anta.tests.greent:\n  - VerifyGreenT:\n</code></pre> Source code in <code>anta/tests/greent.py</code> <pre><code>class VerifyGreenT(AntaTest):\n    \"\"\"Verifies if a GreenT (GRE Encapsulated Telemetry) policy other than the default is created.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if a GreenT policy is created other than the default one.\n    * Failure: The test will fail if no other GreenT policy is created.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.greent:\n      - VerifyGreenT:\n    ```\n\n    \"\"\"\n\n    description = \"Verifies if a GreenT policy other than the default is created.\"\n    categories: ClassVar[list[str]] = [\"greent\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show monitor telemetry postcard policy profile\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyGreenT.\"\"\"\n        command_output = self.instance_commands[0].json_output\n\n        profiles = [profile for profile in command_output[\"profiles\"] if profile != \"default\"]\n\n        if profiles:\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"No GreenT policy is created\")\n</code></pre>"},{"location":"api/tests/greent/#anta.tests.greent.VerifyGreenTCounters","title":"VerifyGreenTCounters","text":"<p>Verifies if the GreenT (GRE Encapsulated Telemetry) counters are incremented.</p> Expected Results <ul> <li>Success: The test will pass if the GreenT counters are incremented.</li> <li>Failure: The test will fail if the GreenT counters are not incremented.</li> </ul> Examples <pre><code>anta.tests.greent:\n  - VerifyGreenTCounters:\n</code></pre> Source code in <code>anta/tests/greent.py</code> <pre><code>class VerifyGreenTCounters(AntaTest):\n    \"\"\"Verifies if the GreenT (GRE Encapsulated Telemetry) counters are incremented.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the GreenT counters are incremented.\n    * Failure: The test will fail if the GreenT counters are not incremented.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.greent:\n      - VerifyGreenTCounters:\n    ```\n\n    \"\"\"\n\n    description = \"Verifies if the GreenT counters are incremented.\"\n    categories: ClassVar[list[str]] = [\"greent\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show monitor telemetry postcard counters\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyGreenTCounters.\"\"\"\n        command_output = self.instance_commands[0].json_output\n\n        if command_output[\"grePktSent\"] &gt; 0:\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"GreenT counters are not incremented\")\n</code></pre>"},{"location":"api/tests/hardware/","title":"Hardware","text":"<p>Module related to the hardware or environment tests.</p>"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyAdverseDrops","title":"VerifyAdverseDrops","text":"<p>Verifies there are no adverse drops on DCS-7280 and DCS-7500 family switches.</p> Expected Results <ul> <li>Success: The test will pass if there are no adverse drops.</li> <li>Failure: The test will fail if there are adverse drops.</li> </ul> Examples <pre><code>anta.tests.hardware:\n  - VerifyAdverseDrops:\n</code></pre> Source code in <code>anta/tests/hardware.py</code> <pre><code>class VerifyAdverseDrops(AntaTest):\n    \"\"\"Verifies there are no adverse drops on DCS-7280 and DCS-7500 family switches.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are no adverse drops.\n    * Failure: The test will fail if there are adverse drops.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.hardware:\n      - VerifyAdverseDrops:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"hardware\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show hardware counter drop\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAdverseDrops.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        total_adverse_drop = command_output.get(\"totalAdverseDrops\", \"\")\n        if total_adverse_drop != 0:\n            self.result.is_failure(f\"Incorrect total adverse drops counter - Expected: 0 Actual: {total_adverse_drop}\")\n</code></pre>"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyEnvironmentCooling","title":"VerifyEnvironmentCooling","text":"<p>Verifies the status of power supply fans and all fan trays.</p> Expected Results <ul> <li>Success: The test will pass if the fans status are within the accepted states list.</li> <li>Failure: The test will fail if some fans status is not within the accepted states list.</li> </ul> Examples <pre><code>anta.tests.hardware:\n  - VerifyEnvironmentCooling:\n      states:\n        - ok\n</code></pre> Source code in <code>anta/tests/hardware.py</code> <pre><code>class VerifyEnvironmentCooling(AntaTest):\n    \"\"\"Verifies the status of power supply fans and all fan trays.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the fans status are within the accepted states list.\n    * Failure: The test will fail if some fans status is not within the accepted states list.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.hardware:\n      - VerifyEnvironmentCooling:\n          states:\n            - ok\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"hardware\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show system environment cooling\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyEnvironmentCooling test.\"\"\"\n\n        states: list[str]\n        \"\"\"List of accepted states of fan status.\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyEnvironmentCooling.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        # First go through power supplies fans\n        for power_supply in command_output.get(\"powerSupplySlots\", []):\n            for fan in power_supply.get(\"fans\", []):\n                if (state := fan[\"status\"]) not in self.inputs.states:\n                    self.result.is_failure(\n                        f\"Power Slot: {power_supply['label']} Fan: {fan['label']} - Invalid state - Expected: {', '.join(self.inputs.states)} Actual: {state}\"\n                    )\n        # Then go through fan trays\n        for fan_tray in command_output.get(\"fanTraySlots\", []):\n            for fan in fan_tray.get(\"fans\", []):\n                if (state := fan[\"status\"]) not in self.inputs.states:\n                    self.result.is_failure(\n                        f\"Fan Tray: {fan_tray['label']} Fan: {fan['label']} - Invalid state - Expected: {', '.join(self.inputs.states)} Actual: {state}\"\n                    )\n</code></pre>"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyEnvironmentCooling-attributes","title":"Inputs","text":"Name Type Description Default <code>states</code> <code>list[str]</code>                      List of accepted states of fan status.                    -"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyEnvironmentPower","title":"VerifyEnvironmentPower","text":"<p>Verifies the power supplies status.</p> Expected Results <ul> <li>Success: The test will pass if the power supplies status are within the accepted states list.</li> <li>Failure: The test will fail if some power supplies status is not within the accepted states list.</li> </ul> Examples <pre><code>anta.tests.hardware:\n  - VerifyEnvironmentPower:\n      states:\n        - ok\n</code></pre> Source code in <code>anta/tests/hardware.py</code> <pre><code>class VerifyEnvironmentPower(AntaTest):\n    \"\"\"Verifies the power supplies status.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the power supplies status are within the accepted states list.\n    * Failure: The test will fail if some power supplies status is not within the accepted states list.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.hardware:\n      - VerifyEnvironmentPower:\n          states:\n            - ok\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"hardware\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show system environment power\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyEnvironmentPower test.\"\"\"\n\n        states: list[str]\n        \"\"\"List of accepted states list of power supplies status.\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyEnvironmentPower.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        power_supplies = command_output.get(\"powerSupplies\", \"{}\")\n        for power_supply, value in dict(power_supplies).items():\n            if (state := value[\"state\"]) not in self.inputs.states:\n                self.result.is_failure(f\"Power Slot: {power_supply} - Invalid power supplies state - Expected: {', '.join(self.inputs.states)} Actual: {state}\")\n</code></pre>"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyEnvironmentPower-attributes","title":"Inputs","text":"Name Type Description Default <code>states</code> <code>list[str]</code>                      List of accepted states list of power supplies status.                    -"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyEnvironmentSystemCooling","title":"VerifyEnvironmentSystemCooling","text":"<p>Verifies the device\u2019s system cooling status.</p> Expected Results <ul> <li>Success: The test will pass if the system cooling status is OK: \u2018coolingOk\u2019.</li> <li>Failure: The test will fail if the system cooling status is NOT OK.</li> </ul> Examples <pre><code>anta.tests.hardware:\n  - VerifyEnvironmentSystemCooling:\n</code></pre> Source code in <code>anta/tests/hardware.py</code> <pre><code>class VerifyEnvironmentSystemCooling(AntaTest):\n    \"\"\"Verifies the device's system cooling status.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the system cooling status is OK: 'coolingOk'.\n    * Failure: The test will fail if the system cooling status is NOT OK.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.hardware:\n      - VerifyEnvironmentSystemCooling:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"hardware\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show system environment cooling\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyEnvironmentSystemCooling.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        sys_status = command_output.get(\"systemStatus\", \"\")\n        self.result.is_success()\n        if sys_status != \"coolingOk\":\n            self.result.is_failure(f\"Device system cooling status invalid - Expected: coolingOk Actual: {sys_status}\")\n</code></pre>"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyTemperature","title":"VerifyTemperature","text":"<p>Verifies if the device temperature is within acceptable limits.</p> Expected Results <ul> <li>Success: The test will pass if the device temperature is currently OK: \u2018temperatureOk\u2019.</li> <li>Failure: The test will fail if the device temperature is NOT OK.</li> </ul> Examples <pre><code>anta.tests.hardware:\n  - VerifyTemperature:\n</code></pre> Source code in <code>anta/tests/hardware.py</code> <pre><code>class VerifyTemperature(AntaTest):\n    \"\"\"Verifies if the device temperature is within acceptable limits.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device temperature is currently OK: 'temperatureOk'.\n    * Failure: The test will fail if the device temperature is NOT OK.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.hardware:\n      - VerifyTemperature:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"hardware\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show system environment temperature\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTemperature.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        temperature_status = command_output.get(\"systemStatus\", \"\")\n        if temperature_status != \"temperatureOk\":\n            self.result.is_failure(f\"Device temperature exceeds acceptable limits - Expected: temperatureOk Actual: {temperature_status}\")\n</code></pre>"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyTransceiversManufacturers","title":"VerifyTransceiversManufacturers","text":"<p>Verifies if all the transceivers come from approved manufacturers.</p> Expected Results <ul> <li>Success: The test will pass if all transceivers are from approved manufacturers.</li> <li>Failure: The test will fail if some transceivers are from unapproved manufacturers.</li> </ul> Examples <pre><code>anta.tests.hardware:\n  - VerifyTransceiversManufacturers:\n      manufacturers:\n        - Not Present\n        - Arista Networks\n        - Arastra, Inc.\n</code></pre> Source code in <code>anta/tests/hardware.py</code> <pre><code>class VerifyTransceiversManufacturers(AntaTest):\n    \"\"\"Verifies if all the transceivers come from approved manufacturers.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all transceivers are from approved manufacturers.\n    * Failure: The test will fail if some transceivers are from unapproved manufacturers.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.hardware:\n      - VerifyTransceiversManufacturers:\n          manufacturers:\n            - Not Present\n            - Arista Networks\n            - Arastra, Inc.\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"hardware\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show inventory\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyTransceiversManufacturers test.\"\"\"\n\n        manufacturers: list[str]\n        \"\"\"List of approved transceivers manufacturers.\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTransceiversManufacturers.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        for interface, value in command_output[\"xcvrSlots\"].items():\n            if value[\"mfgName\"] not in self.inputs.manufacturers:\n                self.result.is_failure(\n                    f\"Interface: {interface} - Transceiver is from unapproved manufacturers - Expected: {', '.join(self.inputs.manufacturers)}\"\n                    f\" Actual: {value['mfgName']}\"\n                )\n</code></pre>"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyTransceiversManufacturers-attributes","title":"Inputs","text":"Name Type Description Default <code>manufacturers</code> <code>list[str]</code>                      List of approved transceivers manufacturers.                    -"},{"location":"api/tests/hardware/#anta.tests.hardware.VerifyTransceiversTemperature","title":"VerifyTransceiversTemperature","text":"<p>Verifies if all the transceivers are operating at an acceptable temperature.</p> Expected Results <ul> <li>Success: The test will pass if all transceivers status are OK: \u2018ok\u2019.</li> <li>Failure: The test will fail if some transceivers are NOT OK.</li> </ul> Examples <pre><code>anta.tests.hardware:\n  - VerifyTransceiversTemperature:\n</code></pre> Source code in <code>anta/tests/hardware.py</code> <pre><code>class VerifyTransceiversTemperature(AntaTest):\n    \"\"\"Verifies if all the transceivers are operating at an acceptable temperature.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all transceivers status are OK: 'ok'.\n    * Failure: The test will fail if some transceivers are NOT OK.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.hardware:\n      - VerifyTransceiversTemperature:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"hardware\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show system environment temperature transceiver\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTransceiversTemperature.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        sensors = command_output.get(\"tempSensors\", \"\")\n        for sensor in sensors:\n            if sensor[\"hwStatus\"] != \"ok\":\n                self.result.is_failure(f\"Sensor: {sensor['name']} - Invalid hardware state - Expected: ok Actual: {sensor['hwStatus']}\")\n            if sensor[\"alertCount\"] != 0:\n                self.result.is_failure(f\"Sensor: {sensor['name']} - Incorrect alert counter - Expected: 0 Actual: {sensor['alertCount']}\")\n</code></pre>"},{"location":"api/tests/interfaces/","title":"Interfaces","text":""},{"location":"api/tests/interfaces/#tests","title":"Tests","text":"<p>Module related to the device interfaces tests.</p>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyIPProxyARP","title":"VerifyIPProxyARP","text":"<p>Verifies if Proxy ARP is enabled.</p> Expected Results <ul> <li>Success: The test will pass if Proxy-ARP is enabled on the specified interface(s).</li> <li>Failure: The test will fail if Proxy-ARP is disabled on the specified interface(s).</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyIPProxyARP:\n      interfaces:\n        - Ethernet1\n        - Ethernet2\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyIPProxyARP(AntaTest):\n    \"\"\"Verifies if Proxy ARP is enabled.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if Proxy-ARP is enabled on the specified interface(s).\n    * Failure: The test will fail if Proxy-ARP is disabled on the specified interface(s).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyIPProxyARP:\n          interfaces:\n            - Ethernet1\n            - Ethernet2\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip interface\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyIPProxyARP test.\"\"\"\n\n        interfaces: list[Interface]\n        \"\"\"List of interfaces to be tested.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIPProxyARP.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        for interface in self.inputs.interfaces:\n            if (interface_detail := get_value(command_output[\"interfaces\"], f\"{interface}\", separator=\"..\")) is None:\n                self.result.is_failure(f\"Interface: {interface} - Not found\")\n                continue\n\n            if not interface_detail[\"proxyArp\"]:\n                self.result.is_failure(f\"Interface: {interface} - Proxy-ARP disabled\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyIPProxyARP-attributes","title":"Inputs","text":"Name Type Description Default <code>interfaces</code> <code>list[Interface]</code>                      List of interfaces to be tested.                    -"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyIllegalLACP","title":"VerifyIllegalLACP","text":"<p>Verifies there are no illegal LACP packets in all port channels.</p> Expected Results <ul> <li>Success: The test will pass if there are no illegal LACP packets received.</li> <li>Failure: The test will fail if there is at least one illegal LACP packet received.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyIllegalLACP:\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyIllegalLACP(AntaTest):\n    \"\"\"Verifies there are no illegal LACP packets in all port channels.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are no illegal LACP packets received.\n    * Failure: The test will fail if there is at least one illegal LACP packet received.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyIllegalLACP:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show lacp counters all-ports\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIllegalLACP.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        for port_channel, port_channel_dict in command_output[\"portChannels\"].items():\n            for interface, interface_details in port_channel_dict[\"interfaces\"].items():\n                # Verify that the no illegal LACP packets in all port channels.\n                if interface_details[\"illegalRxCount\"] != 0:\n                    self.result.is_failure(f\"{port_channel} Interface: {interface} - Illegal LACP packets found\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfaceDiscards","title":"VerifyInterfaceDiscards","text":"<p>Verifies that the interfaces packet discard counters are equal to zero.</p> Expected Results <ul> <li>Success: The test will pass if all interfaces have discard counters equal to zero.</li> <li>Failure: The test will fail if one or more interfaces have non-zero discard counters.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyInterfaceDiscards:\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyInterfaceDiscards(AntaTest):\n    \"\"\"Verifies that the interfaces packet discard counters are equal to zero.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all interfaces have discard counters equal to zero.\n    * Failure: The test will fail if one or more interfaces have non-zero discard counters.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyInterfaceDiscards:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces counters discards\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyInterfaceDiscards.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        for interface, interface_data in command_output[\"interfaces\"].items():\n            counters_data = [f\"{counter}: {value}\" for counter, value in interface_data.items() if value &gt; 0]\n            if counters_data:\n                self.result.is_failure(f\"Interface: {interface} - Non-zero discard counter(s): {', '.join(counters_data)}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfaceErrDisabled","title":"VerifyInterfaceErrDisabled","text":"<p>Verifies there are no interfaces in the errdisabled state.</p> Expected Results <ul> <li>Success: The test will pass if there are no interfaces in the errdisabled state.</li> <li>Failure: The test will fail if there is at least one interface in the errdisabled state.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyInterfaceErrDisabled:\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyInterfaceErrDisabled(AntaTest):\n    \"\"\"Verifies there are no interfaces in the errdisabled state.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are no interfaces in the errdisabled state.\n    * Failure: The test will fail if there is at least one interface in the errdisabled state.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyInterfaceErrDisabled:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces status\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyInterfaceErrDisabled.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        for interface, value in command_output[\"interfaceStatuses\"].items():\n            if value[\"linkStatus\"] == \"errdisabled\":\n                self.result.is_failure(f\"Interface: {interface} - Link status Error disabled\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfaceErrors","title":"VerifyInterfaceErrors","text":"<p>Verifies that the interfaces error counters are equal to zero.</p> Expected Results <ul> <li>Success: The test will pass if all interfaces have error counters equal to zero.</li> <li>Failure: The test will fail if one or more interfaces have non-zero error counters.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyInterfaceErrors:\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyInterfaceErrors(AntaTest):\n    \"\"\"Verifies that the interfaces error counters are equal to zero.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all interfaces have error counters equal to zero.\n    * Failure: The test will fail if one or more interfaces have non-zero error counters.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyInterfaceErrors:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces counters errors\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyInterfaceErrors.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        for interface, counters in command_output[\"interfaceErrorCounters\"].items():\n            counters_data = [f\"{counter}: {value}\" for counter, value in counters.items() if value &gt; 0]\n            if counters_data:\n                self.result.is_failure(f\"Interface: {interface} - Non-zero error counter(s) - {', '.join(counters_data)}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfaceIPv4","title":"VerifyInterfaceIPv4","text":"<p>Verifies the interface IPv4 addresses.</p> Expected Results <ul> <li>Success: The test will pass if an interface is configured with a correct primary and secondary IPv4 address.</li> <li>Failure: The test will fail if an interface is not found or the primary and secondary IPv4 addresses do not match with the input.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyInterfaceIPv4:\n      interfaces:\n        - name: Ethernet2\n          primary_ip: 172.30.11.1/31\n          secondary_ips:\n            - 10.10.10.1/31\n            - 10.10.10.10/31\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyInterfaceIPv4(AntaTest):\n    \"\"\"Verifies the interface IPv4 addresses.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if an interface is configured with a correct primary and secondary IPv4 address.\n    * Failure: The test will fail if an interface is not found or the primary and secondary IPv4 addresses do not match with the input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyInterfaceIPv4:\n          interfaces:\n            - name: Ethernet2\n              primary_ip: 172.30.11.1/31\n              secondary_ips:\n                - 10.10.10.1/31\n                - 10.10.10.10/31\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip interface\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyInterfaceIPv4 test.\"\"\"\n\n        interfaces: list[InterfaceState]\n        \"\"\"List of interfaces with their details.\"\"\"\n        InterfaceDetail: ClassVar[type[InterfaceDetail]] = InterfaceDetail\n\n        @field_validator(\"interfaces\")\n        @classmethod\n        def validate_interfaces(cls, interfaces: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'primary_ip' field is provided in each interface.\"\"\"\n            for interface in interfaces:\n                if interface.primary_ip is None:\n                    msg = f\"{interface} 'primary_ip' field missing in the input\"\n                    raise ValueError(msg)\n            return interfaces\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyInterfaceIPv4.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        for interface in self.inputs.interfaces:\n            if (interface_detail := get_value(command_output[\"interfaces\"], f\"{interface.name}\", separator=\"..\")) is None:\n                self.result.is_failure(f\"{interface} - Not found\")\n                continue\n\n            if (ip_address := get_value(interface_detail, \"interfaceAddress.primaryIp\")) is None:\n                self.result.is_failure(f\"{interface} - IP address is not configured\")\n                continue\n\n            # Combine IP address and subnet for primary IP\n            actual_primary_ip = f\"{ip_address['address']}/{ip_address['maskLen']}\"\n\n            # Check if the primary IP address matches the input\n            if actual_primary_ip != str(interface.primary_ip):\n                self.result.is_failure(f\"{interface} - IP address mismatch - Expected: {interface.primary_ip} Actual: {actual_primary_ip}\")\n\n            if interface.secondary_ips:\n                if not (secondary_ips := get_value(interface_detail, \"interfaceAddress.secondaryIpsOrderedList\")):\n                    self.result.is_failure(f\"{interface} - Secondary IP address is not configured\")\n                    continue\n\n                actual_secondary_ips = sorted([f\"{secondary_ip['address']}/{secondary_ip['maskLen']}\" for secondary_ip in secondary_ips])\n                input_secondary_ips = sorted([str(ip) for ip in interface.secondary_ips])\n\n                if actual_secondary_ips != input_secondary_ips:\n                    self.result.is_failure(\n                        f\"{interface} - Secondary IP address mismatch - Expected: {', '.join(input_secondary_ips)} Actual: {', '.join(actual_secondary_ips)}\"\n                    )\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfaceIPv4-attributes","title":"Inputs","text":"Name Type Description Default <code>interfaces</code> <code>list[InterfaceState]</code>                      List of interfaces with their details.                    -"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfaceUtilization","title":"VerifyInterfaceUtilization","text":"<p>Verifies that the utilization of interfaces is below a certain threshold.</p> <p>Load interval (default to 5 minutes) is defined in device configuration.</p> <p>Warning</p> <p>This test has been implemented for full-duplex interfaces only.</p> Expected Results <ul> <li>Success: The test will pass if all interfaces have a usage below the threshold.</li> <li>Failure: If any of the following occur:<ul> <li>One or more interfaces have a usage above the threshold.</li> <li>The device has at least one non full-duplex interface.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyInterfaceUtilization:\n      threshold: 70.0\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyInterfaceUtilization(AntaTest):\n    \"\"\"Verifies that the utilization of interfaces is below a certain threshold.\n\n    Load interval (default to 5 minutes) is defined in device configuration.\n\n    !!! warning\n        This test has been implemented for full-duplex interfaces only.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all interfaces have a usage below the threshold.\n    * Failure: If any of the following occur:\n        - One or more interfaces have a usage above the threshold.\n        - The device has at least one non full-duplex interface.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyInterfaceUtilization:\n          threshold: 70.0\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaCommand(command=\"show interfaces counters rates\", revision=1),\n        AntaCommand(command=\"show interfaces\", revision=1),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyInterfaceUtilization test.\"\"\"\n\n        threshold: Percent = 75.0\n        \"\"\"Interface utilization threshold above which the test will fail.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyInterfaceUtilization.\"\"\"\n        self.result.is_success()\n        duplex_full = \"duplexFull\"\n        rates = self.instance_commands[0].json_output\n        interfaces = self.instance_commands[1].json_output\n\n        for intf, rate in rates[\"interfaces\"].items():\n            interface_data = []\n            # The utilization logic has been implemented for full-duplex interfaces only\n            if not all([duplex := (interface := interfaces[\"interfaces\"][intf]).get(\"duplex\", None), duplex == duplex_full]):\n                if (members := interface.get(\"memberInterfaces\", None)) is None:\n                    self.result.is_failure(f\"Interface: {intf} - Test not implemented for non-full-duplex interfaces - Expected: {duplex_full} Actual: {duplex}\")\n                    continue\n                interface_data = [(member_interface, state) for member_interface, stats in members.items() if (state := stats[\"duplex\"]) != duplex_full]\n\n            for member_interface in interface_data:\n                self.result.is_failure(\n                    f\"Interface: {intf} Member Interface: {member_interface[0]} - Test not implemented for non-full-duplex interfaces - Expected: {duplex_full}\"\n                    f\" Actual: {member_interface[1]}\"\n                )\n\n            if (bandwidth := interfaces[\"interfaces\"][intf][\"bandwidth\"]) == 0:\n                self.logger.debug(\"Interface %s has been ignored due to null bandwidth value\", intf)\n                continue\n\n            # If one or more interfaces have a usage above the threshold, test fails.\n            for bps_rate in (\"inBpsRate\", \"outBpsRate\"):\n                usage = rate[bps_rate] / bandwidth * 100\n                if usage &gt; self.inputs.threshold:\n                    self.result.is_failure(\n                        f\"Interface: {intf} BPS Rate: {bps_rate} - Usage exceeds the threshold - Expected: &lt; {self.inputs.threshold}% Actual: {usage}%\"\n                    )\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfaceUtilization-attributes","title":"Inputs","text":"Name Type Description Default <code>threshold</code> <code>Percent</code>                      Interface utilization threshold above which the test will fail.                    <code>75.0</code>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfacesSpeed","title":"VerifyInterfacesSpeed","text":"<p>Verifies the speed, lanes, auto-negotiation status, and mode as full duplex for interfaces.</p> <ul> <li>If the auto-negotiation status is set to True, verifies that auto-negotiation is successful, the mode is full duplex and the speed/lanes match the input.</li> <li>If the auto-negotiation status is set to False, verifies that the mode is full duplex and the speed/lanes match the input.</li> </ul> Expected Results <ul> <li>Success: The test will pass if an interface is configured correctly with the specified speed, lanes, auto-negotiation status, and mode as full duplex.</li> <li>Failure: The test will fail if an interface is not found, if the speed, lanes, and auto-negotiation status do not match the input, or mode is not full duplex.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyInterfacesSpeed:\n      interfaces:\n        - name: Ethernet2\n          auto: False\n          speed: 10\n        - name: Eth3\n          auto: True\n          speed: 100\n          lanes: 1\n        - name: Eth2\n          auto: False\n          speed: 2.5\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyInterfacesSpeed(AntaTest):\n    \"\"\"Verifies the speed, lanes, auto-negotiation status, and mode as full duplex for interfaces.\n\n    - If the auto-negotiation status is set to True, verifies that auto-negotiation is successful, the mode is full duplex and the speed/lanes match the input.\n    - If the auto-negotiation status is set to False, verifies that the mode is full duplex and the speed/lanes match the input.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if an interface is configured correctly with the specified speed, lanes, auto-negotiation status, and mode as full duplex.\n    * Failure: The test will fail if an interface is not found, if the speed, lanes, and auto-negotiation status do not match the input, or mode is not full duplex.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyInterfacesSpeed:\n          interfaces:\n            - name: Ethernet2\n              auto: False\n              speed: 10\n            - name: Eth3\n              auto: True\n              speed: 100\n              lanes: 1\n            - name: Eth2\n              auto: False\n              speed: 2.5\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Inputs for the VerifyInterfacesSpeed test.\"\"\"\n\n        interfaces: list[InterfaceState]\n        \"\"\"List of interfaces with their expected state.\"\"\"\n        InterfaceDetail: ClassVar[type[InterfaceDetail]] = InterfaceDetail\n\n        @field_validator(\"interfaces\")\n        @classmethod\n        def validate_interfaces(cls, interfaces: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'speed' field is provided in each interface.\"\"\"\n            for interface in interfaces:\n                if interface.speed is None:\n                    msg = f\"{interface} 'speed' field missing in the input\"\n                    raise ValueError(msg)\n            return interfaces\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyInterfacesSpeed.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        # Iterate over all the interfaces\n        for interface in self.inputs.interfaces:\n            if (interface_detail := get_value(command_output[\"interfaces\"], f\"{interface.name}\", separator=\"..\")) is None:\n                self.result.is_failure(f\"{interface} - Not found\")\n                continue\n\n            # Verifies the bandwidth\n            if (speed := interface_detail.get(\"bandwidth\")) != interface.speed * BPS_GBPS_CONVERSIONS:\n                self.result.is_failure(\n                    f\"{interface} - Bandwidth mismatch - Expected: {interface.speed}Gbps Actual: {custom_division(speed, BPS_GBPS_CONVERSIONS)}Gbps\"\n                )\n\n            # Verifies the duplex mode\n            if (duplex := interface_detail.get(\"duplex\")) != \"duplexFull\":\n                self.result.is_failure(f\"{interface} - Duplex mode mismatch - Expected: duplexFull Actual: {duplex}\")\n\n            # Verifies the auto-negotiation as success if specified\n            if interface.auto and (auto_negotiation := interface_detail.get(\"autoNegotiate\")) != \"success\":\n                self.result.is_failure(f\"{interface} - Auto-negotiation mismatch - Expected: success Actual: {auto_negotiation}\")\n\n            # Verifies the communication lanes if specified\n            if interface.lanes and (lanes := interface_detail.get(\"lanes\")) != interface.lanes:\n                self.result.is_failure(f\"{interface} - Data lanes count mismatch - Expected: {interface.lanes} Actual: {lanes}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfacesSpeed-attributes","title":"Inputs","text":"Name Type Description Default <code>interfaces</code> <code>list[InterfaceState]</code>                      List of interfaces with their expected state.                    -"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfacesStatus","title":"VerifyInterfacesStatus","text":"<p>Verifies the operational states of specified interfaces to ensure they match expected configurations.</p> <p>This test performs the following checks for each specified interface:</p> <ol> <li>If <code>line_protocol_status</code> is defined, both <code>status</code> and <code>line_protocol_status</code> are verified for the specified interface.</li> <li>If <code>line_protocol_status</code> is not provided but the <code>status</code> is \u201cup\u201d, it is assumed that both the status and line protocol should be \u201cup\u201d.</li> <li>If the interface <code>status</code> is not \u201cup\u201d, only the interface\u2019s status is validated, with no line protocol check performed.</li> </ol> Expected Results <ul> <li>Success: If the interface status and line protocol status matches the expected operational state for all specified interfaces.</li> <li>Failure: If any of the following occur:<ul> <li>The specified interface is not configured.</li> <li>The specified interface status and line protocol status does not match the expected operational state for any interface.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyInterfacesStatus:\n      interfaces:\n        - name: Ethernet1\n          status: up\n        - name: Port-Channel100\n          status: down\n          line_protocol_status: lowerLayerDown\n        - name: Ethernet49/1\n          status: adminDown\n          line_protocol_status: notPresent\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyInterfacesStatus(AntaTest):\n    \"\"\"Verifies the operational states of specified interfaces to ensure they match expected configurations.\n\n    This test performs the following checks for each specified interface:\n\n      1. If `line_protocol_status` is defined, both `status` and `line_protocol_status` are verified for the specified interface.\n      2. If `line_protocol_status` is not provided but the `status` is \"up\", it is assumed that both the status and line protocol should be \"up\".\n      3. If the interface `status` is not \"up\", only the interface's status is validated, with no line protocol check performed.\n\n    Expected Results\n    ----------------\n    * Success: If the interface status and line protocol status matches the expected operational state for all specified interfaces.\n    * Failure: If any of the following occur:\n        - The specified interface is not configured.\n        - The specified interface status and line protocol status does not match the expected operational state for any interface.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyInterfacesStatus:\n          interfaces:\n            - name: Ethernet1\n              status: up\n            - name: Port-Channel100\n              status: down\n              line_protocol_status: lowerLayerDown\n            - name: Ethernet49/1\n              status: adminDown\n              line_protocol_status: notPresent\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces description\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyInterfacesStatus test.\"\"\"\n\n        interfaces: list[InterfaceState]\n        \"\"\"List of interfaces with their expected state.\"\"\"\n        InterfaceState: ClassVar[type[InterfaceState]] = InterfaceState\n\n        @field_validator(\"interfaces\")\n        @classmethod\n        def validate_interfaces(cls, interfaces: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'status' field is provided in each interface.\"\"\"\n            for interface in interfaces:\n                if interface.status is None:\n                    msg = f\"{interface} 'status' field missing in the input\"\n                    raise ValueError(msg)\n            return interfaces\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyInterfacesStatus.\"\"\"\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output\n        for interface in self.inputs.interfaces:\n            if (intf_status := get_value(command_output[\"interfaceDescriptions\"], interface.name, separator=\"..\")) is None:\n                self.result.is_failure(f\"{interface.name} - Not configured\")\n                continue\n\n            status = \"up\" if intf_status[\"interfaceStatus\"] in {\"up\", \"connected\"} else intf_status[\"interfaceStatus\"]\n            proto = \"up\" if intf_status[\"lineProtocolStatus\"] in {\"up\", \"connected\"} else intf_status[\"lineProtocolStatus\"]\n\n            # If line protocol status is provided, prioritize checking against both status and line protocol status\n            if interface.line_protocol_status:\n                if any([interface.status != status, interface.line_protocol_status != proto]):\n                    actual_state = f\"Expected: {interface.status}/{interface.line_protocol_status}, Actual: {status}/{proto}\"\n                    self.result.is_failure(f\"{interface.name} - Status mismatch - {actual_state}\")\n\n            # If line protocol status is not provided and interface status is \"up\", expect both status and proto to be \"up\"\n            # If interface status is not \"up\", check only the interface status without considering line protocol status\n            elif all([interface.status == \"up\", status != \"up\" or proto != \"up\"]):\n                self.result.is_failure(f\"{interface.name} - Status mismatch - Expected: up/up, Actual: {status}/{proto}\")\n            elif interface.status != status:\n                self.result.is_failure(f\"{interface.name} - Status mismatch - Expected: {interface.status}, Actual: {status}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyInterfacesStatus-attributes","title":"Inputs","text":"Name Type Description Default <code>interfaces</code> <code>list[InterfaceState]</code>                      List of interfaces with their expected state.                    -"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyIpVirtualRouterMac","title":"VerifyIpVirtualRouterMac","text":"<p>Verifies the IP virtual router MAC address.</p> Expected Results <ul> <li>Success: The test will pass if the IP virtual router MAC address matches the input.</li> <li>Failure: The test will fail if the IP virtual router MAC address does not match the input.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyIpVirtualRouterMac:\n      mac_address: 00:1c:73:00:dc:01\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyIpVirtualRouterMac(AntaTest):\n    \"\"\"Verifies the IP virtual router MAC address.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the IP virtual router MAC address matches the input.\n    * Failure: The test will fail if the IP virtual router MAC address does not match the input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyIpVirtualRouterMac:\n          mac_address: 00:1c:73:00:dc:01\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip virtual-router\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyIpVirtualRouterMac test.\"\"\"\n\n        mac_address: MacAddress\n        \"\"\"IP virtual router MAC address.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIpVirtualRouterMac.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output[\"virtualMacs\"]\n        if get_item(command_output, \"macAddress\", self.inputs.mac_address) is None:\n            self.result.is_failure(f\"IP virtual router MAC address: {self.inputs.mac_address} - Not configured\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyIpVirtualRouterMac-attributes","title":"Inputs","text":"Name Type Description Default <code>mac_address</code> <code>MacAddress</code>                      IP virtual router MAC address.                    -"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyL2MTU","title":"VerifyL2MTU","text":"<p>Verifies the global layer 2 Maximum Transfer Unit (MTU) for all L2 interfaces.</p> <p>Test that L2 interfaces are configured with the correct MTU. It supports Ethernet, Port Channel and VLAN interfaces. You can define a global MTU to check and also an MTU per interface and also ignored some interfaces.</p> Expected Results <ul> <li>Success: The test will pass if all layer 2 interfaces have the proper MTU configured.</li> <li>Failure: The test will fail if one or many layer 2 interfaces have the wrong MTU configured.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyL2MTU:\n      mtu: 1500\n      ignored_interfaces:\n        - Management1\n        - Vxlan1\n      specific_mtu:\n        - Ethernet1/1: 1500\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyL2MTU(AntaTest):\n    \"\"\"Verifies the global layer 2 Maximum Transfer Unit (MTU) for all L2 interfaces.\n\n    Test that L2 interfaces are configured with the correct MTU. It supports Ethernet, Port Channel and VLAN interfaces.\n    You can define a global MTU to check and also an MTU per interface and also ignored some interfaces.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all layer 2 interfaces have the proper MTU configured.\n    * Failure: The test will fail if one or many layer 2 interfaces have the wrong MTU configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyL2MTU:\n          mtu: 1500\n          ignored_interfaces:\n            - Management1\n            - Vxlan1\n          specific_mtu:\n            - Ethernet1/1: 1500\n    ```\n    \"\"\"\n\n    description = \"Verifies the global L2 MTU of all L2 interfaces.\"\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyL2MTU test.\"\"\"\n\n        mtu: int = 9214\n        \"\"\"Default MTU we should have configured on all non-excluded interfaces. Defaults to 9214.\"\"\"\n        ignored_interfaces: list[str] = Field(default=[\"Management\", \"Loopback\", \"Vxlan\", \"Tunnel\"])\n        \"\"\"A list of L2 interfaces to ignore. Defaults to [\"Management\", \"Loopback\", \"Vxlan\", \"Tunnel\"]\"\"\"\n        specific_mtu: list[dict[Interface, int]] = Field(default=[])\n        \"\"\"A list of dictionary of L2 interfaces with their specific MTU configured\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyL2MTU.\"\"\"\n        self.result.is_success()\n        interface_output = self.instance_commands[0].json_output[\"interfaces\"]\n        specific_interfaces = {key: value for details in self.inputs.specific_mtu for key, value in details.items()}\n\n        for interface, details in interface_output.items():\n            catch_interface = re.findall(r\"^[e,p][a-zA-Z]+[-,a-zA-Z]*\\d+\\/*\\d*\", interface, re.IGNORECASE)\n            if catch_interface and catch_interface not in self.inputs.ignored_interfaces and details[\"forwardingModel\"] == \"bridged\":\n                if interface in specific_interfaces:\n                    if (mtu := specific_interfaces[interface]) != (act_mtu := details[\"mtu\"]):\n                        self.result.is_failure(f\"Interface: {interface} - Incorrect MTU configured - Expected: {mtu} Actual: {act_mtu}\")\n\n                elif (act_mtu := details[\"mtu\"]) != self.inputs.mtu:\n                    self.result.is_failure(f\"Interface: {interface} - Incorrect MTU configured - Expected: {self.inputs.mtu} Actual: {act_mtu}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyL2MTU-attributes","title":"Inputs","text":"Name Type Description Default <code>mtu</code> <code>int</code>                      Default MTU we should have configured on all non-excluded interfaces. Defaults to 9214.                    <code>9214</code> <code>ignored_interfaces</code> <code>list[str]</code>                      A list of L2 interfaces to ignore. Defaults to [\"Management\", \"Loopback\", \"Vxlan\", \"Tunnel\"]                    <code>Field(default=['Management', 'Loopback', 'Vxlan', 'Tunnel'])</code> <code>specific_mtu</code> <code>list[dict[Interface, int]]</code>                      A list of dictionary of L2 interfaces with their specific MTU configured                    <code>Field(default=[])</code>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyL3MTU","title":"VerifyL3MTU","text":"<p>Verifies the global layer 3 Maximum Transfer Unit (MTU) for all L3 interfaces.</p> <p>Test that L3 interfaces are configured with the correct MTU. It supports Ethernet, Port Channel and VLAN interfaces.</p> <p>You can define a global MTU to check, or an MTU per interface and you can also ignored some interfaces.</p> Expected Results <ul> <li>Success: The test will pass if all layer 3 interfaces have the proper MTU configured.</li> <li>Failure: The test will fail if one or many layer 3 interfaces have the wrong MTU configured.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyL3MTU:\n      mtu: 1500\n      ignored_interfaces:\n          - Vxlan1\n      specific_mtu:\n          - Ethernet1: 2500\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyL3MTU(AntaTest):\n    \"\"\"Verifies the global layer 3 Maximum Transfer Unit (MTU) for all L3 interfaces.\n\n    Test that L3 interfaces are configured with the correct MTU. It supports Ethernet, Port Channel and VLAN interfaces.\n\n    You can define a global MTU to check, or an MTU per interface and you can also ignored some interfaces.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all layer 3 interfaces have the proper MTU configured.\n    * Failure: The test will fail if one or many layer 3 interfaces have the wrong MTU configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyL3MTU:\n          mtu: 1500\n          ignored_interfaces:\n              - Vxlan1\n          specific_mtu:\n              - Ethernet1: 2500\n    ```\n    \"\"\"\n\n    description = \"Verifies the global L3 MTU of all L3 interfaces.\"\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyL3MTU test.\"\"\"\n\n        mtu: int = 1500\n        \"\"\"Default MTU we should have configured on all non-excluded interfaces. Defaults to 1500.\"\"\"\n        ignored_interfaces: list[str] = Field(default=[\"Management\", \"Loopback\", \"Vxlan\", \"Tunnel\"])\n        \"\"\"A list of L3 interfaces to ignore\"\"\"\n        specific_mtu: list[dict[str, int]] = Field(default=[])\n        \"\"\"A list of dictionary of L3 interfaces with their specific MTU configured\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyL3MTU.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        # Set list of interfaces with specific settings\n        specific_interfaces: list[str] = []\n        if self.inputs.specific_mtu:\n            for d in self.inputs.specific_mtu:\n                specific_interfaces.extend(d)\n        for interface, values in command_output[\"interfaces\"].items():\n            if re.findall(r\"[a-z]+\", interface, re.IGNORECASE)[0] not in self.inputs.ignored_interfaces and values[\"forwardingModel\"] == \"routed\":\n                if interface in specific_interfaces:\n                    invalid_mtu = next(\n                        (values[\"mtu\"] for custom_data in self.inputs.specific_mtu if values[\"mtu\"] != (expected_mtu := custom_data[interface])), None\n                    )\n                    if invalid_mtu:\n                        self.result.is_failure(f\"Interface: {interface} - Incorrect MTU - Expected: {expected_mtu} Actual: {invalid_mtu}\")\n                # Comparison with generic setting\n                elif values[\"mtu\"] != self.inputs.mtu:\n                    self.result.is_failure(f\"Interface: {interface} - Incorrect MTU - Expected: {self.inputs.mtu} Actual: {values['mtu']}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyL3MTU-attributes","title":"Inputs","text":"Name Type Description Default <code>mtu</code> <code>int</code>                      Default MTU we should have configured on all non-excluded interfaces. Defaults to 1500.                    <code>1500</code> <code>ignored_interfaces</code> <code>list[str]</code>                      A list of L3 interfaces to ignore                    <code>Field(default=['Management', 'Loopback', 'Vxlan', 'Tunnel'])</code> <code>specific_mtu</code> <code>list[dict[str, int]]</code>                      A list of dictionary of L3 interfaces with their specific MTU configured                    <code>Field(default=[])</code>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyLACPInterfacesStatus","title":"VerifyLACPInterfacesStatus","text":"<p>Verifies the Link Aggregation Control Protocol (LACP) status of the interface.</p> <p>This test performs the following checks for each specified interface:</p> <ol> <li>Verifies that the interface is a member of the LACP port channel.</li> <li>Verifies LACP port states and operational status:<ul> <li>Activity: Active LACP mode (initiates)</li> <li>Timeout: Short (Fast Mode), Long (Slow Mode - default)</li> <li>Aggregation: Port aggregable</li> <li>Synchronization: Port in sync with partner</li> <li>Collecting: Incoming frames aggregating</li> <li>Distributing: Outgoing frames aggregating</li> </ul> </li> </ol> Expected Results <ul> <li>Success: Interface is bundled and all LACP states match expected values for both actor and partner</li> <li>Failure: If any of the following occur:<ul> <li>Interface or port channel is not configured.</li> <li>Interface is not bundled in port channel.</li> <li>Actor or partner port LACP states don\u2019t match expected configuration.</li> <li>LACP rate (timeout) mismatch when fast mode is configured.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyLACPInterfacesStatus:\n      interfaces:\n        - name: Ethernet1\n          portchannel: Port-Channel100\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyLACPInterfacesStatus(AntaTest):\n    \"\"\"Verifies the Link Aggregation Control Protocol (LACP) status of the interface.\n\n    This test performs the following checks for each specified interface:\n\n      1. Verifies that the interface is a member of the LACP port channel.\n      2. Verifies LACP port states and operational status:\n        - Activity: Active LACP mode (initiates)\n        - Timeout: Short (Fast Mode), Long (Slow Mode - default)\n        - Aggregation: Port aggregable\n        - Synchronization: Port in sync with partner\n        - Collecting: Incoming frames aggregating\n        - Distributing: Outgoing frames aggregating\n\n    Expected Results\n    ----------------\n    * Success: Interface is bundled and all LACP states match expected values for both actor and partner\n    * Failure: If any of the following occur:\n        - Interface or port channel is not configured.\n        - Interface is not bundled in port channel.\n        - Actor or partner port LACP states don't match expected configuration.\n        - LACP rate (timeout) mismatch when fast mode is configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyLACPInterfacesStatus:\n          interfaces:\n            - name: Ethernet1\n              portchannel: Port-Channel100\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show lacp interface\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLACPInterfacesStatus test.\"\"\"\n\n        interfaces: list[InterfaceState]\n        \"\"\"List of interfaces with their expected state.\"\"\"\n        InterfaceState: ClassVar[type[InterfaceState]] = InterfaceState\n\n        @field_validator(\"interfaces\")\n        @classmethod\n        def validate_interfaces(cls, interfaces: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'portchannel' field is provided in each interface.\"\"\"\n            for interface in interfaces:\n                if interface.portchannel is None:\n                    msg = f\"{interface} 'portchannel' field missing in the input\"\n                    raise ValueError(msg)\n            return interfaces\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLACPInterfacesStatus.\"\"\"\n        self.result.is_success()\n\n        # Member port verification parameters.\n        member_port_details = [\"activity\", \"aggregation\", \"synchronization\", \"collecting\", \"distributing\", \"timeout\"]\n\n        command_output = self.instance_commands[0].json_output\n        for interface in self.inputs.interfaces:\n            # Verify if a PortChannel is configured with the provided interface\n            if not (interface_details := get_value(command_output, f\"portChannels..{interface.portchannel}..interfaces..{interface.name}\", separator=\"..\")):\n                self.result.is_failure(f\"{interface} - Not configured\")\n                continue\n\n            # Verify the interface is bundled in port channel.\n            actor_port_status = interface_details.get(\"actorPortStatus\")\n            if actor_port_status != \"bundled\":\n                self.result.is_failure(f\"{interface} - Not bundled - Port Status: {actor_port_status}\")\n                continue\n\n            # Collecting actor and partner port details\n            actor_port_details = interface_details.get(\"actorPortState\", {})\n            partner_port_details = interface_details.get(\"partnerPortState\", {})\n\n            # Collecting actual interface details\n            actual_interface_output = {\n                \"actor_port_details\": {param: actor_port_details.get(param, \"NotFound\") for param in member_port_details},\n                \"partner_port_details\": {param: partner_port_details.get(param, \"NotFound\") for param in member_port_details},\n            }\n\n            # Forming expected interface details\n            expected_details = {param: param != \"timeout\" for param in member_port_details}\n            # Updating the short LACP timeout, if expected.\n            if interface.lacp_rate_fast:\n                expected_details[\"timeout\"] = True\n\n            if (act_port_details := actual_interface_output[\"actor_port_details\"]) != expected_details:\n                self.result.is_failure(f\"{interface} - Actor port details mismatch - {format_data(act_port_details)}\")\n\n            if (part_port_details := actual_interface_output[\"partner_port_details\"]) != expected_details:\n                self.result.is_failure(f\"{interface} - Partner port details mismatch - {format_data(part_port_details)}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyLACPInterfacesStatus-attributes","title":"Inputs","text":"Name Type Description Default <code>interfaces</code> <code>list[InterfaceState]</code>                      List of interfaces with their expected state.                    -"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyLoopbackCount","title":"VerifyLoopbackCount","text":"<p>Verifies that the device has the expected number of loopback interfaces and all are operational.</p> Expected Results <ul> <li>Success: The test will pass if the device has the correct number of loopback interfaces and none are down.</li> <li>Failure: The test will fail if the loopback interface count is incorrect or any are non-operational.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyLoopbackCount:\n      number: 3\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyLoopbackCount(AntaTest):\n    \"\"\"Verifies that the device has the expected number of loopback interfaces and all are operational.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device has the correct number of loopback interfaces and none are down.\n    * Failure: The test will fail if the loopback interface count is incorrect or any are non-operational.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyLoopbackCount:\n          number: 3\n    ```\n    \"\"\"\n\n    description = \"Verifies the number of loopback interfaces and their status.\"\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip interface brief\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLoopbackCount test.\"\"\"\n\n        number: PositiveInteger\n        \"\"\"Number of loopback interfaces expected to be present.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoopbackCount.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        loopback_count = 0\n        for interface, interface_details in command_output[\"interfaces\"].items():\n            if \"Loopback\" in interface:\n                loopback_count += 1\n                if (status := interface_details[\"lineProtocolStatus\"]) != \"up\":\n                    self.result.is_failure(f\"Interface: {interface} - Invalid line protocol status - Expected: up Actual: {status}\")\n\n                if (status := interface_details[\"interfaceStatus\"]) != \"connected\":\n                    self.result.is_failure(f\"Interface: {interface} - Invalid interface status - Expected: connected Actual: {status}\")\n\n        if loopback_count != self.inputs.number:\n            self.result.is_failure(f\"Loopback interface(s) count mismatch: Expected {self.inputs.number} Actual: {loopback_count}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyLoopbackCount-attributes","title":"Inputs","text":"Name Type Description Default <code>number</code> <code>PositiveInteger</code>                      Number of loopback interfaces expected to be present.                    -"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyPortChannels","title":"VerifyPortChannels","text":"<p>Verifies there are no inactive ports in all port channels.</p> Expected Results <ul> <li>Success: The test will pass if there are no inactive ports in all port channels.</li> <li>Failure: The test will fail if there is at least one inactive port in a port channel.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyPortChannels:\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyPortChannels(AntaTest):\n    \"\"\"Verifies there are no inactive ports in all port channels.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are no inactive ports in all port channels.\n    * Failure: The test will fail if there is at least one inactive port in a port channel.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyPortChannels:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show port-channel\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyPortChannels.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        for port_channel, port_channel_details in command_output[\"portChannels\"].items():\n            # Verify that the no inactive ports in all port channels.\n            if inactive_ports := port_channel_details[\"inactivePorts\"]:\n                self.result.is_failure(f\"{port_channel} - Inactive port(s) - {', '.join(inactive_ports.keys())}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifySVI","title":"VerifySVI","text":"<p>Verifies the status of all SVIs.</p> Expected Results <ul> <li>Success: The test will pass if all SVIs are up.</li> <li>Failure: The test will fail if one or many SVIs are not up.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifySVI:\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifySVI(AntaTest):\n    \"\"\"Verifies the status of all SVIs.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all SVIs are up.\n    * Failure: The test will fail if one or many SVIs are not up.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifySVI:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip interface brief\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySVI.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        for interface, int_data in command_output[\"interfaces\"].items():\n            if \"Vlan\" in interface and (status := int_data[\"lineProtocolStatus\"]) != \"up\":\n                self.result.is_failure(f\"SVI: {interface} - Invalid line protocol status - Expected: up Actual: {status}\")\n            if \"Vlan\" in interface and int_data[\"interfaceStatus\"] != \"connected\":\n                self.result.is_failure(f\"SVI: {interface} - Invalid interface status - Expected: connected Actual: {int_data['interfaceStatus']}\")\n</code></pre>"},{"location":"api/tests/interfaces/#anta.tests.interfaces.VerifyStormControlDrops","title":"VerifyStormControlDrops","text":"<p>Verifies there are no interface storm-control drop counters.</p> Expected Results <ul> <li>Success: The test will pass if there are no storm-control drop counters.</li> <li>Failure: The test will fail if there is at least one storm-control drop counter.</li> </ul> Examples <pre><code>anta.tests.interfaces:\n  - VerifyStormControlDrops:\n</code></pre> Source code in <code>anta/tests/interfaces.py</code> <pre><code>class VerifyStormControlDrops(AntaTest):\n    \"\"\"Verifies there are no interface storm-control drop counters.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are no storm-control drop counters.\n    * Failure: The test will fail if there is at least one storm-control drop counter.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.interfaces:\n      - VerifyStormControlDrops:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"interfaces\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show storm-control\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyStormControlDrops.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        storm_controlled_interfaces = []\n        self.result.is_success()\n\n        for interface, interface_dict in command_output[\"interfaces\"].items():\n            for traffic_type, traffic_type_dict in interface_dict[\"trafficTypes\"].items():\n                if \"drop\" in traffic_type_dict and traffic_type_dict[\"drop\"] != 0:\n                    storm_controlled_interfaces.append(f\"{traffic_type}: {traffic_type_dict['drop']}\")\n            if storm_controlled_interfaces:\n                self.result.is_failure(f\"Interface: {interface} - Non-zero storm-control drop counter(s) - {', '.join(storm_controlled_interfaces)}\")\n</code></pre>"},{"location":"api/tests/interfaces/#input-models","title":"Input models","text":"<p>Module containing input models for interface tests.</p>"},{"location":"api/tests/interfaces/#anta.input_models.interfaces.InterfaceDetail","title":"InterfaceDetail","text":"<p>Alias for the InterfaceState model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the InterfaceState model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/interfaces.py</code> <pre><code>class InterfaceDetail(InterfaceState):  # pragma: no cover\n    \"\"\"Alias for the InterfaceState model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the InterfaceState model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the InterfaceState class, emitting a depreciation warning.\"\"\"\n        warn(\n            message=\"InterfaceDetail model is deprecated and will be removed in ANTA v2.0.0. Use the InterfaceState model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/interfaces/#anta.input_models.interfaces.InterfaceDetail.__init__","title":"__init__","text":"<pre><code>__init__(**data: Any) -&gt; None\n</code></pre> Source code in <code>anta/input_models/interfaces.py</code> <pre><code>def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n    \"\"\"Initialize the InterfaceState class, emitting a depreciation warning.\"\"\"\n    warn(\n        message=\"InterfaceDetail model is deprecated and will be removed in ANTA v2.0.0. Use the InterfaceState model instead.\",\n        category=DeprecationWarning,\n        stacklevel=2,\n    )\n    super().__init__(**data)\n</code></pre>"},{"location":"api/tests/interfaces/#anta.input_models.interfaces.InterfaceState","title":"InterfaceState","text":"<p>Model for an interface state.</p> <p>TODO: Need to review this class name in ANTA v2.0.0.</p> Name Type Description Default <code>name</code> <code>Interface</code>                      Interface to validate.                    - <code>status</code> <code>Literal['up', 'down', 'adminDown'] | None</code>                      Expected status of the interface. Required field in the `VerifyInterfacesStatus` test.                    <code>None</code> <code>line_protocol_status</code> <code>Literal['up', 'down', 'testing', 'unknown', 'dormant', 'notPresent', 'lowerLayerDown'] | None</code>                      Expected line protocol status of the interface. Optional field in the `VerifyInterfacesStatus` test.                    <code>None</code> <code>portchannel</code> <code>PortChannelInterface | None</code>                      Port-Channel in which the interface is bundled. Required field in the `VerifyLACPInterfacesStatus` test.                    <code>None</code> <code>lacp_rate_fast</code> <code>bool</code>                      Specifies the LACP timeout mode for the link aggregation group.  Options: - True: Also referred to as fast mode. - False: The default mode, also known as slow mode.  Can be enabled in the `VerifyLACPInterfacesStatus` tests.                    <code>False</code> <code>primary_ip</code> <code>IPv4Interface | None</code>                      Primary IPv4 address in CIDR notation. Required field in the `VerifyInterfaceIPv4` test.                    <code>None</code> <code>secondary_ips</code> <code>list[IPv4Interface] | None</code>                      List of secondary IPv4 addresses in CIDR notation. Can be provided in the `VerifyInterfaceIPv4` test.                    <code>None</code> <code>auto</code> <code>bool</code>                      The auto-negotiation status of the interface. Can be provided in the `VerifyInterfacesSpeed` test.                    <code>False</code> <code>speed</code> <code>float | None</code>                      The speed of the interface in Gigabits per second. Valid range is 1 to 1000. Required field in the `VerifyInterfacesSpeed` test.                    <code>Field(None, ge=1, le=1000)</code> <code>lanes</code> <code>int | None</code>                      The number of lanes in the interface. Valid range is 1 to 8. Can be provided in the `VerifyInterfacesSpeed` test.                    <code>Field(None, ge=1, le=8)</code> Source code in <code>anta/input_models/interfaces.py</code> <pre><code>class InterfaceState(BaseModel):\n    \"\"\"Model for an interface state.\n\n    TODO: Need to review this class name in ANTA v2.0.0.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    name: Interface\n    \"\"\"Interface to validate.\"\"\"\n    status: Literal[\"up\", \"down\", \"adminDown\"] | None = None\n    \"\"\"Expected status of the interface. Required field in the `VerifyInterfacesStatus` test.\"\"\"\n    line_protocol_status: Literal[\"up\", \"down\", \"testing\", \"unknown\", \"dormant\", \"notPresent\", \"lowerLayerDown\"] | None = None\n    \"\"\"Expected line protocol status of the interface. Optional field in the `VerifyInterfacesStatus` test.\"\"\"\n    portchannel: PortChannelInterface | None = None\n    \"\"\"Port-Channel in which the interface is bundled. Required field in the `VerifyLACPInterfacesStatus` test.\"\"\"\n    lacp_rate_fast: bool = False\n    \"\"\"Specifies the LACP timeout mode for the link aggregation group.\n\n    Options:\n    - True: Also referred to as fast mode.\n    - False: The default mode, also known as slow mode.\n\n    Can be enabled in the `VerifyLACPInterfacesStatus` tests.\n    \"\"\"\n    primary_ip: IPv4Interface | None = None\n    \"\"\"Primary IPv4 address in CIDR notation. Required field in the `VerifyInterfaceIPv4` test.\"\"\"\n    secondary_ips: list[IPv4Interface] | None = None\n    \"\"\"List of secondary IPv4 addresses in CIDR notation. Can be provided in the `VerifyInterfaceIPv4` test.\"\"\"\n    auto: bool = False\n    \"\"\"The auto-negotiation status of the interface. Can be provided in the `VerifyInterfacesSpeed` test.\"\"\"\n    speed: float | None = Field(None, ge=1, le=1000)\n    \"\"\"The speed of the interface in Gigabits per second. Valid range is 1 to 1000. Required field in the `VerifyInterfacesSpeed` test.\"\"\"\n    lanes: int | None = Field(None, ge=1, le=8)\n    \"\"\"The number of lanes in the interface. Valid range is 1 to 8. Can be provided in the `VerifyInterfacesSpeed` test.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the InterfaceState for reporting.\n\n        Examples\n        --------\n        - Interface: Ethernet1 Port-Channel: Port-Channel100\n        - Interface: Ethernet1\n        \"\"\"\n        base_string = f\"Interface: {self.name}\"\n        if self.portchannel is not None:\n            base_string += f\" Port-Channel: {self.portchannel}\"\n        return base_string\n</code></pre>"},{"location":"api/tests/lanz/","title":"LANZ","text":"<p>Module related to LANZ tests.</p>"},{"location":"api/tests/lanz/#anta.tests.lanz.VerifyLANZ","title":"VerifyLANZ","text":"<p>Verifies if LANZ (Latency Analyzer) is enabled.</p> Expected Results <ul> <li>Success: The test will pass if LANZ is enabled.</li> <li>Failure: The test will fail if LANZ is disabled.</li> </ul> Examples <pre><code>anta.tests.lanz:\n  - VerifyLANZ:\n</code></pre> Source code in <code>anta/tests/lanz.py</code> <pre><code>class VerifyLANZ(AntaTest):\n    \"\"\"Verifies if LANZ (Latency Analyzer) is enabled.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if LANZ is enabled.\n    * Failure: The test will fail if LANZ is disabled.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.lanz:\n      - VerifyLANZ:\n    ```\n    \"\"\"\n\n    description = \"Verifies if LANZ is enabled.\"\n    categories: ClassVar[list[str]] = [\"lanz\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show queue-monitor length status\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLANZ.\"\"\"\n        command_output = self.instance_commands[0].json_output\n\n        if command_output[\"lanzEnabled\"] is not True:\n            self.result.is_failure(\"LANZ is not enabled\")\n        else:\n            self.result.is_success()\n</code></pre>"},{"location":"api/tests/logging/","title":"Logging","text":""},{"location":"api/tests/logging/#tests","title":"Tests","text":"<p>Module related to the EOS various logging tests.</p> <p>NOTE: The EOS command <code>show logging</code> does not support JSON output format.</p>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingAccounting","title":"VerifyLoggingAccounting","text":"<p>Verifies if AAA accounting logs are generated.</p> Expected Results <ul> <li>Success: The test will pass if AAA accounting logs are generated.</li> <li>Failure: The test will fail if AAA accounting logs are NOT generated.</li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingAccounting:\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingAccounting(AntaTest):\n    \"\"\"Verifies if AAA accounting logs are generated.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if AAA accounting logs are generated.\n    * Failure: The test will fail if AAA accounting logs are NOT generated.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingAccounting:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show aaa accounting logs | tail\", ofmt=\"text\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingAccounting.\"\"\"\n        pattern = r\"cmd=show aaa accounting logs\"\n        output = self.instance_commands[0].text_output\n        if re.search(pattern, output):\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"AAA accounting logs are not generated\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingEntries","title":"VerifyLoggingEntries","text":"<p>Verifies that the expected log string is present in the last specified log messages.</p> Expected Results <ul> <li>Success: The test will pass if the expected log string for the mentioned severity level is present in the last specified log messages.</li> <li>Failure: The test will fail if the specified log string is not present in the last specified log messages.</li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingEntries:\n      logging_entries:\n        - regex_match: \".ACCOUNTING-5-EXEC: cvpadmin ssh.\"\n          last_number_messages: 30\n          severity_level: alerts\n        - regex_match: \".SPANTREE-6-INTERFACE_ADD:.\"\n          last_number_messages: 10\n          severity_level: critical\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingEntries(AntaTest):\n    \"\"\"Verifies that the expected log string is present in the last specified log messages.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the expected log string for the mentioned severity level is present in the last specified log messages.\n    * Failure: The test will fail if the specified log string is not present in the last specified log messages.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingEntries:\n          logging_entries:\n            - regex_match: \".ACCOUNTING-5-EXEC: cvpadmin ssh.\"\n              last_number_messages: 30\n              severity_level: alerts\n            - regex_match: \".SPANTREE-6-INTERFACE_ADD:.\"\n              last_number_messages: 10\n              severity_level: critical\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaTemplate(template=\"show logging {last_number_messages} {severity_level}\", ofmt=\"text\", use_cache=False)\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLoggingEntries test.\"\"\"\n\n        logging_entries: list[LoggingQuery]\n        \"\"\"List of logging entries and regex match.\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for last number messages and log severity level in the input.\"\"\"\n        return [template.render(last_number_messages=entry.last_number_messages, severity_level=entry.severity_level) for entry in self.inputs.logging_entries]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingEntries.\"\"\"\n        self.result.is_success()\n        for command_output, logging_entry in zip(self.instance_commands, self.inputs.logging_entries):\n            output = command_output.text_output\n            if not re.search(logging_entry.regex_match, output):\n                self.result.is_failure(\n                    f\"Pattern: {logging_entry.regex_match} - Not found in last {logging_entry.last_number_messages} {logging_entry.severity_level} log entries\"\n                )\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingEntries-attributes","title":"Inputs","text":"Name Type Description Default <code>logging_entries</code> <code>list[LoggingQuery]</code>                      List of logging entries and regex match.                    -"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingErrors","title":"VerifyLoggingErrors","text":"<p>Verifies there are no syslog messages with a severity of ERRORS or higher.</p> Expected Results <ul> <li>Success: The test will pass if there are NO syslog messages with a severity of ERRORS or higher.</li> <li>Failure: The test will fail if ERRORS or higher syslog messages are present.</li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingErrors:\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingErrors(AntaTest):\n    \"\"\"Verifies there are no syslog messages with a severity of ERRORS or higher.\n\n    Expected Results\n    ----------------\n      * Success: The test will pass if there are NO syslog messages with a severity of ERRORS or higher.\n      * Failure: The test will fail if ERRORS or higher syslog messages are present.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingErrors:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show logging threshold errors\", ofmt=\"text\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingErrors.\"\"\"\n        command_output = self.instance_commands[0].text_output\n\n        if len(command_output) == 0:\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"Device has reported syslog messages with a severity of ERRORS or higher\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingHostname","title":"VerifyLoggingHostname","text":"<p>Verifies if logs are generated with the device FQDN.</p> <p>This test performs the following checks:</p> <ol> <li>Retrieves the device\u2019s configured FQDN.</li> <li>Sends a test log message at the specified severity log level.</li> <li>Retrieves the most recent logs (last 30 seconds).</li> <li>Verifies that the test message includes the complete FQDN of the device.</li> </ol> Expected Results <ul> <li>Success: If logs are generated with the device\u2019s complete FQDN.</li> <li>Failure: If any of the following occur:<ul> <li>The test message is not found in recent logs.</li> <li>The log message does not include the device\u2019s FQDN.</li> <li>The FQDN in the log message doesn\u2019t match the configured FQDN.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingHostname:\n      severity_level: informational\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingHostname(AntaTest):\n    \"\"\"Verifies if logs are generated with the device FQDN.\n\n    This test performs the following checks:\n\n      1. Retrieves the device's configured FQDN.\n      2. Sends a test log message at the specified severity log level.\n      3. Retrieves the most recent logs (last 30 seconds).\n      4. Verifies that the test message includes the complete FQDN of the device.\n\n    Expected Results\n    ----------------\n    * Success: If logs are generated with the device's complete FQDN.\n    * Failure: If any of the following occur:\n        - The test message is not found in recent logs.\n        - The log message does not include the device's FQDN.\n        - The FQDN in the log message doesn't match the configured FQDN.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingHostname:\n          severity_level: informational\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaCommand(command=\"show hostname\", revision=1),\n        AntaTemplate(template=\"send log level {severity_level} message ANTA VerifyLoggingHostname validation\", ofmt=\"text\"),\n        AntaTemplate(template=\"show logging {severity_level} last 30 seconds | grep ANTA\", ofmt=\"text\", use_cache=False),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLoggingHostname test.\"\"\"\n\n        severity_level: LogSeverityLevel = \"informational\"\n        \"\"\"Log severity level. Defaults to informational.\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for log severity level in the input.\"\"\"\n        return [template.render(severity_level=self.inputs.severity_level)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingHostname.\"\"\"\n        output_hostname = self.instance_commands[0].json_output\n        output_logging = self.instance_commands[2].text_output\n        fqdn = output_hostname[\"fqdn\"]\n        lines = output_logging.strip().split(\"\\n\")[::-1]\n        log_pattern = r\"ANTA VerifyLoggingHostname validation\"\n        last_line_with_pattern = \"\"\n        for line in lines:\n            if re.search(log_pattern, line):\n                last_line_with_pattern = line\n                break\n        if fqdn in last_line_with_pattern:\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"Logs are not generated with the device FQDN\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingHostname-attributes","title":"Inputs","text":"Name Type Description Default <code>severity_level</code> <code>LogSeverityLevel</code>                      Log severity level. Defaults to informational.                    <code>'informational'</code>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingHosts","title":"VerifyLoggingHosts","text":"<p>Verifies logging hosts (syslog servers) for a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if the provided syslog servers are configured in the specified VRF.</li> <li>Failure: The test will fail if the provided syslog servers are NOT configured in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingHosts:\n      hosts:\n        - 1.1.1.1\n        - 2.2.2.2\n      vrf: default\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingHosts(AntaTest):\n    \"\"\"Verifies logging hosts (syslog servers) for a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided syslog servers are configured in the specified VRF.\n    * Failure: The test will fail if the provided syslog servers are NOT configured in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingHosts:\n          hosts:\n            - 1.1.1.1\n            - 2.2.2.2\n          vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show logging\", ofmt=\"text\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLoggingHosts test.\"\"\"\n\n        hosts: list[IPv4Address]\n        \"\"\"List of hosts (syslog servers) IP addresses.\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF to transport log messages. Defaults to `default`.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingHosts.\"\"\"\n        output = self.instance_commands[0].text_output\n        not_configured = []\n        for host in self.inputs.hosts:\n            pattern = rf\"Logging to '{host!s}'.*VRF {self.inputs.vrf}\"\n            if not re.search(pattern, _get_logging_states(self.logger, output)):\n                not_configured.append(str(host))\n\n        if not not_configured:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Syslog servers {', '.join(not_configured)} are not configured in VRF {self.inputs.vrf}\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingHosts-attributes","title":"Inputs","text":"Name Type Description Default <code>hosts</code> <code>list[IPv4Address]</code>                      List of hosts (syslog servers) IP addresses.                    - <code>vrf</code> <code>str</code>                      The name of the VRF to transport log messages. Defaults to `default`.                    <code>'default'</code>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingLogsGeneration","title":"VerifyLoggingLogsGeneration","text":"<p>Verifies if logs are generated.</p> <p>This test performs the following checks:</p> <ol> <li>Sends a test log message at the specified severity log level.</li> <li>Retrieves the most recent logs (last 30 seconds).</li> <li>Verifies that the test message was successfully logged.</li> </ol> Expected Results <ul> <li>Success: If logs are being generated and the test message is found in recent logs.</li> <li>Failure: If any of the following occur:<ul> <li>The test message is not found in recent logs.</li> <li>The logging system is not capturing new messages.</li> <li>No logs are being generated.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingLogsGeneration:\n      severity_level: informational\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingLogsGeneration(AntaTest):\n    \"\"\"Verifies if logs are generated.\n\n    This test performs the following checks:\n\n      1. Sends a test log message at the specified severity log level.\n      2. Retrieves the most recent logs (last 30 seconds).\n      3. Verifies that the test message was successfully logged.\n\n    Expected Results\n    ----------------\n    * Success: If logs are being generated and the test message is found in recent logs.\n    * Failure: If any of the following occur:\n        - The test message is not found in recent logs.\n        - The logging system is not capturing new messages.\n        - No logs are being generated.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingLogsGeneration:\n          severity_level: informational\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaTemplate(template=\"send log level {severity_level} message ANTA VerifyLoggingLogsGeneration validation\", ofmt=\"text\"),\n        AntaTemplate(template=\"show logging {severity_level} last 30 seconds | grep ANTA\", ofmt=\"text\", use_cache=False),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLoggingLogsGeneration test.\"\"\"\n\n        severity_level: LogSeverityLevel = \"informational\"\n        \"\"\"Log severity level. Defaults to informational.\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for log severity level in the input.\"\"\"\n        return [template.render(severity_level=self.inputs.severity_level)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingLogsGeneration.\"\"\"\n        log_pattern = r\"ANTA VerifyLoggingLogsGeneration validation\"\n        output = self.instance_commands[1].text_output\n        lines = output.strip().split(\"\\n\")[::-1]\n        for line in lines:\n            if re.search(log_pattern, line):\n                self.result.is_success()\n                return\n        self.result.is_failure(\"Logs are not generated\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingLogsGeneration-attributes","title":"Inputs","text":"Name Type Description Default <code>severity_level</code> <code>LogSeverityLevel</code>                      Log severity level. Defaults to informational.                    <code>'informational'</code>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingPersistent","title":"VerifyLoggingPersistent","text":"<p>Verifies if logging persistent is enabled and logs are saved in flash.</p> Expected Results <ul> <li>Success: The test will pass if logging persistent is enabled and logs are in flash.</li> <li>Failure: The test will fail if logging persistent is disabled or no logs are saved in flash.</li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingPersistent:\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingPersistent(AntaTest):\n    \"\"\"Verifies if logging persistent is enabled and logs are saved in flash.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if logging persistent is enabled and logs are in flash.\n    * Failure: The test will fail if logging persistent is disabled or no logs are saved in flash.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingPersistent:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaCommand(command=\"show logging\", ofmt=\"text\"),\n        AntaCommand(command=\"dir flash:/persist/messages\", ofmt=\"text\"),\n    ]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingPersistent.\"\"\"\n        self.result.is_success()\n        log_output = self.instance_commands[0].text_output\n        dir_flash_output = self.instance_commands[1].text_output\n        if \"Persistent logging: disabled\" in _get_logging_states(self.logger, log_output):\n            self.result.is_failure(\"Persistent logging is disabled\")\n            return\n        pattern = r\"-rw-\\s+(\\d+)\"\n        persist_logs = re.search(pattern, dir_flash_output)\n        if not persist_logs or int(persist_logs.group(1)) == 0:\n            self.result.is_failure(\"No persistent logs are saved in flash\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingSourceIntf","title":"VerifyLoggingSourceIntf","text":"<p>Verifies logging source-interface for a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if the provided logging source-interface is configured in the specified VRF.</li> <li>Failure: The test will fail if the provided logging source-interface is NOT configured in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingSourceIntf:\n      interface: Management0\n      vrf: default\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingSourceIntf(AntaTest):\n    \"\"\"Verifies logging source-interface for a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided logging source-interface is configured in the specified VRF.\n    * Failure: The test will fail if the provided logging source-interface is NOT configured in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingSourceIntf:\n          interface: Management0\n          vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show logging\", ofmt=\"text\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLoggingSourceIntf test.\"\"\"\n\n        interface: str\n        \"\"\"Source-interface to use as source IP of log messages.\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF to transport log messages. Defaults to `default`.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingSourceIntf.\"\"\"\n        output = self.instance_commands[0].text_output\n        pattern = rf\"Logging source-interface '{self.inputs.interface}'.*VRF {self.inputs.vrf}\"\n        if re.search(pattern, _get_logging_states(self.logger, output)):\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Source-interface: {self.inputs.interface} VRF: {self.inputs.vrf} - Not configured\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingSourceIntf-attributes","title":"Inputs","text":"Name Type Description Default <code>interface</code> <code>str</code>                      Source-interface to use as source IP of log messages.                    - <code>vrf</code> <code>str</code>                      The name of the VRF to transport log messages. Defaults to `default`.                    <code>'default'</code>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingTimestamp","title":"VerifyLoggingTimestamp","text":"<p>Verifies if logs are generated with the appropriate timestamp.</p> <p>This test performs the following checks:</p> <ol> <li>Sends a test log message at the specified severity log level.</li> <li>Retrieves the most recent logs (last 30 seconds).</li> <li>Verifies that the test message is present with a high-resolution RFC3339 timestamp format.<ul> <li>Example format: <code>2024-01-25T15:30:45.123456+00:00</code>.</li> <li>Includes microsecond precision.</li> <li>Contains timezone offset.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If logs are generated with the correct high-resolution RFC3339 timestamp format.</li> <li>Failure: If any of the following occur:<ul> <li>The test message is not found in recent logs.</li> <li>The timestamp format does not match the expected RFC3339 format.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifyLoggingTimestamp:\n      severity_level: informational\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifyLoggingTimestamp(AntaTest):\n    \"\"\"Verifies if logs are generated with the appropriate timestamp.\n\n    This test performs the following checks:\n\n      1. Sends a test log message at the specified severity log level.\n      2. Retrieves the most recent logs (last 30 seconds).\n      3. Verifies that the test message is present with a high-resolution RFC3339 timestamp format.\n        - Example format: `2024-01-25T15:30:45.123456+00:00`.\n        - Includes microsecond precision.\n        - Contains timezone offset.\n\n    Expected Results\n    ----------------\n    * Success: If logs are generated with the correct high-resolution RFC3339 timestamp format.\n    * Failure: If any of the following occur:\n        - The test message is not found in recent logs.\n        - The timestamp format does not match the expected RFC3339 format.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifyLoggingTimestamp:\n          severity_level: informational\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaTemplate(template=\"send log level {severity_level} message ANTA VerifyLoggingTimestamp validation\", ofmt=\"text\"),\n        AntaTemplate(template=\"show logging {severity_level} last 30 seconds | grep ANTA\", ofmt=\"text\", use_cache=False),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyLoggingTimestamp test.\"\"\"\n\n        severity_level: LogSeverityLevel = \"informational\"\n        \"\"\"Log severity level. Defaults to informational.\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for log severity level in the input.\"\"\"\n        return [template.render(severity_level=self.inputs.severity_level)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyLoggingTimestamp.\"\"\"\n        log_pattern = r\"ANTA VerifyLoggingTimestamp validation\"\n        timestamp_pattern = r\"\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{6}[+-]\\d{2}:\\d{2}\"\n        output = self.instance_commands[1].text_output\n        lines = output.strip().split(\"\\n\")[::-1]\n        last_line_with_pattern = \"\"\n        for line in lines:\n            if re.search(log_pattern, line):\n                last_line_with_pattern = line\n                break\n        if re.search(timestamp_pattern, last_line_with_pattern):\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"Logs are not generated with the appropriate timestamp format\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging.VerifyLoggingTimestamp-attributes","title":"Inputs","text":"Name Type Description Default <code>severity_level</code> <code>LogSeverityLevel</code>                      Log severity level. Defaults to informational.                    <code>'informational'</code>"},{"location":"api/tests/logging/#anta.tests.logging.VerifySyslogLogging","title":"VerifySyslogLogging","text":"<p>Verifies if syslog logging is enabled.</p> Expected Results <ul> <li>Success: The test will pass if syslog logging is enabled.</li> <li>Failure: The test will fail if syslog logging is disabled.</li> </ul> Examples <pre><code>anta.tests.logging:\n  - VerifySyslogLogging:\n</code></pre> Source code in <code>anta/tests/logging.py</code> <pre><code>class VerifySyslogLogging(AntaTest):\n    \"\"\"Verifies if syslog logging is enabled.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if syslog logging is enabled.\n    * Failure: The test will fail if syslog logging is disabled.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.logging:\n      - VerifySyslogLogging:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"logging\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show logging\", ofmt=\"text\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySyslogLogging.\"\"\"\n        self.result.is_success()\n        log_output = self.instance_commands[0].text_output\n\n        if \"Syslog logging: enabled\" not in _get_logging_states(self.logger, log_output):\n            self.result.is_failure(\"Syslog logging is disabled\")\n</code></pre>"},{"location":"api/tests/logging/#anta.tests.logging._get_logging_states","title":"_get_logging_states","text":"<pre><code>_get_logging_states(\n    logger: Logger, command_output: str\n) -&gt; str\n</code></pre> <p>Parse <code>show logging</code> output and gets operational logging states used in the tests in this module.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>The logger object.</p> required <code>command_output</code> <code>str</code> <p>The <code>show logging</code> output.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The operational logging states.</p> Source code in <code>anta/tests/logging.py</code> <pre><code>def _get_logging_states(logger: logging.Logger, command_output: str) -&gt; str:\n    \"\"\"Parse `show logging` output and gets operational logging states used in the tests in this module.\n\n    Parameters\n    ----------\n    logger\n        The logger object.\n    command_output\n        The `show logging` output.\n\n    Returns\n    -------\n    str\n        The operational logging states.\n\n    \"\"\"\n    log_states = command_output.partition(\"\\n\\nExternal configuration:\")[0]\n    logger.debug(\"Device logging states:\\n%s\", log_states)\n    return log_states\n</code></pre>"},{"location":"api/tests/logging/#input-models","title":"Input models","text":"<p>Module containing input models for logging tests.</p>"},{"location":"api/tests/logging/#anta.input_models.logging.LoggingQuery","title":"LoggingQuery","text":"<p>Logging query model representing the logging details.</p> Name Type Description Default <code>regex_match</code> <code>RegexString</code>                      Log regex pattern to be searched in last log entries.                    - <code>last_number_messages</code> <code>int</code>                      Last number of messages to check in the logging buffers.                    <code>Field(ge=1, le=9999)</code> <code>severity_level</code> <code>LogSeverityLevel</code>                      Log severity level.                    <code>'informational'</code> Source code in <code>anta/input_models/logging.py</code> <pre><code>class LoggingQuery(BaseModel):\n    \"\"\"Logging query model representing the logging details.\"\"\"\n\n    regex_match: RegexString\n    \"\"\"Log regex pattern to be searched in last log entries.\"\"\"\n    last_number_messages: int = Field(ge=1, le=9999)\n    \"\"\"Last number of messages to check in the logging buffers.\"\"\"\n    severity_level: LogSeverityLevel = \"informational\"\n    \"\"\"Log severity level.\"\"\"\n</code></pre>"},{"location":"api/tests/mlag/","title":"MLAG","text":"<p>Module related to Multi-chassis Link Aggregation (MLAG) tests.</p>"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagConfigSanity","title":"VerifyMlagConfigSanity","text":"<p>Verifies there are no MLAG config-sanity inconsistencies.</p> Expected Results <ul> <li>Success: The test will pass if there are NO MLAG config-sanity inconsistencies.</li> <li>Failure: The test will fail if there are MLAG config-sanity inconsistencies.</li> <li>Skipped: The test will be skipped if MLAG is \u2018disabled\u2019.</li> <li>Error: The test will give an error if \u2018mlagActive\u2019 is not found in the JSON response.</li> </ul> Examples <pre><code>anta.tests.mlag:\n  - VerifyMlagConfigSanity:\n</code></pre> Source code in <code>anta/tests/mlag.py</code> <pre><code>class VerifyMlagConfigSanity(AntaTest):\n    \"\"\"Verifies there are no MLAG config-sanity inconsistencies.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are NO MLAG config-sanity inconsistencies.\n    * Failure: The test will fail if there are MLAG config-sanity inconsistencies.\n    * Skipped: The test will be skipped if MLAG is 'disabled'.\n    * Error: The test will give an error if 'mlagActive' is not found in the JSON response.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.mlag:\n      - VerifyMlagConfigSanity:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"mlag\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show mlag config-sanity\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMlagConfigSanity.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        # Skipping the test if MLAG is disabled\n        if command_output[\"mlagActive\"] is False:\n            self.result.is_skipped(\"MLAG is disabled\")\n            return\n\n        # Verifies the globalConfiguration config-sanity\n        if get_value(command_output, \"globalConfiguration\"):\n            self.result.is_failure(\"MLAG config-sanity found in global configuration\")\n\n        # Verifies the interfaceConfiguration config-sanity\n        if get_value(command_output, \"interfaceConfiguration\"):\n            self.result.is_failure(\"MLAG config-sanity found in interface configuration\")\n</code></pre>"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagDualPrimary","title":"VerifyMlagDualPrimary","text":"<p>Verifies the dual-primary detection and its parameters of the MLAG configuration.</p> Expected Results <ul> <li>Success: The test will pass if the dual-primary detection is enabled and its parameters are configured properly.</li> <li>Failure: The test will fail if the dual-primary detection is NOT enabled or its parameters are NOT configured properly.</li> <li>Skipped: The test will be skipped if MLAG is \u2018disabled\u2019.</li> </ul> Examples <pre><code>anta.tests.mlag:\n  - VerifyMlagDualPrimary:\n      detection_delay: 200\n      errdisabled: True\n      recovery_delay: 60\n      recovery_delay_non_mlag: 0\n</code></pre> Source code in <code>anta/tests/mlag.py</code> <pre><code>class VerifyMlagDualPrimary(AntaTest):\n    \"\"\"Verifies the dual-primary detection and its parameters of the MLAG configuration.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the dual-primary detection is enabled and its parameters are configured properly.\n    * Failure: The test will fail if the dual-primary detection is NOT enabled or its parameters are NOT configured properly.\n    * Skipped: The test will be skipped if MLAG is 'disabled'.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.mlag:\n      - VerifyMlagDualPrimary:\n          detection_delay: 200\n          errdisabled: True\n          recovery_delay: 60\n          recovery_delay_non_mlag: 0\n    ```\n    \"\"\"\n\n    description = \"Verifies the MLAG dual-primary detection parameters.\"\n    categories: ClassVar[list[str]] = [\"mlag\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show mlag detail\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyMlagDualPrimary test.\"\"\"\n\n        detection_delay: PositiveInteger\n        \"\"\"Delay detection (seconds).\"\"\"\n        errdisabled: bool = False\n        \"\"\"Errdisabled all interfaces when dual-primary is detected.\"\"\"\n        recovery_delay: PositiveInteger\n        \"\"\"Delay (seconds) after dual-primary detection resolves until non peer-link ports that are part of an MLAG are enabled.\"\"\"\n        recovery_delay_non_mlag: PositiveInteger\n        \"\"\"Delay (seconds) after dual-primary detection resolves until ports that are not part of an MLAG are enabled.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMlagDualPrimary.\"\"\"\n        self.result.is_success()\n        errdisabled_action = \"errdisableAllInterfaces\" if self.inputs.errdisabled else \"none\"\n        command_output = self.instance_commands[0].json_output\n\n        # Skipping the test if MLAG is disabled\n        if command_output[\"state\"] == \"disabled\":\n            self.result.is_skipped(\"MLAG is disabled\")\n            return\n\n        # Verifies the dualPrimaryDetectionState\n        if command_output[\"dualPrimaryDetectionState\"] == \"disabled\":\n            self.result.is_failure(\"Dual-primary detection is disabled\")\n            return\n\n        # Verifies the dualPrimaryAction\n        if (primary_action := get_value(command_output, \"detail.dualPrimaryAction\")) != errdisabled_action:\n            self.result.is_failure(f\"Dual-primary action mismatch - Expected: {errdisabled_action} Actual: {primary_action}\")\n\n        # Verifies the dualPrimaryDetectionDelay\n        if (detection_delay := get_value(command_output, \"detail.dualPrimaryDetectionDelay\")) != self.inputs.detection_delay:\n            self.result.is_failure(f\"Dual-primary detection delay mismatch - Expected: {self.inputs.detection_delay} Actual: {detection_delay}\")\n\n        # Verifies the dualPrimaryMlagRecoveryDelay\n        if (recovery_delay := get_value(command_output, \"dualPrimaryMlagRecoveryDelay\")) != self.inputs.recovery_delay:\n            self.result.is_failure(f\"Dual-primary MLAG recovery delay mismatch - Expected: {self.inputs.recovery_delay} Actual: {recovery_delay}\")\n\n        # Verifies the dualPrimaryNonMlagRecoveryDelay\n        if (recovery_delay_non_mlag := get_value(command_output, \"dualPrimaryNonMlagRecoveryDelay\")) != self.inputs.recovery_delay_non_mlag:\n            self.result.is_failure(\n                f\"Dual-primary non MLAG recovery delay mismatch - Expected: {self.inputs.recovery_delay_non_mlag} Actual: {recovery_delay_non_mlag}\"\n            )\n</code></pre>"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagDualPrimary-attributes","title":"Inputs","text":"Name Type Description Default <code>detection_delay</code> <code>PositiveInteger</code>                      Delay detection (seconds).                    - <code>errdisabled</code> <code>bool</code>                      Errdisabled all interfaces when dual-primary is detected.                    <code>False</code> <code>recovery_delay</code> <code>PositiveInteger</code>                      Delay (seconds) after dual-primary detection resolves until non peer-link ports that are part of an MLAG are enabled.                    - <code>recovery_delay_non_mlag</code> <code>PositiveInteger</code>                      Delay (seconds) after dual-primary detection resolves until ports that are not part of an MLAG are enabled.                    -"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagInterfaces","title":"VerifyMlagInterfaces","text":"<p>Verifies there are no inactive or active-partial MLAG ports.</p> Expected Results <ul> <li>Success: The test will pass if there are NO inactive or active-partial MLAG ports.</li> <li>Failure: The test will fail if there are inactive or active-partial MLAG ports.</li> <li>Skipped: The test will be skipped if MLAG is \u2018disabled\u2019.</li> </ul> Examples <pre><code>anta.tests.mlag:\n  - VerifyMlagInterfaces:\n</code></pre> Source code in <code>anta/tests/mlag.py</code> <pre><code>class VerifyMlagInterfaces(AntaTest):\n    \"\"\"Verifies there are no inactive or active-partial MLAG ports.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are NO inactive or active-partial MLAG ports.\n    * Failure: The test will fail if there are inactive or active-partial MLAG ports.\n    * Skipped: The test will be skipped if MLAG is 'disabled'.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.mlag:\n      - VerifyMlagInterfaces:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"mlag\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show mlag\", revision=2)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMlagInterfaces.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        # Skipping the test if MLAG is disabled\n        if command_output[\"state\"] == \"disabled\":\n            self.result.is_skipped(\"MLAG is disabled\")\n            return\n\n        # Verifies the Inactive and Active-partial ports\n        inactive_ports = command_output[\"mlagPorts\"][\"Inactive\"]\n        partial_active_ports = command_output[\"mlagPorts\"][\"Active-partial\"]\n        if inactive_ports != 0 or partial_active_ports != 0:\n            self.result.is_failure(f\"MLAG status is not ok - Inactive Ports: {inactive_ports} Partial Active Ports: {partial_active_ports}\")\n</code></pre>"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagPrimaryPriority","title":"VerifyMlagPrimaryPriority","text":"<p>Verify the MLAG (Multi-Chassis Link Aggregation) primary priority.</p> Expected Results <ul> <li>Success: The test will pass if the MLAG state is set as \u2018primary\u2019 and the priority matches the input.</li> <li>Failure: The test will fail if the MLAG state is not \u2018primary\u2019 or the priority doesn\u2019t match the input.</li> <li>Skipped: The test will be skipped if MLAG is \u2018disabled\u2019.</li> </ul> Examples <pre><code>anta.tests.mlag:\n  - VerifyMlagPrimaryPriority:\n      primary_priority: 3276\n</code></pre> Source code in <code>anta/tests/mlag.py</code> <pre><code>class VerifyMlagPrimaryPriority(AntaTest):\n    \"\"\"Verify the MLAG (Multi-Chassis Link Aggregation) primary priority.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the MLAG state is set as 'primary' and the priority matches the input.\n    * Failure: The test will fail if the MLAG state is not 'primary' or the priority doesn't match the input.\n    * Skipped: The test will be skipped if MLAG is 'disabled'.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.mlag:\n      - VerifyMlagPrimaryPriority:\n          primary_priority: 3276\n    ```\n    \"\"\"\n\n    description = \"Verifies the configuration of the MLAG primary priority.\"\n    categories: ClassVar[list[str]] = [\"mlag\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show mlag detail\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyMlagPrimaryPriority test.\"\"\"\n\n        primary_priority: MlagPriority\n        \"\"\"The expected MLAG primary priority.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMlagPrimaryPriority.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        # Skip the test if MLAG is disabled\n        if command_output[\"state\"] == \"disabled\":\n            self.result.is_skipped(\"MLAG is disabled\")\n            return\n\n        mlag_state = get_value(command_output, \"detail.mlagState\")\n        primary_priority = get_value(command_output, \"detail.primaryPriority\")\n\n        # Check MLAG state\n        if mlag_state != \"primary\":\n            self.result.is_failure(\"The device is not set as MLAG primary\")\n\n        # Check primary priority\n        if primary_priority != self.inputs.primary_priority:\n            self.result.is_failure(f\"MLAG primary priority mismatch - Expected: {self.inputs.primary_priority} Actual: {primary_priority}\")\n</code></pre>"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagPrimaryPriority-attributes","title":"Inputs","text":"Name Type Description Default <code>primary_priority</code> <code>MlagPriority</code>                      The expected MLAG primary priority.                    -"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagReloadDelay","title":"VerifyMlagReloadDelay","text":"<p>Verifies the reload-delay parameters of the MLAG configuration.</p> Expected Results <ul> <li>Success: The test will pass if the reload-delay parameters are configured properly.</li> <li>Failure: The test will fail if the reload-delay parameters are NOT configured properly.</li> <li>Skipped: The test will be skipped if MLAG is \u2018disabled\u2019.</li> </ul> Examples <pre><code>anta.tests.mlag:\n  - VerifyMlagReloadDelay:\n      reload_delay: 300\n      reload_delay_non_mlag: 330\n</code></pre> Source code in <code>anta/tests/mlag.py</code> <pre><code>class VerifyMlagReloadDelay(AntaTest):\n    \"\"\"Verifies the reload-delay parameters of the MLAG configuration.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the reload-delay parameters are configured properly.\n    * Failure: The test will fail if the reload-delay parameters are NOT configured properly.\n    * Skipped: The test will be skipped if MLAG is 'disabled'.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.mlag:\n      - VerifyMlagReloadDelay:\n          reload_delay: 300\n          reload_delay_non_mlag: 330\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"mlag\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show mlag\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyMlagReloadDelay test.\"\"\"\n\n        reload_delay: PositiveInteger\n        \"\"\"Delay (seconds) after reboot until non peer-link ports that are part of an MLAG are enabled.\"\"\"\n        reload_delay_non_mlag: PositiveInteger\n        \"\"\"Delay (seconds) after reboot until ports that are not part of an MLAG are enabled.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMlagReloadDelay.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        # Skipping the test if MLAG is disabled\n        if command_output[\"state\"] == \"disabled\":\n            self.result.is_skipped(\"MLAG is disabled\")\n            return\n\n        # Verifies the reloadDelay\n        if (reload_delay := get_value(command_output, \"reloadDelay\")) != self.inputs.reload_delay:\n            self.result.is_failure(f\"MLAG reload-delay mismatch - Expected: {self.inputs.reload_delay}s Actual: {reload_delay}s\")\n\n        # Verifies the reloadDelayNonMlag\n        if (non_mlag_reload_delay := get_value(command_output, \"reloadDelayNonMlag\")) != self.inputs.reload_delay_non_mlag:\n            self.result.is_failure(f\"Delay for non-MLAG ports mismatch - Expected: {self.inputs.reload_delay_non_mlag}s Actual: {non_mlag_reload_delay}s\")\n</code></pre>"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagReloadDelay-attributes","title":"Inputs","text":"Name Type Description Default <code>reload_delay</code> <code>PositiveInteger</code>                      Delay (seconds) after reboot until non peer-link ports that are part of an MLAG are enabled.                    - <code>reload_delay_non_mlag</code> <code>PositiveInteger</code>                      Delay (seconds) after reboot until ports that are not part of an MLAG are enabled.                    -"},{"location":"api/tests/mlag/#anta.tests.mlag.VerifyMlagStatus","title":"VerifyMlagStatus","text":"<p>Verifies the health status of the MLAG configuration.</p> Expected Results <ul> <li>Success: The test will pass if the MLAG state is \u2018active\u2019, negotiation status is \u2018connected\u2019, peer-link status and local interface status are \u2018up\u2019.</li> <li>Failure: The test will fail if the MLAG state is not \u2018active\u2019, negotiation status is not \u2018connected\u2019, peer-link status or local interface status are not \u2018up\u2019.</li> <li>Skipped: The test will be skipped if MLAG is \u2018disabled\u2019.</li> </ul> Examples <pre><code>anta.tests.mlag:\n  - VerifyMlagStatus:\n</code></pre> Source code in <code>anta/tests/mlag.py</code> <pre><code>class VerifyMlagStatus(AntaTest):\n    \"\"\"Verifies the health status of the MLAG configuration.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the MLAG state is 'active', negotiation status is 'connected', peer-link status and local interface status are 'up'.\n    * Failure: The test will fail if the MLAG state is not 'active', negotiation status is not 'connected', peer-link status or local interface status are not 'up'.\n    * Skipped: The test will be skipped if MLAG is 'disabled'.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.mlag:\n      - VerifyMlagStatus:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"mlag\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show mlag\", revision=2)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMlagStatus.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        # Skipping the test if MLAG is disabled\n        if command_output[\"state\"] == \"disabled\":\n            self.result.is_skipped(\"MLAG is disabled\")\n            return\n\n        # Verifies the negotiation status\n        if (neg_status := command_output[\"negStatus\"]) != \"connected\":\n            self.result.is_failure(f\"MLAG negotiation status mismatch - Expected: connected Actual: {neg_status}\")\n\n        # Verifies the local interface interface status\n        if (intf_state := command_output[\"localIntfStatus\"]) != \"up\":\n            self.result.is_failure(f\"Operational state of the MLAG local interface is not correct - Expected: up Actual: {intf_state}\")\n\n        # Verifies the peerLinkStatus\n        if (peer_link_state := command_output[\"peerLinkStatus\"]) != \"up\":\n            self.result.is_failure(f\"Operational state of the MLAG peer link is not correct - Expected: up Actual: {peer_link_state}\")\n</code></pre>"},{"location":"api/tests/multicast/","title":"Multicast","text":"<p>Module related to multicast and IGMP tests.</p>"},{"location":"api/tests/multicast/#anta.tests.multicast.VerifyIGMPSnoopingGlobal","title":"VerifyIGMPSnoopingGlobal","text":"<p>Verifies the IGMP snooping global status.</p> Expected Results <ul> <li>Success: The test will pass if the IGMP snooping global status matches the expected status.</li> <li>Failure: The test will fail if the IGMP snooping global status does not match the expected status.</li> </ul> Examples <pre><code>anta.tests.multicast:\n  - VerifyIGMPSnoopingGlobal:\n      enabled: True\n</code></pre> Source code in <code>anta/tests/multicast.py</code> <pre><code>class VerifyIGMPSnoopingGlobal(AntaTest):\n    \"\"\"Verifies the IGMP snooping global status.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the IGMP snooping global status matches the expected status.\n    * Failure: The test will fail if the IGMP snooping global status does not match the expected status.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.multicast:\n      - VerifyIGMPSnoopingGlobal:\n          enabled: True\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"multicast\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip igmp snooping\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyIGMPSnoopingGlobal test.\"\"\"\n\n        enabled: bool\n        \"\"\"Whether global IGMP snopping must be enabled (True) or disabled (False).\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIGMPSnoopingGlobal.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        igmp_state = command_output[\"igmpSnoopingState\"]\n        expected_state = \"enabled\" if self.inputs.enabled else \"disabled\"\n        if igmp_state != expected_state:\n            self.result.is_failure(f\"IGMP state is not valid - Expected: {expected_state} Actual: {igmp_state}\")\n</code></pre>"},{"location":"api/tests/multicast/#anta.tests.multicast.VerifyIGMPSnoopingGlobal-attributes","title":"Inputs","text":"Name Type Description Default <code>enabled</code> <code>bool</code>                      Whether global IGMP snopping must be enabled (True) or disabled (False).                    -"},{"location":"api/tests/multicast/#anta.tests.multicast.VerifyIGMPSnoopingVlans","title":"VerifyIGMPSnoopingVlans","text":"<p>Verifies the IGMP snooping status for the provided VLANs.</p> Expected Results <ul> <li>Success: The test will pass if the IGMP snooping status matches the expected status for the provided VLANs.</li> <li>Failure: The test will fail if the IGMP snooping status does not match the expected status for the provided VLANs.</li> </ul> Examples <pre><code>anta.tests.multicast:\n  - VerifyIGMPSnoopingVlans:\n      vlans:\n        10: False\n        12: False\n</code></pre> Source code in <code>anta/tests/multicast.py</code> <pre><code>class VerifyIGMPSnoopingVlans(AntaTest):\n    \"\"\"Verifies the IGMP snooping status for the provided VLANs.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the IGMP snooping status matches the expected status for the provided VLANs.\n    * Failure: The test will fail if the IGMP snooping status does not match the expected status for the provided VLANs.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.multicast:\n      - VerifyIGMPSnoopingVlans:\n          vlans:\n            10: False\n            12: False\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"multicast\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip igmp snooping\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyIGMPSnoopingVlans test.\"\"\"\n\n        vlans: dict[Vlan, bool]\n        \"\"\"Dictionary with VLAN ID and whether IGMP snooping must be enabled (True) or disabled (False).\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIGMPSnoopingVlans.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        for vlan, enabled in self.inputs.vlans.items():\n            if str(vlan) not in command_output[\"vlans\"]:\n                self.result.is_failure(f\"Supplied vlan {vlan} is not present on the device\")\n                continue\n            expected_state = \"enabled\" if enabled else \"disabled\"\n            igmp_state = command_output[\"vlans\"][str(vlan)][\"igmpSnoopingState\"]\n            if igmp_state != expected_state:\n                self.result.is_failure(f\"VLAN{vlan} - Incorrect IGMP state - Expected: {expected_state} Actual: {igmp_state}\")\n</code></pre>"},{"location":"api/tests/multicast/#anta.tests.multicast.VerifyIGMPSnoopingVlans-attributes","title":"Inputs","text":"Name Type Description Default <code>vlans</code> <code>dict[Vlan, bool]</code>                      Dictionary with VLAN ID and whether IGMP snooping must be enabled (True) or disabled (False).                    -"},{"location":"api/tests/path_selection/","title":"Router Path Selection","text":""},{"location":"api/tests/path_selection/#tests","title":"Tests","text":"<p>Test functions related to various router path-selection settings.</p>"},{"location":"api/tests/path_selection/#anta.tests.path_selection.VerifyPathsHealth","title":"VerifyPathsHealth","text":"<p>Verifies the path and telemetry state of all paths under router path-selection.</p> <p>The expected states are \u2018IPsec established\u2019, \u2018Resolved\u2019 for path and \u2018active\u2019 for telemetry.</p> Expected Results <ul> <li>Success: The test will pass if all path states under router path-selection are either \u2018IPsec established\u2019 or \u2018Resolved\u2019            and their telemetry state as \u2018active\u2019.</li> <li>Failure: The test will fail if router path-selection is not configured or if any path state is not \u2018IPsec established\u2019 or \u2018Resolved\u2019,            or the telemetry state is \u2018inactive\u2019.</li> </ul> Examples <pre><code>anta.tests.path_selection:\n  - VerifyPathsHealth:\n</code></pre> Source code in <code>anta/tests/path_selection.py</code> <pre><code>class VerifyPathsHealth(AntaTest):\n    \"\"\"Verifies the path and telemetry state of all paths under router path-selection.\n\n    The expected states are 'IPsec established', 'Resolved' for path and 'active' for telemetry.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all path states under router path-selection are either 'IPsec established' or 'Resolved'\n               and their telemetry state as 'active'.\n    * Failure: The test will fail if router path-selection is not configured or if any path state is not 'IPsec established' or 'Resolved',\n               or the telemetry state is 'inactive'.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.path_selection:\n      - VerifyPathsHealth:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"path-selection\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show path-selection paths\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyPathsHealth.\"\"\"\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output[\"dpsPeers\"]\n\n        # If no paths are configured for router path-selection, the test fails\n        if not command_output:\n            self.result.is_failure(\"No path configured for router path-selection\")\n            return\n\n        # Check the state of each path\n        for peer, peer_data in command_output.items():\n            for group, group_data in peer_data[\"dpsGroups\"].items():\n                for path_data in group_data[\"dpsPaths\"].values():\n                    path_state = path_data[\"state\"]\n                    session = path_data[\"dpsSessions\"][\"0\"][\"active\"]\n\n                    # If the path state of any path is not 'ipsecEstablished' or 'routeResolved', the test fails\n                    expected_state = [\"ipsecEstablished\", \"routeResolved\"]\n                    if path_state not in expected_state:\n                        self.result.is_failure(f\"Peer: {peer} Path Group: {group} - Invalid path state - Expected: {', '.join(expected_state)} Actual: {path_state}\")\n\n                    # If the telemetry state of any path is inactive, the test fails\n                    elif not session:\n                        self.result.is_failure(f\"Peer: {peer} Path Group {group} - Telemetry state inactive\")\n</code></pre>"},{"location":"api/tests/path_selection/#anta.tests.path_selection.VerifySpecificPath","title":"VerifySpecificPath","text":"<p>Verifies the DPS path and telemetry state of an IPv4 peer.</p> <p>This test performs the following checks:</p> <ol> <li>Verifies that the specified peer is configured.</li> <li>Verifies that the specified path group is found.</li> <li>For each specified DPS path:<ul> <li>Verifies that the expected source and destination address matches the expected.</li> <li>Verifies that the state is <code>ipsecEstablished</code> or <code>routeResolved</code>.</li> <li>Verifies that the telemetry state is <code>active</code>.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: The test will pass if the path state under router path-selection is either \u2018IPsecEstablished\u2019 or \u2018Resolved\u2019            and telemetry state as \u2018active\u2019.</li> <li>Failure: The test will fail if router path selection or the peer is not configured or if the path state is not \u2018IPsec established\u2019 or \u2018Resolved\u2019,            or the telemetry state is \u2018inactive\u2019.</li> </ul> Examples <pre><code>anta.tests.path_selection:\n  - VerifySpecificPath:\n      paths:\n        - peer: 10.255.0.1\n          path_group: internet\n          source_address: 100.64.3.2\n          destination_address: 100.64.1.2\n</code></pre> Source code in <code>anta/tests/path_selection.py</code> <pre><code>class VerifySpecificPath(AntaTest):\n    \"\"\"Verifies the DPS path and telemetry state of an IPv4 peer.\n\n    This test performs the following checks:\n\n      1. Verifies that the specified peer is configured.\n      2. Verifies that the specified path group is found.\n      3. For each specified DPS path:\n         - Verifies that the expected source and destination address matches the expected.\n         - Verifies that the state is `ipsecEstablished` or `routeResolved`.\n         - Verifies that the telemetry state is `active`.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the path state under router path-selection is either 'IPsecEstablished' or 'Resolved'\n               and telemetry state as 'active'.\n    * Failure: The test will fail if router path selection or the peer is not configured or if the path state is not 'IPsec established' or 'Resolved',\n               or the telemetry state is 'inactive'.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.path_selection:\n      - VerifySpecificPath:\n          paths:\n            - peer: 10.255.0.1\n              path_group: internet\n              source_address: 100.64.3.2\n              destination_address: 100.64.1.2\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"path-selection\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show path-selection paths\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySpecificPath test.\"\"\"\n\n        paths: list[DpsPath]\n        \"\"\"List of router paths to verify.\"\"\"\n        RouterPath: ClassVar[type[DpsPath]] = DpsPath\n        \"\"\"To maintain backward compatibility.\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySpecificPath.\"\"\"\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output\n\n        # If the dpsPeers details are not found in the command output, the test fails.\n        if not (dps_peers_details := get_value(command_output, \"dpsPeers\")):\n            self.result.is_failure(\"Router path-selection not configured\")\n            return\n\n        # Iterating on each DPS peer mentioned in the inputs.\n        for dps_path in self.inputs.paths:\n            peer = str(dps_path.peer)\n            peer_details = dps_peers_details.get(peer, {})\n            # If the peer is not configured for the path group, the test fails\n            if not peer_details:\n                self.result.is_failure(f\"{dps_path} - Peer not found\")\n                continue\n\n            path_group = dps_path.path_group\n            source = str(dps_path.source_address)\n            destination = str(dps_path.destination_address)\n            path_group_details = get_value(peer_details, f\"dpsGroups..{path_group}..dpsPaths\", separator=\"..\")\n            # If the expected path group is not found for the peer, the test fails.\n            if not path_group_details:\n                self.result.is_failure(f\"{dps_path} - No DPS path found for this peer and path group\")\n                continue\n\n            path_data = next((path for path in path_group_details.values() if (path.get(\"source\") == source and path.get(\"destination\") == destination)), None)\n            #  Source and destination address do not match, the test fails.\n            if not path_data:\n                self.result.is_failure(f\"{dps_path} - No path matching the source and destination found\")\n                continue\n\n            path_state = path_data.get(\"state\")\n            session = get_value(path_data, \"dpsSessions.0.active\")\n\n            # If the state of the path is not 'ipsecEstablished' or 'routeResolved', or the telemetry state is 'inactive', the test fails\n            if path_state not in [\"ipsecEstablished\", \"routeResolved\"]:\n                self.result.is_failure(f\"{dps_path} - Invalid state path - Expected: ipsecEstablished, routeResolved Actual: {path_state}\")\n            elif not session:\n                self.result.is_failure(f\"{dps_path} - Telemetry state inactive for this path\")\n</code></pre>"},{"location":"api/tests/path_selection/#anta.tests.path_selection.VerifySpecificPath-attributes","title":"Inputs","text":"Name Type Description Default <code>paths</code> <code>list[DpsPath]</code>                      List of router paths to verify.                    - <code>RouterPath</code> <code>type[DpsPath]</code>                      To maintain backward compatibility.                    <code>DpsPath</code>"},{"location":"api/tests/path_selection/#input-models","title":"Input models","text":"<p>Module containing input models for path-selection tests.</p>"},{"location":"api/tests/path_selection/#anta.input_models.path_selection.DpsPath","title":"DpsPath","text":"<p>Model for a list of DPS path entries.</p> Name Type Description Default <code>peer</code> <code>IPv4Address</code>                      Static peer IPv4 address.                    - <code>path_group</code> <code>str</code>                      Router path group name.                    - <code>source_address</code> <code>IPv4Address</code>                      Source IPv4 address of path.                    - <code>destination_address</code> <code>IPv4Address</code>                      Destination IPv4 address of path.                    - Source code in <code>anta/input_models/path_selection.py</code> <pre><code>class DpsPath(BaseModel):\n    \"\"\"Model for a list of DPS path entries.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    peer: IPv4Address\n    \"\"\"Static peer IPv4 address.\"\"\"\n    path_group: str\n    \"\"\"Router path group name.\"\"\"\n    source_address: IPv4Address\n    \"\"\"Source IPv4 address of path.\"\"\"\n    destination_address: IPv4Address\n    \"\"\"Destination IPv4 address of path.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the DpsPath for reporting.\"\"\"\n        return f\"Peer: {self.peer} PathGroup: {self.path_group} Source: {self.source_address} Destination: {self.destination_address}\"\n</code></pre>"},{"location":"api/tests/profiles/","title":"Profiles","text":"<p>Module related to ASIC profile tests.</p>"},{"location":"api/tests/profiles/#anta.tests.profiles.VerifyTcamProfile","title":"VerifyTcamProfile","text":"<p>Verifies that the device is using the provided Ternary Content-Addressable Memory (TCAM) profile.</p> Expected Results <ul> <li>Success: The test will pass if the provided TCAM profile is actually running on the device.</li> <li>Failure: The test will fail if the provided TCAM profile is not running on the device.</li> </ul> Examples <pre><code>anta.tests.profiles:\n  - VerifyTcamProfile:\n      profile: vxlan-routing\n</code></pre> Source code in <code>anta/tests/profiles.py</code> <pre><code>class VerifyTcamProfile(AntaTest):\n    \"\"\"Verifies that the device is using the provided Ternary Content-Addressable Memory (TCAM) profile.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided TCAM profile is actually running on the device.\n    * Failure: The test will fail if the provided TCAM profile is not running on the device.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.profiles:\n      - VerifyTcamProfile:\n          profile: vxlan-routing\n    ```\n    \"\"\"\n\n    description = \"Verifies the device TCAM profile.\"\n    categories: ClassVar[list[str]] = [\"profiles\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show hardware tcam profile\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyTcamProfile test.\"\"\"\n\n        profile: str\n        \"\"\"Expected TCAM profile.\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTcamProfile.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        if command_output[\"pmfProfiles\"][\"FixedSystem\"][\"status\"] == command_output[\"pmfProfiles\"][\"FixedSystem\"][\"config\"] == self.inputs.profile:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Incorrect profile running on device: {command_output['pmfProfiles']['FixedSystem']['status']}\")\n</code></pre>"},{"location":"api/tests/profiles/#anta.tests.profiles.VerifyTcamProfile-attributes","title":"Inputs","text":"Name Type Description Default <code>profile</code> <code>str</code>                      Expected TCAM profile.                    -"},{"location":"api/tests/profiles/#anta.tests.profiles.VerifyUnifiedForwardingTableMode","title":"VerifyUnifiedForwardingTableMode","text":"<p>Verifies the device is using the expected UFT (Unified Forwarding Table) mode.</p> Expected Results <ul> <li>Success: The test will pass if the device is using the expected UFT mode.</li> <li>Failure: The test will fail if the device is not using the expected UFT mode.</li> </ul> Examples <pre><code>anta.tests.profiles:\n  - VerifyUnifiedForwardingTableMode:\n      mode: 3\n</code></pre> Source code in <code>anta/tests/profiles.py</code> <pre><code>class VerifyUnifiedForwardingTableMode(AntaTest):\n    \"\"\"Verifies the device is using the expected UFT (Unified Forwarding Table) mode.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device is using the expected UFT mode.\n    * Failure: The test will fail if the device is not using the expected UFT mode.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.profiles:\n      - VerifyUnifiedForwardingTableMode:\n          mode: 3\n    ```\n    \"\"\"\n\n    description = \"Verifies the device is using the expected UFT mode.\"\n    categories: ClassVar[list[str]] = [\"profiles\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show platform trident forwarding-table partition\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyUnifiedForwardingTableMode test.\"\"\"\n\n        mode: Literal[0, 1, 2, 3, 4, \"flexible\"]\n        \"\"\"Expected UFT mode. Valid values are 0, 1, 2, 3, 4, or \"flexible\".\"\"\"\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyUnifiedForwardingTableMode.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        if command_output[\"uftMode\"] == str(self.inputs.mode):\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Not running the correct UFT mode - Expected: {self.inputs.mode} Actual: {command_output['uftMode']}\")\n</code></pre>"},{"location":"api/tests/profiles/#anta.tests.profiles.VerifyUnifiedForwardingTableMode-attributes","title":"Inputs","text":"Name Type Description Default <code>mode</code> <code>Literal[0, 1, 2, 3, 4, 'flexible']</code>                      Expected UFT mode. Valid values are 0, 1, 2, 3, 4, or \"flexible\".                    -"},{"location":"api/tests/ptp/","title":"PTP","text":"<p>Module related to PTP tests.</p>"},{"location":"api/tests/ptp/#anta.tests.ptp.VerifyPtpGMStatus","title":"VerifyPtpGMStatus","text":"<p>Verifies that the device is locked to a valid PTP Grandmaster.</p> <p>To test PTP failover, re-run the test with a secondary GMID configured.</p> Expected Results <ul> <li>Success: The test will pass if the device is locked to the provided Grandmaster.</li> <li>Failure: The test will fail if the device is not locked to the provided Grandmaster.</li> <li>Skipped: The test will be skipped if PTP is not configured on the device.</li> </ul> Examples <pre><code>anta.tests.ptp:\n  - VerifyPtpGMStatus:\n      gmid: 0xec:46:70:ff:fe:00:ff:a9\n</code></pre> Source code in <code>anta/tests/ptp.py</code> <pre><code>class VerifyPtpGMStatus(AntaTest):\n    \"\"\"Verifies that the device is locked to a valid PTP Grandmaster.\n\n    To test PTP failover, re-run the test with a secondary GMID configured.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device is locked to the provided Grandmaster.\n    * Failure: The test will fail if the device is not locked to the provided Grandmaster.\n    * Skipped: The test will be skipped if PTP is not configured on the device.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.ptp:\n      - VerifyPtpGMStatus:\n          gmid: 0xec:46:70:ff:fe:00:ff:a9\n    ```\n    \"\"\"\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyPtpGMStatus test.\"\"\"\n\n        gmid: str\n        \"\"\"Identifier of the Grandmaster to which the device should be locked.\"\"\"\n\n    categories: ClassVar[list[str]] = [\"ptp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ptp\", revision=2)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyPtpGMStatus.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        if (ptp_clock_summary := command_output.get(\"ptpClockSummary\")) is None:\n            self.result.is_skipped(\"PTP is not configured\")\n            return\n\n        if (act_gmid := ptp_clock_summary[\"gmClockIdentity\"]) != self.inputs.gmid:\n            self.result.is_failure(f\"The device is locked to the incorrect Grandmaster - Expected: {self.inputs.gmid} Actual: {act_gmid}\")\n</code></pre>"},{"location":"api/tests/ptp/#anta.tests.ptp.VerifyPtpGMStatus-attributes","title":"Inputs","text":"Name Type Description Default <code>gmid</code> <code>str</code>                      Identifier of the Grandmaster to which the device should be locked.                    -"},{"location":"api/tests/ptp/#anta.tests.ptp.VerifyPtpLockStatus","title":"VerifyPtpLockStatus","text":"<p>Verifies that the device was locked to the upstream PTP GM in the last minute.</p> Expected Results <ul> <li>Success: The test will pass if the device was locked to the upstream GM in the last minute.</li> <li>Failure: The test will fail if the device was not locked to the upstream GM in the last minute.</li> <li>Skipped: The test will be skipped if PTP is not configured on the device.</li> </ul> Examples <pre><code>anta.tests.ptp:\n  - VerifyPtpLockStatus:\n</code></pre> Source code in <code>anta/tests/ptp.py</code> <pre><code>class VerifyPtpLockStatus(AntaTest):\n    \"\"\"Verifies that the device was locked to the upstream PTP GM in the last minute.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device was locked to the upstream GM in the last minute.\n    * Failure: The test will fail if the device was not locked to the upstream GM in the last minute.\n    * Skipped: The test will be skipped if PTP is not configured on the device.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.ptp:\n      - VerifyPtpLockStatus:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"ptp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ptp\", revision=2)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyPtpLockStatus.\"\"\"\n        threshold = 60\n        command_output = self.instance_commands[0].json_output\n\n        if (ptp_clock_summary := command_output.get(\"ptpClockSummary\")) is None:\n            self.result.is_skipped(\"PTP is not configured\")\n            return\n\n        time_difference = ptp_clock_summary[\"currentPtpSystemTime\"] - ptp_clock_summary[\"lastSyncTime\"]\n\n        if time_difference &gt;= threshold:\n            self.result.is_failure(f\"Lock is more than {threshold}s old - Actual: {time_difference}s\")\n        else:\n            self.result.is_success()\n</code></pre>"},{"location":"api/tests/ptp/#anta.tests.ptp.VerifyPtpModeStatus","title":"VerifyPtpModeStatus","text":"<p>Verifies that the device is configured as a PTP Boundary Clock.</p> Expected Results <ul> <li>Success: The test will pass if the device is a BC.</li> <li>Failure: The test will fail if the device is not a BC.</li> <li>Skipped: The test will be skipped if PTP is not configured on the device.</li> </ul> Examples <pre><code>anta.tests.ptp:\n  - VerifyPtpModeStatus:\n</code></pre> Source code in <code>anta/tests/ptp.py</code> <pre><code>class VerifyPtpModeStatus(AntaTest):\n    \"\"\"Verifies that the device is configured as a PTP Boundary Clock.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device is a BC.\n    * Failure: The test will fail if the device is not a BC.\n    * Skipped: The test will be skipped if PTP is not configured on the device.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.ptp:\n      - VerifyPtpModeStatus:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"ptp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ptp\", revision=2)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyPtpModeStatus.\"\"\"\n        command_output = self.instance_commands[0].json_output\n\n        if (ptp_mode := command_output.get(\"ptpMode\")) is None:\n            self.result.is_skipped(\"PTP is not configured\")\n            return\n\n        if ptp_mode != \"ptpBoundaryClock\":\n            self.result.is_failure(f\"Not configured as a PTP Boundary Clock - Actual: {ptp_mode}\")\n        else:\n            self.result.is_success()\n</code></pre>"},{"location":"api/tests/ptp/#anta.tests.ptp.VerifyPtpOffset","title":"VerifyPtpOffset","text":"<p>Verifies that the PTP timing offset is within \u00b1 1000ns from the master clock.</p> Expected Results <ul> <li>Success: The test will pass if the PTP timing offset is within \u00b1 1000ns from the master clock.</li> <li>Failure: The test will fail if the PTP timing offset is greater than \u00b1 1000ns from the master clock.</li> <li>Skipped: The test will be skipped if PTP is not configured on the device.</li> </ul> Examples <pre><code>anta.tests.ptp:\n  - VerifyPtpOffset:\n</code></pre> Source code in <code>anta/tests/ptp.py</code> <pre><code>class VerifyPtpOffset(AntaTest):\n    \"\"\"Verifies that the PTP timing offset is within +/- 1000ns from the master clock.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the PTP timing offset is within +/- 1000ns from the master clock.\n    * Failure: The test will fail if the PTP timing offset is greater than +/- 1000ns from the master clock.\n    * Skipped: The test will be skipped if PTP is not configured on the device.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.ptp:\n      - VerifyPtpOffset:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"ptp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ptp monitor\", revision=1)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyPtpOffset.\"\"\"\n        threshold = 1000\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        offset_interfaces: dict[str, list[int]] = {}\n        if not command_output[\"ptpMonitorData\"]:\n            self.result.is_skipped(\"PTP is not configured\")\n            return\n\n        for interface in command_output[\"ptpMonitorData\"]:\n            if abs(interface[\"offsetFromMaster\"]) &gt; threshold:\n                offset_interfaces.setdefault(interface[\"intf\"], []).append(interface[\"offsetFromMaster\"])\n\n        for interface, data in offset_interfaces.items():\n            self.result.is_failure(f\"Interface: {interface} - Timing offset from master is greater than +/- {threshold}ns: Actual: {', '.join(map(str, data))}\")\n</code></pre>"},{"location":"api/tests/ptp/#anta.tests.ptp.VerifyPtpPortModeStatus","title":"VerifyPtpPortModeStatus","text":"<p>Verifies the PTP interfaces state.</p> <p>The interfaces can be in one of the following state: Master, Slave, Passive, or Disabled.</p> Expected Results <ul> <li>Success: The test will pass if all PTP enabled interfaces are in a valid state.</li> <li>Failure: The test will fail if there are no PTP enabled interfaces or if some interfaces are not in a valid state.</li> </ul> Examples <pre><code>anta.tests.ptp:\n  - VerifyPtpPortModeStatus:\n</code></pre> Source code in <code>anta/tests/ptp.py</code> <pre><code>class VerifyPtpPortModeStatus(AntaTest):\n    \"\"\"Verifies the PTP interfaces state.\n\n    The interfaces can be in one of the following state: Master, Slave, Passive, or Disabled.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all PTP enabled interfaces are in a valid state.\n    * Failure: The test will fail if there are no PTP enabled interfaces or if some interfaces are not in a valid state.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.ptp:\n      - VerifyPtpPortModeStatus:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"ptp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ptp\", revision=2)]\n\n    @skip_on_platforms([\"cEOSLab\", \"vEOS-lab\", \"cEOSCloudLab\", \"vEOS\"])\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyPtpPortModeStatus.\"\"\"\n        valid_state = (\"psMaster\", \"psSlave\", \"psPassive\", \"psDisabled\")\n        command_output = self.instance_commands[0].json_output\n\n        if not command_output[\"ptpIntfSummaries\"]:\n            self.result.is_failure(\"No interfaces are PTP enabled\")\n            return\n\n        invalid_interfaces = [\n            interface\n            for interface in command_output[\"ptpIntfSummaries\"]\n            for vlan in command_output[\"ptpIntfSummaries\"][interface][\"ptpIntfVlanSummaries\"]\n            if vlan[\"portState\"] not in valid_state\n        ]\n\n        if not invalid_interfaces:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"The following interface(s) are not in a valid PTP state: {', '.join(invalid_interfaces)}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/","title":"BGP","text":"<p>BGP Test Compatibility Note</p> <p>ANTA BGP tests are designed for the <code>multi-agent</code> routing protocol model. Starting from EOS 4.30.1F, <code>service routing protocols models</code> is set to <code>multi-agent</code> by default, and from EOS 4.32.0F it becomes the only supported model.</p> <p>The following tests are available for devices using the legacy <code>ribd</code> model on earlier EOS versions:</p> <ul> <li><code>VerifyBGPPeerSessionRibd</code></li> <li><code>VerifyBGPPeersHealthRibd</code></li> </ul>"},{"location":"api/tests/routing.bgp/#tests","title":"Tests","text":"<p>Module related to BGP tests.</p>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPAdvCommunities","title":"VerifyBGPAdvCommunities","text":"<p>Verifies that advertised communities are standard, extended and large for BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Validates that all required community types are advertised:<ul> <li>Standard communities</li> <li>Extended communities</li> <li>Large communities</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>Each peer advertises standard, extended and large communities.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>A peer does not advertise standard, extended or large communities.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPAdvCommunities:\n        bgp_peers:\n          - peer_address: 172.30.11.17\n            vrf: default\n          - peer_address: 172.30.11.21\n            vrf: default\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPAdvCommunities(AntaTest):\n    \"\"\"Verifies that advertised communities are standard, extended and large for BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Validates that all required community types are advertised:\n        - Standard communities\n        - Extended communities\n        - Large communities\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - Each peer advertises standard, extended and large communities.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - A peer does not advertise standard, extended or large communities.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPAdvCommunities:\n            bgp_peers:\n              - peer_address: 172.30.11.17\n                vrf: default\n              - peer_address: 172.30.11.21\n                vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPAdvCommunities test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPAdvCommunities.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Check BGP peer advertised communities\n            if not all(get_value(peer_data, f\"advertisedCommunities.{community}\") is True for community in [\"standard\", \"extended\", \"large\"]):\n                self.result.is_failure(f\"{peer} - {format_data(peer_data['advertisedCommunities'])}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPAdvCommunities-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPExchangedRoutes","title":"VerifyBGPExchangedRoutes","text":"<p>Verifies the advertised and received routes of BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <p>For each advertised and received route:     - Confirms that the route exists in the BGP route table.     - Verifies that the route is in an \u2018active\u2019 and \u2018valid\u2019 state.</p> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified advertised/received routes are found in the BGP route table.</li> <li>All routes are in both \u2018active\u2019 and \u2018valid\u2019 states.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>An advertised/received route is not found in the BGP route table.</li> <li>Any route is not in an \u2018active\u2019 or \u2018valid\u2019 state.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPExchangedRoutes:\n        bgp_peers:\n          - peer_address: 172.30.255.5\n            vrf: default\n            advertised_routes:\n              - 192.0.254.5/32\n            received_routes:\n              - 192.0.255.4/32\n          - peer_address: 172.30.255.1\n            vrf: default\n            advertised_routes:\n              - 192.0.255.1/32\n              - 192.0.254.5/32\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPExchangedRoutes(AntaTest):\n    \"\"\"Verifies the advertised and received routes of BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      For each advertised and received route:\n        - Confirms that the route exists in the BGP route table.\n        - Verifies that the route is in an 'active' and 'valid' state.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified advertised/received routes are found in the BGP route table.\n        - All routes are in both 'active' and 'valid' states.\n    * Failure: If any of the following occur:\n        - An advertised/received route is not found in the BGP route table.\n        - Any route is not in an 'active' or 'valid' state.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPExchangedRoutes:\n            bgp_peers:\n              - peer_address: 172.30.255.5\n                vrf: default\n                advertised_routes:\n                  - 192.0.254.5/32\n                received_routes:\n                  - 192.0.255.4/32\n              - peer_address: 172.30.255.1\n                vrf: default\n                advertised_routes:\n                  - 192.0.255.1/32\n                  - 192.0.254.5/32\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaTemplate(template=\"show bgp neighbors {peer} advertised-routes vrf {vrf}\", revision=3),\n        AntaTemplate(template=\"show bgp neighbors {peer} routes vrf {vrf}\", revision=3),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPExchangedRoutes test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpNeighbor: ClassVar[type[BgpNeighbor]] = BgpNeighbor\n\n        @field_validator(\"bgp_peers\")\n        @classmethod\n        def validate_bgp_peers(cls, bgp_peers: list[BgpPeer]) -&gt; list[BgpPeer]:\n            \"\"\"Validate that 'advertised_routes' or 'received_routes' field is provided in each BGP peer.\"\"\"\n            for peer in bgp_peers:\n                if peer.advertised_routes is None and peer.received_routes is None:\n                    msg = f\"{peer} 'advertised_routes' or 'received_routes' field missing in the input\"\n                    raise ValueError(msg)\n            return bgp_peers\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for each BGP peer in the input list.\"\"\"\n        return [template.render(peer=str(bgp_peer.peer_address), vrf=bgp_peer.vrf) for bgp_peer in self.inputs.bgp_peers]\n\n    def _validate_bgp_route_paths(self, peer: str, route_type: str, route: str, entries: dict[str, Any]) -&gt; str | None:\n        \"\"\"Validate the BGP route paths.\"\"\"\n        # Check if the route is found\n        if route in entries:\n            # Check if the route is active and valid\n            route_paths = entries[route][\"bgpRoutePaths\"][0][\"routeType\"]\n            is_active = route_paths[\"active\"]\n            is_valid = route_paths[\"valid\"]\n            if not is_active or not is_valid:\n                return f\"{peer} {route_type} route: {route} - Valid: {is_valid} Active: {is_active}\"\n            return None\n\n        return f\"{peer} {route_type} route: {route} - Not found\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPExchangedRoutes.\"\"\"\n        self.result.is_success()\n\n        num_peers = len(self.inputs.bgp_peers)\n\n        # Process each peer and its corresponding command pair\n        for peer_idx, peer in enumerate(self.inputs.bgp_peers):\n            # For n peers, advertised routes are at indices 0 to n-1, and received routes are at indices n to 2n-1\n            advertised_routes_cmd = self.instance_commands[peer_idx]\n            received_routes_cmd = self.instance_commands[peer_idx + num_peers]\n\n            # Get the BGP route entries of each command\n            command_output = {\n                \"Advertised\": get_value(advertised_routes_cmd.json_output, f\"vrfs.{peer.vrf}.bgpRouteEntries\", default={}),\n                \"Received\": get_value(received_routes_cmd.json_output, f\"vrfs.{peer.vrf}.bgpRouteEntries\", default={}),\n            }\n\n            # Validate both advertised and received routes\n            for route_type, routes in zip([\"Advertised\", \"Received\"], [peer.advertised_routes, peer.received_routes]):\n                # Skipping the validation for routes if user input is None\n                if not routes:\n                    continue\n\n                entries = command_output[route_type]\n                for route in routes:\n                    # Check if the route is found. If yes then checks the route is active and valid\n                    failure_msg = self._validate_bgp_route_paths(str(peer), route_type, str(route), entries)\n                    if failure_msg:\n                        self.result.is_failure(failure_msg)\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPExchangedRoutes-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPNlriAcceptance","title":"VerifyBGPNlriAcceptance","text":"<p>Verifies that all received NLRI are accepted for all AFI/SAFI configured for BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Verifies that all received NLRI were accepted by comparing <code>nlrisReceived</code> with <code>nlrisAccepted</code>.</li> </ol> Expected Results <ul> <li>Success: If <code>nlrisReceived</code> equals <code>nlrisAccepted</code>, indicating all NLRI were accepted.</li> <li>Failure: If any of the following occur:<ul> <li>The specified VRF is not configured.</li> <li><code>nlrisReceived</code> does not equal <code>nlrisAccepted</code>, indicating some NLRI were rejected or filtered.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPNlriAcceptance:\n        bgp_peers:\n          - peer_address: 10.100.0.128\n            vrf: default\n            capabilities:\n              - ipv4Unicast\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPNlriAcceptance(AntaTest):\n    \"\"\"Verifies that all received NLRI are accepted for all AFI/SAFI configured for BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Verifies that all received NLRI were accepted by comparing `nlrisReceived` with `nlrisAccepted`.\n\n    Expected Results\n    ----------------\n    * Success: If `nlrisReceived` equals `nlrisAccepted`, indicating all NLRI were accepted.\n    * Failure: If any of the following occur:\n        - The specified VRF is not configured.\n        - `nlrisReceived` does not equal `nlrisAccepted`, indicating some NLRI were rejected or filtered.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPNlriAcceptance:\n            bgp_peers:\n              - peer_address: 10.100.0.128\n                vrf: default\n                capabilities:\n                  - ipv4Unicast\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp summary vrf all\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPNlriAcceptance test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n\n        @field_validator(\"bgp_peers\")\n        @classmethod\n        def validate_bgp_peers(cls, bgp_peers: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'capabilities' field is provided in each BGP peer.\"\"\"\n            for peer in bgp_peers:\n                if peer.capabilities is None:\n                    msg = f\"{peer} 'capabilities' field missing in the input\"\n                    raise ValueError(msg)\n            return bgp_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPNlriAcceptance.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            # Check if the peer is found\n            if not (peer_data := get_value(output, f\"vrfs..{peer.vrf}..peers..{peer.peer_address}\", separator=\"..\")):\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Fetching the multiprotocol capabilities\n            for capability in peer.capabilities:\n                # Check if the capability is found\n                if (capability_status := get_value(peer_data, capability)) is None:\n                    self.result.is_failure(f\"{peer} - {capability} not found\")\n                    continue\n\n                if capability_status[\"afiSafiState\"] != \"negotiated\":\n                    self.result.is_failure(f\"{peer} - {capability} not negotiated\")\n\n                if (received := capability_status.get(\"nlrisReceived\")) != (accepted := capability_status.get(\"nlrisAccepted\")):\n                    self.result.is_failure(f\"{peer} AFI/SAFI: {capability} - Some NLRI were filtered or rejected - Accepted: {accepted} Received: {received}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPNlriAcceptance-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerASNCap","title":"VerifyBGPPeerASNCap","text":"<p>Verifies the four octet ASN capability of BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Validates that the capability is present in the peer configuration.</li> <li>Confirms that the capability is advertised, received, and enabled.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>The four octet ASN capability is present in each peer configuration.</li> <li>The capability is properly negotiated (advertised, received, and enabled) for all peers.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>The four octet ASN capability is not present for a peer.</li> <li>The capability is not properly negotiated (not advertised, received, or enabled) for any peer.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerASNCap:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerASNCap(AntaTest):\n    \"\"\"Verifies the four octet ASN capability of BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Validates that the capability is present in the peer configuration.\n      3. Confirms that the capability is advertised, received, and enabled.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - The four octet ASN capability is present in each peer configuration.\n        - The capability is properly negotiated (advertised, received, and enabled) for all peers.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - The four octet ASN capability is not present for a peer.\n        - The capability is not properly negotiated (not advertised, received, or enabled) for any peer.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerASNCap:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerASNCap test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerASNCap.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Check if the 4-octet ASN capability is found\n            if (capablity_status := get_value(peer_data, \"neighborCapabilities.fourOctetAsnCap\")) is None:\n                self.result.is_failure(f\"{peer} - 4-octet ASN capability not found\")\n                continue\n\n            # Check if the 4-octet ASN capability is advertised, received, and enabled\n            if not _check_bgp_neighbor_capability(capablity_status):\n                self.result.is_failure(f\"{peer} - 4-octet ASN capability not negotiated - {format_data(capablity_status)}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerASNCap-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerCount","title":"VerifyBGPPeerCount","text":"<p>Verifies the count of BGP peers for given address families.</p> <p>This test performs the following checks for each specified address family:</p> <ol> <li>Confirms that the specified VRF is configured.</li> <li>Counts the number of peers that are:<ul> <li>If <code>check_peer_state</code> is set to True, Counts the number of BGP peers that are in the <code>Established</code> state and have successfully negotiated the specified AFI/SAFI</li> <li>If <code>check_peer_state</code> is set to False, skips validation of the <code>Established</code> state and AFI/SAFI negotiation.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If the count of BGP peers matches the expected count with <code>check_peer_state</code> enabled/disabled.</li> <li>Failure: If any of the following occur:<ul> <li>The specified VRF is not configured.</li> <li>The BGP peer count does not match expected value with <code>check_peer_state</code> enabled/disabled.\u201d</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerCount:\n        address_families:\n          - afi: \"evpn\"\n            num_peers: 2\n          - afi: \"ipv4\"\n            safi: \"unicast\"\n            vrf: \"PROD\"\n            num_peers: 2\n          - afi: \"ipv4\"\n            safi: \"unicast\"\n            vrf: \"default\"\n            num_peers: 3\n          - afi: \"ipv4\"\n            safi: \"multicast\"\n            vrf: \"DEV\"\n            num_peers: 3\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerCount(AntaTest):\n    \"\"\"Verifies the count of BGP peers for given address families.\n\n    This test performs the following checks for each specified address family:\n\n      1. Confirms that the specified VRF is configured.\n      2. Counts the number of peers that are:\n        - If `check_peer_state` is set to True, Counts the number of BGP peers that are in the `Established` state and\n        have successfully negotiated the specified AFI/SAFI\n        - If `check_peer_state` is set to False, skips validation of the `Established` state and AFI/SAFI negotiation.\n\n    Expected Results\n    ----------------\n    * Success: If the count of BGP peers matches the expected count with `check_peer_state` enabled/disabled.\n    * Failure: If any of the following occur:\n        - The specified VRF is not configured.\n        - The BGP peer count does not match expected value with `check_peer_state` enabled/disabled.\"\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerCount:\n            address_families:\n              - afi: \"evpn\"\n                num_peers: 2\n              - afi: \"ipv4\"\n                safi: \"unicast\"\n                vrf: \"PROD\"\n                num_peers: 2\n              - afi: \"ipv4\"\n                safi: \"unicast\"\n                vrf: \"default\"\n                num_peers: 3\n              - afi: \"ipv4\"\n                safi: \"multicast\"\n                vrf: \"DEV\"\n                num_peers: 3\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp summary vrf all\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerCount test.\"\"\"\n\n        address_families: list[BgpAddressFamily]\n        \"\"\"List of BGP address families.\"\"\"\n        BgpAfi: ClassVar[type[BgpAfi]] = BgpAfi\n\n        @field_validator(\"address_families\")\n        @classmethod\n        def validate_address_families(cls, address_families: list[BgpAddressFamily]) -&gt; list[BgpAddressFamily]:\n            \"\"\"Validate that 'num_peers' field is provided in each address family.\"\"\"\n            for af in address_families:\n                if af.num_peers is None:\n                    msg = f\"{af} 'num_peers' field missing in the input\"\n                    raise ValueError(msg)\n            return address_families\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerCount.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for address_family in self.inputs.address_families:\n            # Check if the VRF is configured\n            if (vrf_output := get_value(output, f\"vrfs.{address_family.vrf}\")) is None:\n                self.result.is_failure(f\"{address_family} - VRF not configured\")\n                continue\n\n            peers_data = vrf_output.get(\"peers\", {}).values()\n            if not address_family.check_peer_state:\n                # Count the number of peers without considering the state and negotiated AFI/SAFI check if the count matches the expected count\n                peer_count = sum(1 for peer_data in peers_data if address_family.eos_key in peer_data)\n            else:\n                # Count the number of established peers with negotiated AFI/SAFI\n                peer_count = sum(\n                    1\n                    for peer_data in peers_data\n                    if peer_data.get(\"peerState\") == \"Established\" and get_value(peer_data, f\"{address_family.eos_key}.afiSafiState\") == \"negotiated\"\n                )\n\n            # Check if the count matches the expected count\n            if address_family.num_peers != peer_count:\n                self.result.is_failure(f\"{address_family} - Peer count mismatch - Expected: {address_family.num_peers} Actual: {peer_count}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerCount-attributes","title":"Inputs","text":"Name Type Description Default <code>address_families</code> <code>list[BgpAddressFamily]</code>                      List of BGP address families.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerDropStats","title":"VerifyBGPPeerDropStats","text":"<p>Verifies BGP NLRI drop statistics for the provided BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Validates the BGP drop statistics:<ul> <li>If specific drop statistics are provided, checks only those counters.</li> <li>If no specific drop statistics are provided, checks all available counters.</li> <li>Confirms that all checked counters have a value of zero.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>All specified drop statistics counters (or all counters if none specified) are zero.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>Any checked drop statistics counter has a non-zero value.</li> <li>A specified drop statistics counter does not exist.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerDropStats:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n            drop_stats:\n              - inDropAsloop\n              - prefixEvpnDroppedUnsupportedRouteType\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerDropStats(AntaTest):\n    \"\"\"Verifies BGP NLRI drop statistics for the provided BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Validates the BGP drop statistics:\n        - If specific drop statistics are provided, checks only those counters.\n        - If no specific drop statistics are provided, checks all available counters.\n        - Confirms that all checked counters have a value of zero.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - All specified drop statistics counters (or all counters if none specified) are zero.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - Any checked drop statistics counter has a non-zero value.\n        - A specified drop statistics counter does not exist.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerDropStats:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n                drop_stats:\n                  - inDropAsloop\n                  - prefixEvpnDroppedUnsupportedRouteType\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerDropStats test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerDropStats.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            drop_stats_input = peer.drop_stats\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Verify BGP peers' drop stats\n            drop_stats_output = peer_data[\"dropStats\"]\n\n            # In case drop stats not provided, It will check all drop statistics\n            if not drop_stats_input:\n                drop_stats_input = drop_stats_output\n\n            # Verify BGP peer's drop stats\n            for drop_stat in drop_stats_input:\n                if (stat_value := drop_stats_output.get(drop_stat, 0)) != 0:\n                    self.result.is_failure(f\"{peer} - Non-zero NLRI drop statistics counter - {drop_stat}: {stat_value}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerDropStats-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerGroup","title":"VerifyBGPPeerGroup","text":"<p>Verifies BGP peer group of BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Confirms the peer group is correctly assigned to the specified BGP peer.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>The peer group is correctly assigned to the specified BGP peer.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>The peer group is not correctly assigned to the specified BGP peer.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerGroup:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n            peer_group: IPv4-UNDERLAY-PEERS\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerGroup(AntaTest):\n    \"\"\"Verifies BGP peer group of BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Confirms the peer group is correctly assigned to the specified BGP peer.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - The peer group is correctly assigned to the specified BGP peer.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - The peer group is not correctly assigned to the specified BGP peer.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerGroup:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n                peer_group: IPv4-UNDERLAY-PEERS\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerGroup test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n\n        @field_validator(\"bgp_peers\")\n        @classmethod\n        def validate_bgp_peers(cls, bgp_peers: list[BgpPeer]) -&gt; list[BgpPeer]:\n            \"\"\"Validate that 'peer_group' field is provided in each BGP peer.\"\"\"\n            for peer in bgp_peers:\n                if peer.peer_group is None:\n                    msg = f\"{peer} 'peer_group' field missing in the input\"\n                    raise ValueError(msg)\n            return bgp_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerGroup.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            if (actual_peer_group := peer_data.get(\"peerGroupName\", \"Not Found\")) != peer.peer_group:\n                self.result.is_failure(f\"{peer} - Incorrect peer group configured - Expected: {peer.peer_group} Actual: {actual_peer_group}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerGroup-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerMD5Auth","title":"VerifyBGPPeerMD5Auth","text":"<p>Verifies the MD5 authentication and state of IPv4 BGP peer(s) in a specified VRF.</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Validates that the BGP session is in <code>Established</code> state.</li> <li>Confirms that MD5 authentication is enabled for the peer.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>All peers are in <code>Established</code> state.</li> <li>MD5 authentication is enabled for all peers.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>A peer\u2019s session state is not <code>Established</code>.</li> <li>MD5 authentication is not enabled for a peer.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerMD5Auth:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n          - peer_address: 172.30.11.5\n            vrf: default\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerMD5Auth(AntaTest):\n    \"\"\"Verifies the MD5 authentication and state of IPv4 BGP peer(s) in a specified VRF.\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Validates that the BGP session is in `Established` state.\n      3. Confirms that MD5 authentication is enabled for the peer.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - All peers are in `Established` state.\n        - MD5 authentication is enabled for all peers.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - A peer's session state is not `Established`.\n        - MD5 authentication is not enabled for a peer.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerMD5Auth:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n              - peer_address: 172.30.11.5\n                vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerMD5Auth test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of IPv4 BGP peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerMD5Auth.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Check BGP peer state and MD5 authentication\n            state = peer_data.get(\"state\")\n            md5_auth_enabled = peer_data.get(\"md5AuthEnabled\")\n            if state != \"Established\":\n                self.result.is_failure(f\"{peer} - Incorrect session state - Expected: Established Actual: {state}\")\n            if not md5_auth_enabled:\n                self.result.is_failure(f\"{peer} - Session does not have MD5 authentication enabled\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerMD5Auth-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of IPv4 BGP peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerMPCaps","title":"VerifyBGPPeerMPCaps","text":"<p>Verifies the multiprotocol capabilities of BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>For each specified capability:<ul> <li>Validates that the capability is present in the peer configuration.</li> <li>Confirms that the capability is advertised, received, and enabled.</li> </ul> </li> <li>When strict mode is enabled (<code>strict: true</code>):<ul> <li>Verifies that only the specified capabilities are configured.</li> <li>Ensures an exact match between configured and expected capabilities.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>All specified capabilities are present and properly negotiated.</li> <li>In strict mode, only the specified capabilities are configured.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>A specified capability is not found.</li> <li>A capability is not properly negotiated (not advertised, received, or enabled).</li> <li>In strict mode, additional or missing capabilities are detected.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerMPCaps:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n            strict: False\n            capabilities:\n              - ipv4 labeled-Unicast\n              - ipv4MplsVpn\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerMPCaps(AntaTest):\n    \"\"\"Verifies the multiprotocol capabilities of BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. For each specified capability:\n        - Validates that the capability is present in the peer configuration.\n        - Confirms that the capability is advertised, received, and enabled.\n      3. When strict mode is enabled (`strict: true`):\n        - Verifies that only the specified capabilities are configured.\n        - Ensures an exact match between configured and expected capabilities.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - All specified capabilities are present and properly negotiated.\n        - In strict mode, only the specified capabilities are configured.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - A specified capability is not found.\n        - A capability is not properly negotiated (not advertised, received, or enabled).\n        - In strict mode, additional or missing capabilities are detected.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerMPCaps:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n                strict: False\n                capabilities:\n                  - ipv4 labeled-Unicast\n                  - ipv4MplsVpn\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerMPCaps test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n        @field_validator(\"bgp_peers\")\n        @classmethod\n        def validate_bgp_peers(cls, bgp_peers: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'capabilities' field is provided in each BGP peer.\"\"\"\n            for peer in bgp_peers:\n                if peer.capabilities is None:\n                    msg = f\"{peer} 'capabilities' field missing in the input\"\n                    raise ValueError(msg)\n            return bgp_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerMPCaps.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Fetching the multiprotocol capabilities\n            act_mp_caps = get_value(peer_data, \"neighborCapabilities.multiprotocolCaps\")\n\n            # If strict is True, check if only the specified capabilities are configured\n            if peer.strict and sorted(peer.capabilities) != sorted(act_mp_caps):\n                self.result.is_failure(f\"{peer} - Mismatch - Expected: {', '.join(peer.capabilities)} Actual: {', '.join(act_mp_caps)}\")\n                continue\n\n            # Check each capability\n            for capability in peer.capabilities:\n                # Check if the capability is found\n                if (capability_status := get_value(act_mp_caps, capability)) is None:\n                    self.result.is_failure(f\"{peer} - {capability} not found\")\n\n                # Check if the capability is advertised, received, and enabled\n                elif not _check_bgp_neighbor_capability(capability_status):\n                    self.result.is_failure(f\"{peer} - {capability} not negotiated - {format_data(capability_status)}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerMPCaps-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerRouteLimit","title":"VerifyBGPPeerRouteLimit","text":"<p>Verifies maximum routes and warning limit for BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Confirms the maximum routes and maximum routes warning limit, if provided, match the expected value.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>The maximum routes/maximum routes warning limit match the expected value for a peer.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>The maximum routes/maximum routes warning limit do not match the expected value for a peer.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerRouteLimit:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n            maximum_routes: 12000\n            warning_limit: 10000\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerRouteLimit(AntaTest):\n    \"\"\"Verifies maximum routes and warning limit for BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Confirms the maximum routes and maximum routes warning limit, if provided, match the expected value.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - The maximum routes/maximum routes warning limit match the expected value for a peer.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - The maximum routes/maximum routes warning limit do not match the expected value for a peer.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerRouteLimit:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n                maximum_routes: 12000\n                warning_limit: 10000\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerRouteLimit test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n        @field_validator(\"bgp_peers\")\n        @classmethod\n        def validate_bgp_peers(cls, bgp_peers: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'maximum_routes' field is provided in each BGP peer.\"\"\"\n            for peer in bgp_peers:\n                if peer.maximum_routes is None:\n                    msg = f\"{peer} 'maximum_routes' field missing in the input\"\n                    raise ValueError(msg)\n            return bgp_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerRouteLimit.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            maximum_routes = peer.maximum_routes\n            warning_limit = peer.warning_limit\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Verify maximum routes\n            if (actual_maximum_routes := peer_data.get(\"maxTotalRoutes\", \"Not Found\")) != maximum_routes:\n                self.result.is_failure(f\"{peer} - Maximum routes mismatch - Expected: {maximum_routes} Actual: {actual_maximum_routes}\")\n\n            # Verify warning limit if provided. By default, EOS does not have a warning limit and `totalRoutesWarnLimit` is not present in the output.\n            if warning_limit is not None and (actual_warning_limit := peer_data.get(\"totalRoutesWarnLimit\", 0)) != warning_limit:\n                self.result.is_failure(f\"{peer} - Maximum routes warning limit mismatch - Expected: {warning_limit} Actual: {actual_warning_limit}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerRouteLimit-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerRouteRefreshCap","title":"VerifyBGPPeerRouteRefreshCap","text":"<p>Verifies the route refresh capabilities of IPv4 BGP peer(s) in a specified VRF.</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Validates that the route refresh capability is present in the peer configuration.</li> <li>Confirms that the capability is advertised, received, and enabled.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>The route refresh capability is present in each peer configuration.</li> <li>The capability is properly negotiated (advertised, received, and enabled) for all peers.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>The route refresh capability is not present for a peer.</li> <li>The capability is not properly negotiated (not advertised, received, or enabled) for any peer.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerRouteRefreshCap:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerRouteRefreshCap(AntaTest):\n    \"\"\"Verifies the route refresh capabilities of IPv4 BGP peer(s) in a specified VRF.\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Validates that the route refresh capability is present in the peer configuration.\n      3. Confirms that the capability is advertised, received, and enabled.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - The route refresh capability is present in each peer configuration.\n        - The capability is properly negotiated (advertised, received, and enabled) for all peers.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - The route refresh capability is not present for a peer.\n        - The capability is not properly negotiated (not advertised, received, or enabled) for any peer.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerRouteRefreshCap:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerRouteRefreshCap test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerRouteRefreshCap.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Check if the route refresh capability is found\n            if (capablity_status := get_value(peer_data, \"neighborCapabilities.routeRefreshCap\")) is None:\n                self.result.is_failure(f\"{peer} - Route refresh capability not found\")\n                continue\n\n            # Check if the route refresh capability is advertised, received, and enabled\n            if not _check_bgp_neighbor_capability(capablity_status):\n                self.result.is_failure(f\"{peer} - Route refresh capability not negotiated - {format_data(capablity_status)}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerRouteRefreshCap-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerSession","title":"VerifyBGPPeerSession","text":"<p>Verifies the session state of BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Verifies that the BGP session is <code>Established</code> and, if specified, has remained established for at least the duration given by <code>minimum_established_time</code>.</li> <li>Ensures that both input and output TCP message queues are empty.   Can be disabled by setting <code>check_tcp_queues</code> global flag to <code>False</code>.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>All peers sessions state are <code>Established</code> and, if specified, has remained established for at least the duration given by <code>minimum_established_time</code>.</li> <li>All peers have empty TCP message queues if <code>check_tcp_queues</code> is <code>True</code> (default).</li> <li>All peers are established for specified minimum duration.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>A peer\u2019s session state is not <code>Established</code> or if specified, has not remained established for at least the duration specified by the <code>minimum_established_time</code>.</li> <li>A peer has non-empty TCP message queues (input or output) when <code>check_tcp_queues</code> is <code>True</code>.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerSession:\n        minimum_established_time: 10000\n        check_tcp_queues: false\n        bgp_peers:\n          - peer_address: 10.1.0.1\n            vrf: default\n          - peer_address: 10.1.0.2\n            vrf: default\n          - peer_address: 10.1.255.2\n            vrf: DEV\n          - peer_address: 10.1.255.4\n            vrf: DEV\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerSession(AntaTest):\n    \"\"\"Verifies the session state of BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Verifies that the BGP session is `Established` and, if specified, has remained established for at least the duration given by `minimum_established_time`.\n      3. Ensures that both input and output TCP message queues are empty.\n      Can be disabled by setting `check_tcp_queues` global flag to `False`.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - All peers sessions state are `Established` and, if specified, has remained established for at least the duration given by `minimum_established_time`.\n        - All peers have empty TCP message queues if `check_tcp_queues` is `True` (default).\n        - All peers are established for specified minimum duration.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - A peer's session state is not `Established` or if specified, has not remained established for at least the duration specified by\n        the `minimum_established_time`.\n        - A peer has non-empty TCP message queues (input or output) when `check_tcp_queues` is `True`.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerSession:\n            minimum_established_time: 10000\n            check_tcp_queues: false\n            bgp_peers:\n              - peer_address: 10.1.0.1\n                vrf: default\n              - peer_address: 10.1.0.2\n                vrf: default\n              - peer_address: 10.1.255.2\n                vrf: DEV\n              - peer_address: 10.1.255.4\n                vrf: DEV\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerSession test.\"\"\"\n\n        minimum_established_time: PositiveInt | None = None\n        \"\"\"Minimum established time (seconds) for all the BGP sessions.\"\"\"\n        check_tcp_queues: bool = True\n        \"\"\"Flag to check if the TCP session queues are empty for all BGP peers. Defaults to `True`.\"\"\"\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerSession.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Check if the BGP session is established\n            if peer_data[\"state\"] != \"Established\":\n                self.result.is_failure(f\"{peer} - Incorrect session state - Expected: Established Actual: {peer_data['state']}\")\n                continue\n\n            if self.inputs.minimum_established_time and (act_time := peer_data[\"establishedTime\"]) &lt; self.inputs.minimum_established_time:\n                self.result.is_failure(\n                    f\"{peer} - BGP session not established for the minimum required duration - Expected: {self.inputs.minimum_established_time}s Actual: {act_time}s\"\n                )\n\n            # Check the TCP session message queues\n            if self.inputs.check_tcp_queues:\n                inq = peer_data[\"peerTcpInfo\"][\"inputQueueLength\"]\n                outq = peer_data[\"peerTcpInfo\"][\"outputQueueLength\"]\n                if inq != 0 or outq != 0:\n                    self.result.is_failure(f\"{peer} - Session has non-empty message queues - InQ: {inq} OutQ: {outq}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerSession-attributes","title":"Inputs","text":"Name Type Description Default <code>minimum_established_time</code> <code>PositiveInt | None</code>                      Minimum established time (seconds) for all the BGP sessions.                    <code>None</code> <code>check_tcp_queues</code> <code>bool</code>                      Flag to check if the TCP session queues are empty for all BGP peers. Defaults to `True`.                    <code>True</code> <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerSessionRibd","title":"VerifyBGPPeerSessionRibd","text":"<p>Verifies the session state of BGP IPv4 peer(s).</p> <p>Compatible with EOS operating in <code>ribd</code> routing protocol model.</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Verifies that the BGP session is <code>Established</code> and, if specified, has remained established for at least the duration given by <code>minimum_established_time</code>.</li> <li>Ensures that both input and output TCP message queues are empty.   Can be disabled by setting <code>check_tcp_queues</code> global flag to <code>False</code>.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>All peers sessions state are <code>Established</code> and, if specified, has remained established for at least the duration given by <code>minimum_established_time</code>.</li> <li>All peers have empty TCP message queues if <code>check_tcp_queues</code> is <code>True</code> (default).</li> <li>All peers are established for specified minimum duration.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>A peer\u2019s session state is not <code>Established</code> or if specified, has not remained established for at least the duration specified by the <code>minimum_established_time</code>.</li> <li>A peer has non-empty TCP message queues (input or output) when <code>check_tcp_queues</code> is <code>True</code>.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerSessionRibd:\n        minimum_established_time: 10000\n        check_tcp_queues: false\n        bgp_peers:\n          - peer_address: 10.1.0.1\n            vrf: default\n          - peer_address: 10.1.0.2\n            vrf: default\n          - peer_address: 10.1.255.2\n            vrf: DEV\n          - peer_address: 10.1.255.4\n            vrf: DEV\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerSessionRibd(AntaTest):\n    \"\"\"Verifies the session state of BGP IPv4 peer(s).\n\n    Compatible with EOS operating in `ribd` routing protocol model.\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Verifies that the BGP session is `Established` and, if specified, has remained established for at least the duration given by `minimum_established_time`.\n      3. Ensures that both input and output TCP message queues are empty.\n      Can be disabled by setting `check_tcp_queues` global flag to `False`.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - All peers sessions state are `Established` and, if specified, has remained established for at least the duration given by `minimum_established_time`.\n        - All peers have empty TCP message queues if `check_tcp_queues` is `True` (default).\n        - All peers are established for specified minimum duration.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - A peer's session state is not `Established` or if specified, has not remained established for at least the duration specified by\n        the `minimum_established_time`.\n        - A peer has non-empty TCP message queues (input or output) when `check_tcp_queues` is `True`.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerSessionRibd:\n            minimum_established_time: 10000\n            check_tcp_queues: false\n            bgp_peers:\n              - peer_address: 10.1.0.1\n                vrf: default\n              - peer_address: 10.1.0.2\n                vrf: default\n              - peer_address: 10.1.255.2\n                vrf: DEV\n              - peer_address: 10.1.255.4\n                vrf: DEV\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip bgp neighbors vrf all\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerSessionRibd test.\"\"\"\n\n        minimum_established_time: PositiveInt | None = None\n        \"\"\"Minimum established time (seconds) for all the BGP sessions.\"\"\"\n        check_tcp_queues: bool = True\n        \"\"\"Flag to check if the TCP session queues are empty for all BGP peers. Defaults to `True`.\"\"\"\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerSessionRibd.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_address = str(peer.peer_address)\n            peers = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peers, \"peerAddress\", peer_address)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Check if the BGP session is established\n            if peer_data[\"state\"] != \"Established\":\n                self.result.is_failure(f\"{peer} - Incorrect session state - Expected: Established Actual: {peer_data['state']}\")\n                continue\n\n            if self.inputs.minimum_established_time and (act_time := peer_data[\"establishedTime\"]) &lt; self.inputs.minimum_established_time:\n                self.result.is_failure(\n                    f\"{peer} - BGP session not established for the minimum required duration - Expected: {self.inputs.minimum_established_time}s Actual: {act_time}s\"\n                )\n\n            # Check the TCP session message queues\n            if self.inputs.check_tcp_queues:\n                inq_stat = peer_data[\"peerTcpInfo\"][\"inputQueueLength\"]\n                outq_stat = peer_data[\"peerTcpInfo\"][\"outputQueueLength\"]\n                if inq_stat != 0 or outq_stat != 0:\n                    self.result.is_failure(f\"{peer} - Session has non-empty message queues - InQ: {inq_stat} OutQ: {outq_stat}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerSessionRibd-attributes","title":"Inputs","text":"Name Type Description Default <code>minimum_established_time</code> <code>PositiveInt | None</code>                      Minimum established time (seconds) for all the BGP sessions.                    <code>None</code> <code>check_tcp_queues</code> <code>bool</code>                      Flag to check if the TCP session queues are empty for all BGP peers. Defaults to `True`.                    <code>True</code> <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerTtlMultiHops","title":"VerifyBGPPeerTtlMultiHops","text":"<p>Verifies BGP TTL and max-ttl-hops count for BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified BGP peer:</p> <ol> <li>Verifies the specified BGP peer exists in the BGP configuration.</li> <li>Verifies the TTL and max-ttl-hops attribute matches the expected value.</li> </ol> Expected Results <ul> <li>Success: The test will pass if all specified peers exist with TTL and max-ttl-hops attributes matching the expected values.</li> <li>Failure: If any of the following occur:<ul> <li>A specified BGP peer is not found.</li> <li>A TTL or max-ttl-hops attribute doesn\u2019t match the expected value for any peer.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerTtlMultiHops:\n        bgp_peers:\n            - peer_address: 172.30.11.1\n              vrf: default\n              ttl: 3\n              max_ttl_hops: 3\n            - peer_address: 172.30.11.2\n              vrf: test\n              ttl: 30\n              max_ttl_hops: 30\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerTtlMultiHops(AntaTest):\n    \"\"\"Verifies BGP TTL and max-ttl-hops count for BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified BGP peer:\n\n      1. Verifies the specified BGP peer exists in the BGP configuration.\n      2. Verifies the TTL and max-ttl-hops attribute matches the expected value.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all specified peers exist with TTL and max-ttl-hops attributes matching the expected values.\n    * Failure: If any of the following occur:\n        - A specified BGP peer is not found.\n        - A TTL or max-ttl-hops attribute doesn't match the expected value for any peer.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerTtlMultiHops:\n            bgp_peers:\n                - peer_address: 172.30.11.1\n                  vrf: default\n                  ttl: 3\n                  max_ttl_hops: 3\n                - peer_address: 172.30.11.2\n                  vrf: test\n                  ttl: 30\n                  max_ttl_hops: 30\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip bgp neighbors vrf all\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerTtlMultiHops test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of IPv4 peer(s).\"\"\"\n\n        @field_validator(\"bgp_peers\")\n        @classmethod\n        def validate_bgp_peers(cls, bgp_peers: list[BgpPeer]) -&gt; list[BgpPeer]:\n            \"\"\"Validate that 'ttl' and 'max_ttl_hops' field is provided in each BGP peer.\"\"\"\n            for peer in bgp_peers:\n                if peer.ttl is None:\n                    msg = f\"{peer} 'ttl' field missing in the input\"\n                    raise ValueError(msg)\n                if peer.max_ttl_hops is None:\n                    msg = f\"{peer} 'max_ttl_hops' field missing in the input\"\n                    raise ValueError(msg)\n\n            return bgp_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerTtlMultiHops.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(command_output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_details := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Verify if the TTL duration matches the expected value.\n            if peer_details.get(\"ttl\") != peer.ttl:\n                self.result.is_failure(f\"{peer} - TTL mismatch - Expected: {peer.ttl} Actual: {peer_details.get('ttl')}\")\n\n            # Verify if the max-ttl-hops time matches the expected value.\n            if peer_details.get(\"maxTtlHops\") != peer.max_ttl_hops:\n                self.result.is_failure(f\"{peer} - Max TTL Hops mismatch - Expected: {peer.max_ttl_hops} Actual: {peer_details.get('maxTtlHops')}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerTtlMultiHops-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of IPv4 peer(s).                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerUpdateErrors","title":"VerifyBGPPeerUpdateErrors","text":"<p>Verifies BGP update error counters for the provided BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Validates the BGP update error counters:<ul> <li>If specific update error counters are provided, checks only those counters.</li> <li>If no update error counters are provided, checks all available counters.</li> <li>Confirms that all checked counters have a value of zero.</li> </ul> </li> </ol> <p>Note: For \u201cdisabledAfiSafi\u201d error counter field, checking that it\u2019s not \u201cNone\u201d versus 0.</p> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>All specified update error counters (or all counters if none specified) are zero.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>Any checked update error counters has a non-zero value.</li> <li>A specified update error counters does not exist.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeerUpdateErrors:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n            update_errors:\n              - inUpdErrWithdraw\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeerUpdateErrors(AntaTest):\n    \"\"\"Verifies BGP update error counters for the provided BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Validates the BGP update error counters:\n        - If specific update error counters are provided, checks only those counters.\n        - If no update error counters are provided, checks all available counters.\n        - Confirms that all checked counters have a value of zero.\n\n    Note: For \"disabledAfiSafi\" error counter field, checking that it's not \"None\" versus 0.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - All specified update error counters (or all counters if none specified) are zero.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - Any checked update error counters has a non-zero value.\n        - A specified update error counters does not exist.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeerUpdateErrors:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n                update_errors:\n                  - inUpdErrWithdraw\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeerUpdateErrors test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeerUpdateErrors.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            update_errors_input = peer.update_errors\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Getting the BGP peer's error counters output.\n            error_counters_output = peer_data.get(\"peerInUpdateErrors\", {})\n\n            # In case update error counters not provided, It will check all the update error counters.\n            if not update_errors_input:\n                update_errors_input = error_counters_output\n\n            # Verify BGP peer's update error counters\n            for error_counter in update_errors_input:\n                if (stat_value := error_counters_output.get(error_counter, \"Not Found\")) != 0 and stat_value != \"None\":\n                    self.result.is_failure(f\"{peer} - Non-zero update error counter - {error_counter}: {stat_value}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeerUpdateErrors-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeersHealth","title":"VerifyBGPPeersHealth","text":"<p>Verifies the health of BGP peers for given address families.</p> <p>This test performs the following checks for each specified address family:</p> <ol> <li>Validates that the VRF is configured.</li> <li>Checks if there are any peers for the given AFI/SAFI.</li> <li>For each relevant peer:<ul> <li>Verifies that the BGP session is <code>Established</code> and, if specified, has remained established for at least the duration given by <code>minimum_established_time</code>.</li> <li>Confirms that the AFI/SAFI state is <code>negotiated</code>.</li> <li>Checks that both input and output TCP message queues are empty.   Can be disabled by setting <code>check_tcp_queues</code> to <code>False</code>.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If all checks pass for all specified address families and their peers.</li> <li>Failure: If any of the following occur:<ul> <li>The specified VRF is not configured.</li> <li>No peers are found for a given AFI/SAFI.</li> <li>A peer\u2019s session state is not <code>Established</code> or if specified, has not remained established for at least the duration specified by the <code>minimum_established_time</code>.</li> <li>The AFI/SAFI state is not \u2018negotiated\u2019 for any peer.</li> <li>Any TCP message queue (input or output) is not empty when <code>check_tcp_queues</code> is <code>True</code> (default).</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeersHealth:\n        minimum_established_time: 10000\n        address_families:\n          - afi: \"evpn\"\n          - afi: \"ipv4\"\n            safi: \"unicast\"\n            vrf: \"default\"\n          - afi: \"ipv6\"\n            safi: \"unicast\"\n            vrf: \"DEV\"\n            check_tcp_queues: false\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeersHealth(AntaTest):\n    \"\"\"Verifies the health of BGP peers for given address families.\n\n    This test performs the following checks for each specified address family:\n\n      1. Validates that the VRF is configured.\n      2. Checks if there are any peers for the given AFI/SAFI.\n      3. For each relevant peer:\n        - Verifies that the BGP session is `Established` and, if specified, has remained established for at least the duration given by `minimum_established_time`.\n        - Confirms that the AFI/SAFI state is `negotiated`.\n        - Checks that both input and output TCP message queues are empty.\n          Can be disabled by setting `check_tcp_queues` to `False`.\n\n    Expected Results\n    ----------------\n    * Success: If all checks pass for all specified address families and their peers.\n    * Failure: If any of the following occur:\n        - The specified VRF is not configured.\n        - No peers are found for a given AFI/SAFI.\n        - A peer's session state is not `Established` or if specified, has not remained established for at least the duration specified by\n        the `minimum_established_time`.\n        - The AFI/SAFI state is not 'negotiated' for any peer.\n        - Any TCP message queue (input or output) is not empty when `check_tcp_queues` is `True` (default).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeersHealth:\n            minimum_established_time: 10000\n            address_families:\n              - afi: \"evpn\"\n              - afi: \"ipv4\"\n                safi: \"unicast\"\n                vrf: \"default\"\n              - afi: \"ipv6\"\n                safi: \"unicast\"\n                vrf: \"DEV\"\n                check_tcp_queues: false\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeersHealth test.\"\"\"\n\n        minimum_established_time: PositiveInt | None = None\n        \"\"\"Minimum established time (seconds) for all the BGP sessions.\"\"\"\n        address_families: list[BgpAddressFamily]\n        \"\"\"List of BGP address families.\"\"\"\n        BgpAfi: ClassVar[type[BgpAfi]] = BgpAfi\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeersHealth.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for address_family in self.inputs.address_families:\n            # Check if the VRF is configured\n            if (vrf_output := get_value(output, f\"vrfs.{address_family.vrf}\")) is None:\n                self.result.is_failure(f\"{address_family} - VRF not configured\")\n                continue\n\n            # Check if any peers are found for this AFI/SAFI\n            relevant_peers = [\n                peer for peer in vrf_output.get(\"peerList\", []) if get_value(peer, f\"neighborCapabilities.multiprotocolCaps.{address_family.eos_key}\") is not None\n            ]\n\n            if not relevant_peers:\n                self.result.is_failure(f\"{address_family} - No peers found\")\n                continue\n\n            for peer in relevant_peers:\n                # Check if the BGP session is established\n                if peer[\"state\"] != \"Established\":\n                    self.result.is_failure(f\"{address_family} Peer: {peer['peerAddress']} - Incorrect session state - Expected: Established Actual: {peer['state']}\")\n                    continue\n\n                if self.inputs.minimum_established_time and (act_time := peer[\"establishedTime\"]) &lt; self.inputs.minimum_established_time:\n                    msg = f\"BGP session not established for the minimum required duration - Expected: {self.inputs.minimum_established_time}s Actual: {act_time}s\"\n                    self.result.is_failure(f\"{address_family} Peer: {peer['peerAddress']} - {msg}\")\n\n                # Check if the AFI/SAFI state is negotiated\n                capability_status = get_value(peer, f\"neighborCapabilities.multiprotocolCaps.{address_family.eos_key}\")\n                if not _check_bgp_neighbor_capability(capability_status):\n                    self.result.is_failure(f\"{address_family} Peer: {peer['peerAddress']} - AFI/SAFI state is not negotiated - {format_data(capability_status)}\")\n\n                # Check the TCP session message queues\n                if address_family.check_tcp_queues:\n                    inq = peer[\"peerTcpInfo\"][\"inputQueueLength\"]\n                    outq = peer[\"peerTcpInfo\"][\"outputQueueLength\"]\n                    if inq != 0 or outq != 0:\n                        self.result.is_failure(f\"{address_family} Peer: {peer['peerAddress']} - Session has non-empty message queues - InQ: {inq} OutQ: {outq}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeersHealth-attributes","title":"Inputs","text":"Name Type Description Default <code>minimum_established_time</code> <code>PositiveInt | None</code>                      Minimum established time (seconds) for all the BGP sessions.                    <code>None</code> <code>address_families</code> <code>list[BgpAddressFamily]</code>                      List of BGP address families.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeersHealthRibd","title":"VerifyBGPPeersHealthRibd","text":"<p>Verifies the health of all the BGP IPv4 peer(s).</p> <p>Compatible with EOS operating in <code>ribd</code> routing protocol model.</p> <p>This test performs the following checks for all BGP IPv4 peers:</p> <ol> <li>Verifies that the BGP session is in the <code>Established</code> state.</li> <li>Checks that both input and output TCP message queues are empty.   Can be disabled by setting <code>check_tcp_queues</code> global flag to <code>False</code>.</li> </ol> Expected Results <ul> <li>Success: If all checks pass for all BGP IPv4 peers.</li> <li>Failure: If any of the following occur:<ul> <li>Any BGP session is not in the <code>Established</code> state.</li> <li>Any TCP message queue (input or output) is not empty when <code>check_tcp_queues</code> is <code>True</code> (default).</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPPeersHealthRibd:\n        check_tcp_queues: True\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPPeersHealthRibd(AntaTest):\n    \"\"\"Verifies the health of all the BGP IPv4 peer(s).\n\n    Compatible with EOS operating in `ribd` routing protocol model.\n\n    This test performs the following checks for all BGP IPv4 peers:\n\n      1. Verifies that the BGP session is in the `Established` state.\n      2. Checks that both input and output TCP message queues are empty.\n      Can be disabled by setting `check_tcp_queues` global flag to `False`.\n\n    Expected Results\n    ----------------\n    * Success: If all checks pass for all BGP IPv4 peers.\n    * Failure: If any of the following occur:\n        - Any BGP session is not in the `Established` state.\n        - Any TCP message queue (input or output) is not empty when `check_tcp_queues` is `True` (default).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPPeersHealthRibd:\n            check_tcp_queues: True\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip bgp neighbors vrf all\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPPeersHealthRibd test.\"\"\"\n\n        check_tcp_queues: bool = True\n        \"\"\"Flag to check if the TCP session queues are empty for all BGP peers. Defaults to `True`.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPPeersHealthRibd.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for vrf, vrf_data in output[\"vrfs\"].items():\n            peer_list = vrf_data.get(\"peerList\", [])\n\n            for peer in peer_list:\n                # Check if the BGP session is established\n                if peer[\"state\"] != \"Established\":\n                    self.result.is_failure(f\"Peer: {peer['peerAddress']} VRF: {vrf} - Incorrect session state - Expected: Established Actual: {peer['state']}\")\n                    continue\n\n                # Check the TCP session message queues\n                inq = peer[\"peerTcpInfo\"][\"inputQueueLength\"]\n                outq = peer[\"peerTcpInfo\"][\"outputQueueLength\"]\n                if self.inputs.check_tcp_queues and (inq != 0 or outq != 0):\n                    self.result.is_failure(f\"Peer: {peer['peerAddress']} VRF: {vrf} - Session has non-empty message queues - InQ: {inq} OutQ: {outq}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPPeersHealthRibd-attributes","title":"Inputs","text":"Name Type Description Default <code>check_tcp_queues</code> <code>bool</code>                      Flag to check if the TCP session queues are empty for all BGP peers. Defaults to `True`.                    <code>True</code>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPRedistribution","title":"VerifyBGPRedistribution","text":"<p>Verifies BGP redistribution.</p> <p>This test performs the following checks for each specified VRF in the BGP instance:</p> <ol> <li>Ensures that the expected address-family is configured on the device.</li> <li>Confirms that the redistributed route protocol, include leaked and route map match the expected values.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>The expected address-family is configured on the device.</li> <li>The redistributed route protocol, include leaked and route map align with the expected values for the route.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>The expected address-family is not configured on device.</li> <li>The redistributed route protocol, include leaked or route map does not match the expected values.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPRedistribution:\n        vrfs:\n          - vrf: default\n            address_families:\n              - afi_safi: ipv4multicast\n                redistributed_routes:\n                  - proto: Connected\n                    include_leaked: True\n                    route_map: RM-CONN-2-BGP\n                  - proto: IS-IS\n                    include_leaked: True\n                    route_map: RM-CONN-2-BGP\n              - afi_safi: IPv6 Unicast\n                redistributed_routes:\n                  - proto: User # Converted to EOS SDK\n                    route_map: RM-CONN-2-BGP\n                  - proto: Static\n                    include_leaked: True\n                    route_map: RM-CONN-2-BGP\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPRedistribution(AntaTest):\n    \"\"\"Verifies BGP redistribution.\n\n    This test performs the following checks for each specified VRF in the BGP instance:\n\n      1. Ensures that the expected address-family is configured on the device.\n      2. Confirms that the redistributed route protocol, include leaked and route map match the expected values.\n\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - The expected address-family is configured on the device.\n        - The redistributed route protocol, include leaked and route map align with the expected values for the route.\n    * Failure: If any of the following occur:\n        - The expected address-family is not configured on device.\n        - The redistributed route protocol, include leaked or route map does not match the expected values.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPRedistribution:\n            vrfs:\n              - vrf: default\n                address_families:\n                  - afi_safi: ipv4multicast\n                    redistributed_routes:\n                      - proto: Connected\n                        include_leaked: True\n                        route_map: RM-CONN-2-BGP\n                      - proto: IS-IS\n                        include_leaked: True\n                        route_map: RM-CONN-2-BGP\n                  - afi_safi: IPv6 Unicast\n                    redistributed_routes:\n                      - proto: User # Converted to EOS SDK\n                        route_map: RM-CONN-2-BGP\n                      - proto: Static\n                        include_leaked: True\n                        route_map: RM-CONN-2-BGP\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp instance vrf all\", revision=4)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPRedistribution test.\"\"\"\n\n        vrfs: list[BgpVrf]\n        \"\"\"List of VRFs in the BGP instance.\"\"\"\n\n    def _validate_redistribute_route(self, vrf_data: str, addr_family: str, afi_safi_configs: list[dict[str, Any]], route_info: dict[str, Any]) -&gt; list[Any]:\n        \"\"\"Validate the redstributed route details for a given address family.\"\"\"\n        failure_msg = []\n        # If the redistributed route protocol does not match the expected value, test fails.\n        if not (actual_route := get_item(afi_safi_configs.get(\"redistributedRoutes\"), \"proto\", route_info.proto)):\n            failure_msg.append(f\"{vrf_data}, {addr_family}, Proto: {route_info.proto} - Not configured\")\n            return failure_msg\n\n        # If includes leaked field applicable, and it does not matches the expected value, test fails.\n        if (act_include_leaked := actual_route.get(\"includeLeaked\", False)) != route_info.include_leaked:\n            failure_msg.append(f\"{vrf_data}, {addr_family}, {route_info} - Include leaked mismatch - Actual: {act_include_leaked}\")\n\n        # If route map is required and it is not matching the expected value, test fails.\n        if all([route_info.route_map, (act_route_map := actual_route.get(\"routeMap\", \"Not Found\")) != route_info.route_map]):\n            failure_msg.append(f\"{vrf_data}, {addr_family}, {route_info} - Route map mismatch - Actual: {act_route_map}\")\n        return failure_msg\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPRedistribution.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        for vrf_data in self.inputs.vrfs:\n            # If the specified VRF details are not found, test fails.\n            if not (instance_details := get_value(command_output, f\"vrfs.{vrf_data.vrf}\")):\n                self.result.is_failure(f\"{vrf_data} - Not configured\")\n                continue\n            for address_family in vrf_data.address_families:\n                # If the AFI-SAFI configuration details are not found, test fails.\n                if not (afi_safi_configs := get_value(instance_details, f\"afiSafiConfig.{address_family.afi_safi}\")):\n                    self.result.is_failure(f\"{vrf_data}, {address_family} - Not redistributed\")\n                    continue\n\n                for route_info in address_family.redistributed_routes:\n                    failure_msg = self._validate_redistribute_route(str(vrf_data), str(address_family), afi_safi_configs, route_info)\n                    for msg in failure_msg:\n                        self.result.is_failure(msg)\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPRedistribution-attributes","title":"Inputs","text":"Name Type Description Default <code>vrfs</code> <code>list[BgpVrf]</code>                      List of VRFs in the BGP instance.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPRouteECMP","title":"VerifyBGPRouteECMP","text":"<p>Verifies BGP IPv4 route ECMP paths.</p> <p>This test performs the following checks for each specified BGP route entry:</p> <ol> <li>Route exists in BGP table.</li> <li>First path is a valid and active ECMP head.</li> <li>Correct number of valid ECMP contributors follow the head path.</li> <li>Route is installed in RIB with same amount of next-hops.</li> </ol> Expected Results <ul> <li>Success: The test will pass if all specified routes exist in both BGP and RIB tables with correct amount of ECMP paths.</li> <li>Failure: The test will fail if:<ul> <li>A specified route is not found in BGP table.</li> <li>A valid and active ECMP head is not found.</li> <li>ECMP contributors count does not match the expected value.</li> <li>Route is not installed in RIB table.</li> <li>BGP and RIB nexthops count do not match.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPRouteECMP:\n        route_entries:\n            - prefix: 10.100.0.128/31\n              vrf: default\n              ecmp_count: 2\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPRouteECMP(AntaTest):\n    \"\"\"Verifies BGP IPv4 route ECMP paths.\n\n    This test performs the following checks for each specified BGP route entry:\n\n      1. Route exists in BGP table.\n      2. First path is a valid and active ECMP head.\n      3. Correct number of valid ECMP contributors follow the head path.\n      4. Route is installed in RIB with same amount of next-hops.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all specified routes exist in both BGP and RIB tables with correct amount of ECMP paths.\n    * Failure: The test will fail if:\n        - A specified route is not found in BGP table.\n        - A valid and active ECMP head is not found.\n        - ECMP contributors count does not match the expected value.\n        - Route is not installed in RIB table.\n        - BGP and RIB nexthops count do not match.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPRouteECMP:\n            route_entries:\n                - prefix: 10.100.0.128/31\n                  vrf: default\n                  ecmp_count: 2\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaCommand(command=\"show ip bgp vrf all\", revision=3),\n        AntaCommand(command=\"show ip route vrf all bgp\", revision=4),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPRouteECMP test.\"\"\"\n\n        route_entries: list[BgpRoute]\n        \"\"\"List of BGP IPv4 route(s).\"\"\"\n\n        @field_validator(\"route_entries\")\n        @classmethod\n        def validate_route_entries(cls, route_entries: list[BgpRoute]) -&gt; list[BgpRoute]:\n            \"\"\"Validate that 'ecmp_count' field is provided in each BGP route.\"\"\"\n            for route in route_entries:\n                if route.ecmp_count is None:\n                    msg = f\"{route} 'ecmp_count' field missing in the input\"\n                    raise ValueError(msg)\n            return route_entries\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPRouteECMP.\"\"\"\n        self.result.is_success()\n\n        for route in self.inputs.route_entries:\n            # Verify if the prefix exists in BGP table.\n            if not (bgp_route_entry := get_value(self.instance_commands[0].json_output, f\"vrfs..{route.vrf}..bgpRouteEntries..{route.prefix}\", separator=\"..\")):\n                self.result.is_failure(f\"{route} - Prefix not found in BGP table\")\n                continue\n\n            route_paths = iter(bgp_route_entry[\"bgpRoutePaths\"])\n            head = next(route_paths, None)\n            # Verify if the active ECMP head exists.\n            if head is None or not all(head[\"routeType\"][key] for key in [\"valid\", \"active\", \"ecmpHead\"]):\n                self.result.is_failure(f\"{route} - Valid and active ECMP head not found\")\n                continue\n\n            bgp_nexthops = {head[\"nextHop\"]}\n            bgp_nexthops.update([path[\"nextHop\"] for path in route_paths if all(path[\"routeType\"][key] for key in [\"valid\", \"ecmp\", \"ecmpContributor\"])])\n\n            # Verify ECMP count is correct.\n            if len(bgp_nexthops) != route.ecmp_count:\n                self.result.is_failure(f\"{route} - ECMP count mismatch - Expected: {route.ecmp_count} Actual: {len(bgp_nexthops)}\")\n                continue\n\n            # Verify if the prefix exists in routing table.\n            if not (route_entry := get_value(self.instance_commands[1].json_output, f\"vrfs..{route.vrf}..routes..{route.prefix}\", separator=\"..\")):\n                self.result.is_failure(f\"{route} - Prefix not found in routing table\")\n                continue\n\n            # Verify BGP and RIB nexthops are same.\n            if len(bgp_nexthops) != len(route_entry[\"vias\"]):\n                self.result.is_failure(f\"{route} - Nexthops count mismatch - BGP: {len(bgp_nexthops)} RIB: {len(route_entry['vias'])}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPRouteECMP-attributes","title":"Inputs","text":"Name Type Description Default <code>route_entries</code> <code>list[BgpRoute]</code>                      List of BGP IPv4 route(s).                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPRoutePaths","title":"VerifyBGPRoutePaths","text":"<p>Verifies BGP IPv4 route paths.</p> <p>This test performs the following checks for each specified BGP route entry:</p> <ol> <li>Verifies the specified BGP route exists in the routing table.</li> <li>For each expected paths:<ul> <li>Verifies a path with matching next-hop exists.</li> <li>Verifies the path\u2019s origin attribute matches the expected value.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: The test will pass if all specified routes exist with paths matching the expected next-hops and origin attributes.</li> <li>Failure: The test will fail if:<ul> <li>A specified BGP route is not found.</li> <li>A path with specified next-hop is not found.</li> <li>A path\u2019s origin attribute doesn\u2019t match the expected value.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPRoutePaths:\n        route_entries:\n            - prefix: 10.100.0.128/31\n              vrf: default\n              paths:\n                - nexthop: 10.100.0.10\n                  origin: Igp\n                - nexthop: 10.100.4.5\n                  origin: Incomplete\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPRoutePaths(AntaTest):\n    \"\"\"Verifies BGP IPv4 route paths.\n\n    This test performs the following checks for each specified BGP route entry:\n\n      1. Verifies the specified BGP route exists in the routing table.\n      2. For each expected paths:\n          - Verifies a path with matching next-hop exists.\n          - Verifies the path's origin attribute matches the expected value.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all specified routes exist with paths matching the expected next-hops and origin attributes.\n    * Failure: The test will fail if:\n        - A specified BGP route is not found.\n        - A path with specified next-hop is not found.\n        - A path's origin attribute doesn't match the expected value.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPRoutePaths:\n            route_entries:\n                - prefix: 10.100.0.128/31\n                  vrf: default\n                  paths:\n                    - nexthop: 10.100.0.10\n                      origin: Igp\n                    - nexthop: 10.100.4.5\n                      origin: Incomplete\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip bgp vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPRoutePaths test.\"\"\"\n\n        route_entries: list[BgpRoute]\n        \"\"\"List of BGP IPv4 route(s).\"\"\"\n\n        @field_validator(\"route_entries\")\n        @classmethod\n        def validate_route_entries(cls, route_entries: list[BgpRoute]) -&gt; list[BgpRoute]:\n            \"\"\"Validate that 'paths' field is provided in each BGP route.\"\"\"\n            for route in route_entries:\n                if route.paths is None:\n                    msg = f\"{route} 'paths' field missing in the input\"\n                    raise ValueError(msg)\n            return route_entries\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPRoutePaths.\"\"\"\n        self.result.is_success()\n\n        for route in self.inputs.route_entries:\n            # Verify if the prefix exists in BGP table\n            if not (bgp_routes := get_value(self.instance_commands[0].json_output, f\"vrfs..{route.vrf}..bgpRouteEntries..{route.prefix}\", separator=\"..\")):\n                self.result.is_failure(f\"{route} - Prefix not found\")\n                continue\n\n            # Iterating over each path.\n            for path in route.paths:\n                nexthop = str(path.nexthop)\n                origin = path.origin\n                if not (route_path := get_item(bgp_routes[\"bgpRoutePaths\"], \"nextHop\", nexthop)):\n                    self.result.is_failure(f\"{route} {path} - Path not found\")\n                    continue\n\n                if (actual_origin := get_value(route_path, \"routeType.origin\")) != origin:\n                    self.result.is_failure(f\"{route} {path} - Origin mismatch - Actual: {actual_origin}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPRoutePaths-attributes","title":"Inputs","text":"Name Type Description Default <code>route_entries</code> <code>list[BgpRoute]</code>                      List of BGP IPv4 route(s).                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPSpecificPeers","title":"VerifyBGPSpecificPeers","text":"<p>Verifies the health of specific BGP peer(s) for given address families.</p> <p>This test performs the following checks for each specified address family and peer:</p> <ol> <li>Confirms that the specified VRF is configured.</li> <li>For each specified peer:<ul> <li>Verifies that the peer is found in the BGP configuration.</li> <li>Verifies that the BGP session is <code>Established</code> and, if specified, has remained established for at least the duration given by <code>minimum_established_time</code>.</li> <li>Confirms that the AFI/SAFI state is <code>negotiated</code>.</li> <li>Ensures that both input and output TCP message queues are empty.   Can be disabled by setting <code>check_tcp_queues</code> to <code>False</code>.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If all checks pass for all specified peers in all address families.</li> <li>Failure: If any of the following occur:<ul> <li>The specified VRF is not configured.</li> <li>A specified peer is not found in the BGP configuration.</li> <li>A peer\u2019s session state is not <code>Established</code> or if specified, has not remained established for at least the duration specified by the <code>minimum_established_time</code>.</li> <li>The AFI/SAFI state is not <code>negotiated</code> for a peer.</li> <li>Any TCP message queue (input or output) is not empty for a peer when <code>check_tcp_queues</code> is <code>True</code> (default).</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPSpecificPeers:\n        minimum_established_time: 10000\n        address_families:\n          - afi: \"evpn\"\n            peers:\n              - 10.1.0.1\n              - 10.1.0.2\n          - afi: \"ipv4\"\n            safi: \"unicast\"\n            peers:\n              - 10.1.254.1\n              - 10.1.255.0\n              - 10.1.255.2\n              - 10.1.255.4\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPSpecificPeers(AntaTest):\n    \"\"\"Verifies the health of specific BGP peer(s) for given address families.\n\n    This test performs the following checks for each specified address family and peer:\n\n      1. Confirms that the specified VRF is configured.\n      2. For each specified peer:\n        - Verifies that the peer is found in the BGP configuration.\n        - Verifies that the BGP session is `Established` and, if specified, has remained established for at least the duration given by `minimum_established_time`.\n        - Confirms that the AFI/SAFI state is `negotiated`.\n        - Ensures that both input and output TCP message queues are empty.\n          Can be disabled by setting `check_tcp_queues` to `False`.\n\n    Expected Results\n    ----------------\n    * Success: If all checks pass for all specified peers in all address families.\n    * Failure: If any of the following occur:\n        - The specified VRF is not configured.\n        - A specified peer is not found in the BGP configuration.\n        - A peer's session state is not `Established` or if specified, has not remained established for at least the duration specified by\n        the `minimum_established_time`.\n        - The AFI/SAFI state is not `negotiated` for a peer.\n        - Any TCP message queue (input or output) is not empty for a peer when `check_tcp_queues` is `True` (default).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPSpecificPeers:\n            minimum_established_time: 10000\n            address_families:\n              - afi: \"evpn\"\n                peers:\n                  - 10.1.0.1\n                  - 10.1.0.2\n              - afi: \"ipv4\"\n                safi: \"unicast\"\n                peers:\n                  - 10.1.254.1\n                  - 10.1.255.0\n                  - 10.1.255.2\n                  - 10.1.255.4\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPSpecificPeers test.\"\"\"\n\n        minimum_established_time: PositiveInt | None = None\n        \"\"\"Minimum established time (seconds) for all the BGP sessions.\"\"\"\n        address_families: list[BgpAddressFamily]\n        \"\"\"List of BGP address families.\"\"\"\n        BgpAfi: ClassVar[type[BgpAfi]] = BgpAfi\n\n        @field_validator(\"address_families\")\n        @classmethod\n        def validate_address_families(cls, address_families: list[BgpAddressFamily]) -&gt; list[BgpAddressFamily]:\n            \"\"\"Validate that 'peers' field is provided in each address family.\"\"\"\n            for af in address_families:\n                if af.peers is None:\n                    msg = f\"{af} 'peers' field missing in the input\"\n                    raise ValueError(msg)\n            return address_families\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPSpecificPeers.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for address_family in self.inputs.address_families:\n            # Check if the VRF is configured\n            if (vrf_output := get_value(output, f\"vrfs.{address_family.vrf}\")) is None:\n                self.result.is_failure(f\"{address_family} - VRF not configured\")\n                continue\n\n            for peer in address_family.peers:\n                peer_ip = str(peer)\n\n                # Check if the peer is found\n                if (peer_data := get_item(vrf_output[\"peerList\"], \"peerAddress\", peer_ip)) is None:\n                    self.result.is_failure(f\"{address_family} Peer: {peer_ip} - Not configured\")\n                    continue\n\n                # Check if the BGP session is established\n                if peer_data[\"state\"] != \"Established\":\n                    self.result.is_failure(f\"{address_family} Peer: {peer_ip} - Incorrect session state - Expected: Established Actual: {peer_data['state']}\")\n                    continue\n\n                if self.inputs.minimum_established_time and (act_time := peer_data[\"establishedTime\"]) &lt; self.inputs.minimum_established_time:\n                    msg = f\"BGP session not established for the minimum required duration - Expected: {self.inputs.minimum_established_time}s Actual: {act_time}s\"\n                    self.result.is_failure(f\"{address_family} Peer: {peer_ip} - {msg}\")\n\n                # Check if the AFI/SAFI state is negotiated\n                capability_status = get_value(peer_data, f\"neighborCapabilities.multiprotocolCaps.{address_family.eos_key}\")\n                if not capability_status:\n                    self.result.is_failure(f\"{address_family} Peer: {peer_ip} - AFI/SAFI state is not negotiated\")\n\n                if capability_status and not _check_bgp_neighbor_capability(capability_status):\n                    self.result.is_failure(f\"{address_family} Peer: {peer_ip} - AFI/SAFI state is not negotiated - {format_data(capability_status)}\")\n\n                # Check the TCP session message queues\n                inq = peer_data[\"peerTcpInfo\"][\"inputQueueLength\"]\n                outq = peer_data[\"peerTcpInfo\"][\"outputQueueLength\"]\n                if address_family.check_tcp_queues and (inq != 0 or outq != 0):\n                    self.result.is_failure(f\"{address_family} Peer: {peer_ip} - Session has non-empty message queues - InQ: {inq} OutQ: {outq}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPSpecificPeers-attributes","title":"Inputs","text":"Name Type Description Default <code>minimum_established_time</code> <code>PositiveInt | None</code>                      Minimum established time (seconds) for all the BGP sessions.                    <code>None</code> <code>address_families</code> <code>list[BgpAddressFamily]</code>                      List of BGP address families.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPTimers","title":"VerifyBGPTimers","text":"<p>Verifies the timers of BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Confirms the BGP session hold time/keepalive timers match the expected value.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>The hold time/keepalive timers match the expected value for each peer.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>The hold time/keepalive timers do not match the expected value for a peer.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBGPTimers:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n            hold_time: 180\n            keep_alive_time: 60\n          - peer_address: 172.30.11.5\n            vrf: default\n            hold_time: 180\n            keep_alive_time: 60\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBGPTimers(AntaTest):\n    \"\"\"Verifies the timers of BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Confirms the BGP session hold time/keepalive timers match the expected value.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - The hold time/keepalive timers match the expected value for each peer.\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - The hold time/keepalive timers do not match the expected value for a peer.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBGPTimers:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n                hold_time: 180\n                keep_alive_time: 60\n              - peer_address: 172.30.11.5\n                vrf: default\n                hold_time: 180\n                keep_alive_time: 60\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBGPTimers test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n        @field_validator(\"bgp_peers\")\n        @classmethod\n        def validate_bgp_peers(cls, bgp_peers: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'hold_time' or 'keep_alive_time'  field is provided in each BGP peer.\"\"\"\n            for peer in bgp_peers:\n                if peer.hold_time is None or peer.keep_alive_time is None:\n                    msg = f\"{peer} 'hold_time' or 'keep_alive_time' field missing in the input\"\n                    raise ValueError(msg)\n            return bgp_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBGPTimers.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Check BGP peer timers\n            if peer_data[\"holdTime\"] != peer.hold_time:\n                self.result.is_failure(f\"{peer} - Hold time mismatch - Expected: {peer.hold_time} Actual: {peer_data['holdTime']}\")\n            if peer_data[\"keepaliveTime\"] != peer.keep_alive_time:\n                self.result.is_failure(f\"{peer} - Keepalive time mismatch - Expected: {peer.keep_alive_time} Actual: {peer_data['keepaliveTime']}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBGPTimers-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBgpRouteMaps","title":"VerifyBgpRouteMaps","text":"<p>Verifies BGP inbound and outbound route-maps of BGP IPv4 peer(s).</p> <p>This test performs the following checks for each specified peer:</p> <ol> <li>Verifies that the peer is found in its VRF in the BGP configuration.</li> <li>Validates the correct BGP route maps are applied in the correct direction (inbound or outbound).</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified peers are found in the BGP configuration.</li> <li>All specified peers has correct BGP route maps are applied in the correct direction (inbound or outbound).</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified peer is not found in the BGP configuration.</li> <li>A incorrect or missing route map in either the inbound or outbound direction.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyBgpRouteMaps:\n        bgp_peers:\n          - peer_address: 172.30.11.1\n            vrf: default\n            inbound_route_map: RM-MLAG-PEER-IN\n            outbound_route_map: RM-MLAG-PEER-OUT\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyBgpRouteMaps(AntaTest):\n    \"\"\"Verifies BGP inbound and outbound route-maps of BGP IPv4 peer(s).\n\n    This test performs the following checks for each specified peer:\n\n      1. Verifies that the peer is found in its VRF in the BGP configuration.\n      2. Validates the correct BGP route maps are applied in the correct direction (inbound or outbound).\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified peers are found in the BGP configuration.\n        - All specified peers has correct BGP route maps are applied in the correct direction (inbound or outbound).\n    * Failure: If any of the following occur:\n        - A specified peer is not found in the BGP configuration.\n        - A incorrect or missing route map in either the inbound or outbound direction.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyBgpRouteMaps:\n            bgp_peers:\n              - peer_address: 172.30.11.1\n                vrf: default\n                inbound_route_map: RM-MLAG-PEER-IN\n                outbound_route_map: RM-MLAG-PEER-OUT\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show bgp neighbors vrf all\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBgpRouteMaps test.\"\"\"\n\n        bgp_peers: list[BgpPeer]\n        \"\"\"List of BGP IPv4 peers.\"\"\"\n        BgpPeer: ClassVar[type[BgpPeer]] = BgpPeer\n\n        @field_validator(\"bgp_peers\")\n        @classmethod\n        def validate_bgp_peers(cls, bgp_peers: list[T]) -&gt; list[T]:\n            \"\"\"Validate that 'inbound_route_map' or 'outbound_route_map' field is provided in each BGP peer.\"\"\"\n            for peer in bgp_peers:\n                if not (peer.inbound_route_map or peer.outbound_route_map):\n                    msg = f\"{peer} 'inbound_route_map' or 'outbound_route_map' field missing in the input\"\n                    raise ValueError(msg)\n            return bgp_peers\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBgpRouteMaps.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for peer in self.inputs.bgp_peers:\n            peer_ip = str(peer.peer_address)\n            inbound_route_map = peer.inbound_route_map\n            outbound_route_map = peer.outbound_route_map\n            peer_list = get_value(output, f\"vrfs.{peer.vrf}.peerList\", default=[])\n\n            # Check if the peer is found\n            if (peer_data := get_item(peer_list, \"peerAddress\", peer_ip)) is None:\n                self.result.is_failure(f\"{peer} - Not found\")\n                continue\n\n            # Verify Inbound route-map\n            if inbound_route_map and (inbound_map := peer_data.get(\"routeMapInbound\", \"Not Configured\")) != inbound_route_map:\n                self.result.is_failure(f\"{peer} - Inbound route-map mismatch - Expected: {inbound_route_map} Actual: {inbound_map}\")\n\n            # Verify Outbound route-map\n            if outbound_route_map and (outbound_map := peer_data.get(\"routeMapOutbound\", \"Not Configured\")) != outbound_route_map:\n                self.result.is_failure(f\"{peer} - Outbound route-map mismatch - Expected: {outbound_route_map} Actual: {outbound_map}\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyBgpRouteMaps-attributes","title":"Inputs","text":"Name Type Description Default <code>bgp_peers</code> <code>list[BgpPeer]</code>                      List of BGP IPv4 peers.                    -"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyEVPNType2Route","title":"VerifyEVPNType2Route","text":"<p>Verifies the EVPN Type-2 routes for a given IPv4 or MAC address and VNI.</p> <p>This test performs the following checks for each specified VXLAN endpoint:</p> <ol> <li>Verifies that the endpoint exists in the BGP EVPN table.</li> <li>Confirms that at least one EVPN Type-2 route with a valid and active path exists.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All specified VXLAN endpoints are found in the BGP EVPN table.</li> <li>Each endpoint has at least one EVPN Type-2 route with a valid and active path.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A VXLAN endpoint is not found in the BGP EVPN table.</li> <li>No EVPN Type-2 route with a valid and active path exists for an endpoint.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  bgp:\n    - VerifyEVPNType2Route:\n        vxlan_endpoints:\n          - address: 192.168.20.102\n            vni: 10020\n          - address: aac1.ab5d.b41e\n            vni: 10010\n</code></pre> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>class VerifyEVPNType2Route(AntaTest):\n    \"\"\"Verifies the EVPN Type-2 routes for a given IPv4 or MAC address and VNI.\n\n    This test performs the following checks for each specified VXLAN endpoint:\n\n      1. Verifies that the endpoint exists in the BGP EVPN table.\n      2. Confirms that at least one EVPN Type-2 route with a valid and active path exists.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All specified VXLAN endpoints are found in the BGP EVPN table.\n        - Each endpoint has at least one EVPN Type-2 route with a valid and active path.\n    * Failure: If any of the following occur:\n        - A VXLAN endpoint is not found in the BGP EVPN table.\n        - No EVPN Type-2 route with a valid and active path exists for an endpoint.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      bgp:\n        - VerifyEVPNType2Route:\n            vxlan_endpoints:\n              - address: 192.168.20.102\n                vni: 10020\n              - address: aac1.ab5d.b41e\n                vni: 10010\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"bgp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaTemplate(template=\"show bgp evpn route-type mac-ip {address} vni {vni}\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyEVPNType2Route test.\"\"\"\n\n        vxlan_endpoints: list[VxlanEndpoint]\n        \"\"\"List of VXLAN endpoints to verify.\"\"\"\n        VxlanEndpoint: ClassVar[type[VxlanEndpoint]] = VxlanEndpoint\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for each VXLAN endpoint in the input list.\"\"\"\n        return [template.render(address=str(endpoint.address), vni=endpoint.vni) for endpoint in self.inputs.vxlan_endpoints]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyEVPNType2Route.\"\"\"\n        self.result.is_success()\n\n        for command, endpoint in zip(self.instance_commands, self.inputs.vxlan_endpoints):\n            # Verify that the VXLAN endpoint is in the BGP EVPN table\n            evpn_routes = command.json_output[\"evpnRoutes\"]\n            if not evpn_routes:\n                self.result.is_failure(f\"{endpoint} - No EVPN Type-2 route\")\n                continue\n\n            # Verify that at least one EVPN Type-2 route has at least one active and valid path across all learned routes from all RDs combined\n            has_active_path = False\n            for route_data in evpn_routes.values():\n                for path in route_data.get(\"evpnRoutePaths\", []):\n                    route_type = path.get(\"routeType\", {})\n                    if route_type.get(\"active\") and route_type.get(\"valid\"):\n                        has_active_path = True\n                        break\n            if not has_active_path:\n                self.result.is_failure(f\"{endpoint} - No valid and active path\")\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.tests.routing.bgp.VerifyEVPNType2Route-attributes","title":"Inputs","text":"Name Type Description Default <code>vxlan_endpoints</code> <code>list[VxlanEndpoint]</code>                      List of VXLAN endpoints to verify.                    -"},{"location":"api/tests/routing.bgp/#input-models","title":"Input models","text":"<p>Module containing input models for routing BGP tests.</p>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.AFI_SAFI_MAPPINGS","title":"AFI_SAFI_MAPPINGS  <code>module-attribute</code>","text":"<pre><code>AFI_SAFI_MAPPINGS = {\n    \"v4u\": \"IPv4 Unicast\",\n    \"v4m\": \"IPv4 Multicast\",\n    \"v6u\": \"IPv6 Unicast\",\n    \"v6m\": \"IPv6 Multicast\",\n}\n</code></pre> <p>Dictionary mapping AFI/SAFI to EOS key representation for BGP redistributed route protocol.</p>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.IPV4_MULTICAST_SUPPORTED_PROTO","title":"IPV4_MULTICAST_SUPPORTED_PROTO  <code>module-attribute</code>","text":"<pre><code>IPV4_MULTICAST_SUPPORTED_PROTO = [\n    \"AttachedHost\",\n    \"Connected\",\n    \"IS-IS\",\n    \"OSPF Internal\",\n    \"OSPF External\",\n    \"OSPF Nssa-External\",\n    \"OSPFv3 Internal\",\n    \"OSPFv3 External\",\n    \"OSPFv3 Nssa-External\",\n    \"Static\",\n]\n</code></pre> <p>List of BGP redistributed route protocol, supported for IPv4 multicast address family.</p>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.IPV6_MULTICAST_SUPPORTED_PROTO","title":"IPV6_MULTICAST_SUPPORTED_PROTO  <code>module-attribute</code>","text":"<pre><code>IPV6_MULTICAST_SUPPORTED_PROTO = [\n    proto\n    for proto in IPV4_MULTICAST_SUPPORTED_PROTO\n    if proto != \"AttachedHost\"\n]\n</code></pre> <p>List of BGP redistributed route protocol, supported for IPv6 multicast address family.</p>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.AddressFamilyConfig","title":"AddressFamilyConfig","text":"<p>Model representing a BGP address family configuration.</p> Name Type Description Default <code>afi_safi</code> <code>RedistributedAfiSafi</code>                      AFI/SAFI abbreviation per EOS.                    - <code>redistributed_routes</code> <code>list[RedistributedRouteConfig]</code>                      List of redistributed route configuration.                    - Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class AddressFamilyConfig(BaseModel):\n    \"\"\"Model representing a BGP address family configuration.\"\"\"\n\n    afi_safi: RedistributedAfiSafi\n    \"\"\"AFI/SAFI abbreviation per EOS.\"\"\"\n    redistributed_routes: list[RedistributedRouteConfig]\n    \"\"\"List of redistributed route configuration.\"\"\"\n\n    @model_validator(mode=\"after\")\n    def validate_afi_safi_supported_routes(self) -&gt; Self:\n        \"\"\"Validate each address family supported redistributed protocol.\n\n        Following table shows the supported redistributed routes for each address family.\n\n        |    IPv4 Unicast         |    IPv6 Unicast         |   IPv4 Multicast       |   IPv6 Multicast       |\n        | ------------------------|-------------------------|------------------------|------------------------|\n        |    AttachedHost         |    AttachedHost         |   AttachedHost         |   Connected            |\n        |    Bgp                  |    Bgp                  |   Connected            |   IS-IS                |\n        |    Connected            |    Connected            |   IS-IS                |   OSPF Internal        |\n        |    Dynamic              |    DHCP                 |   OSPF Internal        |   OSPF External        |\n        |    IS-IS                |    Dynamic              |   OSPF External        |   OSPF Nssa-External   |\n        |    OSPF Internal        |    IS-IS                |   OSPF Nssa-External   |   OSPFv3 Internal      |\n        |    OSPF External        |    OSPFv3 Internal      |   OSPFv3 Internal      |   OSPFv3 External      |\n        |    OSPF Nssa-External   |    OSPFv3 External      |   OSPFv3 External      |   OSPFv3 Nssa-External |\n        |    OSPFv3 Internal      |    OSPFv3 Nssa-External |   OSPFv3 Nssa-External |   Static               |\n        |    OSPFv3 External      |    Static               |   Static               |                        |\n        |    OSPFv3 Nssa-External |    User                 |                        |                        |\n        |    RIP                  |                         |                        |                        |\n        |    Static               |                         |                        |                        |\n        |    User                 |                         |                        |                        |\n        \"\"\"\n        for routes_data in self.redistributed_routes:\n            if all([self.afi_safi == \"v4u\", routes_data.proto == \"DHCP\"]):\n                msg = f\"Redistributed protocol 'DHCP' is not supported for address-family '{AFI_SAFI_MAPPINGS[self.afi_safi]}'\"\n                raise ValueError(msg)\n\n            if self.afi_safi == \"v6u\" and routes_data.proto in [\"OSPF Internal\", \"OSPF External\", \"OSPF Nssa-External\", \"RIP\"]:\n                msg = f\"Redistributed protocol '{routes_data.proto}' is not supported for address-family '{AFI_SAFI_MAPPINGS[self.afi_safi]}'\"\n                raise ValueError(msg)\n\n            if self.afi_safi == \"v4m\" and routes_data.proto not in IPV4_MULTICAST_SUPPORTED_PROTO:\n                msg = f\"Redistributed protocol '{routes_data.proto}' is not supported for address-family '{AFI_SAFI_MAPPINGS[self.afi_safi]}'\"\n                raise ValueError(msg)\n\n            if self.afi_safi == \"v6m\" and routes_data.proto not in IPV6_MULTICAST_SUPPORTED_PROTO:\n                msg = f\"Redistributed protocol '{routes_data.proto}' is not supported for address-family '{AFI_SAFI_MAPPINGS[self.afi_safi]}'\"\n                raise ValueError(msg)\n\n        return self\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the AddressFamilyConfig for reporting.\n\n        Examples\n        --------\n        - AFI-SAFI: IPv4 Unicast\n        \"\"\"\n        return f\"AFI-SAFI: {AFI_SAFI_MAPPINGS[self.afi_safi]}\"\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.AddressFamilyConfig.validate_afi_safi_supported_routes","title":"validate_afi_safi_supported_routes","text":"<pre><code>validate_afi_safi_supported_routes() -&gt; Self\n</code></pre> <p>Validate each address family supported redistributed protocol.</p> <p>Following table shows the supported redistributed routes for each address family.</p> IPv4 Unicast IPv6 Unicast IPv4 Multicast IPv6 Multicast AttachedHost AttachedHost AttachedHost Connected Bgp Bgp Connected IS-IS Connected Connected IS-IS OSPF Internal Dynamic DHCP OSPF Internal OSPF External IS-IS Dynamic OSPF External OSPF Nssa-External OSPF Internal IS-IS OSPF Nssa-External OSPFv3 Internal OSPF External OSPFv3 Internal OSPFv3 Internal OSPFv3 External OSPF Nssa-External OSPFv3 External OSPFv3 External OSPFv3 Nssa-External OSPFv3 Internal OSPFv3 Nssa-External OSPFv3 Nssa-External Static OSPFv3 External Static Static OSPFv3 Nssa-External User RIP Static User Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_afi_safi_supported_routes(self) -&gt; Self:\n    \"\"\"Validate each address family supported redistributed protocol.\n\n    Following table shows the supported redistributed routes for each address family.\n\n    |    IPv4 Unicast         |    IPv6 Unicast         |   IPv4 Multicast       |   IPv6 Multicast       |\n    | ------------------------|-------------------------|------------------------|------------------------|\n    |    AttachedHost         |    AttachedHost         |   AttachedHost         |   Connected            |\n    |    Bgp                  |    Bgp                  |   Connected            |   IS-IS                |\n    |    Connected            |    Connected            |   IS-IS                |   OSPF Internal        |\n    |    Dynamic              |    DHCP                 |   OSPF Internal        |   OSPF External        |\n    |    IS-IS                |    Dynamic              |   OSPF External        |   OSPF Nssa-External   |\n    |    OSPF Internal        |    IS-IS                |   OSPF Nssa-External   |   OSPFv3 Internal      |\n    |    OSPF External        |    OSPFv3 Internal      |   OSPFv3 Internal      |   OSPFv3 External      |\n    |    OSPF Nssa-External   |    OSPFv3 External      |   OSPFv3 External      |   OSPFv3 Nssa-External |\n    |    OSPFv3 Internal      |    OSPFv3 Nssa-External |   OSPFv3 Nssa-External |   Static               |\n    |    OSPFv3 External      |    Static               |   Static               |                        |\n    |    OSPFv3 Nssa-External |    User                 |                        |                        |\n    |    RIP                  |                         |                        |                        |\n    |    Static               |                         |                        |                        |\n    |    User                 |                         |                        |                        |\n    \"\"\"\n    for routes_data in self.redistributed_routes:\n        if all([self.afi_safi == \"v4u\", routes_data.proto == \"DHCP\"]):\n            msg = f\"Redistributed protocol 'DHCP' is not supported for address-family '{AFI_SAFI_MAPPINGS[self.afi_safi]}'\"\n            raise ValueError(msg)\n\n        if self.afi_safi == \"v6u\" and routes_data.proto in [\"OSPF Internal\", \"OSPF External\", \"OSPF Nssa-External\", \"RIP\"]:\n            msg = f\"Redistributed protocol '{routes_data.proto}' is not supported for address-family '{AFI_SAFI_MAPPINGS[self.afi_safi]}'\"\n            raise ValueError(msg)\n\n        if self.afi_safi == \"v4m\" and routes_data.proto not in IPV4_MULTICAST_SUPPORTED_PROTO:\n            msg = f\"Redistributed protocol '{routes_data.proto}' is not supported for address-family '{AFI_SAFI_MAPPINGS[self.afi_safi]}'\"\n            raise ValueError(msg)\n\n        if self.afi_safi == \"v6m\" and routes_data.proto not in IPV6_MULTICAST_SUPPORTED_PROTO:\n            msg = f\"Redistributed protocol '{routes_data.proto}' is not supported for address-family '{AFI_SAFI_MAPPINGS[self.afi_safi]}'\"\n            raise ValueError(msg)\n\n    return self\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.BgpAddressFamily","title":"BgpAddressFamily","text":"<p>Model for a BGP address family.</p> Name Type Description Default <code>afi</code> <code>Afi</code>                      BGP Address Family Identifier (AFI).                    - <code>safi</code> <code>Safi | None</code>                      BGP Subsequent Address Family Identifier (SAFI). Required when `afi` is `ipv4` or `ipv6`.                    <code>None</code> <code>vrf</code> <code>str</code>                      Optional VRF when `afi` is `ipv4` or `ipv6`. Defaults to `default`.  If the input `afi` is NOT `ipv4` or `ipv6` (e.g. `evpn`, `vpn-ipv4`, etc.), the `vrf` must be `default`.  These AFIs operate at a global level and do not use the VRF concept in the same way as IPv4/IPv6.                    <code>'default'</code> <code>num_peers</code> <code>PositiveInt | None</code>                      Number of expected established BGP peers with negotiated AFI/SAFI. Required field in the `VerifyBGPPeerCount` test.                    <code>None</code> <code>peers</code> <code>list[IPv4Address | IPv6Address] | None</code>                      List of expected IPv4/IPv6 BGP peers supporting the AFI/SAFI. Required field in the `VerifyBGPSpecificPeers` test.                    <code>None</code> <code>check_tcp_queues</code> <code>bool</code>                      Flag to check if the TCP session queues are empty for a BGP peer. Defaults to `True`.  Can be disabled in the `VerifyBGPPeersHealth` and `VerifyBGPSpecificPeers` tests.                    <code>True</code> <code>check_peer_state</code> <code>bool</code>                      Flag to check if the peers are established with negotiated AFI/SAFI. Defaults to `False`.  Can be enabled in the `VerifyBGPPeerCount` tests.                    <code>False</code> Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class BgpAddressFamily(BaseModel):\n    \"\"\"Model for a BGP address family.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    afi: Afi\n    \"\"\"BGP Address Family Identifier (AFI).\"\"\"\n    safi: Safi | None = None\n    \"\"\"BGP Subsequent Address Family Identifier (SAFI). Required when `afi` is `ipv4` or `ipv6`.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"Optional VRF when `afi` is `ipv4` or `ipv6`. Defaults to `default`.\n\n    If the input `afi` is NOT `ipv4` or `ipv6` (e.g. `evpn`, `vpn-ipv4`, etc.), the `vrf` must be `default`.\n\n    These AFIs operate at a global level and do not use the VRF concept in the same way as IPv4/IPv6.\n    \"\"\"\n    num_peers: PositiveInt | None = None\n    \"\"\"Number of expected established BGP peers with negotiated AFI/SAFI. Required field in the `VerifyBGPPeerCount` test.\"\"\"\n    peers: list[IPv4Address | IPv6Address] | None = None\n    \"\"\"List of expected IPv4/IPv6 BGP peers supporting the AFI/SAFI. Required field in the `VerifyBGPSpecificPeers` test.\"\"\"\n    check_tcp_queues: bool = True\n    \"\"\"Flag to check if the TCP session queues are empty for a BGP peer. Defaults to `True`.\n\n    Can be disabled in the `VerifyBGPPeersHealth` and `VerifyBGPSpecificPeers` tests.\n    \"\"\"\n    check_peer_state: bool = False\n    \"\"\"Flag to check if the peers are established with negotiated AFI/SAFI. Defaults to `False`.\n\n    Can be enabled in the `VerifyBGPPeerCount` tests.\"\"\"\n\n    @model_validator(mode=\"after\")\n    def validate_inputs(self) -&gt; Self:\n        \"\"\"Validate the inputs provided to the BgpAddressFamily class.\n\n        If `afi` is either `ipv4` or `ipv6`, `safi` must be provided.\n\n        If `afi` is not `ipv4` or `ipv6`, `safi` must NOT be provided and `vrf` must be `default`.\n        \"\"\"\n        if self.afi in [\"ipv4\", \"ipv6\"]:\n            if self.safi is None:\n                msg = \"'safi' must be provided when afi is ipv4 or ipv6\"\n                raise ValueError(msg)\n        elif self.safi is not None:\n            msg = \"'safi' must not be provided when afi is not ipv4 or ipv6\"\n            raise ValueError(msg)\n        elif self.vrf != \"default\":\n            msg = \"'vrf' must be default when afi is not ipv4 or ipv6\"\n            raise ValueError(msg)\n        return self\n\n    @property\n    def eos_key(self) -&gt; str:\n        \"\"\"AFI/SAFI EOS key representation.\"\"\"\n        # Pydantic handles the validation of the AFI/SAFI combination, so we can ignore error handling here.\n        return AFI_SAFI_EOS_KEY[(self.afi, self.safi)]\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the BgpAddressFamily for reporting.\n\n        Examples\n        --------\n        - AFI:ipv4 SAFI:unicast VRF:default\n        - AFI:evpn\n        \"\"\"\n        base_string = f\"AFI: {self.afi}\"\n        if self.safi is not None:\n            base_string += f\" SAFI: {self.safi}\"\n        if self.afi in [\"ipv4\", \"ipv6\"]:\n            base_string += f\" VRF: {self.vrf}\"\n        return base_string\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.BgpAddressFamily.validate_inputs","title":"validate_inputs","text":"<pre><code>validate_inputs() -&gt; Self\n</code></pre> <p>Validate the inputs provided to the BgpAddressFamily class.</p> <p>If <code>afi</code> is either <code>ipv4</code> or <code>ipv6</code>, <code>safi</code> must be provided.</p> <p>If <code>afi</code> is not <code>ipv4</code> or <code>ipv6</code>, <code>safi</code> must NOT be provided and <code>vrf</code> must be <code>default</code>.</p> Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_inputs(self) -&gt; Self:\n    \"\"\"Validate the inputs provided to the BgpAddressFamily class.\n\n    If `afi` is either `ipv4` or `ipv6`, `safi` must be provided.\n\n    If `afi` is not `ipv4` or `ipv6`, `safi` must NOT be provided and `vrf` must be `default`.\n    \"\"\"\n    if self.afi in [\"ipv4\", \"ipv6\"]:\n        if self.safi is None:\n            msg = \"'safi' must be provided when afi is ipv4 or ipv6\"\n            raise ValueError(msg)\n    elif self.safi is not None:\n        msg = \"'safi' must not be provided when afi is not ipv4 or ipv6\"\n        raise ValueError(msg)\n    elif self.vrf != \"default\":\n        msg = \"'vrf' must be default when afi is not ipv4 or ipv6\"\n        raise ValueError(msg)\n    return self\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.BgpNeighbor","title":"BgpNeighbor","text":"<p>Alias for the BgpPeer model to maintain backward compatibility.</p> <p>When initialised, it will emit a deprecation warning and call the BgpPeer model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class BgpNeighbor(BgpPeer):  # pragma: no cover\n    \"\"\"Alias for the BgpPeer model to maintain backward compatibility.\n\n    When initialised, it will emit a deprecation warning and call the BgpPeer model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the BgpPeer class, emitting a depreciation warning.\"\"\"\n        warn(\n            message=\"BgpNeighbor model is deprecated and will be removed in ANTA v2.0.0. Use the BgpPeer model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.BgpPeer","title":"BgpPeer","text":"<p>Model for a BGP peer.</p> <p>Only IPv4 peers are supported for now.</p> Name Type Description Default <code>peer_address</code> <code>IPv4Address</code>                      IPv4 address of the BGP peer.                    - <code>vrf</code> <code>str</code>                      Optional VRF for the BGP peer. Defaults to `default`.                    <code>'default'</code> <code>peer_group</code> <code>str | None</code>                      Peer group of the BGP peer. Required field in the `VerifyBGPPeerGroup` test.                    <code>None</code> <code>advertised_routes</code> <code>list[IPv4Network] | None</code>                      List of advertised routes in CIDR format. Required field in the `VerifyBGPExchangedRoutes` test.                    <code>None</code> <code>received_routes</code> <code>list[IPv4Network] | None</code>                      List of received routes in CIDR format. Required field in the `VerifyBGPExchangedRoutes` test.                    <code>None</code> <code>capabilities</code> <code>list[MultiProtocolCaps] | None</code>                      List of BGP multiprotocol capabilities. Required field in the `VerifyBGPPeerMPCaps`, `VerifyBGPNlriAcceptance` tests.                    <code>None</code> <code>strict</code> <code>bool</code>                      If True, requires exact match of the provided BGP multiprotocol capabilities.  Optional field in the `VerifyBGPPeerMPCaps` test. Defaults to False.                    <code>False</code> <code>hold_time</code> <code>int | None</code>                      BGP hold time in seconds. Required field in the `VerifyBGPTimers` test.                    <code>Field(default=None, ge=3, le=7200)</code> <code>keep_alive_time</code> <code>int | None</code>                      BGP keepalive time in seconds. Required field in the `VerifyBGPTimers` test.                    <code>Field(default=None, ge=0, le=3600)</code> <code>drop_stats</code> <code>list[BgpDropStats] | None</code>                      List of drop statistics to be verified.  Optional field in the `VerifyBGPPeerDropStats` test. If not provided, the test will verifies all drop statistics.                    <code>None</code> <code>update_errors</code> <code>list[BgpUpdateError] | None</code>                      List of update error counters to be verified.  Optional field in the `VerifyBGPPeerUpdateErrors` test. If not provided, the test will verifies all the update error counters.                    <code>None</code> <code>inbound_route_map</code> <code>str | None</code>                      Inbound route map applied, defaults to None. Required field in the `VerifyBgpRouteMaps` test.                    <code>None</code> <code>outbound_route_map</code> <code>str | None</code>                      Outbound route map applied, defaults to None. Required field in the `VerifyBgpRouteMaps` test.                    <code>None</code> <code>maximum_routes</code> <code>int | None</code>                      The maximum allowable number of BGP routes. `0` means unlimited. Required field in the `VerifyBGPPeerRouteLimit` test                    <code>Field(default=None, ge=0, le=4294967294)</code> <code>warning_limit</code> <code>int | None</code>                      The warning limit for the maximum routes. `0` means no warning.  Optional field in the `VerifyBGPPeerRouteLimit` test. If not provided, the test will not verify the warning limit.                    <code>Field(default=None, ge=0, le=4294967294)</code> <code>ttl</code> <code>int | None</code>                      The Time-To-Live (TTL). Required field in the `VerifyBGPPeerTtlMultiHops` test.                    <code>Field(default=None, ge=1, le=255)</code> <code>max_ttl_hops</code> <code>int | None</code>                      The Max TTL hops. Required field in the `VerifyBGPPeerTtlMultiHops` test.                    <code>Field(default=None, ge=1, le=255)</code> Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class BgpPeer(BaseModel):\n    \"\"\"Model for a BGP peer.\n\n    Only IPv4 peers are supported for now.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    peer_address: IPv4Address\n    \"\"\"IPv4 address of the BGP peer.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"Optional VRF for the BGP peer. Defaults to `default`.\"\"\"\n    peer_group: str | None = None\n    \"\"\"Peer group of the BGP peer. Required field in the `VerifyBGPPeerGroup` test.\"\"\"\n    advertised_routes: list[IPv4Network] | None = None\n    \"\"\"List of advertised routes in CIDR format. Required field in the `VerifyBGPExchangedRoutes` test.\"\"\"\n    received_routes: list[IPv4Network] | None = None\n    \"\"\"List of received routes in CIDR format. Required field in the `VerifyBGPExchangedRoutes` test.\"\"\"\n    capabilities: list[MultiProtocolCaps] | None = None\n    \"\"\"List of BGP multiprotocol capabilities. Required field in the `VerifyBGPPeerMPCaps`, `VerifyBGPNlriAcceptance` tests.\"\"\"\n    strict: bool = False\n    \"\"\"If True, requires exact match of the provided BGP multiprotocol capabilities.\n\n    Optional field in the `VerifyBGPPeerMPCaps` test. Defaults to False.\"\"\"\n    hold_time: int | None = Field(default=None, ge=3, le=7200)\n    \"\"\"BGP hold time in seconds. Required field in the `VerifyBGPTimers` test.\"\"\"\n    keep_alive_time: int | None = Field(default=None, ge=0, le=3600)\n    \"\"\"BGP keepalive time in seconds. Required field in the `VerifyBGPTimers` test.\"\"\"\n    drop_stats: list[BgpDropStats] | None = None\n    \"\"\"List of drop statistics to be verified.\n\n    Optional field in the `VerifyBGPPeerDropStats` test. If not provided, the test will verifies all drop statistics.\"\"\"\n    update_errors: list[BgpUpdateError] | None = None\n    \"\"\"List of update error counters to be verified.\n\n    Optional field in the `VerifyBGPPeerUpdateErrors` test. If not provided, the test will verifies all the update error counters.\"\"\"\n    inbound_route_map: str | None = None\n    \"\"\"Inbound route map applied, defaults to None. Required field in the `VerifyBgpRouteMaps` test.\"\"\"\n    outbound_route_map: str | None = None\n    \"\"\"Outbound route map applied, defaults to None. Required field in the `VerifyBgpRouteMaps` test.\"\"\"\n    maximum_routes: int | None = Field(default=None, ge=0, le=4294967294)\n    \"\"\"The maximum allowable number of BGP routes. `0` means unlimited. Required field in the `VerifyBGPPeerRouteLimit` test\"\"\"\n    warning_limit: int | None = Field(default=None, ge=0, le=4294967294)\n    \"\"\"The warning limit for the maximum routes. `0` means no warning.\n\n    Optional field in the `VerifyBGPPeerRouteLimit` test. If not provided, the test will not verify the warning limit.\"\"\"\n    ttl: int | None = Field(default=None, ge=1, le=255)\n    \"\"\"The Time-To-Live (TTL). Required field in the `VerifyBGPPeerTtlMultiHops` test.\"\"\"\n    max_ttl_hops: int | None = Field(default=None, ge=1, le=255)\n    \"\"\"The Max TTL hops. Required field in the `VerifyBGPPeerTtlMultiHops` test.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the BgpPeer for reporting.\"\"\"\n        return f\"Peer: {self.peer_address} VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.BgpRoute","title":"BgpRoute","text":"<p>Model representing BGP routes.</p> <p>Only IPv4 prefixes are supported for now.</p> Name Type Description Default <code>prefix</code> <code>IPv4Network</code>                      The IPv4 network address.                    - <code>vrf</code> <code>str</code>                      Optional VRF for the BGP peer. Defaults to `default`.                    <code>'default'</code> <code>paths</code> <code>list[BgpRoutePath] | None</code>                      A list of paths for the BGP route. Required field in the `VerifyBGPRoutePaths` test.                    <code>None</code> <code>ecmp_count</code> <code>int | None</code>                      The expected number of ECMP paths for the BGP route. Required field in the `VerifyBGPRouteECMP` test.                    <code>None</code> Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class BgpRoute(BaseModel):\n    \"\"\"Model representing BGP routes.\n\n    Only IPv4 prefixes are supported for now.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    prefix: IPv4Network\n    \"\"\"The IPv4 network address.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"Optional VRF for the BGP peer. Defaults to `default`.\"\"\"\n    paths: list[BgpRoutePath] | None = None\n    \"\"\"A list of paths for the BGP route. Required field in the `VerifyBGPRoutePaths` test.\"\"\"\n    ecmp_count: int | None = None\n    \"\"\"The expected number of ECMP paths for the BGP route. Required field in the `VerifyBGPRouteECMP` test.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the BgpRoute for reporting.\n\n        Examples\n        --------\n        - Prefix: 192.168.66.100/24 VRF: default\n        \"\"\"\n        return f\"Prefix: {self.prefix} VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.BgpRoutePath","title":"BgpRoutePath","text":"<p>Model representing a BGP route path.</p> Name Type Description Default <code>nexthop</code> <code>IPv4Address</code>                      The next-hop IPv4 address for the path.                    - <code>origin</code> <code>Literal['Igp', 'Egp', 'Incomplete']</code>                      The BGP origin attribute of the route.                    - Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class BgpRoutePath(BaseModel):\n    \"\"\"Model representing a BGP route path.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    nexthop: IPv4Address\n    \"\"\"The next-hop IPv4 address for the path.\"\"\"\n    origin: Literal[\"Igp\", \"Egp\", \"Incomplete\"]\n    \"\"\"The BGP origin attribute of the route.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the RoutePath for reporting.\n\n        Examples\n        --------\n        - Next-hop: 192.168.66.101 Origin: Igp\n        \"\"\"\n        return f\"Next-hop: {self.nexthop} Origin: {self.origin}\"\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.BgpVrf","title":"BgpVrf","text":"<p>Model representing a VRF in a BGP instance.</p> Name Type Description Default <code>vrf</code> <code>str</code>                      VRF context.                    <code>'default'</code> <code>address_families</code> <code>list[AddressFamilyConfig]</code>                      List of address family configuration.                    - Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class BgpVrf(BaseModel):\n    \"\"\"Model representing a VRF in a BGP instance.\"\"\"\n\n    vrf: str = \"default\"\n    \"\"\"VRF context.\"\"\"\n    address_families: list[AddressFamilyConfig]\n    \"\"\"List of address family configuration.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the BgpVrf for reporting.\n\n        Examples\n        --------\n        - VRF: default\n        \"\"\"\n        return f\"VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.RedistributedRouteConfig","title":"RedistributedRouteConfig","text":"<p>Model representing a BGP redistributed route configuration.</p> Name Type Description Default <code>proto</code> <code>RedistributedProtocol</code>                      The redistributed protocol.                    - <code>include_leaked</code> <code>bool</code>                      Flag to include leaked routes of the redistributed protocol while redistributing.                    <code>False</code> <code>route_map</code> <code>str | None</code>                      Optional route map applied to the redistribution.                    <code>None</code> Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class RedistributedRouteConfig(BaseModel):\n    \"\"\"Model representing a BGP redistributed route configuration.\"\"\"\n\n    proto: RedistributedProtocol\n    \"\"\"The redistributed protocol.\"\"\"\n    include_leaked: bool = False\n    \"\"\"Flag to include leaked routes of the redistributed protocol while redistributing.\"\"\"\n    route_map: str | None = None\n    \"\"\"Optional route map applied to the redistribution.\"\"\"\n\n    @model_validator(mode=\"after\")\n    def validate_inputs(self) -&gt; Self:\n        \"\"\"Validate that 'include_leaked' is not set when the redistributed protocol is AttachedHost, User, Dynamic, or RIP.\"\"\"\n        if self.include_leaked and self.proto in [\"AttachedHost\", \"EOS SDK\", \"Dynamic\", \"RIP\"]:\n            msg = f\"'include_leaked' field is not supported for redistributed protocol '{self.proto}'\"\n            raise ValueError(msg)\n        return self\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the RedistributedRouteConfig for reporting.\n\n        Examples\n        --------\n        - Proto: Connected, Include Leaked: True, Route Map: RM-CONN-2-BGP\n        \"\"\"\n        base_string = f\"Proto: {self.proto}\"\n        if self.include_leaked:\n            base_string += f\", Include Leaked: {self.include_leaked}\"\n        if self.route_map:\n            base_string += f\", Route Map: {self.route_map}\"\n        return base_string\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.RedistributedRouteConfig.validate_inputs","title":"validate_inputs","text":"<pre><code>validate_inputs() -&gt; Self\n</code></pre> <p>Validate that \u2018include_leaked\u2019 is not set when the redistributed protocol is AttachedHost, User, Dynamic, or RIP.</p> Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_inputs(self) -&gt; Self:\n    \"\"\"Validate that 'include_leaked' is not set when the redistributed protocol is AttachedHost, User, Dynamic, or RIP.\"\"\"\n    if self.include_leaked and self.proto in [\"AttachedHost\", \"EOS SDK\", \"Dynamic\", \"RIP\"]:\n        msg = f\"'include_leaked' field is not supported for redistributed protocol '{self.proto}'\"\n        raise ValueError(msg)\n    return self\n</code></pre>"},{"location":"api/tests/routing.bgp/#anta.input_models.routing.bgp.VxlanEndpoint","title":"VxlanEndpoint","text":"<p>Model for a VXLAN endpoint.</p> Name Type Description Default <code>address</code> <code>IPv4Address | MacAddress</code>                      IPv4 or MAC address of the VXLAN endpoint.                    - <code>vni</code> <code>Vni</code>                      VNI of the VXLAN endpoint.                    - Source code in <code>anta/input_models/routing/bgp.py</code> <pre><code>class VxlanEndpoint(BaseModel):\n    \"\"\"Model for a VXLAN endpoint.\"\"\"\n\n    address: IPv4Address | MacAddress\n    \"\"\"IPv4 or MAC address of the VXLAN endpoint.\"\"\"\n    vni: Vni\n    \"\"\"VNI of the VXLAN endpoint.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the VxlanEndpoint for reporting.\"\"\"\n        return f\"Address: {self.address} VNI: {self.vni}\"\n</code></pre>"},{"location":"api/tests/routing.generic/","title":"Generic","text":""},{"location":"api/tests/routing.generic/#tests","title":"Tests","text":"<p>Module related to generic routing tests.</p>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyIPv4RouteNextHops","title":"VerifyIPv4RouteNextHops","text":"<p>Verifies the next-hops of the IPv4 prefixes.</p> <p>This test performs the following checks for each IPv4 prefix:</p> <ol> <li>Verifies the specified IPv4 route exists in the routing table.</li> <li>For each specified next-hop:<ul> <li>Verifies a path with matching next-hop exists.</li> <li>Supports <code>strict: True</code> to verify that routes must be learned exclusively via the exact next-hops specified.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: The test will pass if routes exist with paths matching the expected next-hops.</li> <li>Failure: The test will fail if:<ul> <li>A route entry is not found for given IPv4 prefixes.</li> <li>A path with specified next-hop is not found.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  generic:\n    - VerifyIPv4RouteNextHops:\n        route_entries:\n            - prefix: 10.10.0.1/32\n              vrf: default\n              strict: false\n              nexthops:\n                - 10.100.0.8\n                - 10.100.0.10\n</code></pre> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>class VerifyIPv4RouteNextHops(AntaTest):\n    \"\"\"Verifies the next-hops of the IPv4 prefixes.\n\n    This test performs the following checks for each IPv4 prefix:\n\n      1. Verifies the specified IPv4 route exists in the routing table.\n      2. For each specified next-hop:\n          - Verifies a path with matching next-hop exists.\n          - Supports `strict: True` to verify that routes must be learned exclusively via the exact next-hops specified.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if routes exist with paths matching the expected next-hops.\n    * Failure: The test will fail if:\n        - A route entry is not found for given IPv4 prefixes.\n        - A path with specified next-hop is not found.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      generic:\n        - VerifyIPv4RouteNextHops:\n            route_entries:\n                - prefix: 10.10.0.1/32\n                  vrf: default\n                  strict: false\n                  nexthops:\n                    - 10.100.0.8\n                    - 10.100.0.10\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"routing\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip route vrf all\", revision=4)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyIPv4RouteNextHops test.\"\"\"\n\n        route_entries: list[IPv4Routes]\n        \"\"\"List of IPv4 route(s).\"\"\"\n\n        @field_validator(\"route_entries\")\n        @classmethod\n        def validate_route_entries(cls, route_entries: list[IPv4Routes]) -&gt; list[IPv4Routes]:\n            \"\"\"Validate that 'nexthops' field is provided in each route entry.\"\"\"\n            for entry in route_entries:\n                if entry.nexthops is None:\n                    msg = f\"{entry} 'nexthops' field missing in the input\"\n                    raise ValueError(msg)\n            return route_entries\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIPv4RouteNextHops.\"\"\"\n        self.result.is_success()\n\n        output = self.instance_commands[0].json_output\n\n        for entry in self.inputs.route_entries:\n            # Verify if the prefix exists in route table\n            if (route_data := get_value(output, f\"vrfs..{entry.vrf}..routes..{entry.prefix}\", separator=\"..\")) is None:\n                self.result.is_failure(f\"{entry} - prefix not found\")\n                continue\n\n            # Verify the nexthop addresses\n            actual_nexthops = sorted([\"Directly connected\" if (next_hop := route.get(\"nexthopAddr\")) == \"\" else next_hop for route in route_data[\"vias\"]])\n            expected_nexthops = sorted([str(nexthop) for nexthop in entry.nexthops])\n\n            if entry.strict and expected_nexthops != actual_nexthops:\n                exp_nexthops = \", \".join(expected_nexthops)\n                self.result.is_failure(f\"{entry} - List of next-hops not matching - Expected: {exp_nexthops} Actual: {', '.join(actual_nexthops)}\")\n                continue\n\n            for nexthop in entry.nexthops:\n                if not get_item(route_data[\"vias\"], \"nexthopAddr\", str(nexthop)):\n                    self.result.is_failure(f\"{entry} Nexthop: {nexthop} - Route not found\")\n</code></pre>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyIPv4RouteNextHops-attributes","title":"Inputs","text":"Name Type Description Default <code>route_entries</code> <code>list[IPv4Routes]</code>                      List of IPv4 route(s).                    -"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyIPv4RouteType","title":"VerifyIPv4RouteType","text":"<p>Verifies the route-type of the IPv4 prefixes.</p> <p>This test performs the following checks for each IPv4 route:</p> <ol> <li>Verifies that the specified VRF is configured.</li> <li>Verifies that the specified IPv4 route is exists in the configuration.</li> <li>Verifies that the the specified IPv4 route is of the expected type.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All the specified VRFs are configured.</li> <li>All the specified IPv4 routes are found.</li> <li>All the specified IPv4 routes are of the expected type.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>A specified VRF is not configured.</li> <li>A specified IPv4 route is not found.</li> <li>Any specified IPv4 route is not of the expected type.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.routing:\n  generic:\n    - VerifyIPv4RouteType:\n        routes_entries:\n          - prefix: 10.10.0.1/32\n            vrf: default\n            route_type: eBGP\n          - prefix: 10.100.0.12/31\n            vrf: default\n            route_type: connected\n          - prefix: 10.100.1.5/32\n            vrf: default\n            route_type: iBGP\n</code></pre> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>class VerifyIPv4RouteType(AntaTest):\n    \"\"\"Verifies the route-type of the IPv4 prefixes.\n\n    This test performs the following checks for each IPv4 route:\n\n      1. Verifies that the specified VRF is configured.\n      2. Verifies that the specified IPv4 route is exists in the configuration.\n      3. Verifies that the the specified IPv4 route is of the expected type.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All the specified VRFs are configured.\n        - All the specified IPv4 routes are found.\n        - All the specified IPv4 routes are of the expected type.\n    * Failure: If any of the following occur:\n        - A specified VRF is not configured.\n        - A specified IPv4 route is not found.\n        - Any specified IPv4 route is not of the expected type.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      generic:\n        - VerifyIPv4RouteType:\n            routes_entries:\n              - prefix: 10.10.0.1/32\n                vrf: default\n                route_type: eBGP\n              - prefix: 10.100.0.12/31\n                vrf: default\n                route_type: connected\n              - prefix: 10.100.1.5/32\n                vrf: default\n                route_type: iBGP\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"routing\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip route vrf all\", revision=4)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyIPv4RouteType test.\"\"\"\n\n        routes_entries: list[IPv4Routes]\n        \"\"\"List of IPv4 route(s).\"\"\"\n\n        @field_validator(\"routes_entries\")\n        @classmethod\n        def validate_routes_entries(cls, routes_entries: list[IPv4Routes]) -&gt; list[IPv4Routes]:\n            \"\"\"Validate that 'route_type' field is provided in each BGP route entry.\"\"\"\n            for entry in routes_entries:\n                if entry.route_type is None:\n                    msg = f\"{entry} 'route_type' field missing in the input\"\n                    raise ValueError(msg)\n            return routes_entries\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIPv4RouteType.\"\"\"\n        self.result.is_success()\n        output = self.instance_commands[0].json_output\n\n        # Iterating over the all routes entries mentioned in the inputs.\n        for entry in self.inputs.routes_entries:\n            prefix = str(entry.prefix)\n            vrf = entry.vrf\n            expected_route_type = entry.route_type\n\n            # Verifying that on device, expected VRF is configured.\n            if (routes_details := get_value(output, f\"vrfs.{vrf}.routes\")) is None:\n                self.result.is_failure(f\"{entry} - VRF not configured\")\n                continue\n\n            # Verifying that the expected IPv4 route is present or not on the device\n            if (route_data := routes_details.get(prefix)) is None:\n                self.result.is_failure(f\"{entry} - Route not found\")\n                continue\n\n            # Verifying that the specified IPv4 routes are of the expected type.\n            if expected_route_type != (actual_route_type := route_data.get(\"routeType\")):\n                self.result.is_failure(f\"{entry} - Incorrect route type - Expected: {expected_route_type} Actual: {actual_route_type}\")\n</code></pre>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyIPv4RouteType-attributes","title":"Inputs","text":"Name Type Description Default <code>routes_entries</code> <code>list[IPv4Routes]</code>                      List of IPv4 route(s).                    -"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyRoutingProtocolModel","title":"VerifyRoutingProtocolModel","text":"<p>Verifies the configured routing protocol model.</p> Expected Results <ul> <li>Success: The test will pass if the configured routing protocol model is the one we expect.</li> <li>Failure: The test will fail if the configured routing protocol model is not the one we expect.</li> </ul> Examples <pre><code>anta.tests.routing:\n  generic:\n    - VerifyRoutingProtocolModel:\n        model: multi-agent\n</code></pre> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>class VerifyRoutingProtocolModel(AntaTest):\n    \"\"\"Verifies the configured routing protocol model.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the configured routing protocol model is the one we expect.\n    * Failure: The test will fail if the configured routing protocol model is not the one we expect.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      generic:\n        - VerifyRoutingProtocolModel:\n            model: multi-agent\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"routing\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip route summary\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyRoutingProtocolModel test.\"\"\"\n\n        model: Literal[\"multi-agent\", \"ribd\"] = \"multi-agent\"\n        \"\"\"Expected routing protocol model. Defaults to `multi-agent`.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyRoutingProtocolModel.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        configured_model = command_output[\"protoModelStatus\"][\"configuredProtoModel\"]\n        operating_model = command_output[\"protoModelStatus\"][\"operatingProtoModel\"]\n        if configured_model == operating_model == self.inputs.model:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Routing model is misconfigured - Expected: {self.inputs.model} Actual: {operating_model}\")\n</code></pre>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyRoutingProtocolModel-attributes","title":"Inputs","text":"Name Type Description Default <code>model</code> <code>Literal['multi-agent', 'ribd']</code>                      Expected routing protocol model. Defaults to `multi-agent`.                    <code>'multi-agent'</code>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyRoutingTableEntry","title":"VerifyRoutingTableEntry","text":"<p>Verifies that the provided routes are present in the routing table of a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if the provided routes are present in the routing table.</li> <li>Failure: The test will fail if one or many provided routes are missing from the routing table.</li> </ul> Examples <pre><code>anta.tests.routing:\n  generic:\n    - VerifyRoutingTableEntry:\n        vrf: default\n        routes:\n          - 10.1.0.1\n          - 10.1.0.2\n</code></pre> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>class VerifyRoutingTableEntry(AntaTest):\n    \"\"\"Verifies that the provided routes are present in the routing table of a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided routes are present in the routing table.\n    * Failure: The test will fail if one or many provided routes are missing from the routing table.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      generic:\n        - VerifyRoutingTableEntry:\n            vrf: default\n            routes:\n              - 10.1.0.1\n              - 10.1.0.2\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"routing\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaTemplate(template=\"show ip route vrf {vrf} {route}\", revision=4),\n        AntaTemplate(template=\"show ip route vrf {vrf}\", revision=4),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyRoutingTableEntry test.\"\"\"\n\n        vrf: str = \"default\"\n        \"\"\"VRF context. Defaults to `default` VRF.\"\"\"\n        routes: list[IPv4Address]\n        \"\"\"List of routes to verify.\"\"\"\n        collect: Literal[\"one\", \"all\"] = \"one\"\n        \"\"\"Route collect behavior: one=one route per command, all=all routes in vrf per command. Defaults to `one`\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for the input vrf.\"\"\"\n        if template == VerifyRoutingTableEntry.commands[0] and self.inputs.collect == \"one\":\n            return [template.render(vrf=self.inputs.vrf, route=route) for route in self.inputs.routes]\n\n        if template == VerifyRoutingTableEntry.commands[1] and self.inputs.collect == \"all\":\n            return [template.render(vrf=self.inputs.vrf)]\n\n        return []\n\n    @staticmethod\n    @cache\n    def ip_interface_ip(route: str) -&gt; IPv4Address:\n        \"\"\"Return the IP address of the provided ip route with mask.\"\"\"\n        return IPv4Interface(route).ip\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyRoutingTableEntry.\"\"\"\n        commands_output_route_ips = set()\n\n        for command in self.instance_commands:\n            command_output_vrf = command.json_output[\"vrfs\"][self.inputs.vrf]\n            commands_output_route_ips |= {self.ip_interface_ip(route) for route in command_output_vrf[\"routes\"]}\n\n        missing_routes = [str(route) for route in self.inputs.routes if route not in commands_output_route_ips]\n\n        if not missing_routes:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"The following route(s) are missing from the routing table of VRF {self.inputs.vrf}: {', '.join(missing_routes)}\")\n</code></pre>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyRoutingTableEntry-attributes","title":"Inputs","text":"Name Type Description Default <code>vrf</code> <code>str</code>                      VRF context. Defaults to `default` VRF.                    <code>'default'</code> <code>routes</code> <code>list[IPv4Address]</code>                      List of routes to verify.                    - <code>collect</code> <code>Literal['one', 'all']</code>                      Route collect behavior: one=one route per command, all=all routes in vrf per command. Defaults to `one`                    <code>'one'</code>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyRoutingTableEntry.ip_interface_ip","title":"ip_interface_ip  <code>cached</code> <code>staticmethod</code>","text":"<pre><code>ip_interface_ip(route: str) -&gt; IPv4Address\n</code></pre> <p>Return the IP address of the provided ip route with mask.</p> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>@staticmethod\n@cache\ndef ip_interface_ip(route: str) -&gt; IPv4Address:\n    \"\"\"Return the IP address of the provided ip route with mask.\"\"\"\n    return IPv4Interface(route).ip\n</code></pre>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyRoutingTableSize","title":"VerifyRoutingTableSize","text":"<p>Verifies the size of the IP routing table of the default VRF.</p> Expected Results <ul> <li>Success: The test will pass if the routing table size is between the provided minimum and maximum values.</li> <li>Failure: The test will fail if the routing table size is not between the provided minimum and maximum values.</li> </ul> Examples <pre><code>anta.tests.routing:\n  generic:\n    - VerifyRoutingTableSize:\n        minimum: 2\n        maximum: 20\n</code></pre> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>class VerifyRoutingTableSize(AntaTest):\n    \"\"\"Verifies the size of the IP routing table of the default VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the routing table size is between the provided minimum and maximum values.\n    * Failure: The test will fail if the routing table size is not between the provided minimum and maximum values.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      generic:\n        - VerifyRoutingTableSize:\n            minimum: 2\n            maximum: 20\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"routing\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip route summary\", revision=3)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyRoutingTableSize test.\"\"\"\n\n        minimum: PositiveInteger\n        \"\"\"Expected minimum routing table size.\"\"\"\n        maximum: PositiveInteger\n        \"\"\"Expected maximum routing table size.\"\"\"\n\n        @model_validator(mode=\"after\")\n        def check_min_max(self) -&gt; Self:\n            \"\"\"Validate that maximum is greater than minimum.\"\"\"\n            if self.minimum &gt; self.maximum:\n                msg = f\"Minimum {self.minimum} is greater than maximum {self.maximum}\"\n                raise ValueError(msg)\n            return self\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyRoutingTableSize.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        total_routes = int(command_output[\"vrfs\"][\"default\"][\"totalRoutes\"])\n        if self.inputs.minimum &lt;= total_routes &lt;= self.inputs.maximum:\n            self.result.is_success()\n        else:\n            self.result.is_failure(\n                f\"Routing table routes are outside the routes range - Expected: {self.inputs.minimum} &lt;= to &gt;= {self.inputs.maximum} Actual: {total_routes}\"\n            )\n</code></pre>"},{"location":"api/tests/routing.generic/#anta.tests.routing.generic.VerifyRoutingTableSize-attributes","title":"Inputs","text":"Name Type Description Default <code>minimum</code> <code>PositiveInteger</code>                      Expected minimum routing table size.                    - <code>maximum</code> <code>PositiveInteger</code>                      Expected maximum routing table size.                    -"},{"location":"api/tests/routing.generic/#input-models","title":"Input models","text":"<p>Module containing input models for generic routing tests.</p>"},{"location":"api/tests/routing.generic/#anta.input_models.routing.generic.IPv4Routes","title":"IPv4Routes","text":"<p>Model for a list of IPV4 route entries.</p> Name Type Description Default <code>prefix</code> <code>IPv4Network</code>                      IPv4 prefix in CIDR notation.                    - <code>vrf</code> <code>str</code>                      VRF context. Defaults to `default` VRF.                    <code>'default'</code> <code>route_type</code> <code>IPv4RouteType | None</code>                      Expected route type. Required field in the `VerifyIPv4RouteType` test.                    <code>None</code> <code>nexthops</code> <code>list[IPv4Address] | None</code>                      A list of the next-hop IP addresses for the route. Required field in the `VerifyIPv4RouteNextHops` test.                    <code>None</code> <code>strict</code> <code>bool</code>                      If True, requires exact matching of provided nexthop(s).  Can be enabled in `VerifyIPv4RouteNextHops` test.                    <code>False</code> Source code in <code>anta/input_models/routing/generic.py</code> <pre><code>class IPv4Routes(BaseModel):\n    \"\"\"Model for a list of IPV4 route entries.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    prefix: IPv4Network\n    \"\"\"IPv4 prefix in CIDR notation.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"VRF context. Defaults to `default` VRF.\"\"\"\n    route_type: IPv4RouteType | None = None\n    \"\"\"Expected route type. Required field in the `VerifyIPv4RouteType` test.\"\"\"\n    nexthops: list[IPv4Address] | None = None\n    \"\"\"A list of the next-hop IP addresses for the route. Required field in the `VerifyIPv4RouteNextHops` test.\"\"\"\n    strict: bool = False\n    \"\"\"If True, requires exact matching of provided nexthop(s).\n\n    Can be enabled in `VerifyIPv4RouteNextHops` test.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the IPv4Routes for reporting.\"\"\"\n        return f\"Prefix: {self.prefix} VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/routing.isis/","title":"ISIS","text":""},{"location":"api/tests/routing.isis/#tests","title":"Tests","text":"<p>Module related to IS-IS tests.</p>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISGracefulRestart","title":"VerifyISISGracefulRestart","text":"<p>Verifies the IS-IS graceful restart feature.</p> <p>This test performs the following checks for each IS-IS instance:</p> <ol> <li>Verifies that the specified IS-IS instance is configured on the device.</li> <li>Verifies the statuses of the graceful restart and graceful restart helper functionalities.</li> </ol> Expected Results <ul> <li>Success: The test will pass if all of the following conditions are met:<ul> <li>The specified IS-IS instance is configured on the device.</li> <li>Expected and actual IS-IS graceful restart and graceful restart helper values match.</li> </ul> </li> <li>Failure: The test will fail if any of the following conditions is met:<ul> <li>The specified IS-IS instance is not configured on the device.</li> <li>Expected and actual IS-IS graceful restart and graceful restart helper values do not match.</li> </ul> </li> <li>Skipped: The test will skip if IS-IS is not configured on the device.</li> </ul> Examples <pre><code>anta.tests.routing:\n  isis:\n    - VerifyISISGracefulRestart:\n        instances:\n          - name: '1'\n            vrf: default\n            graceful_restart: True\n            graceful_restart_helper: False\n          - name: '2'\n            vrf: default\n          - name: '11'\n            vrf: test\n            graceful_restart: True\n          - name: '12'\n            vrf: test\n            graceful_restart_helper: False\n</code></pre> Source code in <code>anta/tests/routing/isis.py</code> <pre><code>class VerifyISISGracefulRestart(AntaTest):\n    \"\"\"Verifies the IS-IS graceful restart feature.\n\n    This test performs the following checks for each IS-IS instance:\n\n      1. Verifies that the specified IS-IS instance is configured on the device.\n      2. Verifies the statuses of the graceful restart and graceful restart helper functionalities.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all of the following conditions are met:\n        - The specified IS-IS instance is configured on the device.\n        - Expected and actual IS-IS graceful restart and graceful restart helper values match.\n    * Failure: The test will fail if any of the following conditions is met:\n        - The specified IS-IS instance is not configured on the device.\n        - Expected and actual IS-IS graceful restart and graceful restart helper values do not match.\n    * Skipped: The test will skip if IS-IS is not configured on the device.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      isis:\n        - VerifyISISGracefulRestart:\n            instances:\n              - name: '1'\n                vrf: default\n                graceful_restart: True\n                graceful_restart_helper: False\n              - name: '2'\n                vrf: default\n              - name: '11'\n                vrf: test\n                graceful_restart: True\n              - name: '12'\n                vrf: test\n                graceful_restart_helper: False\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"isis\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show isis graceful-restart vrf all\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyISISGracefulRestart test.\"\"\"\n\n        instances: list[ISISInstance]\n        \"\"\"List of IS-IS instance entries.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyISISGracefulRestart.\"\"\"\n        self.result.is_success()\n\n        # Verify if IS-IS is configured\n        if not (command_output := self.instance_commands[0].json_output[\"vrfs\"]):\n            self.result.is_skipped(\"IS-IS not configured\")\n            return\n\n        # If IS-IS instance is not found or GR and GR helpers are not matching with the expected values, test fails.\n        for instance in self.inputs.instances:\n            graceful_restart = \"enabled\" if instance.graceful_restart else \"disabled\"\n            graceful_restart_helper = \"enabled\" if instance.graceful_restart_helper else \"disabled\"\n\n            if (instance_details := get_value(command_output, f\"{instance.vrf}..isisInstances..{instance.name}\", separator=\"..\")) is None:\n                self.result.is_failure(f\"{instance} - Not configured\")\n                continue\n\n            if (act_state := instance_details.get(\"gracefulRestart\")) != graceful_restart:\n                self.result.is_failure(f\"{instance} - Incorrect graceful restart state - Expected: {graceful_restart} Actual: {act_state}\")\n\n            if (act_helper_state := instance_details.get(\"gracefulRestartHelper\")) != graceful_restart_helper:\n                self.result.is_failure(f\"{instance} - Incorrect graceful restart helper state - Expected: {graceful_restart_helper} Actual: {act_helper_state}\")\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISGracefulRestart-attributes","title":"Inputs","text":"Name Type Description Default <code>instances</code> <code>list[ISISInstance]</code>                      List of IS-IS instance entries.                    -"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISInterfaceMode","title":"VerifyISISInterfaceMode","text":"<p>Verifies IS-IS interfaces are running in the correct mode.</p> Expected Results <ul> <li>Success: The test will pass if all provided IS-IS interfaces are running in the correct mode.</li> <li>Failure: The test will fail if any of the provided IS-IS interfaces are not configured or running in the incorrect mode.</li> <li>Skipped: The test will be skipped if IS-IS is not configured.</li> </ul> Examples <pre><code>anta.tests.routing:\n  isis:\n    - VerifyISISInterfaceMode:\n        interfaces:\n          - name: Loopback0\n            mode: passive\n          - name: Ethernet2\n            mode: passive\n            level: 2\n          - name: Ethernet1\n            mode: point-to-point\n            vrf: PROD\n</code></pre> Source code in <code>anta/tests/routing/isis.py</code> <pre><code>class VerifyISISInterfaceMode(AntaTest):\n    \"\"\"Verifies IS-IS interfaces are running in the correct mode.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all provided IS-IS interfaces are running in the correct mode.\n    * Failure: The test will fail if any of the provided IS-IS interfaces are not configured or running in the incorrect mode.\n    * Skipped: The test will be skipped if IS-IS is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      isis:\n        - VerifyISISInterfaceMode:\n            interfaces:\n              - name: Loopback0\n                mode: passive\n              - name: Ethernet2\n                mode: passive\n                level: 2\n              - name: Ethernet1\n                mode: point-to-point\n                vrf: PROD\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"isis\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show isis interface brief vrf all\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyISISInterfaceMode test.\"\"\"\n\n        interfaces: list[ISISInterface]\n        \"\"\"List of IS-IS interfaces with their information.\"\"\"\n        InterfaceState: ClassVar[type[InterfaceState]] = InterfaceState\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyISISInterfaceMode.\"\"\"\n        self.result.is_success()\n\n        # Verify if IS-IS is configured\n        if not (command_output := self.instance_commands[0].json_output[\"vrfs\"]):\n            self.result.is_skipped(\"IS-IS not configured\")\n            return\n\n        for interface in self.inputs.interfaces:\n            interface_detail = {}\n            vrf_instances = get_value(command_output, f\"{interface.vrf}..isisInstances\", default={}, separator=\"..\")\n            for instance_data in vrf_instances.values():\n                if interface_data := get_value(instance_data, f\"interfaces..{interface.name}\", separator=\"..\"):\n                    interface_detail = interface_data\n                    # An interface can only be configured in one IS-IS instance at a time\n                    break\n\n            if not interface_detail:\n                self.result.is_failure(f\"{interface} - Not configured\")\n                continue\n\n            # Check for passive\n            if interface.mode == \"passive\":\n                if get_value(interface_detail, f\"intfLevels.{interface.level}.passive\", default=False) is False:\n                    self.result.is_failure(f\"{interface} - Not running in passive mode\")\n\n            # Check for point-to-point or broadcast\n            elif interface.mode != (interface_type := get_value(interface_detail, \"interfaceType\", default=\"unset\")):\n                self.result.is_failure(f\"{interface} - Incorrect interface mode - Expected: {interface.mode} Actual: {interface_type}\")\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISInterfaceMode-attributes","title":"Inputs","text":"Name Type Description Default <code>interfaces</code> <code>list[ISISInterface]</code>                      List of IS-IS interfaces with their information.                    -"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISNeighborCount","title":"VerifyISISNeighborCount","text":"<p>Verifies the number of IS-IS neighbors per interface and level.</p> Expected Results <ul> <li>Success: The test will pass if all provided IS-IS interfaces have the expected number of neighbors.</li> <li>Failure: The test will fail if any of the provided IS-IS interfaces are not configured or have an incorrect number of neighbors.</li> <li>Skipped: The test will be skipped if IS-IS is not configured.</li> </ul> Examples <pre><code>anta.tests.routing:\n  isis:\n    - VerifyISISNeighborCount:\n        interfaces:\n          - name: Ethernet1\n            level: 1\n            count: 2\n          - name: Ethernet2\n            level: 2\n            count: 1\n          - name: Ethernet3\n            count: 2\n</code></pre> Source code in <code>anta/tests/routing/isis.py</code> <pre><code>class VerifyISISNeighborCount(AntaTest):\n    \"\"\"Verifies the number of IS-IS neighbors per interface and level.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all provided IS-IS interfaces have the expected number of neighbors.\n    * Failure: The test will fail if any of the provided IS-IS interfaces are not configured or have an incorrect number of neighbors.\n    * Skipped: The test will be skipped if IS-IS is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      isis:\n        - VerifyISISNeighborCount:\n            interfaces:\n              - name: Ethernet1\n                level: 1\n                count: 2\n              - name: Ethernet2\n                level: 2\n                count: 1\n              - name: Ethernet3\n                count: 2\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"isis\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show isis interface brief vrf all\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyISISNeighborCount test.\"\"\"\n\n        interfaces: list[ISISInterface]\n        \"\"\"List of IS-IS interfaces with their information.\"\"\"\n        InterfaceCount: ClassVar[type[InterfaceCount]] = InterfaceCount\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyISISNeighborCount.\"\"\"\n        self.result.is_success()\n\n        # Verify if IS-IS is configured\n        if not (command_output := self.instance_commands[0].json_output[\"vrfs\"]):\n            self.result.is_skipped(\"IS-IS not configured\")\n            return\n\n        for interface in self.inputs.interfaces:\n            interface_detail = {}\n            vrf_instances = get_value(command_output, f\"{interface.vrf}..isisInstances\", default={}, separator=\"..\")\n            for instance_data in vrf_instances.values():\n                if interface_data := get_value(instance_data, f\"interfaces..{interface.name}..intfLevels..{interface.level}\", separator=\"..\"):\n                    interface_detail = interface_data\n                    # An interface can only be configured in one IS-IS instance at a time\n                    break\n\n            if not interface_detail:\n                self.result.is_failure(f\"{interface} - Not configured\")\n                continue\n\n            if interface_detail[\"passive\"] is False and (act_count := interface_detail[\"numAdjacencies\"]) != interface.count:\n                self.result.is_failure(f\"{interface} - Neighbor count mismatch - Expected: {interface.count} Actual: {act_count}\")\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISNeighborCount-attributes","title":"Inputs","text":"Name Type Description Default <code>interfaces</code> <code>list[ISISInterface]</code>                      List of IS-IS interfaces with their information.                    -"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISNeighborState","title":"VerifyISISNeighborState","text":"<p>Verifies the health of IS-IS neighbors.</p> Expected Results <ul> <li>Success: The test will pass if all IS-IS neighbors are in the <code>up</code> state.</li> <li>Failure: The test will fail if any IS-IS neighbor adjacency is down.</li> <li>Skipped: The test will be skipped if IS-IS is not configured or no IS-IS neighbor is found.</li> </ul> Examples <pre><code>anta.tests.routing:\n  isis:\n    - VerifyISISNeighborState:\n        check_all_vrfs: true\n</code></pre> Source code in <code>anta/tests/routing/isis.py</code> <pre><code>class VerifyISISNeighborState(AntaTest):\n    \"\"\"Verifies the health of IS-IS neighbors.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all IS-IS neighbors are in the `up` state.\n    * Failure: The test will fail if any IS-IS neighbor adjacency is down.\n    * Skipped: The test will be skipped if IS-IS is not configured or no IS-IS neighbor is found.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      isis:\n        - VerifyISISNeighborState:\n            check_all_vrfs: true\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"isis\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show isis neighbors vrf all\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyISISNeighborState test.\"\"\"\n\n        check_all_vrfs: bool = False\n        \"\"\"If enabled, verifies IS-IS instances of all VRFs.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyISISNeighborState.\"\"\"\n        self.result.is_success()\n\n        # Verify if IS-IS is configured\n        if not (command_output := self.instance_commands[0].json_output[\"vrfs\"]):\n            self.result.is_skipped(\"IS-IS not configured\")\n            return\n\n        vrfs_to_check = command_output\n        if not self.inputs.check_all_vrfs:\n            vrfs_to_check = {\"default\": command_output[\"default\"]}\n\n        no_neighbor = True\n        for vrf, vrf_data in vrfs_to_check.items():\n            for isis_instance, instance_data in vrf_data[\"isisInstances\"].items():\n                neighbors = instance_data[\"neighbors\"]\n                if not neighbors:\n                    continue\n                no_neighbor = False\n                interfaces = [(adj[\"interfaceName\"], adj[\"state\"]) for neighbor in neighbors.values() for adj in neighbor[\"adjacencies\"] if adj[\"state\"] != \"up\"]\n                for interface in interfaces:\n                    self.result.is_failure(\n                        f\"Instance: {isis_instance} VRF: {vrf} Interface: {interface[0]} - Incorrect adjacency state - Expected: up Actual: {interface[1]}\"\n                    )\n\n        if no_neighbor:\n            self.result.is_skipped(\"No IS-IS neighbor detected\")\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISNeighborState-attributes","title":"Inputs","text":"Name Type Description Default <code>check_all_vrfs</code> <code>bool</code>                      If enabled, verifies IS-IS instances of all VRFs.                    <code>False</code>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISSegmentRoutingAdjacencySegments","title":"VerifyISISSegmentRoutingAdjacencySegments","text":"<p>Verifies IS-IS segment routing adjacency segments.</p> <p>IS-IS SR Limitation</p> <p>As of EOS 4.33.1F, IS-IS SR is supported only in the default VRF. Please refer to the IS-IS Segment Routing documentation for more information.</p> Expected Results <ul> <li>Success: The test will pass if all provided IS-IS instances have the correct adjacency segments.</li> <li>Failure: The test will fail if any of the provided IS-IS instances have no adjacency segments or incorrect segments.</li> <li>Skipped: The test will be skipped if IS-IS is not configured.</li> </ul> Examples <pre><code>anta.tests.routing:\n  isis:\n    - VerifyISISSegmentRoutingAdjacencySegments:\n        instances:\n          - name: CORE-ISIS\n            vrf: default\n            segments:\n              - interface: Ethernet2\n                address: 10.0.1.3\n                sid_origin: dynamic\n</code></pre> Source code in <code>anta/tests/routing/isis.py</code> <pre><code>class VerifyISISSegmentRoutingAdjacencySegments(AntaTest):\n    \"\"\"Verifies IS-IS segment routing adjacency segments.\n\n    !!! warning \"IS-IS SR Limitation\"\n        As of EOS 4.33.1F, IS-IS SR is supported only in the default VRF.\n        Please refer to the IS-IS Segment Routing [documentation](https://www.arista.com/en/support/toi/eos-4-17-0f/13789-isis-segment-routing)\n        for more information.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all provided IS-IS instances have the correct adjacency segments.\n    * Failure: The test will fail if any of the provided IS-IS instances have no adjacency segments or incorrect segments.\n    * Skipped: The test will be skipped if IS-IS is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      isis:\n        - VerifyISISSegmentRoutingAdjacencySegments:\n            instances:\n              - name: CORE-ISIS\n                vrf: default\n                segments:\n                  - interface: Ethernet2\n                    address: 10.0.1.3\n                    sid_origin: dynamic\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"isis\", \"segment-routing\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show isis segment-routing adjacency-segments\", ofmt=\"json\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyISISSegmentRoutingAdjacencySegments test.\"\"\"\n\n        instances: list[ISISInstance]\n        \"\"\"List of IS-IS instances with their information.\"\"\"\n        IsisInstance: ClassVar[type[IsisInstance]] = IsisInstance\n\n        @field_validator(\"instances\")\n        @classmethod\n        def validate_instances(cls, instances: list[ISISInstance]) -&gt; list[ISISInstance]:\n            \"\"\"Validate that 'vrf' field is 'default' in each IS-IS instance.\"\"\"\n            for instance in instances:\n                if instance.vrf != \"default\":\n                    msg = f\"{instance} 'vrf' field must be 'default'\"\n                    raise ValueError(msg)\n            return instances\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyISISSegmentRoutingAdjacencySegments.\"\"\"\n        self.result.is_success()\n\n        # Verify if IS-IS is configured\n        if not (command_output := self.instance_commands[0].json_output[\"vrfs\"]):\n            self.result.is_skipped(\"IS-IS not configured\")\n            return\n\n        for instance in self.inputs.instances:\n            if not (act_segments := get_value(command_output, f\"{instance.vrf}..isisInstances..{instance.name}..adjacencySegments\", default=[], separator=\"..\")):\n                self.result.is_failure(f\"{instance} - No adjacency segments found\")\n                continue\n\n            for segment in instance.segments:\n                if (act_segment := get_item(act_segments, \"ipAddress\", str(segment.address))) is None:\n                    self.result.is_failure(f\"{instance} {segment} - Adjacency segment not found\")\n                    continue\n\n                # Check SID origin\n                if (act_origin := act_segment[\"sidOrigin\"]) != segment.sid_origin:\n                    self.result.is_failure(f\"{instance} {segment} - Incorrect SID origin - Expected: {segment.sid_origin} Actual: {act_origin}\")\n\n                # Check IS-IS level\n                if (actual_level := act_segment[\"level\"]) != segment.level:\n                    self.result.is_failure(f\"{instance} {segment} - Incorrect IS-IS level - Expected: {segment.level} Actual: {actual_level}\")\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISSegmentRoutingAdjacencySegments-attributes","title":"Inputs","text":"Name Type Description Default <code>instances</code> <code>list[ISISInstance]</code>                      List of IS-IS instances with their information.                    -"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISSegmentRoutingDataplane","title":"VerifyISISSegmentRoutingDataplane","text":"<p>Verifies IS-IS segment routing data-plane configuration.</p> <p>IS-IS SR Limitation</p> <p>As of EOS 4.33.1F, IS-IS SR is supported only in the default VRF. Please refer to the IS-IS Segment Routing documentation for more information.</p> Expected Results <ul> <li>Success: The test will pass if all provided IS-IS instances have the correct data-plane configured.</li> <li>Failure: The test will fail if any of the provided IS-IS instances have an incorrect data-plane configured.</li> <li>Skipped: The test will be skipped if IS-IS is not configured.</li> </ul> Examples <pre><code>anta.tests.routing:\n  isis:\n    - VerifyISISSegmentRoutingDataplane:\n        instances:\n          - name: CORE-ISIS\n            vrf: default\n            dataplane: MPLS\n</code></pre> Source code in <code>anta/tests/routing/isis.py</code> <pre><code>class VerifyISISSegmentRoutingDataplane(AntaTest):\n    \"\"\"Verifies IS-IS segment routing data-plane configuration.\n\n    !!! warning \"IS-IS SR Limitation\"\n        As of EOS 4.33.1F, IS-IS SR is supported only in the default VRF.\n        Please refer to the IS-IS Segment Routing [documentation](https://www.arista.com/en/support/toi/eos-4-17-0f/13789-isis-segment-routing)\n        for more information.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all provided IS-IS instances have the correct data-plane configured.\n    * Failure: The test will fail if any of the provided IS-IS instances have an incorrect data-plane configured.\n    * Skipped: The test will be skipped if IS-IS is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      isis:\n        - VerifyISISSegmentRoutingDataplane:\n            instances:\n              - name: CORE-ISIS\n                vrf: default\n                dataplane: MPLS\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"isis\", \"segment-routing\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show isis segment-routing\", ofmt=\"json\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyISISSegmentRoutingDataplane test.\"\"\"\n\n        instances: list[ISISInstance]\n        \"\"\"List of IS-IS instances with their information.\"\"\"\n        IsisInstance: ClassVar[type[IsisInstance]] = IsisInstance\n\n        @field_validator(\"instances\")\n        @classmethod\n        def validate_instances(cls, instances: list[ISISInstance]) -&gt; list[ISISInstance]:\n            \"\"\"Validate that 'vrf' field is 'default' in each IS-IS instance.\"\"\"\n            for instance in instances:\n                if instance.vrf != \"default\":\n                    msg = f\"{instance} 'vrf' field must be 'default'\"\n                    raise ValueError(msg)\n            return instances\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyISISSegmentRoutingDataplane.\"\"\"\n        self.result.is_success()\n\n        # Verify if IS-IS is configured\n        if not (command_output := self.instance_commands[0].json_output[\"vrfs\"]):\n            self.result.is_skipped(\"IS-IS not configured\")\n            return\n\n        for instance in self.inputs.instances:\n            if not (instance_data := get_value(command_output, f\"{instance.vrf}..isisInstances..{instance.name}\", separator=\"..\")):\n                self.result.is_failure(f\"{instance} - Not configured\")\n                continue\n\n            if instance.dataplane.upper() != (dataplane := instance_data[\"dataPlane\"]):\n                self.result.is_failure(f\"{instance} - Data-plane not correctly configured - Expected: {instance.dataplane.upper()} Actual: {dataplane}\")\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISSegmentRoutingDataplane-attributes","title":"Inputs","text":"Name Type Description Default <code>instances</code> <code>list[ISISInstance]</code>                      List of IS-IS instances with their information.                    -"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISSegmentRoutingTunnels","title":"VerifyISISSegmentRoutingTunnels","text":"<p>Verify ISIS-SR tunnels computed by device.</p> Expected Results <ul> <li>Success: The test will pass if all listed tunnels are computed on device.</li> <li>Failure: The test will fail if one of the listed tunnels is missing.</li> <li>Skipped: The test will be skipped if ISIS-SR is not configured.</li> </ul> Examples <pre><code>anta.tests.routing:\n  isis:\n    - VerifyISISSegmentRoutingTunnels:\n        entries:\n          # Check only endpoint\n          - endpoint: 1.0.0.122/32\n          # Check endpoint and via TI-LFA\n          - endpoint: 1.0.0.13/32\n            vias:\n              - type: tunnel\n                tunnel_id: ti-lfa\n          # Check endpoint and via IP routers\n          - endpoint: 1.0.0.14/32\n            vias:\n              - type: ip\n                nexthop: 1.1.1.1\n</code></pre> Source code in <code>anta/tests/routing/isis.py</code> <pre><code>class VerifyISISSegmentRoutingTunnels(AntaTest):\n    \"\"\"Verify ISIS-SR tunnels computed by device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all listed tunnels are computed on device.\n    * Failure: The test will fail if one of the listed tunnels is missing.\n    * Skipped: The test will be skipped if ISIS-SR is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      isis:\n        - VerifyISISSegmentRoutingTunnels:\n            entries:\n              # Check only endpoint\n              - endpoint: 1.0.0.122/32\n              # Check endpoint and via TI-LFA\n              - endpoint: 1.0.0.13/32\n                vias:\n                  - type: tunnel\n                    tunnel_id: ti-lfa\n              # Check endpoint and via IP routers\n              - endpoint: 1.0.0.14/32\n                vias:\n                  - type: ip\n                    nexthop: 1.1.1.1\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"isis\", \"segment-routing\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show isis segment-routing tunnel\", ofmt=\"json\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyISISSegmentRoutingTunnels test.\"\"\"\n\n        entries: list[Tunnel]\n        \"\"\"List of tunnels to check on device.\"\"\"\n        Entry: ClassVar[type[Entry]] = Entry\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyISISSegmentRoutingTunnels.\n\n        This method performs the main test logic for verifying ISIS Segment Routing tunnels.\n        It checks the command output, initiates defaults, and performs various checks on the tunnels.\n        \"\"\"\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output\n        if len(command_output[\"entries\"]) == 0:\n            self.result.is_skipped(\"IS-IS-SR not configured\")\n            return\n\n        for input_entry in self.inputs.entries:\n            entries = list(command_output[\"entries\"].values())\n            if (eos_entry := get_item(entries, \"endpoint\", str(input_entry.endpoint))) is None:\n                self.result.is_failure(f\"{input_entry} - Tunnel not found\")\n                continue\n\n            if input_entry.vias is not None:\n                for via_input in input_entry.vias:\n                    via_search_result = any(self._via_matches(via_input, eos_via) for eos_via in eos_entry[\"vias\"])\n                    if not via_search_result:\n                        self.result.is_failure(f\"{input_entry} {via_input} - Tunnel is incorrect\")\n\n    def _via_matches(self, via_input: TunnelPath, eos_via: dict[str, Any]) -&gt; bool:\n        \"\"\"Check if the via input matches the eos via.\n\n        Parameters\n        ----------\n        via_input : TunnelPath\n            The input via to check.\n        eos_via : dict[str, Any]\n            The EOS via to compare against.\n\n        Returns\n        -------\n        bool\n            True if the via input matches the eos via, False otherwise.\n        \"\"\"\n        return (\n            (via_input.type is None or via_input.type == eos_via.get(\"type\"))\n            and (via_input.nexthop is None or str(via_input.nexthop) == eos_via.get(\"nexthop\"))\n            and (via_input.interface is None or via_input.interface == eos_via.get(\"interface\"))\n            and (via_input.tunnel_id is None or via_input.tunnel_id.upper() == get_value(eos_via, \"tunnelId.type\", default=\"\").upper())\n        )\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.tests.routing.isis.VerifyISISSegmentRoutingTunnels-attributes","title":"Inputs","text":"Name Type Description Default <code>entries</code> <code>list[Tunnel]</code>                      List of tunnels to check on device.                    -"},{"location":"api/tests/routing.isis/#input-models","title":"Input models","text":"<p>Module containing input models for routing IS-IS tests.</p>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.Entry","title":"Entry","text":"<p>Alias for the Tunnel model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the Tunnel model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class Entry(Tunnel):  # pragma: no cover\n    \"\"\"Alias for the Tunnel model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the Tunnel model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the Entry class, emitting a deprecation warning.\"\"\"\n        warn(\n            message=\"Entry model is deprecated and will be removed in ANTA v2.0.0. Use the Tunnel model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.ISISInstance","title":"ISISInstance","text":"<p>Model for an IS-IS instance.</p> Name Type Description Default <code>name</code> <code>str</code>                      The name of the IS-IS instance.                    - <code>vrf</code> <code>str</code>                      VRF context of the IS-IS instance.                    <code>'default'</code> <code>dataplane</code> <code>Literal['MPLS', 'mpls', 'unset']</code>                      Configured SR data-plane for the IS-IS instance.                    <code>'MPLS'</code> <code>segments</code> <code>list[Segment] | None</code>                      List of IS-IS SR segments associated with the instance. Required field in the `VerifyISISSegmentRoutingAdjacencySegments` test.                    <code>None</code> <code>graceful_restart</code> <code>bool</code>                      Graceful restart status.                    <code>False</code> <code>graceful_restart_helper</code> <code>bool</code>                      Graceful restart helper status.                    <code>True</code> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class ISISInstance(BaseModel):\n    \"\"\"Model for an IS-IS instance.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    name: str\n    \"\"\"The name of the IS-IS instance.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"VRF context of the IS-IS instance.\"\"\"\n    dataplane: Literal[\"MPLS\", \"mpls\", \"unset\"] = \"MPLS\"\n    \"\"\"Configured SR data-plane for the IS-IS instance.\"\"\"\n    segments: list[Segment] | None = None\n    \"\"\"List of IS-IS SR segments associated with the instance. Required field in the `VerifyISISSegmentRoutingAdjacencySegments` test.\"\"\"\n    graceful_restart: bool = False\n    \"\"\"Graceful restart status.\"\"\"\n    graceful_restart_helper: bool = True\n    \"\"\"Graceful restart helper status.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the ISISInstance for reporting.\"\"\"\n        return f\"Instance: {self.name} VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.ISISInterface","title":"ISISInterface","text":"<p>Model for an IS-IS enabled interface.</p> Name Type Description Default <code>name</code> <code>Interface</code>                      Interface name.                    - <code>vrf</code> <code>str</code>                      VRF context of the interface.                    <code>'default'</code> <code>level</code> <code>Literal[1, 2]</code>                      IS-IS level of the interface.                    <code>2</code> <code>count</code> <code>int | None</code>                      Expected number of IS-IS neighbors on this interface. Required field in the `VerifyISISNeighborCount` test.                    <code>None</code> <code>mode</code> <code>Literal['point-to-point', 'broadcast', 'passive'] | None</code>                      IS-IS network type of the interface. Required field in the `VerifyISISInterfaceMode` test.                    <code>None</code> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class ISISInterface(BaseModel):\n    \"\"\"Model for an IS-IS enabled interface.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    name: Interface\n    \"\"\"Interface name.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"VRF context of the interface.\"\"\"\n    level: Literal[1, 2] = 2\n    \"\"\"IS-IS level of the interface.\"\"\"\n    count: int | None = None\n    \"\"\"Expected number of IS-IS neighbors on this interface. Required field in the `VerifyISISNeighborCount` test.\"\"\"\n    mode: Literal[\"point-to-point\", \"broadcast\", \"passive\"] | None = None\n    \"\"\"IS-IS network type of the interface. Required field in the `VerifyISISInterfaceMode` test.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the ISISInterface for reporting.\"\"\"\n        return f\"Interface: {self.name} VRF: {self.vrf} Level: {self.level}\"\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.InterfaceCount","title":"InterfaceCount","text":"<p>Alias for the ISISInterface model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the ISISInterface model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class InterfaceCount(ISISInterface):  # pragma: no cover\n    \"\"\"Alias for the ISISInterface model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the ISISInterface model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the InterfaceCount class, emitting a deprecation warning.\"\"\"\n        warn(\n            message=\"InterfaceCount model is deprecated and will be removed in ANTA v2.0.0. Use the ISISInterface model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.InterfaceState","title":"InterfaceState","text":"<p>Alias for the ISISInterface model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the ISISInterface model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class InterfaceState(ISISInterface):  # pragma: no cover\n    \"\"\"Alias for the ISISInterface model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the ISISInterface model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the InterfaceState class, emitting a deprecation warning.\"\"\"\n        warn(\n            message=\"InterfaceState model is deprecated and will be removed in ANTA v2.0.0. Use the ISISInterface model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.IsisInstance","title":"IsisInstance","text":"<p>Alias for the ISISInstance model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the ISISInstance model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class IsisInstance(ISISInstance):  # pragma: no cover\n    \"\"\"Alias for the ISISInstance model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the ISISInstance model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the IsisInstance class, emitting a deprecation warning.\"\"\"\n        warn(\n            message=\"IsisInstance model is deprecated and will be removed in ANTA v2.0.0. Use the ISISInstance model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.Segment","title":"Segment","text":"<p>Model for an IS-IS segment.</p> Name Type Description Default <code>interface</code> <code>Interface</code>                      Local interface name.                    - <code>level</code> <code>Literal[1, 2]</code>                      IS-IS level of the segment.                    <code>2</code> <code>sid_origin</code> <code>Literal['dynamic', 'configured']</code>                      Origin of the segment ID.                    <code>'dynamic'</code> <code>address</code> <code>IPv4Address</code>                      Adjacency IPv4 address of the segment.                    - Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class Segment(BaseModel):\n    \"\"\"Model for an IS-IS segment.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    interface: Interface\n    \"\"\"Local interface name.\"\"\"\n    level: Literal[1, 2] = 2\n    \"\"\"IS-IS level of the segment.\"\"\"\n    sid_origin: Literal[\"dynamic\", \"configured\"] = \"dynamic\"\n    \"\"\"Origin of the segment ID.\"\"\"\n    address: IPv4Address\n    \"\"\"Adjacency IPv4 address of the segment.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the Segment for reporting.\"\"\"\n        return f\"Local Intf: {self.interface} Adj IP Address: {self.address}\"\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.Tunnel","title":"Tunnel","text":"<p>Model for a IS-IS SR tunnel.</p> Name Type Description Default <code>endpoint</code> <code>IPv4Network</code>                      Endpoint of the tunnel.                    - <code>vias</code> <code>list[TunnelPath] | None</code>                      Optional list of paths to reach the endpoint.                    <code>None</code> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class Tunnel(BaseModel):\n    \"\"\"Model for a IS-IS SR tunnel.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    endpoint: IPv4Network\n    \"\"\"Endpoint of the tunnel.\"\"\"\n    vias: list[TunnelPath] | None = None\n    \"\"\"Optional list of paths to reach the endpoint.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the Tunnel for reporting.\"\"\"\n        return f\"Endpoint: {self.endpoint}\"\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.TunnelPath","title":"TunnelPath","text":"<p>Model for a IS-IS tunnel path.</p> Name Type Description Default <code>nexthop</code> <code>IPv4Address | None</code>                      Nexthop of the tunnel.                    <code>None</code> <code>type</code> <code>Literal['ip', 'tunnel'] | None</code>                      Type of the tunnel.                    <code>None</code> <code>interface</code> <code>Interface | None</code>                      Interface of the tunnel.                    <code>None</code> <code>tunnel_id</code> <code>Literal['TI-LFA', 'ti-lfa', 'unset'] | None</code>                      Computation method of the tunnel.                    <code>None</code> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class TunnelPath(BaseModel):\n    \"\"\"Model for a IS-IS tunnel path.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    nexthop: IPv4Address | None = None\n    \"\"\"Nexthop of the tunnel.\"\"\"\n    type: Literal[\"ip\", \"tunnel\"] | None = None\n    \"\"\"Type of the tunnel.\"\"\"\n    interface: Interface | None = None\n    \"\"\"Interface of the tunnel.\"\"\"\n    tunnel_id: Literal[\"TI-LFA\", \"ti-lfa\", \"unset\"] | None = None\n    \"\"\"Computation method of the tunnel.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the TunnelPath for reporting.\"\"\"\n        base_string = \"\"\n        if self.nexthop:\n            base_string += f\" Next-hop: {self.nexthop}\"\n        if self.type:\n            base_string += f\" Type: {self.type}\"\n        if self.interface:\n            base_string += f\" Interface: {self.interface}\"\n        if self.tunnel_id:\n            base_string += f\" Tunnel ID: {self.tunnel_id}\"\n\n        return base_string.lstrip()\n</code></pre>"},{"location":"api/tests/routing.isis/#anta.input_models.routing.isis.Vias","title":"Vias","text":"<p>Alias for the TunnelPath model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the TunnelPath model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/routing/isis.py</code> <pre><code>class Vias(TunnelPath):  # pragma: no cover\n    \"\"\"Alias for the TunnelPath model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the TunnelPath model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the Vias class, emitting a deprecation warning.\"\"\"\n        warn(\n            message=\"Vias model is deprecated and will be removed in ANTA v2.0.0. Use the TunnelPath model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/routing.ospf/","title":"OSPF","text":"<p>Module related to OSPF tests.</p>"},{"location":"api/tests/routing.ospf/#anta.tests.routing.ospf.VerifyOSPFMaxLSA","title":"VerifyOSPFMaxLSA","text":"<p>Verifies all OSPF instances did not cross the maximum LSA threshold.</p> Expected Results <ul> <li>Success: The test will pass if all OSPF instances did not cross the maximum LSA Threshold.</li> <li>Failure: The test will fail if some OSPF instances crossed the maximum LSA Threshold.</li> <li>Skipped: The test will be skipped if no OSPF instance is found.</li> </ul> Examples <pre><code>anta.tests.routing:\n  ospf:\n    - VerifyOSPFMaxLSA:\n</code></pre> Source code in <code>anta/tests/routing/ospf.py</code> <pre><code>class VerifyOSPFMaxLSA(AntaTest):\n    \"\"\"Verifies all OSPF instances did not cross the maximum LSA threshold.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all OSPF instances did not cross the maximum LSA Threshold.\n    * Failure: The test will fail if some OSPF instances crossed the maximum LSA Threshold.\n    * Skipped: The test will be skipped if no OSPF instance is found.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      ospf:\n        - VerifyOSPFMaxLSA:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"ospf\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip ospf\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyOSPFMaxLSA.\"\"\"\n        self.result.is_success()\n\n        # If OSPF is not configured on device, test skipped.\n        if not (command_output := get_value(self.instance_commands[0].json_output, \"vrfs\")):\n            self.result.is_skipped(\"OSPF not configured\")\n            return\n\n        for vrf_data in command_output.values():\n            for instance, instance_data in vrf_data.get(\"instList\", {}).items():\n                max_lsa = instance_data[\"maxLsaInformation\"][\"maxLsa\"]\n                max_lsa_threshold = instance_data[\"maxLsaInformation\"][\"maxLsaThreshold\"]\n                num_lsa = get_value(instance_data, \"lsaInformation.numLsa\")\n                if num_lsa &gt; (max_lsa_threshold := round(max_lsa * (max_lsa_threshold / 100))):\n                    self.result.is_failure(f\"Instance: {instance} - Crossed the maximum LSA threshold - Expected: &lt; {max_lsa_threshold} Actual: {num_lsa}\")\n</code></pre>"},{"location":"api/tests/routing.ospf/#anta.tests.routing.ospf.VerifyOSPFNeighborCount","title":"VerifyOSPFNeighborCount","text":"<p>Verifies the number of OSPF neighbors in FULL state is the one we expect.</p> Expected Results <ul> <li>Success: The test will pass if the number of OSPF neighbors in FULL state is the one we expect.</li> <li>Failure: The test will fail if the number of OSPF neighbors in FULL state is not the one we expect.</li> <li>Skipped: The test will be skipped if no OSPF neighbor is found.</li> </ul> Examples <pre><code>anta.tests.routing:\n  ospf:\n    - VerifyOSPFNeighborCount:\n        number: 3\n</code></pre> Source code in <code>anta/tests/routing/ospf.py</code> <pre><code>class VerifyOSPFNeighborCount(AntaTest):\n    \"\"\"Verifies the number of OSPF neighbors in FULL state is the one we expect.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the number of OSPF neighbors in FULL state is the one we expect.\n    * Failure: The test will fail if the number of OSPF neighbors in FULL state is not the one we expect.\n    * Skipped: The test will be skipped if no OSPF neighbor is found.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      ospf:\n        - VerifyOSPFNeighborCount:\n            number: 3\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"ospf\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip ospf neighbor\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyOSPFNeighborCount test.\"\"\"\n\n        number: int\n        \"\"\"The expected number of OSPF neighbors in FULL state.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyOSPFNeighborCount.\"\"\"\n        self.result.is_success()\n        # If OSPF is not configured on device, test skipped.\n        if not (command_output := get_value(self.instance_commands[0].json_output, \"vrfs\")):\n            self.result.is_skipped(\"OSPF not configured\")\n            return\n\n        no_neighbor = True\n        interfaces = []\n        for vrf_data in command_output.values():\n            for instance_data in vrf_data[\"instList\"].values():\n                neighbors = instance_data[\"ospfNeighborEntries\"]\n                if not neighbors:\n                    continue\n                no_neighbor = False\n                interfaces.extend([neighbor[\"routerId\"] for neighbor in neighbors if neighbor[\"adjacencyState\"] == \"full\"])\n\n        # If OSPF neighbors are not configured on device, test skipped.\n        if no_neighbor:\n            self.result.is_skipped(\"No OSPF neighbor detected\")\n            return\n\n        # If the number of OSPF neighbors expected to be in the FULL state does not match with actual one, test fails.\n        if len(interfaces) != self.inputs.number:\n            self.result.is_failure(f\"Neighbor count mismatch - Expected: {self.inputs.number} Actual: {len(interfaces)}\")\n</code></pre>"},{"location":"api/tests/routing.ospf/#anta.tests.routing.ospf.VerifyOSPFNeighborCount-attributes","title":"Inputs","text":"Name Type Description Default <code>number</code> <code>int</code>                      The expected number of OSPF neighbors in FULL state.                    -"},{"location":"api/tests/routing.ospf/#anta.tests.routing.ospf.VerifyOSPFNeighborState","title":"VerifyOSPFNeighborState","text":"<p>Verifies all OSPF neighbors are in FULL state.</p> Expected Results <ul> <li>Success: The test will pass if all OSPF neighbors are in FULL state.</li> <li>Failure: The test will fail if some OSPF neighbors are not in FULL state.</li> <li>Skipped: The test will be skipped if no OSPF neighbor is found.</li> </ul> Examples <pre><code>anta.tests.routing:\n  ospf:\n    - VerifyOSPFNeighborState:\n</code></pre> Source code in <code>anta/tests/routing/ospf.py</code> <pre><code>class VerifyOSPFNeighborState(AntaTest):\n    \"\"\"Verifies all OSPF neighbors are in FULL state.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all OSPF neighbors are in FULL state.\n    * Failure: The test will fail if some OSPF neighbors are not in FULL state.\n    * Skipped: The test will be skipped if no OSPF neighbor is found.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.routing:\n      ospf:\n        - VerifyOSPFNeighborState:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"ospf\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip ospf neighbor\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyOSPFNeighborState.\"\"\"\n        self.result.is_success()\n\n        # If OSPF is not configured on device, test skipped.\n        if not (command_output := get_value(self.instance_commands[0].json_output, \"vrfs\")):\n            self.result.is_skipped(\"OSPF not configured\")\n            return\n\n        no_neighbor = True\n        for vrf, vrf_data in command_output.items():\n            for instance, instance_data in vrf_data[\"instList\"].items():\n                neighbors = instance_data[\"ospfNeighborEntries\"]\n                if not neighbors:\n                    continue\n                no_neighbor = False\n                interfaces = [(neighbor[\"routerId\"], state) for neighbor in neighbors if (state := neighbor[\"adjacencyState\"]) != \"full\"]\n                for interface in interfaces:\n                    self.result.is_failure(\n                        f\"Instance: {instance} VRF: {vrf} Interface: {interface[0]} - Incorrect adjacency state - Expected: Full Actual: {interface[1]}\"\n                    )\n\n        # If OSPF neighbors are not configured on device, test skipped.\n        if no_neighbor:\n            self.result.is_skipped(\"No OSPF neighbor detected\")\n</code></pre>"},{"location":"api/tests/security/","title":"Security","text":""},{"location":"api/tests/security/#tests","title":"Tests","text":"<p>Module related to the EOS various security tests.</p>"},{"location":"api/tests/security/#anta.tests.security.VerifyAPIHttpStatus","title":"VerifyAPIHttpStatus","text":"<p>Verifies if eAPI HTTP server is disabled globally.</p> Expected Results <ul> <li>Success: The test will pass if eAPI HTTP server is disabled globally.</li> <li>Failure: The test will fail if eAPI HTTP server is NOT disabled globally.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyAPIHttpStatus:\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyAPIHttpStatus(AntaTest):\n    \"\"\"Verifies if eAPI HTTP server is disabled globally.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if eAPI HTTP server is disabled globally.\n    * Failure: The test will fail if eAPI HTTP server is NOT disabled globally.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyAPIHttpStatus:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management api http-commands\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAPIHttpStatus.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        if command_output[\"enabled\"] and not command_output[\"httpServer\"][\"running\"]:\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"eAPI HTTP server is enabled globally\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyAPIHttpsSSL","title":"VerifyAPIHttpsSSL","text":"<p>Verifies if the eAPI has a valid SSL profile.</p> Expected Results <ul> <li>Success: The test will pass if the eAPI HTTPS server SSL profile is configured and valid.</li> <li>Failure: The test will fail if the eAPI HTTPS server SSL profile is NOT configured, misconfigured or invalid.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyAPIHttpsSSL:\n      profile: default\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyAPIHttpsSSL(AntaTest):\n    \"\"\"Verifies if the eAPI has a valid SSL profile.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the eAPI HTTPS server SSL profile is configured and valid.\n    * Failure: The test will fail if the eAPI HTTPS server SSL profile is NOT configured, misconfigured or invalid.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyAPIHttpsSSL:\n          profile: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management api http-commands\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyAPIHttpsSSL test.\"\"\"\n\n        profile: str\n        \"\"\"SSL profile to verify.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAPIHttpsSSL.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        try:\n            if command_output[\"sslProfile\"][\"name\"] == self.inputs.profile and command_output[\"sslProfile\"][\"state\"] == \"valid\":\n                self.result.is_success()\n            else:\n                self.result.is_failure(f\"eAPI HTTPS server SSL profile {self.inputs.profile} is misconfigured or invalid\")\n\n        except KeyError:\n            self.result.is_failure(f\"eAPI HTTPS server SSL profile {self.inputs.profile} is not configured\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyAPIHttpsSSL-attributes","title":"Inputs","text":"Name Type Description Default <code>profile</code> <code>str</code>                      SSL profile to verify.                    -"},{"location":"api/tests/security/#anta.tests.security.VerifyAPIIPv4Acl","title":"VerifyAPIIPv4Acl","text":"<p>Verifies if eAPI has the right number IPv4 ACL(s) configured for a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if eAPI has the provided number of IPv4 ACL(s) in the specified VRF.</li> <li>Failure: The test will fail if eAPI has not the right number of IPv4 ACL(s) in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyAPIIPv4Acl:\n      number: 3\n      vrf: default\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyAPIIPv4Acl(AntaTest):\n    \"\"\"Verifies if eAPI has the right number IPv4 ACL(s) configured for a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if eAPI has the provided number of IPv4 ACL(s) in the specified VRF.\n    * Failure: The test will fail if eAPI has not the right number of IPv4 ACL(s) in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyAPIIPv4Acl:\n          number: 3\n          vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management api http-commands ip access-list summary\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input parameters for the VerifyAPIIPv4Acl test.\"\"\"\n\n        number: PositiveInteger\n        \"\"\"The number of expected IPv4 ACL(s).\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF in which to check for eAPI. Defaults to `default` VRF.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAPIIPv4Acl.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        ipv4_acl_list = command_output[\"ipAclList\"][\"aclList\"]\n        ipv4_acl_number = len(ipv4_acl_list)\n        if ipv4_acl_number != self.inputs.number:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - eAPI IPv4 ACL(s) count mismatch - Expected: {self.inputs.number} Actual: {ipv4_acl_number}\")\n            return\n\n        not_configured_acl = [acl[\"name\"] for acl in ipv4_acl_list if self.inputs.vrf not in acl[\"configuredVrfs\"] or self.inputs.vrf not in acl[\"activeVrfs\"]]\n\n        if not_configured_acl:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - Following eAPI IPv4 ACL(s) not configured or active: {', '.join(not_configured_acl)}\")\n        else:\n            self.result.is_success()\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyAPIIPv4Acl-attributes","title":"Inputs","text":"Name Type Description Default <code>number</code> <code>PositiveInteger</code>                      The number of expected IPv4 ACL(s).                    - <code>vrf</code> <code>str</code>                      The name of the VRF in which to check for eAPI. Defaults to `default` VRF.                    <code>'default'</code>"},{"location":"api/tests/security/#anta.tests.security.VerifyAPIIPv6Acl","title":"VerifyAPIIPv6Acl","text":"<p>Verifies if eAPI has the right number IPv6 ACL(s) configured for a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if eAPI has the provided number of IPv6 ACL(s) in the specified VRF.</li> <li>Failure: The test will fail if eAPI has not the right number of IPv6 ACL(s) in the specified VRF.</li> <li>Skipped: The test will be skipped if the number of IPv6 ACL(s) or VRF parameter is not provided.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyAPIIPv6Acl:\n      number: 3\n      vrf: default\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyAPIIPv6Acl(AntaTest):\n    \"\"\"Verifies if eAPI has the right number IPv6 ACL(s) configured for a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if eAPI has the provided number of IPv6 ACL(s) in the specified VRF.\n    * Failure: The test will fail if eAPI has not the right number of IPv6 ACL(s) in the specified VRF.\n    * Skipped: The test will be skipped if the number of IPv6 ACL(s) or VRF parameter is not provided.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyAPIIPv6Acl:\n          number: 3\n          vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management api http-commands ipv6 access-list summary\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input parameters for the VerifyAPIIPv6Acl test.\"\"\"\n\n        number: PositiveInteger\n        \"\"\"The number of expected IPv6 ACL(s).\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF in which to check for eAPI. Defaults to `default` VRF.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAPIIPv6Acl.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        ipv6_acl_list = command_output[\"ipv6AclList\"][\"aclList\"]\n        ipv6_acl_number = len(ipv6_acl_list)\n        if ipv6_acl_number != self.inputs.number:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - eAPI IPv6 ACL(s) count mismatch - Expected: {self.inputs.number} Actual: {ipv6_acl_number}\")\n            return\n\n        not_configured_acl = [acl[\"name\"] for acl in ipv6_acl_list if self.inputs.vrf not in acl[\"configuredVrfs\"] or self.inputs.vrf not in acl[\"activeVrfs\"]]\n\n        if not_configured_acl:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - Following eAPI IPv6 ACL(s) not configured or active: {', '.join(not_configured_acl)}\")\n        else:\n            self.result.is_success()\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyAPIIPv6Acl-attributes","title":"Inputs","text":"Name Type Description Default <code>number</code> <code>PositiveInteger</code>                      The number of expected IPv6 ACL(s).                    - <code>vrf</code> <code>str</code>                      The name of the VRF in which to check for eAPI. Defaults to `default` VRF.                    <code>'default'</code>"},{"location":"api/tests/security/#anta.tests.security.VerifyAPISSLCertificate","title":"VerifyAPISSLCertificate","text":"<p>Verifies the eAPI SSL certificate expiry, common subject name, encryption algorithm and key size.</p> <p>This test performs the following checks for each certificate:</p> <ol> <li>Validates that the certificate is not expired and meets the configured expiry threshold.</li> <li>Validates that the certificate Common Name matches the expected one.</li> <li>Ensures the certificate uses the specified encryption algorithm.</li> <li>Verifies the certificate key matches the expected key size.</li> </ol> Expected Results <ul> <li>Success: If all of the following occur:<ul> <li>The certificate\u2019s expiry date exceeds the configured threshold.</li> <li>The certificate\u2019s Common Name matches the input configuration.</li> <li>The encryption algorithm used by the certificate is as expected.</li> <li>The key size of the certificate matches the input configuration.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>The certificate is expired or set to expire within the defined threshold.</li> <li>The certificate\u2019s common name does not match the expected input.</li> <li>The encryption algorithm is incorrect.</li> <li>The key size does not match the expected input.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyAPISSLCertificate:\n      certificates:\n        - certificate_name: ARISTA_SIGNING_CA.crt\n          expiry_threshold: 30\n          common_name: AristaIT-ICA ECDSA Issuing Cert Authority\n          encryption_algorithm: ECDSA\n          key_size: 256\n        - certificate_name: ARISTA_ROOT_CA.crt\n          expiry_threshold: 30\n          common_name: Arista Networks Internal IT Root Cert Authority\n          encryption_algorithm: RSA\n          key_size: 4096\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyAPISSLCertificate(AntaTest):\n    \"\"\"Verifies the eAPI SSL certificate expiry, common subject name, encryption algorithm and key size.\n\n    This test performs the following checks for each certificate:\n\n      1. Validates that the certificate is not expired and meets the configured expiry threshold.\n      2. Validates that the certificate Common Name matches the expected one.\n      3. Ensures the certificate uses the specified encryption algorithm.\n      4. Verifies the certificate key matches the expected key size.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following occur:\n        - The certificate's expiry date exceeds the configured threshold.\n        - The certificate's Common Name matches the input configuration.\n        - The encryption algorithm used by the certificate is as expected.\n        - The key size of the certificate matches the input configuration.\n    * Failure: If any of the following occur:\n        - The certificate is expired or set to expire within the defined threshold.\n        - The certificate's common name does not match the expected input.\n        - The encryption algorithm is incorrect.\n        - The key size does not match the expected input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyAPISSLCertificate:\n          certificates:\n            - certificate_name: ARISTA_SIGNING_CA.crt\n              expiry_threshold: 30\n              common_name: AristaIT-ICA ECDSA Issuing Cert Authority\n              encryption_algorithm: ECDSA\n              key_size: 256\n            - certificate_name: ARISTA_ROOT_CA.crt\n              expiry_threshold: 30\n              common_name: Arista Networks Internal IT Root Cert Authority\n              encryption_algorithm: RSA\n              key_size: 4096\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaCommand(command=\"show management security ssl certificate\", revision=1),\n        AntaCommand(command=\"show clock\", revision=1),\n    ]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input parameters for the VerifyAPISSLCertificate test.\"\"\"\n\n        certificates: list[APISSLCertificate]\n        \"\"\"List of API SSL certificates.\"\"\"\n        APISSLCertificate: ClassVar[type[APISSLCertificate]] = APISSLCertificate\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAPISSLCertificate.\"\"\"\n        # Mark the result as success by default\n        self.result.is_success()\n\n        # Extract certificate and clock output\n        certificate_output = self.instance_commands[0].json_output\n        clock_output = self.instance_commands[1].json_output\n        current_timestamp = clock_output[\"utcTime\"]\n\n        # Iterate over each API SSL certificate\n        for certificate in self.inputs.certificates:\n            # Collecting certificate expiry time and current EOS time.\n            # These times are used to calculate the number of days until the certificate expires.\n            if not (certificate_data := get_value(certificate_output, f\"certificates..{certificate.certificate_name}\", separator=\"..\")):\n                self.result.is_failure(f\"{certificate} - Not found\")\n                continue\n\n            expiry_time = certificate_data[\"notAfter\"]\n            day_difference = (datetime.fromtimestamp(expiry_time, tz=timezone.utc) - datetime.fromtimestamp(current_timestamp, tz=timezone.utc)).days\n\n            # Verify certificate expiry\n            if 0 &lt; day_difference &lt; certificate.expiry_threshold:\n                self.result.is_failure(\n                    f\"{certificate} - set to expire within the threshold - Threshold: {certificate.expiry_threshold} days Actual: {day_difference} days\"\n                )\n            elif day_difference &lt; 0:\n                self.result.is_failure(f\"{certificate} - certificate expired\")\n\n            # Verify certificate common subject name, encryption algorithm and key size\n            common_name = get_value(certificate_data, \"subject.commonName\", default=\"Not found\")\n            encryp_algo = get_value(certificate_data, \"publicKey.encryptionAlgorithm\", default=\"Not found\")\n            key_size = get_value(certificate_data, \"publicKey.size\", default=\"Not found\")\n\n            if common_name != certificate.common_name:\n                self.result.is_failure(f\"{certificate} - incorrect common name - Expected: {certificate.common_name} Actual: {common_name}\")\n\n            if encryp_algo != certificate.encryption_algorithm:\n                self.result.is_failure(f\"{certificate} - incorrect encryption algorithm - Expected: {certificate.encryption_algorithm} Actual: {encryp_algo}\")\n\n            if key_size != certificate.key_size:\n                self.result.is_failure(f\"{certificate} - incorrect public key - Expected: {certificate.key_size} Actual: {key_size}\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyAPISSLCertificate-attributes","title":"Inputs","text":"Name Type Description Default <code>certificates</code> <code>list[APISSLCertificate]</code>                      List of API SSL certificates.                    -"},{"location":"api/tests/security/#anta.tests.security.VerifyBannerLogin","title":"VerifyBannerLogin","text":"<p>Verifies the login banner of a device.</p> Expected Results <ul> <li>Success: The test will pass if the login banner matches the provided input.</li> <li>Failure: The test will fail if the login banner does not match the provided input.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyBannerLogin:\n      login_banner: |\n        # Copyright (c) 2023-2024 Arista Networks, Inc.\n        # Use of this source code is governed by the Apache License 2.0\n        # that can be found in the LICENSE file.\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyBannerLogin(AntaTest):\n    \"\"\"Verifies the login banner of a device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the login banner matches the provided input.\n    * Failure: The test will fail if the login banner does not match the provided input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyBannerLogin:\n          login_banner: |\n            # Copyright (c) 2023-2024 Arista Networks, Inc.\n            # Use of this source code is governed by the Apache License 2.0\n            # that can be found in the LICENSE file.\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show banner login\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBannerLogin test.\"\"\"\n\n        login_banner: str\n        \"\"\"Expected login banner of the device.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBannerLogin.\"\"\"\n        self.result.is_success()\n        if not (login_banner := self.instance_commands[0].json_output[\"loginBanner\"]):\n            self.result.is_failure(\"Login banner is not configured\")\n            return\n\n        # Remove leading and trailing whitespaces from each line\n        cleaned_banner = \"\\n\".join(line.strip() for line in self.inputs.login_banner.split(\"\\n\"))\n        if login_banner != cleaned_banner:\n            self.result.is_failure(f\"Incorrect login banner configured - Expected: {cleaned_banner} Actual: {login_banner}\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyBannerLogin-attributes","title":"Inputs","text":"Name Type Description Default <code>login_banner</code> <code>str</code>                      Expected login banner of the device.                    -"},{"location":"api/tests/security/#anta.tests.security.VerifyBannerMotd","title":"VerifyBannerMotd","text":"<p>Verifies the motd banner of a device.</p> Expected Results <ul> <li>Success: The test will pass if the motd banner matches the provided input.</li> <li>Failure: The test will fail if the motd banner does not match the provided input.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyBannerMotd:\n      motd_banner: |\n        # Copyright (c) 2023-2024 Arista Networks, Inc.\n        # Use of this source code is governed by the Apache License 2.0\n        # that can be found in the LICENSE file.\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyBannerMotd(AntaTest):\n    \"\"\"Verifies the motd banner of a device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the motd banner matches the provided input.\n    * Failure: The test will fail if the motd banner does not match the provided input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyBannerMotd:\n          motd_banner: |\n            # Copyright (c) 2023-2024 Arista Networks, Inc.\n            # Use of this source code is governed by the Apache License 2.0\n            # that can be found in the LICENSE file.\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show banner motd\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyBannerMotd test.\"\"\"\n\n        motd_banner: str\n        \"\"\"Expected motd banner of the device.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyBannerMotd.\"\"\"\n        self.result.is_success()\n        if not (motd_banner := self.instance_commands[0].json_output[\"motd\"]):\n            self.result.is_failure(\"MOTD banner is not configured\")\n            return\n\n        # Remove leading and trailing whitespaces from each line\n        cleaned_banner = \"\\n\".join(line.strip() for line in self.inputs.motd_banner.split(\"\\n\"))\n        if motd_banner != cleaned_banner:\n            self.result.is_failure(f\"Incorrect MOTD banner configured - Expected: {cleaned_banner} Actual: {motd_banner}\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyBannerMotd-attributes","title":"Inputs","text":"Name Type Description Default <code>motd_banner</code> <code>str</code>                      Expected motd banner of the device.                    -"},{"location":"api/tests/security/#anta.tests.security.VerifyHardwareEntropy","title":"VerifyHardwareEntropy","text":"<p>Verifies hardware entropy generation is enabled on device.</p> Expected Results <ul> <li>Success: The test will pass if hardware entropy generation is enabled.</li> <li>Failure: The test will fail if hardware entropy generation is not enabled.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyHardwareEntropy:\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyHardwareEntropy(AntaTest):\n    \"\"\"Verifies hardware entropy generation is enabled on device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if hardware entropy generation is enabled.\n    * Failure: The test will fail if hardware entropy generation is not enabled.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyHardwareEntropy:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management security\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyHardwareEntropy.\"\"\"\n        command_output = self.instance_commands[0].json_output\n\n        # Check if hardware entropy generation is enabled.\n        if not command_output.get(\"hardwareEntropyEnabled\"):\n            self.result.is_failure(\"Hardware entropy generation is disabled\")\n        else:\n            self.result.is_success()\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyIPSecConnHealth","title":"VerifyIPSecConnHealth","text":"<p>Verifies all IPv4 security connections.</p> Expected Results <ul> <li>Success: The test will pass if all the IPv4 security connections are established in all vrf.</li> <li>Failure: The test will fail if IPv4 security is not configured or any of IPv4 security connections are not established in any vrf.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyIPSecConnHealth:\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyIPSecConnHealth(AntaTest):\n    \"\"\"Verifies all IPv4 security connections.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all the IPv4 security connections are established in all vrf.\n    * Failure: The test will fail if IPv4 security is not configured or any of IPv4 security connections are not established in any vrf.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyIPSecConnHealth:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip security connection vrf all\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIPSecConnHealth.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output[\"connections\"]\n\n        # Check if IP security connection is configured\n        if not command_output:\n            self.result.is_failure(\"No IPv4 security connection configured\")\n            return\n\n        # Iterate over all ipsec connections\n        for conn_data in command_output.values():\n            state = next(iter(conn_data[\"pathDict\"].values()))\n            if state != \"Established\":\n                source = conn_data.get(\"saddr\")\n                destination = conn_data.get(\"daddr\")\n                vrf = conn_data.get(\"tunnelNs\")\n                self.result.is_failure(f\"Source: {source} Destination: {destination} VRF: {vrf} - IPv4 security connection not established\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyIPv4ACL","title":"VerifyIPv4ACL","text":"<p>Verifies the configuration of IPv4 ACLs.</p> <p>This test performs the following checks for each IPv4 ACL:</p> <ol> <li>Validates that the IPv4 ACL is properly configured.</li> <li>Validates that the sequence entries in the ACL are correctly ordered.</li> </ol> Expected Results <ul> <li>Success: If all of the following occur:<ul> <li>Any IPv4 ACL entry is not configured.</li> <li>The sequency entries are correctly configured.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>The IPv4 ACL is not configured.</li> <li>The any IPv4 ACL entry is not configured.</li> <li>The action for any entry does not match the expected input.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyIPv4ACL:\n      ipv4_access_lists:\n        - name: default-control-plane-acl\n          entries:\n            - sequence: 10\n              action: permit icmp any any\n            - sequence: 20\n              action: permit ip any any tracked\n            - sequence: 30\n              action: permit udp any any eq bfd ttl eq 255\n        - name: LabTest\n          entries:\n            - sequence: 10\n              action: permit icmp any any\n            - sequence: 20\n              action: permit tcp any any range 5900 5910\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyIPv4ACL(AntaTest):\n    \"\"\"Verifies the configuration of IPv4 ACLs.\n\n    This test performs the following checks for each IPv4 ACL:\n\n      1. Validates that the IPv4 ACL is properly configured.\n      2. Validates that the sequence entries in the ACL are correctly ordered.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following occur:\n        - Any IPv4 ACL entry is not configured.\n        - The sequency entries are correctly configured.\n    * Failure: If any of the following occur:\n        - The IPv4 ACL is not configured.\n        - The any IPv4 ACL entry is not configured.\n        - The action for any entry does not match the expected input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyIPv4ACL:\n          ipv4_access_lists:\n            - name: default-control-plane-acl\n              entries:\n                - sequence: 10\n                  action: permit icmp any any\n                - sequence: 20\n                  action: permit ip any any tracked\n                - sequence: 30\n                  action: permit udp any any eq bfd ttl eq 255\n            - name: LabTest\n              entries:\n                - sequence: 10\n                  action: permit icmp any any\n                - sequence: 20\n                  action: permit tcp any any range 5900 5910\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip access-lists\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyIPv4ACL test.\"\"\"\n\n        ipv4_access_lists: list[ACL]\n        \"\"\"List of IPv4 ACLs to verify.\"\"\"\n        IPv4ACL: ClassVar[type[ACL]] = ACL\n        \"\"\"To maintain backward compatibility.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyIPv4ACL.\"\"\"\n        self.result.is_success()\n\n        if not (command_output := self.instance_commands[0].json_output[\"aclList\"]):\n            self.result.is_failure(\"No Access Control List (ACL) configured\")\n            return\n\n        for access_list in self.inputs.ipv4_access_lists:\n            if not (access_list_output := get_item(command_output, \"name\", access_list.name)):\n                self.result.is_failure(f\"{access_list} - Not configured\")\n                continue\n\n            for entry in access_list.entries:\n                if not (actual_entry := get_item(access_list_output[\"sequence\"], \"sequenceNumber\", entry.sequence)):\n                    self.result.is_failure(f\"{access_list} {entry} - Not configured\")\n                    continue\n\n                if (act_action := actual_entry[\"text\"]) != entry.action:\n                    self.result.is_failure(f\"{access_list} {entry} - action mismatch - Expected: {entry.action} Actual: {act_action}\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifyIPv4ACL-attributes","title":"Inputs","text":"Name Type Description Default <code>ipv4_access_lists</code> <code>list[ACL]</code>                      List of IPv4 ACLs to verify.                    - <code>IPv4ACL</code> <code>type[ACL]</code>                      To maintain backward compatibility.                    <code>ACL</code>"},{"location":"api/tests/security/#anta.tests.security.VerifySSHIPv4Acl","title":"VerifySSHIPv4Acl","text":"<p>Verifies if the SSHD agent has the right number IPv4 ACL(s) configured for a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if the SSHD agent has the provided number of IPv4 ACL(s) in the specified VRF.</li> <li>Failure: The test will fail if the SSHD agent has not the right number of IPv4 ACL(s) in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifySSHIPv4Acl:\n      number: 3\n      vrf: default\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifySSHIPv4Acl(AntaTest):\n    \"\"\"Verifies if the SSHD agent has the right number IPv4 ACL(s) configured for a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SSHD agent has the provided number of IPv4 ACL(s) in the specified VRF.\n    * Failure: The test will fail if the SSHD agent has not the right number of IPv4 ACL(s) in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifySSHIPv4Acl:\n          number: 3\n          vrf: default\n    ```\n    \"\"\"\n\n    description = \"Verifies if the SSHD agent has IPv4 ACL(s) configured.\"\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management ssh ip access-list summary\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySSHIPv4Acl test.\"\"\"\n\n        number: PositiveInteger\n        \"\"\"The number of expected IPv4 ACL(s).\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF in which to check for the SSHD agent. Defaults to `default` VRF.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySSHIPv4Acl.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        ipv4_acl_list = command_output[\"ipAclList\"][\"aclList\"]\n        ipv4_acl_number = len(ipv4_acl_list)\n        if ipv4_acl_number != self.inputs.number:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - SSH IPv4 ACL(s) count mismatch - Expected: {self.inputs.number} Actual: {ipv4_acl_number}\")\n            return\n\n        not_configured_acl = [acl[\"name\"] for acl in ipv4_acl_list if self.inputs.vrf not in acl[\"configuredVrfs\"] or self.inputs.vrf not in acl[\"activeVrfs\"]]\n\n        if not_configured_acl:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - Following SSH IPv4 ACL(s) not configured or active: {', '.join(not_configured_acl)}\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifySSHIPv4Acl-attributes","title":"Inputs","text":"Name Type Description Default <code>number</code> <code>PositiveInteger</code>                      The number of expected IPv4 ACL(s).                    - <code>vrf</code> <code>str</code>                      The name of the VRF in which to check for the SSHD agent. Defaults to `default` VRF.                    <code>'default'</code>"},{"location":"api/tests/security/#anta.tests.security.VerifySSHIPv6Acl","title":"VerifySSHIPv6Acl","text":"<p>Verifies if the SSHD agent has the right number IPv6 ACL(s) configured for a specified VRF.</p> Expected Results <ul> <li>Success: The test will pass if the SSHD agent has the provided number of IPv6 ACL(s) in the specified VRF.</li> <li>Failure: The test will fail if the SSHD agent has not the right number of IPv6 ACL(s) in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifySSHIPv6Acl:\n      number: 3\n      vrf: default\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifySSHIPv6Acl(AntaTest):\n    \"\"\"Verifies if the SSHD agent has the right number IPv6 ACL(s) configured for a specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SSHD agent has the provided number of IPv6 ACL(s) in the specified VRF.\n    * Failure: The test will fail if the SSHD agent has not the right number of IPv6 ACL(s) in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifySSHIPv6Acl:\n          number: 3\n          vrf: default\n    ```\n    \"\"\"\n\n    description = \"Verifies if the SSHD agent has IPv6 ACL(s) configured.\"\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management ssh ipv6 access-list summary\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySSHIPv6Acl test.\"\"\"\n\n        number: PositiveInteger\n        \"\"\"The number of expected IPv6 ACL(s).\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF in which to check for the SSHD agent. Defaults to `default` VRF.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySSHIPv6Acl.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        ipv6_acl_list = command_output[\"ipv6AclList\"][\"aclList\"]\n        ipv6_acl_number = len(ipv6_acl_list)\n        if ipv6_acl_number != self.inputs.number:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - SSH IPv6 ACL(s) count mismatch - Expected: {self.inputs.number} Actual: {ipv6_acl_number}\")\n            return\n\n        not_configured_acl = [acl[\"name\"] for acl in ipv6_acl_list if self.inputs.vrf not in acl[\"configuredVrfs\"] or self.inputs.vrf not in acl[\"activeVrfs\"]]\n\n        if not_configured_acl:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - Following SSH IPv6 ACL(s) not configured or active: {', '.join(not_configured_acl)}\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifySSHIPv6Acl-attributes","title":"Inputs","text":"Name Type Description Default <code>number</code> <code>PositiveInteger</code>                      The number of expected IPv6 ACL(s).                    - <code>vrf</code> <code>str</code>                      The name of the VRF in which to check for the SSHD agent. Defaults to `default` VRF.                    <code>'default'</code>"},{"location":"api/tests/security/#anta.tests.security.VerifySSHStatus","title":"VerifySSHStatus","text":"<p>Verifies if the SSHD agent is disabled in the default VRF.</p> Expected Results <ul> <li>Success: The test will pass if the SSHD agent is disabled in the default VRF.</li> <li>Failure: The test will fail if the SSHD agent is NOT disabled in the default VRF.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifySSHStatus:\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifySSHStatus(AntaTest):\n    \"\"\"Verifies if the SSHD agent is disabled in the default VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SSHD agent is disabled in the default VRF.\n    * Failure: The test will fail if the SSHD agent is NOT disabled in the default VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifySSHStatus:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management ssh\", ofmt=\"text\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySSHStatus.\"\"\"\n        command_output = self.instance_commands[0].text_output\n\n        try:\n            line = next(line for line in command_output.split(\"\\n\") if line.startswith(\"SSHD status\"))\n        except StopIteration:\n            self.result.is_failure(\"Could not find SSH status in returned output\")\n            return\n        status = line.split()[-1]\n\n        if status == \"disabled\":\n            self.result.is_success()\n        else:\n            self.result.is_failure(line)\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifySpecificIPSecConn","title":"VerifySpecificIPSecConn","text":"<p>Verifies the IPv4 security connections.</p> <p>This test performs the following checks for each peer:</p> <ol> <li>Validates that the VRF is configured.</li> <li>Checks for the presence of IPv4 security connections for the specified peer.</li> <li>For each relevant peer:<ul> <li>If source and destination addresses are provided, verifies the security connection for the specific path exists and is <code>Established</code>.</li> <li>If no addresses are provided, verifies that all security connections associated with the peer are <code>Established</code>.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If all checks pass for all specified IPv4 security connections.</li> <li>Failure: If any of the following occur:<ul> <li>No IPv4 security connections are found for the peer</li> <li>The security connection is not established for the specified path or any of the peer connections is not established when no path is specified.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifySpecificIPSecConn:\n      ip_security_connections:\n        - peer: 10.255.0.1\n        - peer: 10.255.0.2\n          vrf: default\n          connections:\n            - source_address: 100.64.3.2\n              destination_address: 100.64.2.2\n            - source_address: 172.18.3.2\n              destination_address: 172.18.2.2\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifySpecificIPSecConn(AntaTest):\n    \"\"\"Verifies the IPv4 security connections.\n\n    This test performs the following checks for each peer:\n\n      1. Validates that the VRF is configured.\n      2. Checks for the presence of IPv4 security connections for the specified peer.\n      3. For each relevant peer:\n        - If source and destination addresses are provided, verifies the security connection for the specific path exists and is `Established`.\n        - If no addresses are provided, verifies that all security connections associated with the peer are `Established`.\n\n    Expected Results\n    ----------------\n    * Success: If all checks pass for all specified IPv4 security connections.\n    * Failure: If any of the following occur:\n        - No IPv4 security connections are found for the peer\n        - The security connection is not established for the specified path or any of the peer connections is not established when no path is specified.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifySpecificIPSecConn:\n          ip_security_connections:\n            - peer: 10.255.0.1\n            - peer: 10.255.0.2\n              vrf: default\n              connections:\n                - source_address: 100.64.3.2\n                  destination_address: 100.64.2.2\n                - source_address: 172.18.3.2\n                  destination_address: 172.18.2.2\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaTemplate(template=\"show ip security connection vrf {vrf} path peer {peer}\", revision=2)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySpecificIPSecConn test.\"\"\"\n\n        ip_security_connections: list[IPSecPeer]\n        \"\"\"List of IP4v security peers.\"\"\"\n        IPSecPeers: ClassVar[type[IPSecPeers]] = IPSecPeers\n        \"\"\"To maintain backward compatibility.\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for each input IP Sec connection.\"\"\"\n        return [template.render(peer=conn.peer, vrf=conn.vrf) for conn in self.inputs.ip_security_connections]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySpecificIPSecConn.\"\"\"\n        self.result.is_success()\n\n        for command_output, input_peer in zip(self.instance_commands, self.inputs.ip_security_connections):\n            conn_output = command_output.json_output[\"connections\"]\n            conn_input = input_peer.connections\n            vrf = input_peer.vrf\n\n            # Check if IPv4 security connection is configured\n            if not conn_output:\n                self.result.is_failure(f\"{input_peer} - Not configured\")\n                continue\n\n            # If connection details are not provided then check all connections of a peer\n            if conn_input is None:\n                for conn_data in conn_output.values():\n                    state = next(iter(conn_data[\"pathDict\"].values()))\n                    if state != \"Established\":\n                        source = conn_data.get(\"saddr\")\n                        destination = conn_data.get(\"daddr\")\n                        self.result.is_failure(f\"{input_peer} Source: {source} Destination: {destination} - Connection down - Expected: Established Actual: {state}\")\n                continue\n\n            # Create a dictionary of existing connections for faster lookup\n            existing_connections = {\n                (conn_data.get(\"saddr\"), conn_data.get(\"daddr\"), conn_data.get(\"tunnelNs\")): next(iter(conn_data[\"pathDict\"].values()))\n                for conn_data in conn_output.values()\n            }\n            for connection in conn_input:\n                source_input = str(connection.source_address)\n                destination_input = str(connection.destination_address)\n\n                if (source_input, destination_input, vrf) in existing_connections:\n                    existing_state = existing_connections[(source_input, destination_input, vrf)]\n                    if existing_state != \"Established\":\n                        failure = f\"Expected: Established Actual: {existing_state}\"\n                        self.result.is_failure(f\"{input_peer} Source: {source_input} Destination: {destination_input} - Connection down - {failure}\")\n                else:\n                    self.result.is_failure(f\"{input_peer} Source: {source_input} Destination: {destination_input} - Connection not found.\")\n</code></pre>"},{"location":"api/tests/security/#anta.tests.security.VerifySpecificIPSecConn-attributes","title":"Inputs","text":"Name Type Description Default <code>ip_security_connections</code> <code>list[IPSecPeer]</code>                      List of IP4v security peers.                    - <code>IPSecPeers</code> <code>type[IPSecPeers]</code>                      To maintain backward compatibility.                    <code>IPSecPeers</code>"},{"location":"api/tests/security/#anta.tests.security.VerifyTelnetStatus","title":"VerifyTelnetStatus","text":"<p>Verifies if Telnet is disabled in the default VRF.</p> Expected Results <ul> <li>Success: The test will pass if Telnet is disabled in the default VRF.</li> <li>Failure: The test will fail if Telnet is NOT disabled in the default VRF.</li> </ul> Examples <pre><code>anta.tests.security:\n  - VerifyTelnetStatus:\n</code></pre> Source code in <code>anta/tests/security.py</code> <pre><code>class VerifyTelnetStatus(AntaTest):\n    \"\"\"Verifies if Telnet is disabled in the default VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if Telnet is disabled in the default VRF.\n    * Failure: The test will fail if Telnet is NOT disabled in the default VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.security:\n      - VerifyTelnetStatus:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"security\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show management telnet\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTelnetStatus.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        if command_output[\"serverState\"] == \"disabled\":\n            self.result.is_success()\n        else:\n            self.result.is_failure(\"Telnet status for Default VRF is enabled\")\n</code></pre>"},{"location":"api/tests/security/#input-models","title":"Input models","text":"<p>Module containing input models for security tests.</p>"},{"location":"api/tests/security/#anta.input_models.security.ACL","title":"ACL","text":"<p>Model for an Access Control List (ACL).</p> Name Type Description Default <code>name</code> <code>str</code>                      Name of the ACL.                    - <code>entries</code> <code>list[ACLEntry]</code>                      List of the ACL entries.                    - <code>IPv4ACLEntry</code> <code>type[ACLEntry]</code>                      To maintain backward compatibility.                    <code>ACLEntry</code> Source code in <code>anta/input_models/security.py</code> <pre><code>class ACL(BaseModel):\n    \"\"\"Model for an Access Control List (ACL).\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    name: str\n    \"\"\"Name of the ACL.\"\"\"\n    entries: list[ACLEntry]\n    \"\"\"List of the ACL entries.\"\"\"\n    IPv4ACLEntry: ClassVar[type[ACLEntry]] = ACLEntry\n    \"\"\"To maintain backward compatibility.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the ACL for reporting.\n\n        Examples\n        --------\n        - ACL name: Test\n        \"\"\"\n        return f\"ACL name: {self.name}\"\n</code></pre>"},{"location":"api/tests/security/#anta.input_models.security.ACLEntry","title":"ACLEntry","text":"<p>Model for an Access Control List (ACL) entry.</p> Name Type Description Default <code>sequence</code> <code>int</code>                      Sequence number of the ACL entry, used to define the order of processing. Must be between 1 and 4294967295.                    <code>Field(ge=1, le=4294967295)</code> <code>action</code> <code>str</code>                      Action of the ACL entry. Example: `deny ip any any`.                    - Source code in <code>anta/input_models/security.py</code> <pre><code>class ACLEntry(BaseModel):\n    \"\"\"Model for an Access Control List (ACL) entry.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    sequence: int = Field(ge=1, le=4294967295)\n    \"\"\"Sequence number of the ACL entry, used to define the order of processing. Must be between 1 and 4294967295.\"\"\"\n    action: str\n    \"\"\"Action of the ACL entry. Example: `deny ip any any`.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the ACLEntry for reporting.\n\n        Examples\n        --------\n        - Sequence: 10\n        \"\"\"\n        return f\"Sequence: {self.sequence}\"\n</code></pre>"},{"location":"api/tests/security/#anta.input_models.security.APISSLCertificate","title":"APISSLCertificate","text":"<p>Model for an API SSL certificate.</p> Name Type Description Default <code>certificate_name</code> <code>str</code>                      The name of the certificate to be verified.                    - <code>expiry_threshold</code> <code>int</code>                      The expiry threshold of the certificate in days.                    - <code>common_name</code> <code>str</code>                      The Common Name of the certificate.                    - <code>encryption_algorithm</code> <code>EncryptionAlgorithm</code>                      The encryption algorithm used by the certificate.                    - <code>key_size</code> <code>RsaKeySize | EcdsaKeySize</code>                      The key size (in bits) of the encryption algorithm.                    - Source code in <code>anta/input_models/security.py</code> <pre><code>class APISSLCertificate(BaseModel):\n    \"\"\"Model for an API SSL certificate.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    certificate_name: str\n    \"\"\"The name of the certificate to be verified.\"\"\"\n    expiry_threshold: int\n    \"\"\"The expiry threshold of the certificate in days.\"\"\"\n    common_name: str\n    \"\"\"The Common Name of the certificate.\"\"\"\n    encryption_algorithm: EncryptionAlgorithm\n    \"\"\"The encryption algorithm used by the certificate.\"\"\"\n    key_size: RsaKeySize | EcdsaKeySize\n    \"\"\"The key size (in bits) of the encryption algorithm.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the APISSLCertificate for reporting.\n\n        Examples\n        --------\n        - Certificate: SIGNING_CA.crt\n        \"\"\"\n        return f\"Certificate: {self.certificate_name}\"\n\n    @model_validator(mode=\"after\")\n    def validate_inputs(self) -&gt; Self:\n        \"\"\"Validate the key size provided to the APISSLCertificates class.\n\n        If encryption_algorithm is RSA then key_size should be in {2048, 3072, 4096}.\n\n        If encryption_algorithm is ECDSA then key_size should be in {256, 384, 521}.\n        \"\"\"\n        if self.encryption_algorithm == \"RSA\" and self.key_size not in get_args(RsaKeySize):\n            msg = f\"`{self.certificate_name}` key size {self.key_size} is invalid for RSA encryption. Allowed sizes are {get_args(RsaKeySize)}.\"\n            raise ValueError(msg)\n\n        if self.encryption_algorithm == \"ECDSA\" and self.key_size not in get_args(EcdsaKeySize):\n            msg = f\"`{self.certificate_name}` key size {self.key_size} is invalid for ECDSA encryption. Allowed sizes are {get_args(EcdsaKeySize)}.\"\n            raise ValueError(msg)\n\n        return self\n</code></pre>"},{"location":"api/tests/security/#anta.input_models.security.APISSLCertificate.validate_inputs","title":"validate_inputs","text":"<pre><code>validate_inputs() -&gt; Self\n</code></pre> <p>Validate the key size provided to the APISSLCertificates class.</p> <p>If encryption_algorithm is RSA then key_size should be in {2048, 3072, 4096}.</p> <p>If encryption_algorithm is ECDSA then key_size should be in {256, 384, 521}.</p> Source code in <code>anta/input_models/security.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_inputs(self) -&gt; Self:\n    \"\"\"Validate the key size provided to the APISSLCertificates class.\n\n    If encryption_algorithm is RSA then key_size should be in {2048, 3072, 4096}.\n\n    If encryption_algorithm is ECDSA then key_size should be in {256, 384, 521}.\n    \"\"\"\n    if self.encryption_algorithm == \"RSA\" and self.key_size not in get_args(RsaKeySize):\n        msg = f\"`{self.certificate_name}` key size {self.key_size} is invalid for RSA encryption. Allowed sizes are {get_args(RsaKeySize)}.\"\n        raise ValueError(msg)\n\n    if self.encryption_algorithm == \"ECDSA\" and self.key_size not in get_args(EcdsaKeySize):\n        msg = f\"`{self.certificate_name}` key size {self.key_size} is invalid for ECDSA encryption. Allowed sizes are {get_args(EcdsaKeySize)}.\"\n        raise ValueError(msg)\n\n    return self\n</code></pre>"},{"location":"api/tests/security/#anta.input_models.security.IPSecConn","title":"IPSecConn","text":"<p>Details of an IPv4 security connection for a peer.</p> Name Type Description Default <code>source_address</code> <code>IPv4Address</code>                      The IPv4 address of the source in the security connection.                    - <code>destination_address</code> <code>IPv4Address</code>                      The IPv4 address of the destination in the security connection.                    - Source code in <code>anta/input_models/security.py</code> <pre><code>class IPSecConn(BaseModel):\n    \"\"\"Details of an IPv4 security connection for a peer.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    source_address: IPv4Address\n    \"\"\"The IPv4 address of the source in the security connection.\"\"\"\n    destination_address: IPv4Address\n    \"\"\"The IPv4 address of the destination in the security connection.\"\"\"\n</code></pre>"},{"location":"api/tests/security/#anta.input_models.security.IPSecPeer","title":"IPSecPeer","text":"<p>IPSec (Internet Protocol Security) model represents the details of an IPv4 security peer.</p> Name Type Description Default <code>peer</code> <code>IPv4Address</code>                      The IPv4 address of the security peer.                    - <code>vrf</code> <code>str</code>                      VRF context. Defaults to `default`.                    <code>'default'</code> <code>connections</code> <code>list[IPSecConn] | None</code>                      A list of IPv4 security connections associated with the peer. Defaults to None.                    <code>None</code> Source code in <code>anta/input_models/security.py</code> <pre><code>class IPSecPeer(BaseModel):\n    \"\"\"IPSec (Internet Protocol Security) model represents the details of an IPv4 security peer.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    peer: IPv4Address\n    \"\"\"The IPv4 address of the security peer.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"VRF context. Defaults to `default`.\"\"\"\n    connections: list[IPSecConn] | None = None\n    \"\"\"A list of IPv4 security connections associated with the peer. Defaults to None.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the IPSecPeer model. Used in failure messages.\n\n        Examples\n        --------\n        - Peer: 1.1.1.1 VRF: default\n        \"\"\"\n        return f\"Peer: {self.peer} VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/security/#anta.input_models.security.IPSecPeers","title":"IPSecPeers","text":"<p>Alias for the IPSecPeers model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the IPSecPeer model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/security.py</code> <pre><code>class IPSecPeers(IPSecPeer):  # pragma: no cover\n    \"\"\"Alias for the IPSecPeers model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the IPSecPeer model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the IPSecPeers class, emitting a deprecation warning.\"\"\"\n        warn(\n            message=\"IPSecPeers model is deprecated and will be removed in ANTA v2.0.0. Use the IPSecPeer model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/security/#anta.input_models.security.IPv4ACL","title":"IPv4ACL","text":"<p>Alias for the ACL model to maintain backward compatibility.</p> <p>When initialized, it will emit a deprecation warning and call the ACL model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/security.py</code> <pre><code>class IPv4ACL(ACL):  # pragma: no cover\n    \"\"\"Alias for the ACL model to maintain backward compatibility.\n\n    When initialized, it will emit a deprecation warning and call the ACL model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the IPv4ACL class, emitting a deprecation warning.\"\"\"\n        warn(\n            message=\"IPv4ACL model is deprecated and will be removed in ANTA v2.0.0. Use the ACL model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/services/","title":"Services","text":""},{"location":"api/tests/services/#tests","title":"Tests","text":"<p>Module related to the EOS various services tests.</p>"},{"location":"api/tests/services/#anta.tests.services.VerifyDNSLookup","title":"VerifyDNSLookup","text":"<p>Verifies the DNS (Domain Name Service) name to IP address resolution.</p> Expected Results <ul> <li>Success: The test will pass if a domain name is resolved to an IP address.</li> <li>Failure: The test will fail if a domain name does not resolve to an IP address.</li> <li>Error: This test will error out if a domain name is invalid.</li> </ul> Examples <pre><code>anta.tests.services:\n  - VerifyDNSLookup:\n      domain_names:\n        - arista.com\n        - www.google.com\n        - arista.ca\n</code></pre> Source code in <code>anta/tests/services.py</code> <pre><code>class VerifyDNSLookup(AntaTest):\n    \"\"\"Verifies the DNS (Domain Name Service) name to IP address resolution.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if a domain name is resolved to an IP address.\n    * Failure: The test will fail if a domain name does not resolve to an IP address.\n    * Error: This test will error out if a domain name is invalid.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.services:\n      - VerifyDNSLookup:\n          domain_names:\n            - arista.com\n            - www.google.com\n            - arista.ca\n    ```\n    \"\"\"\n\n    description = \"Verifies the DNS name to IP address resolution.\"\n    categories: ClassVar[list[str]] = [\"services\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaTemplate(template=\"bash timeout 10 nslookup {domain}\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyDNSLookup test.\"\"\"\n\n        domain_names: list[str]\n        \"\"\"List of domain names.\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for each domain name in the input list.\"\"\"\n        return [template.render(domain=domain_name) for domain_name in self.inputs.domain_names]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyDNSLookup.\"\"\"\n        self.result.is_success()\n        failed_domains = []\n        for command in self.instance_commands:\n            domain = command.params.domain\n            output = command.json_output[\"messages\"][0]\n            if f\"Can't find {domain}: No answer\" in output:\n                failed_domains.append(domain)\n        if failed_domains:\n            self.result.is_failure(f\"The following domain(s) are not resolved to an IP address: {', '.join(failed_domains)}\")\n</code></pre>"},{"location":"api/tests/services/#anta.tests.services.VerifyDNSLookup-attributes","title":"Inputs","text":"Name Type Description Default <code>domain_names</code> <code>list[str]</code>                      List of domain names.                    -"},{"location":"api/tests/services/#anta.tests.services.VerifyDNSServers","title":"VerifyDNSServers","text":"<p>Verifies if the DNS (Domain Name Service) servers are correctly configured.</p> <p>This test performs the following checks for each specified DNS Server:</p> <ol> <li>Confirming correctly registered with a valid IPv4 or IPv6 address with the designated VRF.</li> <li>Ensuring an appropriate priority level.</li> </ol> Expected Results <ul> <li>Success: The test will pass if the DNS server specified in the input is configured with the correct VRF and priority.</li> <li>Failure: The test will fail if any of the following conditions are met:<ul> <li>The provided DNS server is not configured.</li> <li>The provided DNS server with designated VRF and priority does not match the expected information.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.services:\n  - VerifyDNSServers:\n      dns_servers:\n        - server_address: 10.14.0.1\n          vrf: default\n          priority: 1\n        - server_address: 10.14.0.11\n          vrf: MGMT\n          priority: 0\n</code></pre> Source code in <code>anta/tests/services.py</code> <pre><code>class VerifyDNSServers(AntaTest):\n    \"\"\"Verifies if the DNS (Domain Name Service) servers are correctly configured.\n\n    This test performs the following checks for each specified DNS Server:\n\n      1. Confirming correctly registered with a valid IPv4 or IPv6 address with the designated VRF.\n      2. Ensuring an appropriate priority level.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the DNS server specified in the input is configured with the correct VRF and priority.\n    * Failure: The test will fail if any of the following conditions are met:\n        - The provided DNS server is not configured.\n        - The provided DNS server with designated VRF and priority does not match the expected information.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.services:\n      - VerifyDNSServers:\n          dns_servers:\n            - server_address: 10.14.0.1\n              vrf: default\n              priority: 1\n            - server_address: 10.14.0.11\n              vrf: MGMT\n              priority: 0\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"services\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ip name-server\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyDNSServers test.\"\"\"\n\n        dns_servers: list[DnsServer]\n        \"\"\"List of DNS servers to verify.\"\"\"\n        DnsServer: ClassVar[type[DnsServer]] = DnsServer\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyDNSServers.\"\"\"\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output[\"nameServerConfigs\"]\n        for server in self.inputs.dns_servers:\n            address = str(server.server_address)\n            vrf = server.vrf\n            priority = server.priority\n            input_dict = {\"ipAddr\": address, \"vrf\": vrf}\n\n            # Check if the DNS server is configured with specified VRF.\n            if (output := get_dict_superset(command_output, input_dict)) is None:\n                self.result.is_failure(f\"{server} - Not configured\")\n                continue\n\n            # Check if the DNS server priority matches with expected.\n            if output[\"priority\"] != priority:\n                self.result.is_failure(f\"{server} - Incorrect priority - Priority: {output['priority']}\")\n</code></pre>"},{"location":"api/tests/services/#anta.tests.services.VerifyDNSServers-attributes","title":"Inputs","text":"Name Type Description Default <code>dns_servers</code> <code>list[DnsServer]</code>                      List of DNS servers to verify.                    -"},{"location":"api/tests/services/#anta.tests.services.VerifyErrdisableRecovery","title":"VerifyErrdisableRecovery","text":"<p>Verifies the error disable recovery functionality.</p> <p>This test performs the following checks for each specified error disable reason:</p> <ol> <li>Verifying if the specified error disable reason exists.</li> <li>Checking if the recovery timer status matches the expected enabled/disabled state.</li> <li>Validating that the timer interval matches the configured value.</li> </ol> Expected Results <ul> <li>Success: The test will pass if:<ul> <li>The specified error disable reason exists.</li> <li>The recovery timer status matches the expected state.</li> <li>The timer interval matches the configured value.</li> </ul> </li> <li>Failure: The test will fail if:<ul> <li>The specified error disable reason does not exist.</li> <li>The recovery timer status does not match the expected state.</li> <li>The timer interval does not match the configured value.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.services:\n  - VerifyErrdisableRecovery:\n      reasons:\n        - reason: acl\n          interval: 30\n          status: Enabled\n        - reason: bpduguard\n          interval: 30\n          status: Enabled\n</code></pre> Source code in <code>anta/tests/services.py</code> <pre><code>class VerifyErrdisableRecovery(AntaTest):\n    \"\"\"Verifies the error disable recovery functionality.\n\n    This test performs the following checks for each specified error disable reason:\n\n      1. Verifying if the specified error disable reason exists.\n      2. Checking if the recovery timer status matches the expected enabled/disabled state.\n      3. Validating that the timer interval matches the configured value.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if:\n        - The specified error disable reason exists.\n        - The recovery timer status matches the expected state.\n        - The timer interval matches the configured value.\n    * Failure: The test will fail if:\n        - The specified error disable reason does not exist.\n        - The recovery timer status does not match the expected state.\n        - The timer interval does not match the configured value.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.services:\n      - VerifyErrdisableRecovery:\n          reasons:\n            - reason: acl\n              interval: 30\n              status: Enabled\n            - reason: bpduguard\n              interval: 30\n              status: Enabled\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"services\"]\n    # NOTE: Only `text` output format is supported for this command\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show errdisable recovery\", ofmt=\"text\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyErrdisableRecovery test.\"\"\"\n\n        reasons: list[ErrdisableRecovery]\n        \"\"\"List of errdisable reasons.\"\"\"\n        ErrDisableReason: ClassVar[type[ErrdisableRecovery]] = ErrDisableReason\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyErrdisableRecovery.\"\"\"\n        self.result.is_success()\n\n        # Skip header and last empty line\n        command_output = self.instance_commands[0].text_output.split(\"\\n\")[2:-1]\n\n        # Collecting the actual errdisable reasons for faster lookup\n        errdisable_reasons = [\n            {\"reason\": reason, \"status\": status, \"interval\": interval}\n            for line in command_output\n            if line.strip()  # Skip empty lines\n            for reason, status, interval in [line.split(None, 2)]  # Unpack split result\n        ]\n\n        for error_reason in self.inputs.reasons:\n            if not (reason_output := get_item(errdisable_reasons, \"reason\", error_reason.reason)):\n                self.result.is_failure(f\"{error_reason} - Not found\")\n                continue\n\n            if not all(\n                [\n                    error_reason.status == (act_status := reason_output[\"status\"]),\n                    error_reason.interval == (act_interval := int(reason_output[\"interval\"])),\n                ]\n            ):\n                self.result.is_failure(f\"{error_reason} - Incorrect configuration - Status: {act_status} Interval: {act_interval}\")\n</code></pre>"},{"location":"api/tests/services/#anta.tests.services.VerifyErrdisableRecovery-attributes","title":"Inputs","text":"Name Type Description Default <code>reasons</code> <code>list[ErrdisableRecovery]</code>                      List of errdisable reasons.                    -"},{"location":"api/tests/services/#anta.tests.services.VerifyHostname","title":"VerifyHostname","text":"<p>Verifies the hostname of a device.</p> Expected Results <ul> <li>Success: The test will pass if the hostname matches the provided input.</li> <li>Failure: The test will fail if the hostname does not match the provided input.</li> </ul> Examples <pre><code>anta.tests.services:\n  - VerifyHostname:\n      hostname: s1-spine1\n</code></pre> Source code in <code>anta/tests/services.py</code> <pre><code>class VerifyHostname(AntaTest):\n    \"\"\"Verifies the hostname of a device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the hostname matches the provided input.\n    * Failure: The test will fail if the hostname does not match the provided input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.services:\n      - VerifyHostname:\n          hostname: s1-spine1\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"services\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show hostname\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyHostname test.\"\"\"\n\n        hostname: str\n        \"\"\"Expected hostname of the device.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyHostname.\"\"\"\n        hostname = self.instance_commands[0].json_output[\"hostname\"]\n\n        if hostname != self.inputs.hostname:\n            self.result.is_failure(f\"Incorrect Hostname - Expected: {self.inputs.hostname} Actual: {hostname}\")\n        else:\n            self.result.is_success()\n</code></pre>"},{"location":"api/tests/services/#anta.tests.services.VerifyHostname-attributes","title":"Inputs","text":"Name Type Description Default <code>hostname</code> <code>str</code>                      Expected hostname of the device.                    -"},{"location":"api/tests/services/#input-models","title":"Input models","text":"<p>Module containing input models for services tests.</p>"},{"location":"api/tests/services/#anta.input_models.services.DnsServer","title":"DnsServer","text":"<p>Model for a DNS server configuration.</p> Name Type Description Default <code>server_address</code> <code>IPv4Address | IPv6Address</code>                      The IPv4 or IPv6 address of the DNS server.                    - <code>vrf</code> <code>str</code>                      The VRF instance in which the DNS server resides. Defaults to 'default'.                    <code>'default'</code> <code>priority</code> <code>int</code>                      The priority level of the DNS server, ranging from 0 to 4. Lower values indicate a higher priority, with 0 being the highest and 4 the lowest.                    <code>Field(ge=0, le=4)</code> Source code in <code>anta/input_models/services.py</code> <pre><code>class DnsServer(BaseModel):\n    \"\"\"Model for a DNS server configuration.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    server_address: IPv4Address | IPv6Address\n    \"\"\"The IPv4 or IPv6 address of the DNS server.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"The VRF instance in which the DNS server resides. Defaults to 'default'.\"\"\"\n    priority: int = Field(ge=0, le=4)\n    \"\"\"The priority level of the DNS server, ranging from 0 to 4. Lower values indicate a higher priority, with 0 being the highest and 4 the lowest.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the DnsServer for reporting.\n\n        Examples\n        --------\n        Server 10.0.0.1 (VRF: default, Priority: 1)\n        \"\"\"\n        return f\"Server {self.server_address} VRF: {self.vrf} Priority: {self.priority}\"\n</code></pre>"},{"location":"api/tests/services/#anta.input_models.services.ErrDisableReason","title":"ErrDisableReason","text":"<p>Alias for the ErrdisableRecovery model to maintain backward compatibility.</p> <p>When initialised, it will emit a deprecation warning and call the ErrdisableRecovery model.</p> <p>TODO: Remove this class in ANTA v2.0.0.</p> Source code in <code>anta/input_models/services.py</code> <pre><code>class ErrDisableReason(ErrdisableRecovery):  # pragma: no cover\n    \"\"\"Alias for the ErrdisableRecovery model to maintain backward compatibility.\n\n    When initialised, it will emit a deprecation warning and call the ErrdisableRecovery model.\n\n    TODO: Remove this class in ANTA v2.0.0.\n    \"\"\"\n\n    def __init__(self, **data: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Initialize the ErrdisableRecovery class, emitting a depreciation warning.\"\"\"\n        warn(\n            message=\"ErrDisableReason model is deprecated and will be removed in ANTA v2.0.0. Use the ErrdisableRecovery model instead.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        super().__init__(**data)\n</code></pre>"},{"location":"api/tests/services/#anta.input_models.services.ErrdisableRecovery","title":"ErrdisableRecovery","text":"<p>Model for the error disable recovery functionality.</p> Name Type Description Default <code>reason</code> <code>ErrDisableReasons</code>                      Name of the error disable reason.                    - <code>status</code> <code>Literal['Enabled', 'Disabled']</code>                      Operational status of the reason. Defaults to 'Enabled'.                    <code>'Enabled'</code> <code>interval</code> <code>int</code>                      Timer interval of the reason in seconds.                    <code>Field(ge=30, le=86400)</code> Source code in <code>anta/input_models/services.py</code> <pre><code>class ErrdisableRecovery(BaseModel):\n    \"\"\"Model for the error disable recovery functionality.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    reason: ErrDisableReasons\n    \"\"\"Name of the error disable reason.\"\"\"\n    status: Literal[\"Enabled\", \"Disabled\"] = \"Enabled\"\n    \"\"\"Operational status of the reason. Defaults to 'Enabled'.\"\"\"\n    interval: int = Field(ge=30, le=86400)\n    \"\"\"Timer interval of the reason in seconds.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the ErrdisableRecovery for reporting.\n\n        Examples\n        --------\n        Reason: acl Status: Enabled Interval: 300\n        \"\"\"\n        return f\"Reason: {self.reason} Status: {self.status} Interval: {self.interval}\"\n</code></pre>"},{"location":"api/tests/snmp/","title":"SNMP","text":""},{"location":"api/tests/snmp/#tests","title":"Tests","text":"<p>Module related to the EOS various SNMP tests.</p>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpContact","title":"VerifySnmpContact","text":"<p>Verifies the SNMP contact of a device.</p> Expected Results <ul> <li>Success: The test will pass if the SNMP contact matches the provided input.</li> <li>Failure: The test will fail if the SNMP contact does not match the provided input.</li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpContact:\n      contact: Jon@example.com\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpContact(AntaTest):\n    \"\"\"Verifies the SNMP contact of a device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SNMP contact matches the provided input.\n    * Failure: The test will fail if the SNMP contact does not match the provided input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpContact:\n          contact: Jon@example.com\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpContact test.\"\"\"\n\n        contact: str\n        \"\"\"Expected SNMP contact details of the device.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpContact.\"\"\"\n        self.result.is_success()\n        # Verifies the SNMP contact is configured.\n        if not (contact := get_value(self.instance_commands[0].json_output, \"contact.contact\")):\n            self.result.is_failure(\"SNMP contact is not configured\")\n            return\n\n        # Verifies the expected SNMP contact.\n        if contact != self.inputs.contact:\n            self.result.is_failure(f\"Incorrect SNMP contact - Expected: {self.inputs.contact} Actual: {contact}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpContact-attributes","title":"Inputs","text":"Name Type Description Default <code>contact</code> <code>str</code>                      Expected SNMP contact details of the device.                    -"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpErrorCounters","title":"VerifySnmpErrorCounters","text":"<p>Verifies the SNMP error counters.</p> <p>By default, all  error counters will be checked for any non-zero values. An optional list of specific error counters can be provided for granular testing.</p> Expected Results <ul> <li>Success: The test will pass if the SNMP error counter(s) are zero/None.</li> <li>Failure: The test will fail if the SNMP error counter(s) are non-zero/not None/Not Found or is not configured.</li> </ul> Examples <p>```yaml anta.tests.snmp:   - VerifySnmpErrorCounters:       error_counters:         - inVersionErrs         - inBadCommunityNames</p> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpErrorCounters(AntaTest):\n    \"\"\"Verifies the SNMP error counters.\n\n    By default, all  error counters will be checked for any non-zero values.\n    An optional list of specific error counters can be provided for granular testing.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SNMP error counter(s) are zero/None.\n    * Failure: The test will fail if the SNMP error counter(s) are non-zero/not None/Not Found or is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpErrorCounters:\n          error_counters:\n            - inVersionErrs\n            - inBadCommunityNames\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpErrorCounters test.\"\"\"\n\n        error_counters: list[SnmpErrorCounter] | None = None\n        \"\"\"Optional list of SNMP error counters to be verified. If not provided, test will verifies all error counters.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpErrorCounters.\"\"\"\n        self.result.is_success()\n        error_counters = self.inputs.error_counters\n        command_output = self.instance_commands[0].json_output\n\n        # Verify SNMP PDU counters.\n        if not (snmp_counters := get_value(command_output, \"counters\")):\n            self.result.is_failure(\"SNMP counters not found\")\n            return\n\n        # In case SNMP error counters not provided, It will check all the error counters.\n        if not error_counters:\n            error_counters = list(get_args(SnmpErrorCounter))\n\n        error_counters_not_ok = {counter for counter in error_counters if snmp_counters.get(counter)}\n\n        # Check if any failures\n        if error_counters_not_ok:\n            self.result.is_failure(f\"The following SNMP error counters are not found or have non-zero error counters: {', '.join(sorted(error_counters_not_ok))}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpErrorCounters-attributes","title":"Inputs","text":"Name Type Description Default <code>error_counters</code> <code>list[SnmpErrorCounter] | None</code>                      Optional list of SNMP error counters to be verified. If not provided, test will verifies all error counters.                    <code>None</code>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpGroup","title":"VerifySnmpGroup","text":"<p>Verifies the SNMP group configurations for specified version(s).</p> <p>This test performs the following checks:</p> <ol> <li>Verifies that the SNMP group is configured for the specified version.</li> <li>For SNMP version 3, verify that the security model matches the expected value.</li> <li>Ensures that SNMP group configurations, including read, write, and notify views, align with version-specific requirements.</li> </ol> Expected Results <ul> <li>Success: The test will pass if the provided SNMP group and all specified parameters are correctly configured.</li> <li>Failure: The test will fail if the provided SNMP group is not configured or if any specified parameter is not correctly configured.</li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpGroup:\n      snmp_groups:\n        - group_name: Group1\n          version: v1\n          read_view: group_read_1\n          write_view: group_write_1\n          notify_view: group_notify_1\n        - group_name: Group2\n          version: v3\n          read_view: group_read_2\n          write_view: group_write_2\n          notify_view: group_notify_2\n          authentication: priv\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpGroup(AntaTest):\n    \"\"\"Verifies the SNMP group configurations for specified version(s).\n\n    This test performs the following checks:\n\n      1. Verifies that the SNMP group is configured for the specified version.\n      2. For SNMP version 3, verify that the security model matches the expected value.\n      3. Ensures that SNMP group configurations, including read, write, and notify views, align with version-specific requirements.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided SNMP group and all specified parameters are correctly configured.\n    * Failure: The test will fail if the provided SNMP group is not configured or if any specified parameter is not correctly configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpGroup:\n          snmp_groups:\n            - group_name: Group1\n              version: v1\n              read_view: group_read_1\n              write_view: group_write_1\n              notify_view: group_notify_1\n            - group_name: Group2\n              version: v3\n              read_view: group_read_2\n              write_view: group_write_2\n              notify_view: group_notify_2\n              authentication: priv\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp group\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpGroup test.\"\"\"\n\n        snmp_groups: list[SnmpGroup]\n        \"\"\"List of SNMP groups.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpGroup.\"\"\"\n        self.result.is_success()\n        for group in self.inputs.snmp_groups:\n            # Verify SNMP group details.\n            if not (group_details := get_value(self.instance_commands[0].json_output, f\"groups.{group.group_name}.versions.{group.version}\")):\n                self.result.is_failure(f\"{group} - Not configured\")\n                continue\n\n            view_types = [view_type for view_type in [\"read\", \"write\", \"notify\"] if getattr(group, f\"{view_type}_view\")]\n            # Verify SNMP views, the read, write and notify settings aligning with version-specific requirements.\n            for view_type in view_types:\n                expected_view = getattr(group, f\"{view_type}_view\")\n                # Verify actual view is configured.\n                if group_details.get(f\"{view_type}View\") == \"\":\n                    self.result.is_failure(f\"{group} View: {view_type} - Not configured\")\n                elif (act_view := group_details.get(f\"{view_type}View\")) != expected_view:\n                    self.result.is_failure(f\"{group} - Incorrect {view_type.title()} view - Expected: {expected_view} Actual: {act_view}\")\n                elif not group_details.get(f\"{view_type}ViewConfig\"):\n                    self.result.is_failure(f\"{group} {view_type.title()} View: {expected_view} - Not configured\")\n\n            # For version v3, verify that the security model aligns with the expected value.\n            if group.version == \"v3\" and (actual_auth := group_details.get(\"secModel\")) != group.authentication:\n                self.result.is_failure(f\"{group} - Incorrect security model - Expected: {group.authentication} Actual: {actual_auth}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpGroup-attributes","title":"Inputs","text":"Name Type Description Default <code>snmp_groups</code> <code>list[SnmpGroup]</code>                      List of SNMP groups.                    -"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpHostLogging","title":"VerifySnmpHostLogging","text":"<p>Verifies SNMP logging configurations.</p> <p>This test performs the following checks:</p> <ol> <li>SNMP logging is enabled globally.</li> <li>For each specified SNMP host:<ul> <li>Host exists in configuration.</li> <li>Host\u2019s VRF assignment matches expected value.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: The test will pass if all of the following conditions are met:<ul> <li>SNMP logging is enabled on the device.</li> <li>All specified hosts are configured with correct VRF assignments.</li> </ul> </li> <li>Failure: The test will fail if any of the following conditions is met:<ul> <li>SNMP logging is disabled on the device.</li> <li>SNMP host not found in configuration.</li> <li>Host\u2019s VRF assignment doesn\u2019t match expected value.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpHostLogging:\n      hosts:\n        - hostname: 192.168.1.100\n          vrf: default\n        - hostname: 192.168.1.103\n          vrf: MGMT\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpHostLogging(AntaTest):\n    \"\"\"Verifies SNMP logging configurations.\n\n    This test performs the following checks:\n\n     1. SNMP logging is enabled globally.\n     2. For each specified SNMP host:\n         - Host exists in configuration.\n         - Host's VRF assignment matches expected value.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all of the following conditions are met:\n        - SNMP logging is enabled on the device.\n        - All specified hosts are configured with correct VRF assignments.\n    * Failure: The test will fail if any of the following conditions is met:\n        - SNMP logging is disabled on the device.\n        - SNMP host not found in configuration.\n        - Host's VRF assignment doesn't match expected value.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpHostLogging:\n          hosts:\n            - hostname: 192.168.1.100\n              vrf: default\n            - hostname: 192.168.1.103\n              vrf: MGMT\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpHostLogging test.\"\"\"\n\n        hosts: list[SnmpHost]\n        \"\"\"List of SNMP hosts.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpHostLogging.\"\"\"\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output.get(\"logging\", {})\n        # If SNMP logging is disabled, test fails.\n        if not command_output.get(\"loggingEnabled\"):\n            self.result.is_failure(\"SNMP logging is disabled\")\n            return\n\n        host_details = command_output.get(\"hosts\", {})\n\n        for host in self.inputs.hosts:\n            hostname = str(host.hostname)\n            vrf = host.vrf\n            actual_snmp_host = host_details.get(hostname, {})\n\n            # If SNMP host is not configured on the device, test fails.\n            if not actual_snmp_host:\n                self.result.is_failure(f\"{host} - Not configured\")\n                continue\n\n            # If VRF is not matches the expected value, test fails.\n            actual_vrf = \"default\" if (vrf_name := actual_snmp_host.get(\"vrf\")) == \"\" else vrf_name\n            if actual_vrf != vrf:\n                self.result.is_failure(f\"{host} - Incorrect VRF - Actual: {actual_vrf}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpHostLogging-attributes","title":"Inputs","text":"Name Type Description Default <code>hosts</code> <code>list[SnmpHost]</code>                      List of SNMP hosts.                    -"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpIPv4Acl","title":"VerifySnmpIPv4Acl","text":"<p>Verifies if the SNMP agent has IPv4 ACL(s) configured.</p> Expected Results <ul> <li>Success: The test will pass if the SNMP agent has the provided number of IPv4 ACL(s) in the specified VRF.</li> <li>Failure: The test will fail if the SNMP agent has not the right number of IPv4 ACL(s) in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpIPv4Acl:\n      number: 3\n      vrf: default\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpIPv4Acl(AntaTest):\n    \"\"\"Verifies if the SNMP agent has IPv4 ACL(s) configured.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SNMP agent has the provided number of IPv4 ACL(s) in the specified VRF.\n    * Failure: The test will fail if the SNMP agent has not the right number of IPv4 ACL(s) in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpIPv4Acl:\n          number: 3\n          vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp ipv4 access-list summary\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpIPv4Acl test.\"\"\"\n\n        number: PositiveInteger\n        \"\"\"The number of expected IPv4 ACL(s).\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF in which to check for the SNMP agent. Defaults to `default` VRF.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpIPv4Acl.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        ipv4_acl_list = command_output[\"ipAclList\"][\"aclList\"]\n        ipv4_acl_number = len(ipv4_acl_list)\n        if ipv4_acl_number != self.inputs.number:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - Incorrect SNMP IPv4 ACL(s) - Expected: {self.inputs.number} Actual: {ipv4_acl_number}\")\n            return\n\n        not_configured_acl = [acl[\"name\"] for acl in ipv4_acl_list if self.inputs.vrf not in acl[\"configuredVrfs\"] or self.inputs.vrf not in acl[\"activeVrfs\"]]\n\n        if not_configured_acl:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - Following SNMP IPv4 ACL(s) not configured or active: {', '.join(not_configured_acl)}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpIPv4Acl-attributes","title":"Inputs","text":"Name Type Description Default <code>number</code> <code>PositiveInteger</code>                      The number of expected IPv4 ACL(s).                    - <code>vrf</code> <code>str</code>                      The name of the VRF in which to check for the SNMP agent. Defaults to `default` VRF.                    <code>'default'</code>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpIPv6Acl","title":"VerifySnmpIPv6Acl","text":"<p>Verifies if the SNMP agent has IPv6 ACL(s) configured.</p> Expected Results <ul> <li>Success: The test will pass if the SNMP agent has the provided number of IPv6 ACL(s) in the specified VRF.</li> <li>Failure: The test will fail if the SNMP agent has not the right number of IPv6 ACL(s) in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpIPv6Acl:\n      number: 3\n      vrf: default\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpIPv6Acl(AntaTest):\n    \"\"\"Verifies if the SNMP agent has IPv6 ACL(s) configured.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SNMP agent has the provided number of IPv6 ACL(s) in the specified VRF.\n    * Failure: The test will fail if the SNMP agent has not the right number of IPv6 ACL(s) in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpIPv6Acl:\n          number: 3\n          vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp ipv6 access-list summary\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpIPv6Acl test.\"\"\"\n\n        number: PositiveInteger\n        \"\"\"The number of expected IPv6 ACL(s).\"\"\"\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF in which to check for the SNMP agent. Defaults to `default` VRF.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpIPv6Acl.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        ipv6_acl_list = command_output[\"ipv6AclList\"][\"aclList\"]\n        ipv6_acl_number = len(ipv6_acl_list)\n        if ipv6_acl_number != self.inputs.number:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - Incorrect SNMP IPv6 ACL(s) - Expected: {self.inputs.number} Actual: {ipv6_acl_number}\")\n            return\n\n        acl_not_configured = [acl[\"name\"] for acl in ipv6_acl_list if self.inputs.vrf not in acl[\"configuredVrfs\"] or self.inputs.vrf not in acl[\"activeVrfs\"]]\n\n        if acl_not_configured:\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - Following SNMP IPv6 ACL(s) not configured or active: {', '.join(acl_not_configured)}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpIPv6Acl-attributes","title":"Inputs","text":"Name Type Description Default <code>number</code> <code>PositiveInteger</code>                      The number of expected IPv6 ACL(s).                    - <code>vrf</code> <code>str</code>                      The name of the VRF in which to check for the SNMP agent. Defaults to `default` VRF.                    <code>'default'</code>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpLocation","title":"VerifySnmpLocation","text":"<p>Verifies the SNMP location of a device.</p> Expected Results <ul> <li>Success: The test will pass if the SNMP location matches the provided input.</li> <li>Failure: The test will fail if the SNMP location does not match the provided input.</li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpLocation:\n      location: New York\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpLocation(AntaTest):\n    \"\"\"Verifies the SNMP location of a device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SNMP location matches the provided input.\n    * Failure: The test will fail if the SNMP location does not match the provided input.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpLocation:\n          location: New York\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpLocation test.\"\"\"\n\n        location: str\n        \"\"\"Expected SNMP location of the device.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpLocation.\"\"\"\n        self.result.is_success()\n        # Verifies the SNMP location is configured.\n        if not (location := get_value(self.instance_commands[0].json_output, \"location.location\")):\n            self.result.is_failure(\"SNMP location is not configured\")\n            return\n\n        # Verifies the expected SNMP location.\n        if location != self.inputs.location:\n            self.result.is_failure(f\"Incorrect SNMP location - Expected: {self.inputs.location} Actual: {location}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpLocation-attributes","title":"Inputs","text":"Name Type Description Default <code>location</code> <code>str</code>                      Expected SNMP location of the device.                    -"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpNotificationHost","title":"VerifySnmpNotificationHost","text":"<p>Verifies the SNMP notification host(s) (SNMP manager) configurations.</p> <p>This test performs the following checks for each specified host:</p> <ol> <li>Verifies that the SNMP host(s) is configured on the device.</li> <li>Verifies that the notification type (\u201ctrap\u201d or \u201cinform\u201d) matches the expected value.</li> <li>Ensures that UDP port provided matches the expected value.</li> <li>Ensures the following depending on SNMP version:<ul> <li>For SNMP version v1/v2c, a valid community string is set and matches the expected value.</li> <li>For SNMP version v3, a valid user field is set and matches the expected value.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: The test will pass if all of the following conditions are met:<ul> <li>The SNMP host(s) is configured on the device.</li> <li>The notification type (\u201ctrap\u201d or \u201cinform\u201d) and UDP port match the expected value.</li> <li>Ensures the following depending on SNMP version:<ul> <li>For SNMP version v1/v2c, a community string is set and it matches the expected value.</li> <li>For SNMP version v3, a valid user field is set and matches the expected value.</li> </ul> </li> </ul> </li> <li>Failure: The test will fail if any of the following conditions is met:<ul> <li>The SNMP host(s) is not configured on the device.</li> <li>The notification type (\u201ctrap\u201d or \u201cinform\u201d) or UDP port do not matches the expected value.</li> <li>Ensures the following depending on SNMP version:<ul> <li>For SNMP version v1/v2c, a community string is not matches the expected value.</li> <li>For SNMP version v3, an user field is not matches the expected value.</li> </ul> </li> </ul> </li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpNotificationHost:\n      notification_hosts:\n        - hostname: spine\n          vrf: default\n          notification_type: trap\n          version: v1\n          udp_port: 162\n          community_string: public\n        - hostname: 192.168.1.100\n          vrf: default\n          notification_type: trap\n          version: v3\n          udp_port: 162\n          user: public\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpNotificationHost(AntaTest):\n    \"\"\"Verifies the SNMP notification host(s) (SNMP manager) configurations.\n\n    This test performs the following checks for each specified host:\n\n     1. Verifies that the SNMP host(s) is configured on the device.\n     2. Verifies that the notification type (\"trap\" or \"inform\") matches the expected value.\n     3. Ensures that UDP port provided matches the expected value.\n     4. Ensures the following depending on SNMP version:\n        - For SNMP version v1/v2c, a valid community string is set and matches the expected value.\n        - For SNMP version v3, a valid user field is set and matches the expected value.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all of the following conditions are met:\n        - The SNMP host(s) is configured on the device.\n        - The notification type (\"trap\" or \"inform\") and UDP port match the expected value.\n        - Ensures the following depending on SNMP version:\n            - For SNMP version v1/v2c, a community string is set and it matches the expected value.\n            - For SNMP version v3, a valid user field is set and matches the expected value.\n    * Failure: The test will fail if any of the following conditions is met:\n        - The SNMP host(s) is not configured on the device.\n        - The notification type (\"trap\" or \"inform\") or UDP port do not matches the expected value.\n        - Ensures the following depending on SNMP version:\n            - For SNMP version v1/v2c, a community string is not matches the expected value.\n            - For SNMP version v3, an user field is not matches the expected value.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpNotificationHost:\n          notification_hosts:\n            - hostname: spine\n              vrf: default\n              notification_type: trap\n              version: v1\n              udp_port: 162\n              community_string: public\n            - hostname: 192.168.1.100\n              vrf: default\n              notification_type: trap\n              version: v3\n              udp_port: 162\n              user: public\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp notification host\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpNotificationHost test.\"\"\"\n\n        notification_hosts: list[SnmpHost]\n        \"\"\"List of SNMP host(s).\"\"\"\n\n        @field_validator(\"notification_hosts\")\n        @classmethod\n        def validate_notification_hosts(cls, notification_hosts: list[SnmpHost]) -&gt; list[SnmpHost]:\n            \"\"\"Validate that all required fields are provided in each SNMP Notification Host.\"\"\"\n            for host in notification_hosts:\n                if host.version is None:\n                    msg = f\"{host}; 'version' field missing in the input\"\n                    raise ValueError(msg)\n                if host.version in [\"v1\", \"v2c\"] and host.community_string is None:\n                    msg = f\"{host} Version: {host.version}; 'community_string' field missing in the input\"\n                    raise ValueError(msg)\n                if host.version == \"v3\" and host.user is None:\n                    msg = f\"{host} Version: {host.version}; 'user' field missing in the input\"\n                    raise ValueError(msg)\n            return notification_hosts\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpNotificationHost.\"\"\"\n        self.result.is_success()\n\n        # If SNMP is not configured, test fails.\n        if not (snmp_hosts := get_value(self.instance_commands[0].json_output, \"hosts\")):\n            self.result.is_failure(\"No SNMP host is configured\")\n            return\n\n        for host in self.inputs.notification_hosts:\n            vrf = \"\" if host.vrf == \"default\" else host.vrf\n            hostname = str(host.hostname)\n            notification_type = host.notification_type\n            version = host.version\n            udp_port = host.udp_port\n            community_string = host.community_string\n            user = host.user\n            default_value = \"Not Found\"\n\n            host_details = next(\n                (host for host in snmp_hosts if (host.get(\"hostname\") == hostname and host.get(\"protocolVersion\") == version and host.get(\"vrf\") == vrf)), None\n            )\n            # If expected SNMP host is not configured with the specified protocol version, test fails.\n            if not host_details:\n                self.result.is_failure(f\"{host} Version: {version} - Not configured\")\n                continue\n\n            # If actual notification type does not match the expected value, test fails.\n            if notification_type != (actual_notification_type := get_value(host_details, \"notificationType\", default_value)):\n                self.result.is_failure(f\"{host} - Incorrect notification type - Expected: {notification_type} Actual: {actual_notification_type}\")\n\n            # If actual UDP port does not match the expected value, test fails.\n            if udp_port != (actual_udp_port := get_value(host_details, \"port\", default_value)):\n                self.result.is_failure(f\"{host} - Incorrect UDP port - Expected: {udp_port} Actual: {actual_udp_port}\")\n\n            user_found = user != (actual_user := get_value(host_details, \"v3Params.user\", default_value))\n            version_user_check = (version == \"v3\", user_found)\n\n            # If SNMP protocol version is v1 or v2c and actual community string does not match the expected value, test fails.\n            if version in [\"v1\", \"v2c\"] and community_string != (actual_community_string := get_value(host_details, \"v1v2cParams.communityString\", default_value)):\n                self.result.is_failure(f\"{host} Version: {version} - Incorrect community string - Expected: {community_string} Actual: {actual_community_string}\")\n\n            # If SNMP protocol version is v3 and actual user does not match the expected value, test fails.\n            elif all(version_user_check):\n                self.result.is_failure(f\"{host} Version: {version} - Incorrect user - Expected: {user} Actual: {actual_user}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpNotificationHost-attributes","title":"Inputs","text":"Name Type Description Default <code>notification_hosts</code> <code>list[SnmpHost]</code>                      List of SNMP host(s).                    -"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpPDUCounters","title":"VerifySnmpPDUCounters","text":"<p>Verifies the SNMP PDU counters.</p> <p>By default, all SNMP PDU counters will be checked for any non-zero values. An optional list of specific SNMP PDU(s) can be provided for granular testing.</p> Expected Results <ul> <li>Success: The test will pass if the SNMP PDU counter(s) are non-zero/greater than zero.</li> <li>Failure: The test will fail if the SNMP PDU counter(s) are zero/None/Not Found.</li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpPDUCounters:\n      pdus:\n        - outTrapPdus\n        - inGetNextPdus\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpPDUCounters(AntaTest):\n    \"\"\"Verifies the SNMP PDU counters.\n\n    By default, all SNMP PDU counters will be checked for any non-zero values.\n    An optional list of specific SNMP PDU(s) can be provided for granular testing.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SNMP PDU counter(s) are non-zero/greater than zero.\n    * Failure: The test will fail if the SNMP PDU counter(s) are zero/None/Not Found.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpPDUCounters:\n          pdus:\n            - outTrapPdus\n            - inGetNextPdus\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpPDUCounters test.\"\"\"\n\n        pdus: list[SnmpPdu] | None = None\n        \"\"\"Optional list of SNMP PDU counters to be verified. If not provided, test will verifies all PDU counters.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpPDUCounters.\"\"\"\n        self.result.is_success()\n        snmp_pdus = self.inputs.pdus\n        command_output = self.instance_commands[0].json_output\n\n        # Verify SNMP PDU counters.\n        if not (pdu_counters := get_value(command_output, \"counters\")):\n            self.result.is_failure(\"SNMP counters not found\")\n            return\n\n        # In case SNMP PDUs not provided, It will check all the update error counters.\n        if not snmp_pdus:\n            snmp_pdus = list(get_args(SnmpPdu))\n\n        failures = {pdu for pdu in snmp_pdus if (value := pdu_counters.get(pdu, \"Not Found\")) == \"Not Found\" or value == 0}\n\n        # Check if any failures\n        if failures:\n            self.result.is_failure(f\"The following SNMP PDU counters are not found or have zero PDU counters: {', '.join(sorted(failures))}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpPDUCounters-attributes","title":"Inputs","text":"Name Type Description Default <code>pdus</code> <code>list[SnmpPdu] | None</code>                      Optional list of SNMP PDU counters to be verified. If not provided, test will verifies all PDU counters.                    <code>None</code>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpSourceInterface","title":"VerifySnmpSourceInterface","text":"<p>Verifies SNMP source interfaces.</p> <p>This test performs the following checks:</p> <ol> <li>Verifies that source interface(s) are configured for SNMP.</li> <li>For each specified source interface:<ul> <li>Interface is configured in the specified VRF.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: The test will pass if the provided SNMP source interface(s) are configured in their specified VRF.</li> <li>Failure: The test will fail if any of the provided SNMP source interface(s) are NOT configured in their specified VRF.</li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpSourceInterface:\n      interfaces:\n        - interface: Ethernet1\n          vrf: default\n        - interface: Management0\n          vrf: MGMT\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpSourceInterface(AntaTest):\n    \"\"\"Verifies SNMP source interfaces.\n\n    This test performs the following checks:\n\n      1. Verifies that source interface(s) are configured for SNMP.\n      2. For each specified source interface:\n          - Interface is configured in the specified VRF.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the provided SNMP source interface(s) are configured in their specified VRF.\n    * Failure: The test will fail if any of the provided SNMP source interface(s) are NOT configured in their specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpSourceInterface:\n          interfaces:\n            - interface: Ethernet1\n              vrf: default\n            - interface: Management0\n              vrf: MGMT\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpSourceInterface test.\"\"\"\n\n        interfaces: list[SnmpSourceInterface]\n        \"\"\"List of source interfaces.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpSourceInterface.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output.get(\"srcIntf\", {})\n\n        if not (interface_output := command_output.get(\"sourceInterfaces\")):\n            self.result.is_failure(\"SNMP source interface(s) not configured\")\n            return\n\n        for interface_details in self.inputs.interfaces:\n            # If the source interface is not configured, or if it does not match the expected value, the test fails.\n            if not (actual_interface := interface_output.get(interface_details.vrf)):\n                self.result.is_failure(f\"{interface_details} - Not configured\")\n            elif actual_interface != interface_details.interface:\n                self.result.is_failure(f\"{interface_details} - Incorrect source interface - Actual: {actual_interface}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpSourceInterface-attributes","title":"Inputs","text":"Name Type Description Default <code>interfaces</code> <code>list[SnmpSourceInterface]</code>                      List of source interfaces.                    -"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpStatus","title":"VerifySnmpStatus","text":"<p>Verifies if the SNMP agent is enabled.</p> Expected Results <ul> <li>Success: The test will pass if the SNMP agent is enabled in the specified VRF.</li> <li>Failure: The test will fail if the SNMP agent is disabled in the specified VRF.</li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpStatus:\n      vrf: default\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpStatus(AntaTest):\n    \"\"\"Verifies if the SNMP agent is enabled.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the SNMP agent is enabled in the specified VRF.\n    * Failure: The test will fail if the SNMP agent is disabled in the specified VRF.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpStatus:\n          vrf: default\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpStatus test.\"\"\"\n\n        vrf: str = \"default\"\n        \"\"\"The name of the VRF in which to check for the SNMP agent. Defaults to `default` VRF.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpStatus.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        if not (command_output[\"enabled\"] and self.inputs.vrf in command_output[\"vrfs\"][\"snmpVrfs\"]):\n            self.result.is_failure(f\"VRF: {self.inputs.vrf} - SNMP agent disabled\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpStatus-attributes","title":"Inputs","text":"Name Type Description Default <code>vrf</code> <code>str</code>                      The name of the VRF in which to check for the SNMP agent. Defaults to `default` VRF.                    <code>'default'</code>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpUser","title":"VerifySnmpUser","text":"<p>Verifies the SNMP user configurations.</p> <p>This test performs the following checks for each specified user:</p> <ol> <li>User exists in SNMP configuration.</li> <li>Group assignment is correct.</li> <li>For SNMPv3 users only:<ul> <li>Authentication type matches (if specified)</li> <li>Privacy type matches (if specified)</li> </ul> </li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>All users exist with correct group assignments.</li> <li>SNMPv3 authentication and privacy types match specified values.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>User not found in SNMP configuration.</li> <li>Incorrect group assignment.</li> <li>For SNMPv3: Mismatched authentication or privacy types.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.snmp:\n  - VerifySnmpUser:\n      snmp_users:\n        - username: test\n          group_name: test_group\n          version: v3\n          auth_type: MD5\n          priv_type: AES-128\n</code></pre> Source code in <code>anta/tests/snmp.py</code> <pre><code>class VerifySnmpUser(AntaTest):\n    \"\"\"Verifies the SNMP user configurations.\n\n    This test performs the following checks for each specified user:\n\n      1. User exists in SNMP configuration.\n      2. Group assignment is correct.\n      3. For SNMPv3 users only:\n          - Authentication type matches (if specified)\n          - Privacy type matches (if specified)\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - All users exist with correct group assignments.\n        - SNMPv3 authentication and privacy types match specified values.\n    * Failure: If any of the following occur:\n        - User not found in SNMP configuration.\n        - Incorrect group assignment.\n        - For SNMPv3: Mismatched authentication or privacy types.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.snmp:\n      - VerifySnmpUser:\n          snmp_users:\n            - username: test\n              group_name: test_group\n              version: v3\n              auth_type: MD5\n              priv_type: AES-128\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"snmp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show snmp user\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySnmpUser test.\"\"\"\n\n        snmp_users: list[SnmpUser]\n        \"\"\"List of SNMP users.\"\"\"\n\n        @field_validator(\"snmp_users\")\n        @classmethod\n        def validate_snmp_users(cls, snmp_users: list[SnmpUser]) -&gt; list[SnmpUser]:\n            \"\"\"Validate that 'auth_type' or 'priv_type' field is provided in each SNMPv3 user.\"\"\"\n            for user in snmp_users:\n                if user.version == \"v3\" and not (user.auth_type or user.priv_type):\n                    msg = f\"{user} 'auth_type' or 'priv_type' field is required with 'version: v3'\"\n                    raise ValueError(msg)\n            return snmp_users\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySnmpUser.\"\"\"\n        self.result.is_success()\n\n        for user in self.inputs.snmp_users:\n            # Verify SNMP user details.\n            if not (user_details := get_value(self.instance_commands[0].json_output, f\"usersByVersion.{user.version}.users.{user.username}\")):\n                self.result.is_failure(f\"{user} - Not found\")\n                continue\n\n            if user.group_name != (act_group := user_details.get(\"groupName\", \"Not Found\")):\n                self.result.is_failure(f\"{user} - Incorrect user group - Actual: {act_group}\")\n\n            if user.version == \"v3\":\n                if user.auth_type and (act_auth_type := get_value(user_details, \"v3Params.authType\", \"Not Found\")) != user.auth_type:\n                    self.result.is_failure(f\"{user} - Incorrect authentication type - Expected: {user.auth_type} Actual: {act_auth_type}\")\n\n                if user.priv_type and (act_encryption := get_value(user_details, \"v3Params.privType\", \"Not Found\")) != user.priv_type:\n                    self.result.is_failure(f\"{user} - Incorrect privacy type - Expected: {user.priv_type} Actual: {act_encryption}\")\n</code></pre>"},{"location":"api/tests/snmp/#anta.tests.snmp.VerifySnmpUser-attributes","title":"Inputs","text":"Name Type Description Default <code>snmp_users</code> <code>list[SnmpUser]</code>                      List of SNMP users.                    -"},{"location":"api/tests/snmp/#input-models","title":"Input models","text":"<p>Module containing input models for SNMP tests.</p>"},{"location":"api/tests/snmp/#anta.input_models.snmp.SnmpGroup","title":"SnmpGroup","text":"<p>Model for an SNMP group.</p> Name Type Description Default <code>group_name</code> <code>str</code>                      SNMP group name.                    - <code>version</code> <code>SnmpVersion</code>                      SNMP protocol version.                    - <code>read_view</code> <code>str | None</code>                      Optional field, View to restrict read access.                    <code>None</code> <code>write_view</code> <code>str | None</code>                      Optional field, View to restrict write access.                    <code>None</code> <code>notify_view</code> <code>str | None</code>                      Optional field, View to restrict notifications.                    <code>None</code> <code>authentication</code> <code>SnmpVersionV3AuthType | None</code>                      SNMPv3 authentication settings. Required when version is v3. Can be provided in the `VerifySnmpGroup` test.                    <code>None</code> Source code in <code>anta/input_models/snmp.py</code> <pre><code>class SnmpGroup(BaseModel):\n    \"\"\"Model for an SNMP group.\"\"\"\n\n    group_name: str\n    \"\"\"SNMP group name.\"\"\"\n    version: SnmpVersion\n    \"\"\"SNMP protocol version.\"\"\"\n    read_view: str | None = None\n    \"\"\"Optional field, View to restrict read access.\"\"\"\n    write_view: str | None = None\n    \"\"\"Optional field, View to restrict write access.\"\"\"\n    notify_view: str | None = None\n    \"\"\"Optional field, View to restrict notifications.\"\"\"\n    authentication: SnmpVersionV3AuthType | None = None\n    \"\"\"SNMPv3 authentication settings. Required when version is v3. Can be provided in the `VerifySnmpGroup` test.\"\"\"\n\n    @model_validator(mode=\"after\")\n    def validate_inputs(self) -&gt; Self:\n        \"\"\"Validate the inputs provided to the SnmpGroup class.\"\"\"\n        if self.version == \"v3\" and self.authentication is None:\n            msg = f\"{self!s}: `authentication` field is missing in the input\"\n            raise ValueError(msg)\n        return self\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the SnmpGroup for reporting.\n\n        Examples\n        --------\n        - Group: Test_Group Version: v2c\n        \"\"\"\n        return f\"Group: {self.group_name} Version: {self.version}\"\n</code></pre>"},{"location":"api/tests/snmp/#anta.input_models.snmp.SnmpGroup.validate_inputs","title":"validate_inputs","text":"<pre><code>validate_inputs() -&gt; Self\n</code></pre> <p>Validate the inputs provided to the SnmpGroup class.</p> Source code in <code>anta/input_models/snmp.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_inputs(self) -&gt; Self:\n    \"\"\"Validate the inputs provided to the SnmpGroup class.\"\"\"\n    if self.version == \"v3\" and self.authentication is None:\n        msg = f\"{self!s}: `authentication` field is missing in the input\"\n        raise ValueError(msg)\n    return self\n</code></pre>"},{"location":"api/tests/snmp/#anta.input_models.snmp.SnmpHost","title":"SnmpHost","text":"<p>Model for a SNMP host.</p> Name Type Description Default <code>hostname</code> <code>IPv4Address | Hostname</code>                      IPv4 address or Hostname of the SNMP notification host.                    - <code>vrf</code> <code>str</code>                      Optional VRF for SNMP Hosts. If not provided, it defaults to `default`.                    <code>'default'</code> <code>notification_type</code> <code>Literal['trap', 'inform']</code>                      Type of SNMP notification (trap or inform), it defaults to trap.                    <code>'trap'</code> <code>version</code> <code>SnmpVersion | None</code>                      SNMP protocol version. Required field in the `VerifySnmpNotificationHost` test.                    <code>None</code> <code>udp_port</code> <code>Port | int</code>                      UDP port for SNMP. If not provided then defaults to 162.                    <code>162</code> <code>community_string</code> <code>str | None</code>                      Optional SNMP community string for authentication,required for SNMP version is v1 or v2c. Can be provided in the `VerifySnmpNotificationHost` test.                    <code>None</code> <code>user</code> <code>str | None</code>                      Optional SNMP user for authentication, required for SNMP version v3. Can be provided in the `VerifySnmpNotificationHost` test.                    <code>None</code> Source code in <code>anta/input_models/snmp.py</code> <pre><code>class SnmpHost(BaseModel):\n    \"\"\"Model for a SNMP host.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    hostname: IPv4Address | Hostname\n    \"\"\"IPv4 address or Hostname of the SNMP notification host.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"Optional VRF for SNMP Hosts. If not provided, it defaults to `default`.\"\"\"\n    notification_type: Literal[\"trap\", \"inform\"] = \"trap\"\n    \"\"\"Type of SNMP notification (trap or inform), it defaults to trap.\"\"\"\n    version: SnmpVersion | None = None\n    \"\"\"SNMP protocol version. Required field in the `VerifySnmpNotificationHost` test.\"\"\"\n    udp_port: Port | int = 162\n    \"\"\"UDP port for SNMP. If not provided then defaults to 162.\"\"\"\n    community_string: str | None = None\n    \"\"\"Optional SNMP community string for authentication,required for SNMP version is v1 or v2c. Can be provided in the `VerifySnmpNotificationHost` test.\"\"\"\n    user: str | None = None\n    \"\"\"Optional SNMP user for authentication, required for SNMP version v3. Can be provided in the `VerifySnmpNotificationHost` test.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the SnmpHost for reporting.\n\n        Examples\n        --------\n         - Host: 192.168.1.100  VRF: default\n        \"\"\"\n        return f\"Host: {self.hostname} VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/snmp/#anta.input_models.snmp.SnmpSourceInterface","title":"SnmpSourceInterface","text":"<p>Model for a SNMP source-interface.</p> Name Type Description Default <code>interface</code> <code>Interface</code>                      Interface to use as the source IP address of SNMP messages.                    - <code>vrf</code> <code>str</code>                      VRF of the source interface.                    <code>'default'</code> Source code in <code>anta/input_models/snmp.py</code> <pre><code>class SnmpSourceInterface(BaseModel):\n    \"\"\"Model for a SNMP source-interface.\"\"\"\n\n    interface: Interface\n    \"\"\"Interface to use as the source IP address of SNMP messages.\"\"\"\n    vrf: str = \"default\"\n    \"\"\"VRF of the source interface.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the SnmpSourceInterface for reporting.\n\n        Examples\n        --------\n        - Source Interface: Ethernet1 VRF: default\n        \"\"\"\n        return f\"Source Interface: {self.interface} VRF: {self.vrf}\"\n</code></pre>"},{"location":"api/tests/snmp/#anta.input_models.snmp.SnmpUser","title":"SnmpUser","text":"<p>Model for a SNMP User.</p> Name Type Description Default <code>username</code> <code>str</code>                      SNMP user name.                    - <code>group_name</code> <code>str</code>                      SNMP group for the user.                    - <code>version</code> <code>SnmpVersion</code>                      SNMP protocol version.                    - <code>auth_type</code> <code>SnmpHashingAlgorithm | None</code>                      User authentication algorithm. Can be provided in the `VerifySnmpUser` test.                    <code>None</code> <code>priv_type</code> <code>SnmpEncryptionAlgorithm | None</code>                      User privacy algorithm. Can be provided in the `VerifySnmpUser` test.                    <code>None</code> Source code in <code>anta/input_models/snmp.py</code> <pre><code>class SnmpUser(BaseModel):\n    \"\"\"Model for a SNMP User.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    username: str\n    \"\"\"SNMP user name.\"\"\"\n    group_name: str\n    \"\"\"SNMP group for the user.\"\"\"\n    version: SnmpVersion\n    \"\"\"SNMP protocol version.\"\"\"\n    auth_type: SnmpHashingAlgorithm | None = None\n    \"\"\"User authentication algorithm. Can be provided in the `VerifySnmpUser` test.\"\"\"\n    priv_type: SnmpEncryptionAlgorithm | None = None\n    \"\"\"User privacy algorithm. Can be provided in the `VerifySnmpUser` test.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the SnmpUser for reporting.\n\n        Examples\n        --------\n        - User: Test Group: Test_Group Version: v2c\n        \"\"\"\n        return f\"User: {self.username} Group: {self.group_name} Version: {self.version}\"\n</code></pre>"},{"location":"api/tests/software/","title":"Software","text":"<p>Module related to the EOS software tests.</p>"},{"location":"api/tests/software/#anta.tests.software.VerifyEOSExtensions","title":"VerifyEOSExtensions","text":"<p>Verifies that all EOS extensions installed on the device are enabled for boot persistence.</p> Expected Results <ul> <li>Success: The test will pass if all EOS extensions installed on the device are enabled for boot persistence.</li> <li>Failure: The test will fail if some EOS extensions installed on the device are not enabled for boot persistence.</li> </ul> Examples <pre><code>anta.tests.software:\n  - VerifyEOSExtensions:\n</code></pre> Source code in <code>anta/tests/software.py</code> <pre><code>class VerifyEOSExtensions(AntaTest):\n    \"\"\"Verifies that all EOS extensions installed on the device are enabled for boot persistence.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all EOS extensions installed on the device are enabled for boot persistence.\n    * Failure: The test will fail if some EOS extensions installed on the device are not enabled for boot persistence.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.software:\n      - VerifyEOSExtensions:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"software\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [\n        AntaCommand(command=\"show extensions\", revision=2),\n        AntaCommand(command=\"show boot-extensions\", revision=1),\n    ]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyEOSExtensions.\"\"\"\n        boot_extensions = []\n        self.result.is_success()\n        show_extensions_command_output = self.instance_commands[0].json_output\n        show_boot_extensions_command_output = self.instance_commands[1].json_output\n        installed_extensions = [\n            extension for extension, extension_data in show_extensions_command_output[\"extensions\"].items() if extension_data[\"status\"] == \"installed\"\n        ]\n        for extension in show_boot_extensions_command_output[\"extensions\"]:\n            formatted_extension = extension.strip(\"\\n\")\n            if formatted_extension != \"\":\n                boot_extensions.append(formatted_extension)\n        installed_extensions.sort()\n        boot_extensions.sort()\n        if installed_extensions != boot_extensions:\n            str_installed_extensions = \", \".join(installed_extensions) if installed_extensions else \"Not found\"\n            str_boot_extensions = \", \".join(boot_extensions) if boot_extensions else \"Not found\"\n            self.result.is_failure(f\"EOS extensions mismatch - Installed: {str_installed_extensions} Configured: {str_boot_extensions}\")\n</code></pre>"},{"location":"api/tests/software/#anta.tests.software.VerifyEOSVersion","title":"VerifyEOSVersion","text":"<p>Verifies the EOS version of the device.</p> Expected Results <ul> <li>Success: The test will pass if the device is running one of the allowed EOS version.</li> <li>Failure: The test will fail if the device is not running one of the allowed EOS version.</li> </ul> Examples <pre><code>anta.tests.software:\n  - VerifyEOSVersion:\n      versions:\n        - 4.25.4M\n        - 4.26.1F\n</code></pre> Source code in <code>anta/tests/software.py</code> <pre><code>class VerifyEOSVersion(AntaTest):\n    \"\"\"Verifies the EOS version of the device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device is running one of the allowed EOS version.\n    * Failure: The test will fail if the device is not running one of the allowed EOS version.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.software:\n      - VerifyEOSVersion:\n          versions:\n            - 4.25.4M\n            - 4.26.1F\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"software\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show version\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyEOSVersion test.\"\"\"\n\n        versions: list[str]\n        \"\"\"List of allowed EOS versions.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyEOSVersion.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        if command_output[\"version\"] not in self.inputs.versions:\n            self.result.is_failure(f\"EOS version mismatch - Actual: {command_output['version']} not in Expected: {', '.join(self.inputs.versions)}\")\n</code></pre>"},{"location":"api/tests/software/#anta.tests.software.VerifyEOSVersion-attributes","title":"Inputs","text":"Name Type Description Default <code>versions</code> <code>list[str]</code>                      List of allowed EOS versions.                    -"},{"location":"api/tests/software/#anta.tests.software.VerifyTerminAttrVersion","title":"VerifyTerminAttrVersion","text":"<p>Verifies the TerminAttr version of the device.</p> Expected Results <ul> <li>Success: The test will pass if the device is running one of the allowed TerminAttr version.</li> <li>Failure: The test will fail if the device is not running one of the allowed TerminAttr version.</li> </ul> Examples <pre><code>anta.tests.software:\n  - VerifyTerminAttrVersion:\n      versions:\n        - v1.13.6\n        - v1.8.0\n</code></pre> Source code in <code>anta/tests/software.py</code> <pre><code>class VerifyTerminAttrVersion(AntaTest):\n    \"\"\"Verifies the TerminAttr version of the device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device is running one of the allowed TerminAttr version.\n    * Failure: The test will fail if the device is not running one of the allowed TerminAttr version.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.software:\n      - VerifyTerminAttrVersion:\n          versions:\n            - v1.13.6\n            - v1.8.0\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"software\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show version detail\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyTerminAttrVersion test.\"\"\"\n\n        versions: list[str]\n        \"\"\"List of allowed TerminAttr versions.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyTerminAttrVersion.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        self.result.is_success()\n        command_output_data = command_output[\"details\"][\"packages\"][\"TerminAttr-core\"][\"version\"]\n        if command_output_data not in self.inputs.versions:\n            self.result.is_failure(f\"TerminAttr version mismatch - Actual: {command_output_data} not in Expected: {', '.join(self.inputs.versions)}\")\n</code></pre>"},{"location":"api/tests/software/#anta.tests.software.VerifyTerminAttrVersion-attributes","title":"Inputs","text":"Name Type Description Default <code>versions</code> <code>list[str]</code>                      List of allowed TerminAttr versions.                    -"},{"location":"api/tests/stp/","title":"STP","text":"<p>Module related to various Spanning Tree Protocol (STP) tests.</p>"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPBlockedPorts","title":"VerifySTPBlockedPorts","text":"<p>Verifies there is no STP blocked ports.</p> Expected Results <ul> <li>Success: The test will pass if there are NO ports blocked by STP.</li> <li>Failure: The test will fail if there are ports blocked by STP.</li> </ul> Examples <pre><code>anta.tests.stp:\n  - VerifySTPBlockedPorts:\n</code></pre> Source code in <code>anta/tests/stp.py</code> <pre><code>class VerifySTPBlockedPorts(AntaTest):\n    \"\"\"Verifies there is no STP blocked ports.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are NO ports blocked by STP.\n    * Failure: The test will fail if there are ports blocked by STP.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stp:\n      - VerifySTPBlockedPorts:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"stp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show spanning-tree blockedports\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySTPBlockedPorts.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        if not (stp_instances := command_output[\"spanningTreeInstances\"]):\n            self.result.is_success()\n        else:\n            for key, value in stp_instances.items():\n                stp_block_ports = value.get(\"spanningTreeBlockedPorts\")\n                self.result.is_failure(f\"STP Instance: {key} - Blocked ports - {', '.join(stp_block_ports)}\")\n</code></pre>"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPCounters","title":"VerifySTPCounters","text":"<p>Verifies there is no errors in STP BPDU packets.</p> Expected Results <ul> <li>Success: The test will pass if there are NO STP BPDU packet errors under all interfaces participating in STP.</li> <li>Failure: The test will fail if there are STP BPDU packet errors on one or many interface(s).</li> </ul> Examples <pre><code>anta.tests.stp:\n  - VerifySTPCounters:\n</code></pre> Source code in <code>anta/tests/stp.py</code> <pre><code>class VerifySTPCounters(AntaTest):\n    \"\"\"Verifies there is no errors in STP BPDU packets.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are NO STP BPDU packet errors under all interfaces participating in STP.\n    * Failure: The test will fail if there are STP BPDU packet errors on one or many interface(s).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stp:\n      - VerifySTPCounters:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"stp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show spanning-tree counters\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySTPCounters.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        for interface, counters in command_output[\"interfaces\"].items():\n            if counters[\"bpduTaggedError\"] != 0:\n                self.result.is_failure(f\"Interface {interface} - STP BPDU packet tagged errors count mismatch - Expected: 0 Actual: {counters['bpduTaggedError']}\")\n            if counters[\"bpduOtherError\"] != 0:\n                self.result.is_failure(f\"Interface {interface} - STP BPDU packet other errors count mismatch - Expected: 0 Actual: {counters['bpduOtherError']}\")\n</code></pre>"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPDisabledVlans","title":"VerifySTPDisabledVlans","text":"<p>Verifies the STP disabled VLAN(s).</p> <p>This test performs the following checks:</p> <ol> <li>Verifies that the STP is configured.</li> <li>Verifies that the specified VLAN(s) exist on the device.</li> <li>Verifies that the STP is disabled for the specified VLAN(s).</li> </ol> Expected Results <ul> <li>Success: The test will pass if all of the following conditions are met:<ul> <li>STP is properly configured on the device.</li> <li>The specified VLAN(s) exist on the device.</li> <li>STP is confirmed to be disabled for all the specified VLAN(s).</li> </ul> </li> <li>Failure: The test will fail if any of the following condition is met:<ul> <li>STP is not configured on the device.</li> <li>The specified VLAN(s) do not exist on the device.</li> <li>STP is enabled for any of the specified VLAN(s).</li> </ul> </li> </ul> Examples <pre><code>anta.tests.stp:\n  - VerifySTPDisabledVlans:\n        vlans:\n          - 6\n          - 4094\n</code></pre> Source code in <code>anta/tests/stp.py</code> <pre><code>class VerifySTPDisabledVlans(AntaTest):\n    \"\"\"Verifies the STP disabled VLAN(s).\n\n    This test performs the following checks:\n\n      1. Verifies that the STP is configured.\n      2. Verifies that the specified VLAN(s) exist on the device.\n      3. Verifies that the STP is disabled for the specified VLAN(s).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all of the following conditions are met:\n        - STP is properly configured on the device.\n        - The specified VLAN(s) exist on the device.\n        - STP is confirmed to be disabled for all the specified VLAN(s).\n    * Failure: The test will fail if any of the following condition is met:\n        - STP is not configured on the device.\n        - The specified VLAN(s) do not exist on the device.\n        - STP is enabled for any of the specified VLAN(s).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stp:\n      - VerifySTPDisabledVlans:\n            vlans:\n              - 6\n              - 4094\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"stp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show spanning-tree vlan detail\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySTPDisabledVlans test.\"\"\"\n\n        vlans: list[Vlan]\n        \"\"\"List of STP disabled VLAN(s).\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySTPDisabledVlans.\"\"\"\n        self.result.is_success()\n\n        command_output = self.instance_commands[0].json_output\n        stp_vlan_instances = command_output.get(\"spanningTreeVlanInstances\", {})\n\n        # If the spanningTreeVlanInstances detail are not found in the command output, the test fails.\n        if not stp_vlan_instances:\n            self.result.is_failure(\"STP is not configured\")\n            return\n\n        actual_vlans = list(stp_vlan_instances)\n        # If the specified VLAN is not present on the device, STP is enabled for the VLAN(s), test fails.\n        for vlan in self.inputs.vlans:\n            if str(vlan) not in actual_vlans:\n                self.result.is_failure(f\"VLAN: {vlan} - Not configured\")\n                continue\n\n            if stp_vlan_instances.get(str(vlan)):\n                self.result.is_failure(f\"VLAN: {vlan} - STP is enabled\")\n</code></pre>"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPDisabledVlans-attributes","title":"Inputs","text":"Name Type Description Default <code>vlans</code> <code>list[Vlan]</code>                      List of STP disabled VLAN(s).                    -"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPForwardingPorts","title":"VerifySTPForwardingPorts","text":"<p>Verifies that all interfaces are in a forwarding state for a provided list of VLAN(s).</p> Expected Results <ul> <li>Success: The test will pass if all interfaces are in a forwarding state for the specified VLAN(s).</li> <li>Failure: The test will fail if one or many interfaces are NOT in a forwarding state in the specified VLAN(s).</li> </ul> Examples <pre><code>anta.tests.stp:\n  - VerifySTPForwardingPorts:\n      vlans:\n        - 10\n        - 20\n</code></pre> Source code in <code>anta/tests/stp.py</code> <pre><code>class VerifySTPForwardingPorts(AntaTest):\n    \"\"\"Verifies that all interfaces are in a forwarding state for a provided list of VLAN(s).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all interfaces are in a forwarding state for the specified VLAN(s).\n    * Failure: The test will fail if one or many interfaces are NOT in a forwarding state in the specified VLAN(s).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stp:\n      - VerifySTPForwardingPorts:\n          vlans:\n            - 10\n            - 20\n    ```\n    \"\"\"\n\n    description = \"Verifies that all interfaces are forwarding for a provided list of VLAN(s).\"\n    categories: ClassVar[list[str]] = [\"stp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaTemplate(template=\"show spanning-tree topology vlan {vlan} status\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySTPForwardingPorts test.\"\"\"\n\n        vlans: list[Vlan]\n        \"\"\"List of VLAN on which to verify forwarding states.\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for each VLAN in the input list.\"\"\"\n        return [template.render(vlan=vlan) for vlan in self.inputs.vlans]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySTPForwardingPorts.\"\"\"\n        self.result.is_success()\n        interfaces_state = []\n        for command in self.instance_commands:\n            vlan_id = command.params.vlan\n            if not (topologies := get_value(command.json_output, \"topologies\")):\n                self.result.is_failure(f\"VLAN {vlan_id} - STP instance is not configured\")\n                continue\n            for value in topologies.values():\n                if vlan_id and int(vlan_id) in value[\"vlans\"]:\n                    interfaces_state = [\n                        (interface, actual_state) for interface, state in value[\"interfaces\"].items() if (actual_state := state[\"state\"]) != \"forwarding\"\n                    ]\n\n            if interfaces_state:\n                for interface, state in interfaces_state:\n                    self.result.is_failure(f\"VLAN {vlan_id} Interface: {interface} - Invalid state - Expected: forwarding Actual: {state}\")\n</code></pre>"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPForwardingPorts-attributes","title":"Inputs","text":"Name Type Description Default <code>vlans</code> <code>list[Vlan]</code>                      List of VLAN on which to verify forwarding states.                    -"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPMode","title":"VerifySTPMode","text":"<p>Verifies the configured STP mode for a provided list of VLAN(s).</p> Expected Results <ul> <li>Success: The test will pass if the STP mode is configured properly in the specified VLAN(s).</li> <li>Failure: The test will fail if the STP mode is NOT configured properly for one or more specified VLAN(s).</li> </ul> Examples <pre><code>anta.tests.stp:\n  - VerifySTPMode:\n      mode: rapidPvst\n      vlans:\n        - 10\n        - 20\n</code></pre> Source code in <code>anta/tests/stp.py</code> <pre><code>class VerifySTPMode(AntaTest):\n    \"\"\"Verifies the configured STP mode for a provided list of VLAN(s).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the STP mode is configured properly in the specified VLAN(s).\n    * Failure: The test will fail if the STP mode is NOT configured properly for one or more specified VLAN(s).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stp:\n      - VerifySTPMode:\n          mode: rapidPvst\n          vlans:\n            - 10\n            - 20\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"stp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaTemplate(template=\"show spanning-tree vlan {vlan}\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySTPMode test.\"\"\"\n\n        mode: Literal[\"mstp\", \"rstp\", \"rapidPvst\"] = \"mstp\"\n        \"\"\"STP mode to verify. Supported values: mstp, rstp, rapidPvst. Defaults to mstp.\"\"\"\n        vlans: list[Vlan]\n        \"\"\"List of VLAN on which to verify STP mode.\"\"\"\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for each VLAN in the input list.\"\"\"\n        return [template.render(vlan=vlan) for vlan in self.inputs.vlans]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySTPMode.\"\"\"\n        self.result.is_success()\n        for command in self.instance_commands:\n            vlan_id = command.params.vlan\n            if not (\n                stp_mode := get_value(\n                    command.json_output,\n                    f\"spanningTreeVlanInstances.{vlan_id}.spanningTreeVlanInstance.protocol\",\n                )\n            ):\n                self.result.is_failure(f\"VLAN {vlan_id} STP mode: {self.inputs.mode} - Not configured\")\n            elif stp_mode != self.inputs.mode:\n                self.result.is_failure(f\"VLAN {vlan_id} - Incorrect STP mode - Expected: {self.inputs.mode} Actual: {stp_mode}\")\n</code></pre>"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPMode-attributes","title":"Inputs","text":"Name Type Description Default <code>mode</code> <code>Literal['mstp', 'rstp', 'rapidPvst']</code>                      STP mode to verify. Supported values: mstp, rstp, rapidPvst. Defaults to mstp.                    <code>'mstp'</code> <code>vlans</code> <code>list[Vlan]</code>                      List of VLAN on which to verify STP mode.                    -"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPRootPriority","title":"VerifySTPRootPriority","text":"<p>Verifies the STP root priority for a provided list of VLAN or MST instance ID(s).</p> Expected Results <ul> <li>Success: The test will pass if the STP root priority is configured properly for the specified VLAN or MST instance ID(s).</li> <li>Failure: The test will fail if the STP root priority is NOT configured properly for the specified VLAN or MST instance ID(s).</li> </ul> Examples <pre><code>anta.tests.stp:\n  - VerifySTPRootPriority:\n      priority: 32768\n      instances:\n        - 10\n        - 20\n</code></pre> Source code in <code>anta/tests/stp.py</code> <pre><code>class VerifySTPRootPriority(AntaTest):\n    \"\"\"Verifies the STP root priority for a provided list of VLAN or MST instance ID(s).\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the STP root priority is configured properly for the specified VLAN or MST instance ID(s).\n    * Failure: The test will fail if the STP root priority is NOT configured properly for the specified VLAN or MST instance ID(s).\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stp:\n      - VerifySTPRootPriority:\n          priority: 32768\n          instances:\n            - 10\n            - 20\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"stp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show spanning-tree root detail\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifySTPRootPriority test.\"\"\"\n\n        priority: int\n        \"\"\"STP root priority to verify.\"\"\"\n        instances: list[Vlan] = Field(default=[])\n        \"\"\"List of VLAN or MST instance ID(s). If empty, ALL VLAN or MST instance ID(s) will be verified.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifySTPRootPriority.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        if not (stp_instances := command_output[\"instances\"]):\n            self.result.is_failure(\"No STP instances configured\")\n            return\n        # Checking the type of instances based on first instance\n        first_name = next(iter(stp_instances))\n        if first_name.startswith(\"MST\"):\n            prefix = \"MST\"\n        elif first_name.startswith(\"VL\"):\n            prefix = \"VL\"\n        else:\n            self.result.is_failure(f\"STP Instance: {first_name} - Unsupported STP instance type\")\n            return\n        check_instances = [f\"{prefix}{instance_id}\" for instance_id in self.inputs.instances] if self.inputs.instances else command_output[\"instances\"].keys()\n        for instance in check_instances:\n            if not (instance_details := get_value(command_output, f\"instances.{instance}\")):\n                self.result.is_failure(f\"Instance: {instance} - Not configured\")\n                continue\n            if (priority := get_value(instance_details, \"rootBridge.priority\")) != self.inputs.priority:\n                self.result.is_failure(f\"STP Instance: {instance} - Incorrect root priority - Expected: {self.inputs.priority} Actual: {priority}\")\n</code></pre>"},{"location":"api/tests/stp/#anta.tests.stp.VerifySTPRootPriority-attributes","title":"Inputs","text":"Name Type Description Default <code>priority</code> <code>int</code>                      STP root priority to verify.                    - <code>instances</code> <code>list[Vlan]</code>                      List of VLAN or MST instance ID(s). If empty, ALL VLAN or MST instance ID(s) will be verified.                    <code>Field(default=[])</code>"},{"location":"api/tests/stp/#anta.tests.stp.VerifyStpTopologyChanges","title":"VerifyStpTopologyChanges","text":"<p>Verifies the number of changes across all interfaces in the Spanning Tree Protocol (STP) topology is below a threshold.</p> Expected Results <ul> <li>Success: The test will pass if the total number of changes across all interfaces is less than the specified threshold.</li> <li>Failure: The test will fail if the total number of changes across all interfaces meets or exceeds the specified threshold, indicating potential instability in the topology.</li> </ul> Examples <pre><code>anta.tests.stp:\n  - VerifyStpTopologyChanges:\n      threshold: 10\n</code></pre> Source code in <code>anta/tests/stp.py</code> <pre><code>class VerifyStpTopologyChanges(AntaTest):\n    \"\"\"Verifies the number of changes across all interfaces in the Spanning Tree Protocol (STP) topology is below a threshold.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the total number of changes across all interfaces is less than the specified threshold.\n    * Failure: The test will fail if the total number of changes across all interfaces meets or exceeds the specified threshold,\n    indicating potential instability in the topology.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stp:\n      - VerifyStpTopologyChanges:\n          threshold: 10\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"stp\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show spanning-tree topology status detail\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyStpTopologyChanges test.\"\"\"\n\n        threshold: int\n        \"\"\"The threshold number of changes in the STP topology.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyStpTopologyChanges.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        stp_topologies = command_output.get(\"topologies\", {})\n\n        # verifies all available topologies except the \"NoStp\" topology.\n        stp_topologies.pop(\"NoStp\", None)\n\n        # Verify the STP topology(s).\n        if not stp_topologies:\n            self.result.is_failure(\"STP is not configured\")\n            return\n\n        # Verifies the number of changes across all interfaces\n        for topology, topology_details in stp_topologies.items():\n            for interface, details in topology_details.get(\"interfaces\", {}).items():\n                if (num_of_changes := details.get(\"numChanges\")) &gt; self.inputs.threshold:\n                    self.result.is_failure(\n                        f\"Topology: {topology} Interface: {interface} - Number of changes not within the threshold - Expected: \"\n                        f\"{self.inputs.threshold} Actual: {num_of_changes}\"\n                    )\n</code></pre>"},{"location":"api/tests/stp/#anta.tests.stp.VerifyStpTopologyChanges-attributes","title":"Inputs","text":"Name Type Description Default <code>threshold</code> <code>int</code>                      The threshold number of changes in the STP topology.                    -"},{"location":"api/tests/stun/","title":"STUN","text":""},{"location":"api/tests/stun/#tests","title":"Tests","text":"<p>Test functions related to various STUN settings.</p>"},{"location":"api/tests/stun/#anta.tests.stun.VerifyStunClient","title":"VerifyStunClient","text":"Replaced with: <code>VerifyStunClientTranslation</code> <p>(Deprecated) Verifies the translation for a source address on a STUN client.</p> <p>Alias for the VerifyStunClientTranslation test to maintain backward compatibility. When initialized, it will emit a deprecation warning and call the VerifyStunClientTranslation test.</p> Examples <pre><code>anta.tests.stun:\n  - VerifyStunClient:\n      stun_clients:\n        - source_address: 172.18.3.2\n          public_address: 172.18.3.21\n          source_port: 4500\n          public_port: 6006\n</code></pre>"},{"location":"api/tests/stun/#anta.tests.stun.VerifyStunClientTranslation","title":"VerifyStunClientTranslation","text":"<p>Verifies the translation for a source address on a STUN client.</p> <p>This test performs the following checks for each specified address family:</p> <ol> <li>Validates that there is a translation for the source address on the STUN client.</li> <li>If public IP and port details are provided, validates their correctness against the configuration.</li> </ol> Expected Results <ul> <li>Success: If all of the following conditions are met:<ul> <li>The test will pass if the source address translation is present.</li> <li>If public IP and port details are provided, they must also match the translation information.</li> </ul> </li> <li>Failure: If any of the following occur:<ul> <li>There is no translation for the source address on the STUN client.</li> <li>The public IP or port details, if specified, are incorrect.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.stun:\n  - VerifyStunClientTranslation:\n      stun_clients:\n        - source_address: 172.18.3.2\n          public_address: 172.18.3.21\n          source_port: 4500\n          public_port: 6006\n        - source_address: 100.64.3.2\n          public_address: 100.64.3.21\n          source_port: 4500\n          public_port: 6006\n</code></pre> Source code in <code>anta/tests/stun.py</code> <pre><code>class VerifyStunClientTranslation(AntaTest):\n    \"\"\"Verifies the translation for a source address on a STUN client.\n\n    This test performs the following checks for each specified address family:\n\n      1. Validates that there is a translation for the source address on the STUN client.\n      2. If public IP and port details are provided, validates their correctness against the configuration.\n\n    Expected Results\n    ----------------\n    * Success: If all of the following conditions are met:\n        - The test will pass if the source address translation is present.\n        - If public IP and port details are provided, they must also match the translation information.\n    * Failure: If any of the following occur:\n        - There is no translation for the source address on the STUN client.\n        - The public IP or port details, if specified, are incorrect.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stun:\n      - VerifyStunClientTranslation:\n          stun_clients:\n            - source_address: 172.18.3.2\n              public_address: 172.18.3.21\n              source_port: 4500\n              public_port: 6006\n            - source_address: 100.64.3.2\n              public_address: 100.64.3.21\n              source_port: 4500\n              public_port: 6006\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"stun\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaTemplate(template=\"show stun client translations {source_address} {source_port}\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyStunClientTranslation test.\"\"\"\n\n        stun_clients: list[StunClientTranslation]\n        \"\"\"List of STUN clients.\"\"\"\n        StunClientTranslation: ClassVar[type[StunClientTranslation]] = StunClientTranslation\n\n    def render(self, template: AntaTemplate) -&gt; list[AntaCommand]:\n        \"\"\"Render the template for each STUN translation.\"\"\"\n        return [template.render(source_address=client.source_address, source_port=client.source_port) for client in self.inputs.stun_clients]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyStunClientTranslation.\"\"\"\n        self.result.is_success()\n\n        # Iterate over each command output and corresponding client input\n        for command, client_input in zip(self.instance_commands, self.inputs.stun_clients):\n            bindings = command.json_output[\"bindings\"]\n            input_public_address = client_input.public_address\n            input_public_port = client_input.public_port\n\n            # If no bindings are found for the STUN client, mark the test as a failure and continue with the next client\n            if not bindings:\n                self.result.is_failure(f\"{client_input} - STUN client translation not found\")\n                continue\n\n            # Extract the transaction ID from the bindings\n            transaction_id = next(iter(bindings.keys()))\n\n            # Verifying the public address if provided\n            if input_public_address and str(input_public_address) != (actual_public_address := get_value(bindings, f\"{transaction_id}.publicAddress.ip\")):\n                self.result.is_failure(f\"{client_input} - Incorrect public-facing address - Expected: {input_public_address} Actual: {actual_public_address}\")\n\n            # Verifying the public port if provided\n            if input_public_port and input_public_port != (actual_public_port := get_value(bindings, f\"{transaction_id}.publicAddress.port\")):\n                self.result.is_failure(f\"{client_input} - Incorrect public-facing port - Expected: {input_public_port} Actual: {actual_public_port}\")\n</code></pre>"},{"location":"api/tests/stun/#anta.tests.stun.VerifyStunClientTranslation-attributes","title":"Inputs","text":"Name Type Description Default <code>stun_clients</code> <code>list[StunClientTranslation]</code>                      List of STUN clients.                    -"},{"location":"api/tests/stun/#anta.tests.stun.VerifyStunServer","title":"VerifyStunServer","text":"<p>Verifies the STUN server status is enabled and running.</p> Expected Results <ul> <li>Success: The test will pass if the STUN server status is enabled and running.</li> <li>Failure: The test will fail if the STUN server is disabled or not running.</li> </ul> Examples <pre><code>anta.tests.stun:\n  - VerifyStunServer:\n</code></pre> Source code in <code>anta/tests/stun.py</code> <pre><code>class VerifyStunServer(AntaTest):\n    \"\"\"Verifies the STUN server status is enabled and running.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the STUN server status is enabled and running.\n    * Failure: The test will fail if the STUN server is disabled or not running.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.stun:\n      - VerifyStunServer:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"stun\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show stun server status\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyStunServer.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        status_disabled = not command_output.get(\"enabled\")\n        not_running = command_output.get(\"pid\") == 0\n\n        if status_disabled and not_running:\n            self.result.is_failure(\"STUN server status is disabled and not running\")\n        elif status_disabled:\n            self.result.is_failure(\"STUN server status is disabled\")\n        elif not_running:\n            self.result.is_failure(\"STUN server is not running\")\n        else:\n            self.result.is_success()\n</code></pre>"},{"location":"api/tests/stun/#input-models","title":"Input models","text":"<p>Module containing input models for services tests.</p>"},{"location":"api/tests/stun/#anta.input_models.stun.StunClientTranslation","title":"StunClientTranslation","text":"<p>STUN (Session Traversal Utilities for NAT) model represents the configuration of an IPv4-based client translations.</p> Name Type Description Default <code>source_address</code> <code>IPv4Address</code>                      The IPv4 address of the STUN client                    - <code>source_port</code> <code>Port</code>                      The port number used by the STUN client for communication. Defaults to 4500.                    <code>4500</code> <code>public_address</code> <code>IPv4Address | None</code>                      The public-facing IPv4 address of the STUN client, discovered via the STUN server.                    <code>None</code> <code>public_port</code> <code>Port | None</code>                      The public-facing port number of the STUN client, discovered via the STUN server.                    <code>None</code> Source code in <code>anta/input_models/stun.py</code> <pre><code>class StunClientTranslation(BaseModel):\n    \"\"\"STUN (Session Traversal Utilities for NAT) model represents the configuration of an IPv4-based client translations.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    source_address: IPv4Address\n    \"\"\"The IPv4 address of the STUN client\"\"\"\n    source_port: Port = 4500\n    \"\"\"The port number used by the STUN client for communication. Defaults to 4500.\"\"\"\n    public_address: IPv4Address | None = None\n    \"\"\"The public-facing IPv4 address of the STUN client, discovered via the STUN server.\"\"\"\n    public_port: Port | None = None\n    \"\"\"The public-facing port number of the STUN client, discovered via the STUN server.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a human-readable string representation of the StunClientTranslation for reporting.\n\n        Examples\n        --------\n        Client 10.0.0.1 Port: 4500\n        \"\"\"\n        return f\"Client {self.source_address} Port: {self.source_port}\"\n</code></pre>"},{"location":"api/tests/system/","title":"System","text":""},{"location":"api/tests/system/#tests","title":"Tests","text":"<p>Module related to system-level features and protocols tests.</p>"},{"location":"api/tests/system/#anta.tests.system.VerifyAgentLogs","title":"VerifyAgentLogs","text":"<p>Verifies there are no agent crash reports.</p> Expected Results <ul> <li>Success: The test will pass if there is NO agent crash reported.</li> <li>Failure: The test will fail if any agent crashes are reported.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyAgentLogs:\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyAgentLogs(AntaTest):\n    \"\"\"Verifies there are no agent crash reports.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there is NO agent crash reported.\n    * Failure: The test will fail if any agent crashes are reported.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyAgentLogs:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show agent logs crash\", ofmt=\"text\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyAgentLogs.\"\"\"\n        command_output = self.instance_commands[0].text_output\n        if len(command_output) == 0:\n            self.result.is_success()\n        else:\n            pattern = re.compile(r\"^===&gt; (.*?) &lt;===$\", re.MULTILINE)\n            agents = \"\\n * \".join(pattern.findall(command_output))\n            self.result.is_failure(f\"Device has reported agent crashes:\\n * {agents}\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyCPUUtilization","title":"VerifyCPUUtilization","text":"<p>Verifies whether the CPU utilization is below 75%.</p> Expected Results <ul> <li>Success: The test will pass if the CPU utilization is below 75%.</li> <li>Failure: The test will fail if the CPU utilization is over 75%.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyCPUUtilization:\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyCPUUtilization(AntaTest):\n    \"\"\"Verifies whether the CPU utilization is below 75%.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the CPU utilization is below 75%.\n    * Failure: The test will fail if the CPU utilization is over 75%.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyCPUUtilization:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show processes top once\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyCPUUtilization.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        command_output_data = command_output[\"cpuInfo\"][\"%Cpu(s)\"][\"idle\"]\n        if command_output_data &lt; CPU_IDLE_THRESHOLD:\n            self.result.is_failure(f\"Device has reported a high CPU utilization -  Expected: &lt; 75% Actual: {100 - command_output_data}%\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyCoredump","title":"VerifyCoredump","text":"<p>Verifies there are no core dump files.</p> Expected Results <ul> <li>Success: The test will pass if there are NO core dump(s) in /var/core.</li> <li>Failure: The test will fail if there are core dump(s) in /var/core.</li> </ul> Notes <ul> <li>This test will NOT check for minidump(s) generated by certain agents in /var/core/minidump.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyCoredump:\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyCoredump(AntaTest):\n    \"\"\"Verifies there are no core dump files.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are NO core dump(s) in /var/core.\n    * Failure: The test will fail if there are core dump(s) in /var/core.\n\n    Notes\n    -----\n    * This test will NOT check for minidump(s) generated by certain agents in /var/core/minidump.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyCoredump:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show system coredump\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyCoredump.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        core_files = command_output[\"coreFiles\"]\n        if \"minidump\" in core_files:\n            core_files.remove(\"minidump\")\n        if not core_files:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Core dump(s) have been found: {', '.join(core_files)}\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyFileSystemUtilization","title":"VerifyFileSystemUtilization","text":"<p>Verifies that no partition is utilizing more than 75% of its disk space.</p> Expected Results <ul> <li>Success: The test will pass if all partitions are using less than 75% of its disk space.</li> <li>Failure: The test will fail if any partitions are using more than 75% of its disk space.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyFileSystemUtilization:\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyFileSystemUtilization(AntaTest):\n    \"\"\"Verifies that no partition is utilizing more than 75% of its disk space.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all partitions are using less than 75% of its disk space.\n    * Failure: The test will fail if any partitions are using more than 75% of its disk space.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyFileSystemUtilization:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"bash timeout 10 df -h\", ofmt=\"text\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyFileSystemUtilization.\"\"\"\n        command_output = self.instance_commands[0].text_output\n        self.result.is_success()\n        for line in command_output.split(\"\\n\")[1:]:\n            if \"loop\" not in line and len(line) &gt; 0 and (percentage := int(line.split()[4].replace(\"%\", \"\"))) &gt; DISK_SPACE_THRESHOLD:\n                self.result.is_failure(f\"Mount point: {line} - Higher disk space utilization - Expected: {DISK_SPACE_THRESHOLD}% Actual: {percentage}%\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyMaintenance","title":"VerifyMaintenance","text":"<p>Verifies that the device is not currently under or entering maintenance.</p> Expected Results <ul> <li>Success: The test will pass if the device is not under or entering maintenance.</li> <li>Failure: The test will fail if the device is under or entering maintenance.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyMaintenance:\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyMaintenance(AntaTest):\n    \"\"\"Verifies that the device is not currently under or entering maintenance.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device is not under or entering maintenance.\n    * Failure: The test will fail if the device is under or entering maintenance.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyMaintenance:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show maintenance\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMaintenance.\"\"\"\n        self.result.is_success()\n\n        # If units is not empty we have to examine the output for details.\n        if not (units := get_value(self.instance_commands[0].json_output, \"units\")):\n            return\n        units_under_maintenance = [unit for unit, info in units.items() if info[\"state\"] == \"underMaintenance\"]\n        units_entering_maintenance = [unit for unit, info in units.items() if info[\"state\"] == \"maintenanceModeEnter\"]\n        causes = set()\n        # Iterate over units, check for units under or entering maintenance, and examine the causes.\n        for info in units.values():\n            if info[\"adminState\"] == \"underMaintenance\":\n                causes.add(\"Quiesce is configured\")\n            if info[\"onBootMaintenance\"]:\n                causes.add(\"On-boot maintenance is configured\")\n            if info[\"intfsViolatingTrafficThreshold\"]:\n                causes.add(\"Interface traffic threshold violation\")\n\n        # Building the error message.\n        if units_under_maintenance:\n            self.result.is_failure(f\"Units under maintenance: '{', '.join(units_under_maintenance)}'\")\n        if units_entering_maintenance:\n            self.result.is_failure(f\"Units entering maintenance: '{', '.join(units_entering_maintenance)}'\")\n        if causes:\n            self.result.is_failure(f\"Possible causes: '{', '.join(sorted(causes))}'\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyMemoryUtilization","title":"VerifyMemoryUtilization","text":"<p>Verifies whether the memory utilization is below 75%.</p> Expected Results <ul> <li>Success: The test will pass if the memory utilization is below 75%.</li> <li>Failure: The test will fail if the memory utilization is over 75%.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyMemoryUtilization:\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyMemoryUtilization(AntaTest):\n    \"\"\"Verifies whether the memory utilization is below 75%.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the memory utilization is below 75%.\n    * Failure: The test will fail if the memory utilization is over 75%.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyMemoryUtilization:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show version\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyMemoryUtilization.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        memory_usage = command_output[\"memFree\"] / command_output[\"memTotal\"]\n        if memory_usage &lt; MEMORY_THRESHOLD:\n            self.result.is_failure(f\"Device has reported a high memory usage - Expected: &lt; 75% Actual: {(1 - memory_usage) * 100:.2f}%\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyNTP","title":"VerifyNTP","text":"<p>Verifies if NTP is synchronised.</p> Expected Results <ul> <li>Success: The test will pass if the NTP is synchronised.</li> <li>Failure: The test will fail if the NTP is NOT synchronised.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyNTP:\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyNTP(AntaTest):\n    \"\"\"Verifies if NTP is synchronised.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the NTP is synchronised.\n    * Failure: The test will fail if the NTP is NOT synchronised.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyNTP:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ntp status\", ofmt=\"text\")]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyNTP.\"\"\"\n        command_output = self.instance_commands[0].text_output\n        if command_output.split(\"\\n\")[0].split(\" \")[0] == \"synchronised\":\n            self.result.is_success()\n        else:\n            data = command_output.split(\"\\n\")[0]\n            self.result.is_failure(f\"NTP status mismatch - Expected: synchronised Actual: {data}\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyNTPAssociations","title":"VerifyNTPAssociations","text":"<p>Verifies the Network Time Protocol (NTP) associations.</p> <p>This test performs the following checks:</p> <ol> <li>For the NTP servers:<ul> <li>The primary NTP server (marked as preferred) has the condition \u2018sys.peer\u2019.</li> <li>All other NTP servers have the condition \u2018candidate\u2019.</li> <li>All the NTP servers have the expected stratum level.</li> </ul> </li> <li>For the NTP servers pool:<ul> <li>All the NTP servers belong to the specified NTP pool.</li> <li>All the NTP servers have valid condition (sys.peer | candidate).</li> <li>All the NTP servers have the stratum level within the specified startum level.</li> </ul> </li> </ol> Expected Results <ul> <li>Success: The test will pass if all the NTP servers meet the expected state.</li> <li>Failure: The test will fail if any of the NTP server does not meet the expected state.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyNTPAssociations:\n      ntp_servers:\n        - server_address: 1.1.1.1\n          preferred: True\n          stratum: 1\n        - server_address: 2.2.2.2\n          stratum: 2\n        - server_address: 3.3.3.3\n          stratum: 2\n  - VerifyNTPAssociations:\n      ntp_pool:\n        server_addresses: [1.1.1.1, 2.2.2.2]\n        preferred_stratum_range: [1,3]\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyNTPAssociations(AntaTest):\n    \"\"\"Verifies the Network Time Protocol (NTP) associations.\n\n    This test performs the following checks:\n\n      1. For the NTP servers:\n        - The primary NTP server (marked as preferred) has the condition 'sys.peer'.\n        - All other NTP servers have the condition 'candidate'.\n        - All the NTP servers have the expected stratum level.\n      2. For the NTP servers pool:\n        - All the NTP servers belong to the specified NTP pool.\n        - All the NTP servers have valid condition (sys.peer | candidate).\n        - All the NTP servers have the stratum level within the specified startum level.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all the NTP servers meet the expected state.\n    * Failure: The test will fail if any of the NTP server does not meet the expected state.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyNTPAssociations:\n          ntp_servers:\n            - server_address: 1.1.1.1\n              preferred: True\n              stratum: 1\n            - server_address: 2.2.2.2\n              stratum: 2\n            - server_address: 3.3.3.3\n              stratum: 2\n      - VerifyNTPAssociations:\n          ntp_pool:\n            server_addresses: [1.1.1.1, 2.2.2.2]\n            preferred_stratum_range: [1,3]\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show ntp associations\")]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyNTPAssociations test.\"\"\"\n\n        ntp_servers: list[NTPServer] | None = None\n        \"\"\"List of NTP servers.\"\"\"\n        ntp_pool: NTPPool | None = None\n        \"\"\"NTP servers pool.\"\"\"\n        NTPServer: ClassVar[type[NTPServer]] = NTPServer\n\n        @model_validator(mode=\"after\")\n        def validate_inputs(self) -&gt; Self:\n            \"\"\"Validate the inputs provided to the VerifyNTPAssociations test.\n\n            Either `ntp_servers` or `ntp_pool` can be provided at the same time.\n            \"\"\"\n            if not self.ntp_servers and not self.ntp_pool:\n                msg = \"'ntp_servers' or 'ntp_pool' must be provided\"\n                raise ValueError(msg)\n            if self.ntp_servers and self.ntp_pool:\n                msg = \"Either 'ntp_servers' or 'ntp_pool' can be provided at the same time\"\n                raise ValueError(msg)\n\n            # Verifies the len of preferred_stratum_range in NTP Pool should be 2 as this is the range.\n            stratum_range = 2\n            if self.ntp_pool and len(self.ntp_pool.preferred_stratum_range) &gt; stratum_range:\n                msg = \"'preferred_stratum_range' list should have at most 2 items\"\n                raise ValueError(msg)\n            return self\n\n    def _validate_ntp_server(self, ntp_server: NTPServer, peers: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate the NTP server, condition and stratum level.\"\"\"\n        failure_msgs: list[str] = []\n        server_address = str(ntp_server.server_address)\n\n        # We check `peerIpAddr` in the peer details - covering IPv4Address input, or the peer key - covering Hostname input.\n        matching_peer = next((peer for peer, peer_details in peers.items() if (server_address in {peer_details[\"peerIpAddr\"], peer})), None)\n\n        if not matching_peer:\n            failure_msgs.append(f\"{ntp_server} - Not configured\")\n            return failure_msgs\n\n        # Collecting the expected/actual NTP peer details.\n        exp_condition = \"sys.peer\" if ntp_server.preferred else \"candidate\"\n        exp_stratum = ntp_server.stratum\n        act_condition = get_value(peers[matching_peer], \"condition\")\n        act_stratum = get_value(peers[matching_peer], \"stratumLevel\")\n\n        if act_condition != exp_condition:\n            failure_msgs.append(f\"{ntp_server} - Incorrect condition - Expected: {exp_condition} Actual: {act_condition}\")\n\n        if act_stratum != exp_stratum:\n            failure_msgs.append(f\"{ntp_server} - Incorrect stratum level - Expected: {exp_stratum} Actual: {act_stratum}\")\n\n        return failure_msgs\n\n    def _validate_ntp_pool(self, server_addresses: list[Hostname | IPv4Address], peer: str, stratum_range: list[int], peer_details: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate the NTP server pool, condition and stratum level.\"\"\"\n        failure_msgs: list[str] = []\n\n        # We check `peerIpAddr` and `peer` in the peer details - covering server_addresses input\n        if (peer_ip := peer_details[\"peerIpAddr\"]) not in server_addresses and peer not in server_addresses:\n            failure_msgs.append(f\"NTP Server: {peer_ip} Hostname: {peer} - Associated but not part of the provided NTP pool\")\n            return failure_msgs\n\n        act_condition = get_value(peer_details, \"condition\")\n        act_stratum = get_value(peer_details, \"stratumLevel\")\n\n        if act_condition not in [\"sys.peer\", \"candidate\"]:\n            failure_msgs.append(f\"NTP Server: {peer_ip} Hostname: {peer} - Incorrect condition  - Expected: sys.peer, candidate Actual: {act_condition}\")\n\n        if int(act_stratum) not in range(stratum_range[0], stratum_range[1] + 1):\n            msg = f\"Expected Stratum Range: {stratum_range[0]} to {stratum_range[1]} Actual: {act_stratum}\"\n            failure_msgs.append(f\"NTP Server: {peer_ip} Hostname: {peer} - Incorrect stratum level - {msg}\")\n\n        return failure_msgs\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyNTPAssociations.\"\"\"\n        self.result.is_success()\n\n        if not (peers := get_value(self.instance_commands[0].json_output, \"peers\")):\n            self.result.is_failure(\"No NTP peers configured\")\n            return\n\n        if self.inputs.ntp_servers:\n            # Iterate over each NTP server.\n            for ntp_server in self.inputs.ntp_servers:\n                failure_msgs = self._validate_ntp_server(ntp_server, peers)\n                for msg in failure_msgs:\n                    self.result.is_failure(msg)\n            return\n\n        # Verifies the NTP pool details\n        server_addresses = self.inputs.ntp_pool.server_addresses\n        exp_stratum_range = self.inputs.ntp_pool.preferred_stratum_range\n        for peer, peer_details in peers.items():\n            failure_msgs = self._validate_ntp_pool(server_addresses, peer, exp_stratum_range, peer_details)\n            for msg in failure_msgs:\n                self.result.is_failure(msg)\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyNTPAssociations-attributes","title":"Inputs","text":"Name Type Description Default <code>ntp_servers</code> <code>list[NTPServer] | None</code>                      List of NTP servers.                    <code>None</code> <code>ntp_pool</code> <code>NTPPool | None</code>                      NTP servers pool.                    <code>None</code>"},{"location":"api/tests/system/#anta.tests.system.VerifyReloadCause","title":"VerifyReloadCause","text":"<p>Verifies the last reload cause of the device.</p> Expected Results <ul> <li>Success: The test will pass if there are NO reload causes or if the last reload was caused by the user or after an FPGA upgrade.</li> <li>Failure: The test will fail if the last reload was NOT caused by the user or after an FPGA upgrade.</li> <li>Error: The test will report an error if the reload cause is NOT available.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyReloadCause:\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyReloadCause(AntaTest):\n    \"\"\"Verifies the last reload cause of the device.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if there are NO reload causes or if the last reload was caused by the user or after an FPGA upgrade.\n    * Failure: The test will fail if the last reload was NOT caused by the user or after an FPGA upgrade.\n    * Error: The test will report an error if the reload cause is NOT available.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyReloadCause:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show reload cause\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyReloadCause.\"\"\"\n        command_output = self.instance_commands[0].json_output\n        if len(command_output[\"resetCauses\"]) == 0:\n            # No reload causes\n            self.result.is_success()\n            return\n        reset_causes = command_output[\"resetCauses\"]\n        command_output_data = reset_causes[0].get(\"description\")\n        if command_output_data in [\n            \"Reload requested by the user.\",\n            \"Reload requested after FPGA upgrade\",\n        ]:\n            self.result.is_success()\n        else:\n            self.result.is_failure(f\"Reload cause is: {command_output_data}\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyUptime","title":"VerifyUptime","text":"<p>Verifies the device uptime.</p> Expected Results <ul> <li>Success: The test will pass if the device uptime is higher than the provided value.</li> <li>Failure: The test will fail if the device uptime is lower than the provided value.</li> </ul> Examples <pre><code>anta.tests.system:\n  - VerifyUptime:\n      minimum: 86400\n</code></pre> Source code in <code>anta/tests/system.py</code> <pre><code>class VerifyUptime(AntaTest):\n    \"\"\"Verifies the device uptime.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the device uptime is higher than the provided value.\n    * Failure: The test will fail if the device uptime is lower than the provided value.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.system:\n      - VerifyUptime:\n          minimum: 86400\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"system\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show uptime\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyUptime test.\"\"\"\n\n        minimum: PositiveInteger\n        \"\"\"Minimum uptime in seconds.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyUptime.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        if command_output[\"upTime\"] &lt; self.inputs.minimum:\n            self.result.is_failure(f\"Device uptime is incorrect - Expected: {self.inputs.minimum}s Actual: {command_output['upTime']}s\")\n</code></pre>"},{"location":"api/tests/system/#anta.tests.system.VerifyUptime-attributes","title":"Inputs","text":"Name Type Description Default <code>minimum</code> <code>PositiveInteger</code>                      Minimum uptime in seconds.                    -"},{"location":"api/tests/system/#input-models","title":"Input models","text":"<p>Module containing input models for system tests.</p>"},{"location":"api/tests/system/#anta.input_models.system.NTPPool","title":"NTPPool","text":"<p>Model for a NTP server pool.</p> Name Type Description Default <code>server_addresses</code> <code>list[Hostname | IPv4Address]</code>                      The list of NTP server addresses as an IPv4 addresses or hostnames.                    - <code>preferred_stratum_range</code> <code>list[NTPStratumLevel]</code>                      Preferred NTP stratum range for the NTP server pool. If the expected stratum range is 1 to 3 then preferred_stratum_range should be `[1,3]`.                    - Source code in <code>anta/input_models/system.py</code> <pre><code>class NTPPool(BaseModel):\n    \"\"\"Model for a NTP server pool.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    server_addresses: list[Hostname | IPv4Address]\n    \"\"\"The list of NTP server addresses as an IPv4 addresses or hostnames.\"\"\"\n    preferred_stratum_range: list[NTPStratumLevel]\n    \"\"\"Preferred NTP stratum range for the NTP server pool. If the expected stratum range is 1 to 3 then preferred_stratum_range should be `[1,3]`.\"\"\"\n</code></pre>"},{"location":"api/tests/system/#anta.input_models.system.NTPServer","title":"NTPServer","text":"<p>Model for a NTP server.</p> Name Type Description Default <code>server_address</code> <code>Hostname | IPv4Address</code>                      The NTP server address as an IPv4 address or hostname. The NTP server name defined in the running configuration of the device may change during DNS resolution, which is not handled in ANTA. Please provide the DNS-resolved server name. For example, 'ntp.example.com' in the configuration might resolve to 'ntp3.example.com' in the device output.                    - <code>preferred</code> <code>bool</code>                      Optional preferred for NTP server. If not provided, it defaults to `False`.                    <code>False</code> <code>stratum</code> <code>NTPStratumLevel</code>                      NTP stratum level (0 to 15) where 0 is the reference clock and 16 indicates unsynchronized. Values should be between 0 and 15 for valid synchronization and 16 represents an out-of-sync state.                    - Source code in <code>anta/input_models/system.py</code> <pre><code>class NTPServer(BaseModel):\n    \"\"\"Model for a NTP server.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n    server_address: Hostname | IPv4Address\n    \"\"\"The NTP server address as an IPv4 address or hostname. The NTP server name defined in the running configuration\n    of the device may change during DNS resolution, which is not handled in ANTA. Please provide the DNS-resolved server name.\n    For example, 'ntp.example.com' in the configuration might resolve to 'ntp3.example.com' in the device output.\"\"\"\n    preferred: bool = False\n    \"\"\"Optional preferred for NTP server. If not provided, it defaults to `False`.\"\"\"\n    stratum: NTPStratumLevel\n    \"\"\"NTP stratum level (0 to 15) where 0 is the reference clock and 16 indicates unsynchronized.\n    Values should be between 0 and 15 for valid synchronization and 16 represents an out-of-sync state.\"\"\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Representation of the NTPServer model.\"\"\"\n        return f\"NTP Server: {self.server_address} Preferred: {self.preferred} Stratum: {self.stratum}\"\n</code></pre>"},{"location":"api/tests/types/","title":"Input Types","text":""},{"location":"api/tests/types/#anta.custom_types","title":"anta.custom_types","text":"<p>Module that provides predefined types for AntaTest.Input instances.</p>"},{"location":"api/tests/types/#anta.custom_types.AAAAuthMethod","title":"AAAAuthMethod  <code>module-attribute</code>","text":"<pre><code>AAAAuthMethod = Annotated[\n    str, AfterValidator(aaa_group_prefix)\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Afi","title":"Afi  <code>module-attribute</code>","text":"<pre><code>Afi = Literal[\n    \"ipv4\",\n    \"ipv6\",\n    \"vpn-ipv4\",\n    \"vpn-ipv6\",\n    \"evpn\",\n    \"rt-membership\",\n    \"path-selection\",\n    \"link-state\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.BfdInterval","title":"BfdInterval  <code>module-attribute</code>","text":"<pre><code>BfdInterval = Annotated[int, Field(ge=50, le=60000)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.BfdMultiplier","title":"BfdMultiplier  <code>module-attribute</code>","text":"<pre><code>BfdMultiplier = Annotated[int, Field(ge=3, le=50)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.BfdProtocol","title":"BfdProtocol  <code>module-attribute</code>","text":"<pre><code>BfdProtocol = Literal[\n    \"bgp\",\n    \"isis\",\n    \"lag\",\n    \"ospf\",\n    \"ospfv3\",\n    \"pim\",\n    \"route-input\",\n    \"static-bfd\",\n    \"static-route\",\n    \"vrrp\",\n    \"vxlan\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.BgpDropStats","title":"BgpDropStats  <code>module-attribute</code>","text":"<pre><code>BgpDropStats = Literal[\n    \"inDropAsloop\",\n    \"inDropClusterIdLoop\",\n    \"inDropMalformedMpbgp\",\n    \"inDropOrigId\",\n    \"inDropNhLocal\",\n    \"inDropNhAfV6\",\n    \"prefixDroppedMartianV4\",\n    \"prefixDroppedMaxRouteLimitViolatedV4\",\n    \"prefixDroppedMartianV6\",\n    \"prefixDroppedMaxRouteLimitViolatedV6\",\n    \"prefixLuDroppedV4\",\n    \"prefixLuDroppedMartianV4\",\n    \"prefixLuDroppedMaxRouteLimitViolatedV4\",\n    \"prefixLuDroppedV6\",\n    \"prefixLuDroppedMartianV6\",\n    \"prefixLuDroppedMaxRouteLimitViolatedV6\",\n    \"prefixEvpnDroppedUnsupportedRouteType\",\n    \"prefixBgpLsDroppedReceptionUnsupported\",\n    \"outDropV4LocalAddr\",\n    \"outDropV6LocalAddr\",\n    \"prefixVpnIpv4DroppedImportMatchFailure\",\n    \"prefixVpnIpv4DroppedMaxRouteLimitViolated\",\n    \"prefixVpnIpv6DroppedImportMatchFailure\",\n    \"prefixVpnIpv6DroppedMaxRouteLimitViolated\",\n    \"prefixEvpnDroppedImportMatchFailure\",\n    \"prefixEvpnDroppedMaxRouteLimitViolated\",\n    \"prefixRtMembershipDroppedLocalAsReject\",\n    \"prefixRtMembershipDroppedMaxRouteLimitViolated\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.BgpUpdateError","title":"BgpUpdateError  <code>module-attribute</code>","text":"<pre><code>BgpUpdateError = Literal[\n    \"inUpdErrWithdraw\",\n    \"inUpdErrIgnore\",\n    \"inUpdErrDisableAfiSafi\",\n    \"disabledAfiSafi\",\n    \"lastUpdErrTime\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.DynamicVlanSource","title":"DynamicVlanSource  <code>module-attribute</code>","text":"<pre><code>DynamicVlanSource = Literal[\n    \"dmf\",\n    \"dot1x\",\n    \"dynvtep\",\n    \"evpn\",\n    \"mlag\",\n    \"mlagsync\",\n    \"mvpn\",\n    \"swfwd\",\n    \"vccbfd\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.EcdsaKeySize","title":"EcdsaKeySize  <code>module-attribute</code>","text":"<pre><code>EcdsaKeySize = Literal[256, 384, 512]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.EncryptionAlgorithm","title":"EncryptionAlgorithm  <code>module-attribute</code>","text":"<pre><code>EncryptionAlgorithm = Literal['RSA', 'ECDSA']\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.ErrDisableInterval","title":"ErrDisableInterval  <code>module-attribute</code>","text":"<pre><code>ErrDisableInterval = Annotated[int, Field(ge=30, le=86400)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.ErrDisableReasons","title":"ErrDisableReasons  <code>module-attribute</code>","text":"<pre><code>ErrDisableReasons = Literal[\n    \"acl\",\n    \"arp-inspection\",\n    \"bgp-session-tracking\",\n    \"bpduguard\",\n    \"dot1x\",\n    \"dot1x-coa\",\n    \"dot1x-session-replace\",\n    \"evpn-sa-mh\",\n    \"fabric-link-failure\",\n    \"fabric-link-flap\",\n    \"hitless-reload-down\",\n    \"lacp-no-portid\",\n    \"lacp-rate-limit\",\n    \"license-enforce\",\n    \"link-flap\",\n    \"mlagasu\",\n    \"mlagdualprimary\",\n    \"mlagissu\",\n    \"mlagmaintdown\",\n    \"no-internal-vlan\",\n    \"out-of-voqs\",\n    \"portchannelguard\",\n    \"portgroup-disabled\",\n    \"portsec\",\n    \"speed-misconfigured\",\n    \"storm-control\",\n    \"stp-no-portid\",\n    \"stuck-queue\",\n    \"tapagg\",\n    \"uplink-failure-detection\",\n    \"xcvr-misconfigured\",\n    \"xcvr-overheat\",\n    \"xcvr-power-unsupported\",\n    \"xcvr-unsupported\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.EthernetInterface","title":"EthernetInterface  <code>module-attribute</code>","text":"<pre><code>EthernetInterface = Annotated[\n    str,\n    Field(pattern=\"^Ethernet[0-9]+(\\\\/[0-9]+)*$\"),\n    BeforeValidator(interface_autocomplete),\n    BeforeValidator(interface_case_sensitivity),\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Hostname","title":"Hostname  <code>module-attribute</code>","text":"<pre><code>Hostname = Annotated[\n    str, Field(pattern=REGEXP_TYPE_HOSTNAME)\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.IPv4RouteType","title":"IPv4RouteType  <code>module-attribute</code>","text":"<pre><code>IPv4RouteType = Literal[\n    \"connected\",\n    \"static\",\n    \"kernel\",\n    \"OSPF\",\n    \"OSPF inter area\",\n    \"OSPF external type 1\",\n    \"OSPF external type 2\",\n    \"OSPF NSSA external type 1\",\n    \"OSPF NSSA external type2\",\n    \"Other BGP Routes\",\n    \"iBGP\",\n    \"eBGP\",\n    \"RIP\",\n    \"IS-IS level 1\",\n    \"IS-IS level 2\",\n    \"OSPFv3\",\n    \"BGP Aggregate\",\n    \"OSPF Summary\",\n    \"Nexthop Group Static Route\",\n    \"VXLAN Control Service\",\n    \"Martian\",\n    \"DHCP client installed default route\",\n    \"Dynamic Policy Route\",\n    \"VRF Leaked\",\n    \"gRIBI\",\n    \"Route Cache Route\",\n    \"CBF Leaked Route\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Interface","title":"Interface  <code>module-attribute</code>","text":"<pre><code>Interface = Annotated[\n    str,\n    Field(pattern=REGEXP_TYPE_EOS_INTERFACE),\n    BeforeValidator(interface_autocomplete),\n    BeforeValidator(interface_case_sensitivity),\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.LogSeverityLevel","title":"LogSeverityLevel  <code>module-attribute</code>","text":"<pre><code>LogSeverityLevel = Literal[\n    \"alerts\",\n    \"critical\",\n    \"debugging\",\n    \"emergencies\",\n    \"errors\",\n    \"informational\",\n    \"notifications\",\n    \"warnings\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.MlagPriority","title":"MlagPriority  <code>module-attribute</code>","text":"<pre><code>MlagPriority = Annotated[int, Field(ge=1, le=32767)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.MultiProtocolCaps","title":"MultiProtocolCaps  <code>module-attribute</code>","text":"<pre><code>MultiProtocolCaps = Annotated[\n    Literal[\n        \"dps\",\n        \"ipv4Unicast\",\n        \"ipv6Unicast\",\n        \"ipv4Multicast\",\n        \"ipv6Multicast\",\n        \"ipv4MplsLabels\",\n        \"ipv6MplsLabels\",\n        \"ipv4SrTe\",\n        \"ipv6SrTe\",\n        \"ipv4MplsVpn\",\n        \"ipv6MplsVpn\",\n        \"ipv4FlowSpec\",\n        \"ipv6FlowSpec\",\n        \"ipv4FlowSpecVpn\",\n        \"ipv6FlowSpecVpn\",\n        \"l2VpnVpls\",\n        \"l2VpnEvpn\",\n        \"linkState\",\n        \"rtMembership\",\n        \"ipv4Mvpn\",\n    ],\n    BeforeValidator(\n        bgp_multiprotocol_capabilities_abbreviations\n    ),\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.NTPStratumLevel","title":"NTPStratumLevel  <code>module-attribute</code>","text":"<pre><code>NTPStratumLevel = Annotated[int, Field(ge=0, le=16)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Percent","title":"Percent  <code>module-attribute</code>","text":"<pre><code>Percent = Annotated[float, Field(ge=0.0, le=100.0)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Port","title":"Port  <code>module-attribute</code>","text":"<pre><code>Port = Annotated[int, Field(ge=1, le=65535)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.PortChannelInterface","title":"PortChannelInterface  <code>module-attribute</code>","text":"<pre><code>PortChannelInterface = Annotated[\n    str,\n    Field(pattern=REGEX_TYPE_PORTCHANNEL),\n    BeforeValidator(interface_autocomplete),\n    BeforeValidator(interface_case_sensitivity),\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.PositiveInteger","title":"PositiveInteger  <code>module-attribute</code>","text":"<pre><code>PositiveInteger = Annotated[int, Field(ge=0)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.REGEXP_INTERFACE_ID","title":"REGEXP_INTERFACE_ID  <code>module-attribute</code>","text":"<pre><code>REGEXP_INTERFACE_ID = '\\\\d+(\\\\/\\\\d+)*(\\\\.\\\\d+)?'\n</code></pre> <p>Match Interface ID lilke 1/1.1.</p>"},{"location":"api/tests/types/#anta.custom_types.REGEXP_PATH_MARKERS","title":"REGEXP_PATH_MARKERS  <code>module-attribute</code>","text":"<pre><code>REGEXP_PATH_MARKERS = '[\\\\\\\\\\\\/\\\\s]'\n</code></pre> <p>Match directory path from string.</p>"},{"location":"api/tests/types/#anta.custom_types.REGEXP_TYPE_EOS_INTERFACE","title":"REGEXP_TYPE_EOS_INTERFACE  <code>module-attribute</code>","text":"<pre><code>REGEXP_TYPE_EOS_INTERFACE = \"^(Dps|Ethernet|Fabric|Loopback|Management|Port-Channel|Tunnel|Vlan|Vxlan)[0-9]+(\\\\/[0-9]+)*(\\\\.[0-9]+)?$\"\n</code></pre> <p>Match EOS interface types like Ethernet1/1, Vlan1, Loopback1, etc.</p>"},{"location":"api/tests/types/#anta.custom_types.REGEXP_TYPE_HOSTNAME","title":"REGEXP_TYPE_HOSTNAME  <code>module-attribute</code>","text":"<pre><code>REGEXP_TYPE_HOSTNAME = \"^(([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\\\\-]*[a-zA-Z0-9])\\\\.)*([A-Za-z0-9]|[A-Za-z0-9][A-Za-z0-9\\\\-]*[A-Za-z0-9])$\"\n</code></pre> <p>Match hostname like <code>my-hostname</code>, <code>my-hostname-1</code>, <code>my-hostname-1-2</code>.</p>"},{"location":"api/tests/types/#anta.custom_types.REGEXP_TYPE_VXLAN_SRC_INTERFACE","title":"REGEXP_TYPE_VXLAN_SRC_INTERFACE  <code>module-attribute</code>","text":"<pre><code>REGEXP_TYPE_VXLAN_SRC_INTERFACE = \"^(Loopback)([0-9]|[1-9][0-9]{1,2}|[1-7][0-9]{3}|8[01][0-9]{2}|819[01])$\"\n</code></pre> <p>Match Vxlan source interface like Loopback10.</p>"},{"location":"api/tests/types/#anta.custom_types.REGEX_IPV4_MULTICAST","title":"REGEX_IPV4_MULTICAST  <code>module-attribute</code>","text":"<pre><code>REGEX_IPV4_MULTICAST = 'ipv4[-_ ]?multicast$'\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.REGEX_IPV4_UNICAST","title":"REGEX_IPV4_UNICAST  <code>module-attribute</code>","text":"<pre><code>REGEX_IPV4_UNICAST = 'ipv4[-_ ]?unicast$'\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.REGEX_IPV6_MULTICAST","title":"REGEX_IPV6_MULTICAST  <code>module-attribute</code>","text":"<pre><code>REGEX_IPV6_MULTICAST = 'ipv6[-_ ]?multicast$'\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.REGEX_IPV6_UNICAST","title":"REGEX_IPV6_UNICAST  <code>module-attribute</code>","text":"<pre><code>REGEX_IPV6_UNICAST = 'ipv6[-_ ]?unicast$'\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.REGEX_TYPE_PORTCHANNEL","title":"REGEX_TYPE_PORTCHANNEL  <code>module-attribute</code>","text":"<pre><code>REGEX_TYPE_PORTCHANNEL = '^Port-Channel[0-9]{1,6}$'\n</code></pre> <p>Match Port Channel interface like Port-Channel5.</p>"},{"location":"api/tests/types/#anta.custom_types.RedistributedAfiSafi","title":"RedistributedAfiSafi  <code>module-attribute</code>","text":"<pre><code>RedistributedAfiSafi = Annotated[\n    Literal[\"v4u\", \"v4m\", \"v6u\", \"v6m\"],\n    BeforeValidator(\n        bgp_redistributed_route_proto_abbreviations\n    ),\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.RedistributedProtocol","title":"RedistributedProtocol  <code>module-attribute</code>","text":"<pre><code>RedistributedProtocol = Annotated[\n    Literal[\n        \"AttachedHost\",\n        \"Bgp\",\n        \"Connected\",\n        \"DHCP\",\n        \"Dynamic\",\n        \"IS-IS\",\n        \"OSPF Internal\",\n        \"OSPF External\",\n        \"OSPF Nssa-External\",\n        \"OSPFv3 Internal\",\n        \"OSPFv3 External\",\n        \"OSPFv3 Nssa-External\",\n        \"RIP\",\n        \"Static\",\n        \"User\",\n    ],\n    AfterValidator(update_bgp_redistributed_proto_user),\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.RegexString","title":"RegexString  <code>module-attribute</code>","text":"<pre><code>RegexString = Annotated[str, AfterValidator(validate_regex)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Revision","title":"Revision  <code>module-attribute</code>","text":"<pre><code>Revision = Annotated[int, Field(ge=1, le=99)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.RsaKeySize","title":"RsaKeySize  <code>module-attribute</code>","text":"<pre><code>RsaKeySize = Literal[2048, 3072, 4096]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Safi","title":"Safi  <code>module-attribute</code>","text":"<pre><code>Safi = Literal[\n    \"unicast\", \"multicast\", \"labeled-unicast\", \"sr-te\"\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.SnmpEncryptionAlgorithm","title":"SnmpEncryptionAlgorithm  <code>module-attribute</code>","text":"<pre><code>SnmpEncryptionAlgorithm = Literal[\n    \"AES-128\", \"AES-192\", \"AES-256\", \"DES\"\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.SnmpErrorCounter","title":"SnmpErrorCounter  <code>module-attribute</code>","text":"<pre><code>SnmpErrorCounter = Literal[\n    \"inVersionErrs\",\n    \"inBadCommunityNames\",\n    \"inBadCommunityUses\",\n    \"inParseErrs\",\n    \"outTooBigErrs\",\n    \"outNoSuchNameErrs\",\n    \"outBadValueErrs\",\n    \"outGeneralErrs\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.SnmpHashingAlgorithm","title":"SnmpHashingAlgorithm  <code>module-attribute</code>","text":"<pre><code>SnmpHashingAlgorithm = Literal[\n    \"MD5\", \"SHA\", \"SHA-224\", \"SHA-256\", \"SHA-384\", \"SHA-512\"\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.SnmpPdu","title":"SnmpPdu  <code>module-attribute</code>","text":"<pre><code>SnmpPdu = Literal[\n    \"inGetPdus\",\n    \"inGetNextPdus\",\n    \"inSetPdus\",\n    \"outGetResponsePdus\",\n    \"outTrapPdus\",\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.SnmpVersion","title":"SnmpVersion  <code>module-attribute</code>","text":"<pre><code>SnmpVersion = Literal['v1', 'v2c', 'v3']\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.SnmpVersionV3AuthType","title":"SnmpVersionV3AuthType  <code>module-attribute</code>","text":"<pre><code>SnmpVersionV3AuthType = Annotated[\n    Literal[\"auth\", \"priv\", \"noauth\"],\n    AfterValidator(snmp_v3_prefix),\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Vlan","title":"Vlan  <code>module-attribute</code>","text":"<pre><code>Vlan = Annotated[int, Field(ge=0, le=4094)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.Vni","title":"Vni  <code>module-attribute</code>","text":"<pre><code>Vni = Annotated[int, Field(ge=1, le=16777215)]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.VxlanSrcIntf","title":"VxlanSrcIntf  <code>module-attribute</code>","text":"<pre><code>VxlanSrcIntf = Annotated[\n    str,\n    Field(pattern=REGEXP_TYPE_VXLAN_SRC_INTERFACE),\n    BeforeValidator(interface_autocomplete),\n    BeforeValidator(interface_case_sensitivity),\n]\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.aaa_group_prefix","title":"aaa_group_prefix","text":"<pre><code>aaa_group_prefix(v: str) -&gt; str\n</code></pre> <p>Prefix the AAA method with \u2018group\u2019 if it is known.</p> Source code in <code>anta/custom_types.py</code> <pre><code>def aaa_group_prefix(v: str) -&gt; str:\n    \"\"\"Prefix the AAA method with 'group' if it is known.\"\"\"\n    built_in_methods = [\"local\", \"none\", \"logging\"]\n    return f\"group {v}\" if v not in built_in_methods and not v.startswith(\"group \") else v\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.bgp_multiprotocol_capabilities_abbreviations","title":"bgp_multiprotocol_capabilities_abbreviations","text":"<pre><code>bgp_multiprotocol_capabilities_abbreviations(\n    value: str,\n) -&gt; str\n</code></pre> <p>Abbreviations for different BGP multiprotocol capabilities.</p> <p>Handles different separators (hyphen, underscore, space) and case sensitivity.</p> Examples <pre><code>&gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"IPv4 Unicast\")\n'ipv4Unicast'\n&gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"ipv4-Flow_Spec Vpn\")\n'ipv4FlowSpecVpn'\n &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"ipv6_labeled-unicast\")\n'ipv6MplsLabels'\n &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"ipv4_mpls_vpn\")\n'ipv4MplsVpn'\n &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"ipv4 mpls labels\")\n'ipv4MplsLabels'\n&gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"rt-membership\")\n'rtMembership'\n &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"dynamic-path-selection\")\n'dps'\n</code></pre> Source code in <code>anta/custom_types.py</code> <pre><code>def bgp_multiprotocol_capabilities_abbreviations(value: str) -&gt; str:\n    \"\"\"Abbreviations for different BGP multiprotocol capabilities.\n\n    Handles different separators (hyphen, underscore, space) and case sensitivity.\n\n    Examples\n    --------\n    ```python\n    &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"IPv4 Unicast\")\n    'ipv4Unicast'\n    &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"ipv4-Flow_Spec Vpn\")\n    'ipv4FlowSpecVpn'\n     &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"ipv6_labeled-unicast\")\n    'ipv6MplsLabels'\n     &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"ipv4_mpls_vpn\")\n    'ipv4MplsVpn'\n     &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"ipv4 mpls labels\")\n    'ipv4MplsLabels'\n    &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"rt-membership\")\n    'rtMembership'\n     &gt;&gt;&gt; bgp_multiprotocol_capabilities_abbreviations(\"dynamic-path-selection\")\n    'dps'\n    ```\n    \"\"\"\n    patterns = {\n        f\"{r'dynamic[-_ ]?path[-_ ]?selection$'}\": \"dps\",\n        f\"{r'dps$'}\": \"dps\",\n        f\"{REGEX_IPV4_UNICAST}\": \"ipv4Unicast\",\n        f\"{REGEX_IPV6_UNICAST}\": \"ipv6Unicast\",\n        f\"{REGEX_IPV4_MULTICAST}\": \"ipv4Multicast\",\n        f\"{REGEX_IPV6_MULTICAST}\": \"ipv6Multicast\",\n        f\"{r'ipv4[-_ ]?labeled[-_ ]?Unicast$'}\": \"ipv4MplsLabels\",\n        f\"{r'ipv4[-_ ]?mpls[-_ ]?labels$'}\": \"ipv4MplsLabels\",\n        f\"{r'ipv6[-_ ]?labeled[-_ ]?Unicast$'}\": \"ipv6MplsLabels\",\n        f\"{r'ipv6[-_ ]?mpls[-_ ]?labels$'}\": \"ipv6MplsLabels\",\n        f\"{r'ipv4[-_ ]?sr[-_ ]?te$'}\": \"ipv4SrTe\",  # codespell:ignore\n        f\"{r'ipv6[-_ ]?sr[-_ ]?te$'}\": \"ipv6SrTe\",  # codespell:ignore\n        f\"{r'ipv4[-_ ]?mpls[-_ ]?vpn$'}\": \"ipv4MplsVpn\",\n        f\"{r'ipv6[-_ ]?mpls[-_ ]?vpn$'}\": \"ipv6MplsVpn\",\n        f\"{r'ipv4[-_ ]?Flow[-_ ]?spec$'}\": \"ipv4FlowSpec\",\n        f\"{r'ipv6[-_ ]?Flow[-_ ]?spec$'}\": \"ipv6FlowSpec\",\n        f\"{r'ipv4[-_ ]?Flow[-_ ]?spec[-_ ]?vpn$'}\": \"ipv4FlowSpecVpn\",\n        f\"{r'ipv6[-_ ]?Flow[-_ ]?spec[-_ ]?vpn$'}\": \"ipv6FlowSpecVpn\",\n        f\"{r'l2[-_ ]?vpn[-_ ]?vpls$'}\": \"l2VpnVpls\",\n        f\"{r'l2[-_ ]?vpn[-_ ]?evpn$'}\": \"l2VpnEvpn\",\n        f\"{r'link[-_ ]?state$'}\": \"linkState\",\n        f\"{r'rt[-_ ]?membership$'}\": \"rtMembership\",\n        f\"{r'ipv4[-_ ]?rt[-_ ]?membership$'}\": \"rtMembership\",\n        f\"{r'ipv4[-_ ]?mvpn$'}\": \"ipv4Mvpn\",\n    }\n    for pattern, replacement in patterns.items():\n        match = re.match(pattern, value, re.IGNORECASE)\n        if match:\n            return replacement\n    return value\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.bgp_redistributed_route_proto_abbreviations","title":"bgp_redistributed_route_proto_abbreviations","text":"<pre><code>bgp_redistributed_route_proto_abbreviations(\n    value: str,\n) -&gt; str\n</code></pre> <p>Abbreviations for different BGP redistributed route protocols.</p> <p>Handles different separators (hyphen, underscore, space) and case sensitivity.</p> Examples <pre><code>&gt;&gt;&gt; bgp_redistributed_route_proto_abbreviations(\"IPv4 Unicast\")\n'v4u'\n&gt;&gt;&gt; bgp_redistributed_route_proto_abbreviations(\"IPv4-multicast\")\n'v4m'\n&gt;&gt;&gt; bgp_redistributed_route_proto_abbreviations(\"IPv6_multicast\")\n'v6m'\n&gt;&gt;&gt; bgp_redistributed_route_proto_abbreviations(\"ipv6unicast\")\n'v6u'\n</code></pre> Source code in <code>anta/custom_types.py</code> <pre><code>def bgp_redistributed_route_proto_abbreviations(value: str) -&gt; str:\n    \"\"\"Abbreviations for different BGP redistributed route protocols.\n\n    Handles different separators (hyphen, underscore, space) and case sensitivity.\n\n    Examples\n    --------\n    ```python\n    &gt;&gt;&gt; bgp_redistributed_route_proto_abbreviations(\"IPv4 Unicast\")\n    'v4u'\n    &gt;&gt;&gt; bgp_redistributed_route_proto_abbreviations(\"IPv4-multicast\")\n    'v4m'\n    &gt;&gt;&gt; bgp_redistributed_route_proto_abbreviations(\"IPv6_multicast\")\n    'v6m'\n    &gt;&gt;&gt; bgp_redistributed_route_proto_abbreviations(\"ipv6unicast\")\n    'v6u'\n    ```\n    \"\"\"\n    patterns = {REGEX_IPV4_UNICAST: \"v4u\", REGEX_IPV4_MULTICAST: \"v4m\", REGEX_IPV6_UNICAST: \"v6u\", REGEX_IPV6_MULTICAST: \"v6m\"}\n\n    for pattern, replacement in patterns.items():\n        match = re.match(pattern, value, re.IGNORECASE)\n        if match:\n            return replacement\n\n    return value\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.interface_autocomplete","title":"interface_autocomplete","text":"<pre><code>interface_autocomplete(v: str) -&gt; str\n</code></pre> <p>Allow the user to only provide the beginning of an interface name.</p> <p>Supported alias:      - <code>et</code>, <code>eth</code> will be changed to <code>Ethernet</code>      - <code>po</code> will be changed to <code>Port-Channel</code> - <code>lo</code> will be changed to <code>Loopback</code></p> Source code in <code>anta/custom_types.py</code> <pre><code>def interface_autocomplete(v: str) -&gt; str:\n    \"\"\"Allow the user to only provide the beginning of an interface name.\n\n    Supported alias:\n         - `et`, `eth` will be changed to `Ethernet`\n         - `po` will be changed to `Port-Channel`\n    - `lo` will be changed to `Loopback`\n    \"\"\"\n    intf_id_re = re.compile(REGEXP_INTERFACE_ID)\n    m = intf_id_re.search(v)\n    if m is None:\n        msg = f\"Could not parse interface ID in interface '{v}'\"\n        raise ValueError(msg)\n    intf_id = m[0]\n\n    alias_map = {\"et\": \"Ethernet\", \"eth\": \"Ethernet\", \"po\": \"Port-Channel\", \"lo\": \"Loopback\", \"vl\": \"Vlan\"}\n\n    return next((f\"{full_name}{intf_id}\" for alias, full_name in alias_map.items() if v.lower().startswith(alias)), v)\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.interface_case_sensitivity","title":"interface_case_sensitivity","text":"<pre><code>interface_case_sensitivity(v: str) -&gt; str\n</code></pre> <p>Reformat interface name to match expected case sensitivity.</p> Examples <ul> <li>ethernet -&gt; Ethernet</li> <li>vlan -&gt; Vlan</li> <li>loopback -&gt; Loopback</li> </ul> Source code in <code>anta/custom_types.py</code> <pre><code>def interface_case_sensitivity(v: str) -&gt; str:\n    \"\"\"Reformat interface name to match expected case sensitivity.\n\n    Examples\n    --------\n    - ethernet -&gt; Ethernet\n    - vlan -&gt; Vlan\n    - loopback -&gt; Loopback\n\n    \"\"\"\n    if isinstance(v, str) and v != \"\" and not v[0].isupper():\n        return f\"{v[0].upper()}{v[1:]}\"\n    return v\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.snmp_v3_prefix","title":"snmp_v3_prefix","text":"<pre><code>snmp_v3_prefix(\n    auth_type: Literal[\"auth\", \"priv\", \"noauth\"],\n) -&gt; str\n</code></pre> <p>Prefix the SNMP authentication type with \u2018v3\u2019.</p> Source code in <code>anta/custom_types.py</code> <pre><code>def snmp_v3_prefix(auth_type: Literal[\"auth\", \"priv\", \"noauth\"]) -&gt; str:\n    \"\"\"Prefix the SNMP authentication type with 'v3'.\"\"\"\n    if auth_type == \"noauth\":\n        return \"v3NoAuth\"\n    return f\"v3{auth_type.title()}\"\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.update_bgp_redistributed_proto_user","title":"update_bgp_redistributed_proto_user","text":"<pre><code>update_bgp_redistributed_proto_user(value: str) -&gt; str\n</code></pre> <p>Update BGP redistributed route <code>User</code> proto with EOS SDK.</p> Examples <pre><code>&gt;&gt;&gt; update_bgp_redistributed_proto_user(\"User\")\n'EOS SDK'\n&gt;&gt;&gt; update_bgp_redistributed_proto_user(\"Bgp\")\n'Bgp'\n&gt;&gt;&gt; update_bgp_redistributed_proto_user(\"RIP\")\n'RIP'\n</code></pre> Source code in <code>anta/custom_types.py</code> <pre><code>def update_bgp_redistributed_proto_user(value: str) -&gt; str:\n    \"\"\"Update BGP redistributed route `User` proto with EOS SDK.\n\n    Examples\n    --------\n    ```python\n    &gt;&gt;&gt; update_bgp_redistributed_proto_user(\"User\")\n    'EOS SDK'\n    &gt;&gt;&gt; update_bgp_redistributed_proto_user(\"Bgp\")\n    'Bgp'\n    &gt;&gt;&gt; update_bgp_redistributed_proto_user(\"RIP\")\n    'RIP'\n    ```\n    \"\"\"\n    if value == \"User\":\n        value = \"EOS SDK\"\n\n    return value\n</code></pre>"},{"location":"api/tests/types/#anta.custom_types.validate_regex","title":"validate_regex","text":"<pre><code>validate_regex(value: str) -&gt; str\n</code></pre> <p>Validate that the input value is a valid regex format.</p> Source code in <code>anta/custom_types.py</code> <pre><code>def validate_regex(value: str) -&gt; str:\n    \"\"\"Validate that the input value is a valid regex format.\"\"\"\n    try:\n        re.compile(value)\n    except re.error as e:\n        msg = f\"Invalid regex: {e}\"\n        raise ValueError(msg) from e\n    return value\n</code></pre>"},{"location":"api/tests/vlan/","title":"VLAN","text":"<p>Module related to VLAN tests.</p>"},{"location":"api/tests/vlan/#anta.tests.vlan.VerifyDynamicVlanSource","title":"VerifyDynamicVlanSource","text":"<p>Verifies dynamic VLAN allocation for specified VLAN sources.</p> <p>This test performs the following checks for each specified VLAN source:</p> <ol> <li>Validates source exists in dynamic VLAN table.</li> <li>Verifies at least one VLAN is allocated to the source.</li> <li>When strict mode is enabled (<code>strict: true</code>), ensures no other sources have VLANs allocated.</li> </ol> Expected Results <ul> <li>Success: The test will pass if all of the following conditions are met:<ul> <li>Each specified source exists in dynamic VLAN table.</li> <li>Each specified source has at least one VLAN allocated.</li> <li>In strict mode: No other sources have VLANs allocated.</li> </ul> </li> <li>Failure: The test will fail if any of the following conditions is met:<ul> <li>Specified source not found in configuration.</li> <li>Source exists but has no VLANs allocated.</li> <li>In strict mode: Non-specified sources have VLANs allocated.</li> </ul> </li> </ul> Examples <pre><code>anta.tests.vlan:\n  - VerifyDynamicVlanSource:\n      sources:\n        - evpn\n        - mlagsync\n      strict: False\n</code></pre> Source code in <code>anta/tests/vlan.py</code> <pre><code>class VerifyDynamicVlanSource(AntaTest):\n    \"\"\"Verifies dynamic VLAN allocation for specified VLAN sources.\n\n    This test performs the following checks for each specified VLAN source:\n\n      1. Validates source exists in dynamic VLAN table.\n      2. Verifies at least one VLAN is allocated to the source.\n      3. When strict mode is enabled (`strict: true`), ensures no other sources have VLANs allocated.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all of the following conditions are met:\n        - Each specified source exists in dynamic VLAN table.\n        - Each specified source has at least one VLAN allocated.\n        - In strict mode: No other sources have VLANs allocated.\n    * Failure: The test will fail if any of the following conditions is met:\n        - Specified source not found in configuration.\n        - Source exists but has no VLANs allocated.\n        - In strict mode: Non-specified sources have VLANs allocated.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.vlan:\n      - VerifyDynamicVlanSource:\n          sources:\n            - evpn\n            - mlagsync\n          strict: False\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"vlan\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show vlan dynamic\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyDynamicVlanSource test.\"\"\"\n\n        sources: list[DynamicVlanSource]\n        \"\"\"The dynamic VLAN source list.\"\"\"\n        strict: bool = False\n        \"\"\"If True, only specified sources are allowed to have VLANs allocated. Default is False.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyDynamicVlanSource.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n        dynamic_vlans = command_output.get(\"dynamicVlans\", {})\n\n        # Get all configured sources and sources with VLANs allocated\n        configured_sources = set(dynamic_vlans.keys())\n        sources_with_vlans = {source for source, data in dynamic_vlans.items() if data.get(\"vlanIds\")}\n        expected_sources = set(self.inputs.sources)\n\n        # Check if all specified sources exist in configuration\n        missing_sources = expected_sources - configured_sources\n        if missing_sources:\n            self.result.is_failure(f\"Dynamic VLAN source(s) not found in configuration: {', '.join(sorted(missing_sources))}\")\n            return\n\n        # Check if configured sources have VLANs allocated\n        sources_without_vlans = expected_sources - sources_with_vlans\n        if sources_without_vlans:\n            self.result.is_failure(f\"Dynamic VLAN source(s) exist but have no VLANs allocated: {', '.join(sorted(sources_without_vlans))}\")\n            return\n\n        # In strict mode, verify no other sources have VLANs allocated\n        if self.inputs.strict:\n            unexpected_sources = sources_with_vlans - expected_sources\n            if unexpected_sources:\n                self.result.is_failure(f\"Strict mode enabled: Unexpected sources have VLANs allocated: {', '.join(sorted(unexpected_sources))}\")\n</code></pre>"},{"location":"api/tests/vlan/#anta.tests.vlan.VerifyDynamicVlanSource-attributes","title":"Inputs","text":"Name Type Description Default <code>sources</code> <code>list[DynamicVlanSource]</code>                      The dynamic VLAN source list.                    - <code>strict</code> <code>bool</code>                      If True, only specified sources are allowed to have VLANs allocated. Default is False.                    <code>False</code>"},{"location":"api/tests/vlan/#anta.tests.vlan.VerifyVlanInternalPolicy","title":"VerifyVlanInternalPolicy","text":"<p>Verifies if the VLAN internal allocation policy is ascending or descending and if the VLANs are within the specified range.</p> Expected Results <ul> <li>Success: The test will pass if the VLAN internal allocation policy is either ascending or descending              and the VLANs are within the specified range.</li> <li>Failure: The test will fail if the VLAN internal allocation policy is neither ascending nor descending              or the VLANs are outside the specified range.</li> </ul> Examples <pre><code>anta.tests.vlan:\n  - VerifyVlanInternalPolicy:\n      policy: ascending\n      start_vlan_id: 1006\n      end_vlan_id: 4094\n</code></pre> Source code in <code>anta/tests/vlan.py</code> <pre><code>class VerifyVlanInternalPolicy(AntaTest):\n    \"\"\"Verifies if the VLAN internal allocation policy is ascending or descending and if the VLANs are within the specified range.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the VLAN internal allocation policy is either ascending or descending\n                 and the VLANs are within the specified range.\n    * Failure: The test will fail if the VLAN internal allocation policy is neither ascending nor descending\n                 or the VLANs are outside the specified range.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.vlan:\n      - VerifyVlanInternalPolicy:\n          policy: ascending\n          start_vlan_id: 1006\n          end_vlan_id: 4094\n    ```\n    \"\"\"\n\n    description = \"Verifies the VLAN internal allocation policy and the range of VLANs.\"\n    categories: ClassVar[list[str]] = [\"vlan\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show vlan internal allocation policy\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyVlanInternalPolicy test.\"\"\"\n\n        policy: Literal[\"ascending\", \"descending\"]\n        \"\"\"The VLAN internal allocation policy. Supported values: ascending, descending.\"\"\"\n        start_vlan_id: Vlan\n        \"\"\"The starting VLAN ID in the range.\"\"\"\n        end_vlan_id: Vlan\n        \"\"\"The ending VLAN ID in the range.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyVlanInternalPolicy.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        if (policy := self.inputs.policy) != (act_policy := get_value(command_output, \"policy\")):\n            self.result.is_failure(f\"Incorrect VLAN internal allocation policy configured - Expected: {policy} Actual: {act_policy}\")\n            return\n\n        if (start_vlan_id := self.inputs.start_vlan_id) != (act_vlan_id := get_value(command_output, \"startVlanId\")):\n            self.result.is_failure(\n                f\"VLAN internal allocation policy: {self.inputs.policy} - Incorrect start VLAN id configured - Expected: {start_vlan_id} Actual: {act_vlan_id}\"\n            )\n\n        if (end_vlan_id := self.inputs.end_vlan_id) != (act_vlan_id := get_value(command_output, \"endVlanId\")):\n            self.result.is_failure(\n                f\"VLAN internal allocation policy: {self.inputs.policy} - Incorrect end VLAN id configured - Expected: {end_vlan_id} Actual: {act_vlan_id}\"\n            )\n</code></pre>"},{"location":"api/tests/vlan/#anta.tests.vlan.VerifyVlanInternalPolicy-attributes","title":"Inputs","text":"Name Type Description Default <code>policy</code> <code>Literal['ascending', 'descending']</code>                      The VLAN internal allocation policy. Supported values: ascending, descending.                    - <code>start_vlan_id</code> <code>Vlan</code>                      The starting VLAN ID in the range.                    - <code>end_vlan_id</code> <code>Vlan</code>                      The ending VLAN ID in the range.                    -"},{"location":"api/tests/vxlan/","title":"VXLAN","text":"<p>Module related to VXLAN tests.</p>"},{"location":"api/tests/vxlan/#anta.tests.vxlan.VerifyVxlan1ConnSettings","title":"VerifyVxlan1ConnSettings","text":"<p>Verifies Vxlan1 source interface and UDP port.</p> Expected Results <ul> <li>Success: Passes if the interface vxlan1 source interface and UDP port are correct.</li> <li>Failure: Fails if the interface vxlan1 source interface or UDP port are incorrect.</li> <li>Skipped: Skips if the Vxlan1 interface is not configured.</li> </ul> Examples <pre><code>anta.tests.vxlan:\n  - VerifyVxlan1ConnSettings:\n      source_interface: Loopback1\n      udp_port: 4789\n</code></pre> Source code in <code>anta/tests/vxlan.py</code> <pre><code>class VerifyVxlan1ConnSettings(AntaTest):\n    \"\"\"Verifies Vxlan1 source interface and UDP port.\n\n    Expected Results\n    ----------------\n    * Success: Passes if the interface vxlan1 source interface and UDP port are correct.\n    * Failure: Fails if the interface vxlan1 source interface or UDP port are incorrect.\n    * Skipped: Skips if the Vxlan1 interface is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.vxlan:\n      - VerifyVxlan1ConnSettings:\n          source_interface: Loopback1\n          udp_port: 4789\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"vxlan\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyVxlan1ConnSettings test.\"\"\"\n\n        source_interface: VxlanSrcIntf\n        \"\"\"Source loopback interface of vxlan1 interface.\"\"\"\n        udp_port: int = Field(ge=1024, le=65335)\n        \"\"\"UDP port used for vxlan1 interface.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyVxlan1ConnSettings.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        # Skip the test case if vxlan1 interface is not configured\n        vxlan_output = get_value(command_output, \"interfaces.Vxlan1\")\n        if not vxlan_output:\n            self.result.is_skipped(\"Interface: Vxlan1 - Not configured\")\n            return\n\n        src_intf = vxlan_output.get(\"srcIpIntf\")\n        port = vxlan_output.get(\"udpPort\")\n\n        # Check vxlan1 source interface and udp port\n        if src_intf != self.inputs.source_interface:\n            self.result.is_failure(f\"Interface: Vxlan1 - Incorrect Source interface - Expected: {self.inputs.source_interface} Actual: {src_intf}\")\n        if port != self.inputs.udp_port:\n            self.result.is_failure(f\"Interface: Vxlan1 - Incorrect UDP port - Expected: {self.inputs.udp_port} Actual: {port}\")\n</code></pre>"},{"location":"api/tests/vxlan/#anta.tests.vxlan.VerifyVxlan1ConnSettings-attributes","title":"Inputs","text":"Name Type Description Default <code>source_interface</code> <code>VxlanSrcIntf</code>                      Source loopback interface of vxlan1 interface.                    - <code>udp_port</code> <code>int</code>                      UDP port used for vxlan1 interface.                    <code>Field(ge=1024, le=65335)</code>"},{"location":"api/tests/vxlan/#anta.tests.vxlan.VerifyVxlan1Interface","title":"VerifyVxlan1Interface","text":"<p>Verifies the Vxlan1 interface status.</p> Warnings <p>The name of this test has been updated from \u2018VerifyVxlan\u2019 for better representation.</p> Expected Results <ul> <li>Success: The test will pass if the Vxlan1 interface is configured with line protocol status and interface status \u2018up\u2019.</li> <li>Failure: The test will fail if the Vxlan1 interface line protocol status or interface status are not \u2018up\u2019.</li> <li>Skipped: The test will be skipped if the Vxlan1 interface is not configured.</li> </ul> Examples <pre><code>anta.tests.vxlan:\n  - VerifyVxlan1Interface:\n</code></pre> Source code in <code>anta/tests/vxlan.py</code> <pre><code>class VerifyVxlan1Interface(AntaTest):\n    \"\"\"Verifies the Vxlan1 interface status.\n\n    Warnings\n    --------\n    The name of this test has been updated from 'VerifyVxlan' for better representation.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the Vxlan1 interface is configured with line protocol status and interface status 'up'.\n    * Failure: The test will fail if the Vxlan1 interface line protocol status or interface status are not 'up'.\n    * Skipped: The test will be skipped if the Vxlan1 interface is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.vxlan:\n      - VerifyVxlan1Interface:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"vxlan\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show interfaces description\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyVxlan1Interface.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        # Skipping the test if the Vxlan1 interface is not configured\n        if \"Vxlan1\" not in (interface_details := command_output[\"interfaceDescriptions\"]):\n            self.result.is_skipped(\"Interface: Vxlan1 - Not configured\")\n            return\n\n        line_protocol_status = interface_details[\"Vxlan1\"][\"lineProtocolStatus\"]\n        interface_status = interface_details[\"Vxlan1\"][\"interfaceStatus\"]\n\n        # Checking against both status and line protocol status\n        if interface_status != \"up\" or line_protocol_status != \"up\":\n            self.result.is_failure(f\"Interface: Vxlan1 - Incorrect Line protocol status/Status - Expected: up/up Actual: {line_protocol_status}/{interface_status}\")\n</code></pre>"},{"location":"api/tests/vxlan/#anta.tests.vxlan.VerifyVxlanConfigSanity","title":"VerifyVxlanConfigSanity","text":"<p>Verifies there are no VXLAN config-sanity inconsistencies.</p> Expected Results <ul> <li>Success: The test will pass if no issues are detected with the VXLAN configuration.</li> <li>Failure: The test will fail if issues are detected with the VXLAN configuration.</li> <li>Skipped: The test will be skipped if VXLAN is not configured on the device.</li> </ul> Examples <pre><code>anta.tests.vxlan:\n  - VerifyVxlanConfigSanity:\n</code></pre> Source code in <code>anta/tests/vxlan.py</code> <pre><code>class VerifyVxlanConfigSanity(AntaTest):\n    \"\"\"Verifies there are no VXLAN config-sanity inconsistencies.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if no issues are detected with the VXLAN configuration.\n    * Failure: The test will fail if issues are detected with the VXLAN configuration.\n    * Skipped: The test will be skipped if VXLAN is not configured on the device.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.vxlan:\n      - VerifyVxlanConfigSanity:\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"vxlan\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show vxlan config-sanity\", revision=1)]\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyVxlanConfigSanity.\"\"\"\n        self.result.is_success()\n        command_output = self.instance_commands[0].json_output\n\n        # Skipping the test if VXLAN is not configured\n        if \"categories\" not in command_output or len(command_output[\"categories\"]) == 0:\n            self.result.is_skipped(\"VXLAN is not configured\")\n            return\n\n        # Verifies the Vxlan config sanity\n        categories_to_check = [\"localVtep\", \"mlag\", \"pd\"]\n        for category in categories_to_check:\n            if not get_value(command_output, f\"categories.{category}.allCheckPass\"):\n                self.result.is_failure(f\"Vxlan Category: {category} - Config sanity check is not passing\")\n</code></pre>"},{"location":"api/tests/vxlan/#anta.tests.vxlan.VerifyVxlanVniBinding","title":"VerifyVxlanVniBinding","text":"<p>Verifies the VNI-VLAN bindings of the Vxlan1 interface.</p> Expected Results <ul> <li>Success: The test will pass if the VNI-VLAN bindings provided are properly configured.</li> <li>Failure: The test will fail if any VNI lacks bindings or if any bindings are incorrect.</li> <li>Skipped: The test will be skipped if the Vxlan1 interface is not configured.</li> </ul> Examples <pre><code>anta.tests.vxlan:\n  - VerifyVxlanVniBinding:\n      bindings:\n        10010: 10\n        10020: 20\n</code></pre> Source code in <code>anta/tests/vxlan.py</code> <pre><code>class VerifyVxlanVniBinding(AntaTest):\n    \"\"\"Verifies the VNI-VLAN bindings of the Vxlan1 interface.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if the VNI-VLAN bindings provided are properly configured.\n    * Failure: The test will fail if any VNI lacks bindings or if any bindings are incorrect.\n    * Skipped: The test will be skipped if the Vxlan1 interface is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.vxlan:\n      - VerifyVxlanVniBinding:\n          bindings:\n            10010: 10\n            10020: 20\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"vxlan\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show vxlan vni\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyVxlanVniBinding test.\"\"\"\n\n        bindings: dict[Vni, Vlan]\n        \"\"\"VNI to VLAN bindings to verify.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyVxlanVniBinding.\"\"\"\n        self.result.is_success()\n\n        if (vxlan1 := get_value(self.instance_commands[0].json_output, \"vxlanIntfs.Vxlan1\")) is None:\n            self.result.is_skipped(\"Interface: Vxlan1 - Not configured\")\n            return\n\n        for vni, vlan in self.inputs.bindings.items():\n            str_vni = str(vni)\n            retrieved_vlan = \"\"\n            if str_vni in vxlan1[\"vniBindings\"]:\n                retrieved_vlan = get_value(vxlan1, f\"vniBindings..{str_vni}..vlan\", separator=\"..\")\n            elif str_vni in vxlan1[\"vniBindingsToVrf\"]:\n                retrieved_vlan = get_value(vxlan1, f\"vniBindingsToVrf..{str_vni}..vlan\", separator=\"..\")\n\n            if not retrieved_vlan:\n                self.result.is_failure(f\"Interface: Vxlan1 VNI: {str_vni} - Binding not found\")\n\n            elif vlan != retrieved_vlan:\n                self.result.is_failure(f\"Interface: Vxlan1 VNI: {str_vni} VLAN: {vlan} - Wrong VLAN binding - Actual: {retrieved_vlan}\")\n</code></pre>"},{"location":"api/tests/vxlan/#anta.tests.vxlan.VerifyVxlanVniBinding-attributes","title":"Inputs","text":"Name Type Description Default <code>bindings</code> <code>dict[Vni, Vlan]</code>                      VNI to VLAN bindings to verify.                    -"},{"location":"api/tests/vxlan/#anta.tests.vxlan.VerifyVxlanVtep","title":"VerifyVxlanVtep","text":"<p>Verifies Vxlan1 VTEP peers.</p> Expected Results <ul> <li>Success: The test will pass if all provided VTEP peers are identified and matching.</li> <li>Failure: The test will fail if any VTEP peer is missing or there are unexpected VTEP peers.</li> <li>Skipped: The test will be skipped if the Vxlan1 interface is not configured.</li> </ul> Examples <pre><code>anta.tests.vxlan:\n  - VerifyVxlanVtep:\n      vteps:\n        - 10.1.1.5\n        - 10.1.1.6\n</code></pre> Source code in <code>anta/tests/vxlan.py</code> <pre><code>class VerifyVxlanVtep(AntaTest):\n    \"\"\"Verifies Vxlan1 VTEP peers.\n\n    Expected Results\n    ----------------\n    * Success: The test will pass if all provided VTEP peers are identified and matching.\n    * Failure: The test will fail if any VTEP peer is missing or there are unexpected VTEP peers.\n    * Skipped: The test will be skipped if the Vxlan1 interface is not configured.\n\n    Examples\n    --------\n    ```yaml\n    anta.tests.vxlan:\n      - VerifyVxlanVtep:\n          vteps:\n            - 10.1.1.5\n            - 10.1.1.6\n    ```\n    \"\"\"\n\n    categories: ClassVar[list[str]] = [\"vxlan\"]\n    commands: ClassVar[list[AntaCommand | AntaTemplate]] = [AntaCommand(command=\"show vxlan vtep\", revision=1)]\n\n    class Input(AntaTest.Input):\n        \"\"\"Input model for the VerifyVxlanVtep test.\"\"\"\n\n        vteps: list[IPv4Address]\n        \"\"\"List of VTEP peers to verify.\"\"\"\n\n    @AntaTest.anta_test\n    def test(self) -&gt; None:\n        \"\"\"Main test function for VerifyVxlanVtep.\"\"\"\n        self.result.is_success()\n\n        inputs_vteps = [str(input_vtep) for input_vtep in self.inputs.vteps]\n\n        if (vxlan1 := get_value(self.instance_commands[0].json_output, \"interfaces.Vxlan1\")) is None:\n            self.result.is_skipped(\"Interface: Vxlan1 - Not configured\")\n            return\n\n        difference1 = set(inputs_vteps).difference(set(vxlan1[\"vteps\"]))\n        difference2 = set(vxlan1[\"vteps\"]).difference(set(inputs_vteps))\n\n        if difference1:\n            self.result.is_failure(f\"The following VTEP peer(s) are missing from the Vxlan1 interface: {', '.join(sorted(difference1))}\")\n\n        if difference2:\n            self.result.is_failure(f\"Unexpected VTEP peer(s) on Vxlan1 interface: {', '.join(sorted(difference2))}\")\n</code></pre>"},{"location":"api/tests/vxlan/#anta.tests.vxlan.VerifyVxlanVtep-attributes","title":"Inputs","text":"Name Type Description Default <code>vteps</code> <code>list[IPv4Address]</code>                      List of VTEP peers to verify.                    -"},{"location":"cli/check/","title":"Check commands","text":"<p>The ANTA check command allow to execute some checks on the ANTA input files. Only checking the catalog is currently supported.</p> <pre><code>anta check --help\nUsage: anta check [OPTIONS] COMMAND [ARGS]...\n\n  Check commands for building ANTA\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  catalog  Check that the catalog is valid\n</code></pre>"},{"location":"cli/check/#checking-the-catalog","title":"Checking the catalog","text":"<pre><code>Usage: anta check catalog [OPTIONS]\n\n  Check that the catalog is valid.\n\nOptions:\n  -c, --catalog FILE            Path to the test catalog file  [env var:\n                                ANTA_CATALOG; required]\n  --catalog-format [yaml|json]  Format of the catalog file, either 'yaml' or\n                                'json'  [env var: ANTA_CATALOG_FORMAT]\n  --help                        Show this message and exit.\n</code></pre>"},{"location":"cli/debug/","title":"Debug commands","text":"<p>The ANTA CLI includes a set of debugging tools, making it easier to build and test ANTA content. This functionality is accessed via the <code>debug</code> subcommand and offers the following options:</p> <ul> <li>Executing a command on a device from your inventory and retrieving the result.</li> <li>Running a templated command on a device from your inventory and retrieving the result.</li> </ul> <p>These tools are especially helpful in building the tests, as they give a visual access to the output received from the eAPI. They also facilitate the extraction of output content for use in unit tests, as described in our contribution guide.</p> <p>Warning</p> <p>The <code>debug</code> tools require a device from your inventory. Thus, you must use a valid ANTA Inventory.</p>"},{"location":"cli/debug/#executing-an-eos-command","title":"Executing an EOS command","text":"<p>You can use the <code>run-cmd</code> entrypoint to run a command, which includes the following options:</p>"},{"location":"cli/debug/#command-overview","title":"Command overview","text":"<pre><code>Usage: anta debug run-cmd [OPTIONS]\n\n  Run arbitrary command to an ANTA device.\n\nOptions:\n  -u, --username TEXT       Username to connect to EOS  [env var:\n                            ANTA_USERNAME; required]\n  -p, --password TEXT       Password to connect to EOS that must be provided.\n                            It can be prompted using '--prompt' option.  [env\n                            var: ANTA_PASSWORD]\n  --enable-password TEXT    Password to access EOS Privileged EXEC mode. It\n                            can be prompted using '--prompt' option. Requires\n                            '--enable' option.  [env var:\n                            ANTA_ENABLE_PASSWORD]\n  --enable                  Some commands may require EOS Privileged EXEC\n                            mode. This option tries to access this mode before\n                            sending a command to the device.  [env var:\n                            ANTA_ENABLE]\n  -P, --prompt              Prompt for passwords if they are not provided.\n                            [env var: ANTA_PROMPT]\n  --timeout FLOAT           Global API timeout. This value will be used for\n                            all devices.  [env var: ANTA_TIMEOUT; default:\n                            30.0]\n  --insecure                Disable SSH Host Key validation.  [env var:\n                            ANTA_INSECURE]\n  --disable-cache           Disable cache globally.  [env var:\n                            ANTA_DISABLE_CACHE]\n  -i, --inventory FILE      Path to the inventory YAML file.  [env var:\n                            ANTA_INVENTORY; required]\n  --ofmt [json|text]        EOS eAPI format to use. can be text or json\n  -v, --version [1|latest]  EOS eAPI version\n  -r, --revision INTEGER    eAPI command revision\n  -d, --device TEXT         Device from inventory to use  [required]\n  -c, --command TEXT        Command to run  [required]\n  --help                    Show this message and exit.\n</code></pre> <p>Tip</p> <p><code>username</code>, <code>password</code>, <code>enable-password</code>, <code>enable</code>, <code>timeout</code> and <code>insecure</code> values are the same for all devices</p>"},{"location":"cli/debug/#example","title":"Example","text":"<p>This example illustrates how to run the <code>show interfaces description</code> command with a <code>JSON</code> format (default):</p> <pre><code>anta debug run-cmd --command \"show interfaces description\" --device DC1-SPINE1\nRun command show interfaces description on DC1-SPINE1\n{\n    'interfaceDescriptions': {\n        'Ethernet1': {'lineProtocolStatus': 'up', 'description': 'P2P_LINK_TO_DC1-LEAF1A_Ethernet1', 'interfaceStatus': 'up'},\n        'Ethernet2': {'lineProtocolStatus': 'up', 'description': 'P2P_LINK_TO_DC1-LEAF1B_Ethernet1', 'interfaceStatus': 'up'},\n        'Ethernet3': {'lineProtocolStatus': 'up', 'description': 'P2P_LINK_TO_DC1-BL1_Ethernet1', 'interfaceStatus': 'up'},\n        'Ethernet4': {'lineProtocolStatus': 'up', 'description': 'P2P_LINK_TO_DC1-BL2_Ethernet1', 'interfaceStatus': 'up'},\n        'Loopback0': {'lineProtocolStatus': 'up', 'description': 'EVPN_Overlay_Peering', 'interfaceStatus': 'up'},\n        'Management0': {'lineProtocolStatus': 'up', 'description': 'oob_management', 'interfaceStatus': 'up'}\n    }\n}\n</code></pre>"},{"location":"cli/debug/#executing-an-eos-command-using-templates","title":"Executing an EOS command using templates","text":"<p>The <code>run-template</code> entrypoint allows the user to provide an <code>f-string</code> templated command. It is followed by a list of arguments (key-value pairs) that build a dictionary used as template parameters.</p>"},{"location":"cli/debug/#command-overview_1","title":"Command overview","text":"<pre><code>Usage: anta debug run-template [OPTIONS] PARAMS...\n\n  Run arbitrary templated command to an ANTA device.\n\n  Takes a list of arguments (keys followed by a value) to build a dictionary\n  used as template parameters.\n\n  Example\n  -------\n      anta debug run-template -d leaf1a -t 'show vlan {vlan_id}' vlan_id 1\n\nOptions:\n  -u, --username TEXT       Username to connect to EOS  [env var:\n                            ANTA_USERNAME; required]\n  -p, --password TEXT       Password to connect to EOS that must be provided.\n                            It can be prompted using '--prompt' option.  [env\n                            var: ANTA_PASSWORD]\n  --enable-password TEXT    Password to access EOS Privileged EXEC mode. It\n                            can be prompted using '--prompt' option. Requires\n                            '--enable' option.  [env var:\n                            ANTA_ENABLE_PASSWORD]\n  --enable                  Some commands may require EOS Privileged EXEC\n                            mode. This option tries to access this mode before\n                            sending a command to the device.  [env var:\n                            ANTA_ENABLE]\n  -P, --prompt              Prompt for passwords if they are not provided.\n                            [env var: ANTA_PROMPT]\n  --timeout FLOAT           Global API timeout. This value will be used for\n                            all devices.  [env var: ANTA_TIMEOUT; default:\n                            30.0]\n  --insecure                Disable SSH Host Key validation.  [env var:\n                            ANTA_INSECURE]\n  --disable-cache           Disable cache globally.  [env var:\n                            ANTA_DISABLE_CACHE]\n  -i, --inventory FILE      Path to the inventory YAML file.  [env var:\n                            ANTA_INVENTORY; required]\n  --ofmt [json|text]        EOS eAPI format to use. can be text or json\n  -v, --version [1|latest]  EOS eAPI version\n  -r, --revision INTEGER    eAPI command revision\n  -d, --device TEXT         Device from inventory to use  [required]\n  -t, --template TEXT       Command template to run. E.g. 'show vlan\n                            {vlan_id}'  [required]\n  --help                    Show this message and exit.\n</code></pre> <p><code>username</code>, <code>password</code>, <code>enable-password</code>, <code>enable</code>, <code>timeout</code> and <code>insecure</code> values are the same for all devices</p>"},{"location":"cli/debug/#example_1","title":"Example","text":"<p>This example uses the <code>show vlan {vlan_id}</code> command in a <code>JSON</code> format:</p> <pre><code>anta debug run-template --template \"show vlan {vlan_id}\" vlan_id 10 --device DC1-LEAF1A\nRun templated command 'show vlan {vlan_id}' with {'vlan_id': '10'} on DC1-LEAF1A\n{\n    'vlans': {\n        '10': {\n            'name': 'VRFPROD_VLAN10',\n            'dynamic': False,\n            'status': 'active',\n            'interfaces': {\n                'Cpu': {'privatePromoted': False, 'blocked': None},\n                'Port-Channel11': {'privatePromoted': False, 'blocked': None},\n                'Vxlan1': {'privatePromoted': False, 'blocked': None}\n            }\n        }\n    },\n    'sourceDetail': ''\n}\n</code></pre>"},{"location":"cli/debug/#example-of-multiple-arguments","title":"Example of multiple arguments","text":"<p>Warning</p> <p>If multiple arguments of the same key are provided, only the last argument value will be kept in the template parameters.</p> <pre><code>anta -log DEBUG debug run-template --template \"ping {dst} source {src}\" dst \"8.8.8.8\" src Loopback0 --device DC1-SPINE1 \u00a0 \u00a0\n&gt; {'dst': '8.8.8.8', 'src': 'Loopback0'}\n\nanta -log DEBUG debug run-template --template \"ping {dst} source {src}\" dst \"8.8.8.8\" src Loopback0 dst \"1.1.1.1\" src Loopback1 --device DC1-SPINE1 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\n&gt; {'dst': '1.1.1.1', 'src': 'Loopback1'}\n# Notice how `src` and `dst` keep only the latest value\n</code></pre>"},{"location":"cli/exec/","title":"Execute commands","text":"<p>ANTA CLI provides a set of entrypoints to facilitate remote command execution on EOS devices.</p>"},{"location":"cli/exec/#exec-command-overview","title":"EXEC command overview","text":"<pre><code>anta exec --help\nUsage: anta exec [OPTIONS] COMMAND [ARGS]...\n\n  Execute commands to inventory devices\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  clear-counters        Clear counter statistics on EOS devices\n  collect-tech-support  Collect scheduled tech-support from EOS devices\n  snapshot              Collect commands output from devices in inventory\n</code></pre>"},{"location":"cli/exec/#clear-interfaces-counters","title":"Clear interfaces counters","text":"<p>This command clears interface counters on EOS devices specified in your inventory.</p>"},{"location":"cli/exec/#command-overview","title":"Command overview","text":"<pre><code>Usage: anta exec clear-counters [OPTIONS]\n\n  Clear counter statistics on EOS devices.\n\nOptions:\n  -u, --username TEXT     Username to connect to EOS  [env var: ANTA_USERNAME;\n                          required]\n  -p, --password TEXT     Password to connect to EOS that must be provided. It\n                          can be prompted using '--prompt' option.  [env var:\n                          ANTA_PASSWORD]\n  --enable-password TEXT  Password to access EOS Privileged EXEC mode. It can\n                          be prompted using '--prompt' option. Requires '--\n                          enable' option.  [env var: ANTA_ENABLE_PASSWORD]\n  --enable                Some commands may require EOS Privileged EXEC mode.\n                          This option tries to access this mode before sending\n                          a command to the device.  [env var: ANTA_ENABLE]\n  -P, --prompt            Prompt for passwords if they are not provided.  [env\n                          var: ANTA_PROMPT]\n  --timeout FLOAT         Global API timeout. This value will be used for all\n                          devices.  [env var: ANTA_TIMEOUT; default: 30.0]\n  --insecure              Disable SSH Host Key validation.  [env var:\n                          ANTA_INSECURE]\n  --disable-cache         Disable cache globally.  [env var:\n                          ANTA_DISABLE_CACHE]\n  -i, --inventory FILE    Path to the inventory YAML file.  [env var:\n                          ANTA_INVENTORY; required]\n  --tags TEXT             List of tags using comma as separator:\n                          tag1,tag2,tag3.  [env var: ANTA_TAGS]\n  --help                  Show this message and exit.\n</code></pre> <p>Tip</p> <p><code>username</code>, <code>password</code>, <code>enable-password</code>, <code>enable</code>, <code>timeout</code> and <code>insecure</code> values are the same for all devices</p>"},{"location":"cli/exec/#example","title":"Example","text":"<pre><code>anta exec clear-counters --tags SPINE\n[20:19:13] INFO     Connecting to devices...                                                                                                                         utils.py:43\n           INFO     Clearing counters on remote devices...                                                                                                           utils.py:46\n           INFO     Cleared counters on DC1-SPINE2 (cEOSLab)                                                                                                         utils.py:41\n           INFO     Cleared counters on DC2-SPINE1 (cEOSLab)                                                                                                         utils.py:41\n           INFO     Cleared counters on DC1-SPINE1 (cEOSLab)                                                                                                         utils.py:41\n           INFO     Cleared counters on DC2-SPINE2 (cEOSLab)\n</code></pre>"},{"location":"cli/exec/#collect-a-set-of-commands","title":"Collect a set of commands","text":"<p>This command collects all the commands specified in a commands-list file, which can be in either <code>json</code> or <code>text</code> format.</p>"},{"location":"cli/exec/#command-overview_1","title":"Command overview","text":"<pre><code>Usage: anta exec snapshot [OPTIONS]\n\n  Collect commands output from devices in inventory.\n\nOptions:\n  -u, --username TEXT       Username to connect to EOS  [env var:\n                            ANTA_USERNAME; required]\n  -p, --password TEXT       Password to connect to EOS that must be provided.\n                            It can be prompted using '--prompt' option.  [env\n                            var: ANTA_PASSWORD]\n  --enable-password TEXT    Password to access EOS Privileged EXEC mode. It\n                            can be prompted using '--prompt' option. Requires\n                            '--enable' option.  [env var:\n                            ANTA_ENABLE_PASSWORD]\n  --enable                  Some commands may require EOS Privileged EXEC\n                            mode. This option tries to access this mode before\n                            sending a command to the device.  [env var:\n                            ANTA_ENABLE]\n  -P, --prompt              Prompt for passwords if they are not provided.\n                            [env var: ANTA_PROMPT]\n  --timeout FLOAT           Global API timeout. This value will be used for\n                            all devices.  [env var: ANTA_TIMEOUT; default:\n                            30.0]\n  --insecure                Disable SSH Host Key validation.  [env var:\n                            ANTA_INSECURE]\n  --disable-cache           Disable cache globally.  [env var:\n                            ANTA_DISABLE_CACHE]\n  -i, --inventory FILE      Path to the inventory YAML file.  [env var:\n                            ANTA_INVENTORY; required]\n  --tags TEXT               List of tags using comma as separator:\n                            tag1,tag2,tag3.  [env var: ANTA_TAGS]\n  -c, --commands-list FILE  File with list of commands to collect  [env var:\n                            ANTA_EXEC_SNAPSHOT_COMMANDS_LIST; required]\n  -o, --output DIRECTORY    Directory to save commands output.  [env var:\n                            ANTA_EXEC_SNAPSHOT_OUTPUT; default:\n                            anta_snapshot_2024-04-09_15_56_19]\n  --help                    Show this message and exit.\n</code></pre> <p><code>username</code>, <code>password</code>, <code>enable-password</code>, <code>enable</code>, <code>timeout</code> and <code>insecure</code> values are the same for all devices</p> <p>The commands-list file should follow this structure:</p> <pre><code>---\njson_format:\n  - show version\ntext_format:\n  - show bfd peers\n</code></pre>"},{"location":"cli/exec/#example_1","title":"Example","text":"<pre><code>anta exec snapshot --tags SPINE --commands-list ./commands.yaml --output ./\n[20:25:15] INFO     Connecting to devices...                                                                                                                         utils.py:78\n           INFO     Collecting commands from remote devices                                                                                                          utils.py:81\n           INFO     Collected command 'show version' from device DC2-SPINE1 (cEOSLab)                                                                                utils.py:76\n           INFO     Collected command 'show version' from device DC2-SPINE2 (cEOSLab)                                                                                utils.py:76\n           INFO     Collected command 'show version' from device DC1-SPINE1 (cEOSLab)                                                                                utils.py:76\n           INFO     Collected command 'show version' from device DC1-SPINE2 (cEOSLab)                                                                                utils.py:76\n[20:25:16] INFO     Collected command 'show bfd peers' from device DC2-SPINE2 (cEOSLab)                                                                              utils.py:76\n           INFO     Collected command 'show bfd peers' from device DC2-SPINE1 (cEOSLab)                                                                              utils.py:76\n           INFO     Collected command 'show bfd peers' from device DC1-SPINE1 (cEOSLab)                                                                              utils.py:76\n           INFO     Collected command 'show bfd peers' from device DC1-SPINE2 (cEOSLab)\n</code></pre> <p>The results of the executed commands will be stored in the output directory specified during command execution:</p> <pre><code>tree _2023-07-14_20_25_15\n_2023-07-14_20_25_15\n\u251c\u2500\u2500 DC1-SPINE1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 show version.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 text\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 show bfd peers.log\n\u251c\u2500\u2500 DC1-SPINE2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 show version.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 text\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 show bfd peers.log\n\u251c\u2500\u2500 DC2-SPINE1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 show version.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 text\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 show bfd peers.log\n\u2514\u2500\u2500 DC2-SPINE2\n    \u251c\u2500\u2500 json\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 show version.json\n    \u2514\u2500\u2500 text\n        \u2514\u2500\u2500 show bfd peers.log\n\n12 directories, 8 files\n</code></pre>"},{"location":"cli/exec/#get-scheduled-tech-support","title":"Get Scheduled tech-support","text":"<p>EOS offers a feature that automatically creates a tech-support archive every hour by default. These archives are stored under <code>/mnt/flash/schedule/tech-support</code>.</p> <pre><code>leaf1#show schedule summary\nMaximum concurrent jobs  1\nPrepend host name to logfile: Yes\nName                 At Time       Last        Interval       Timeout        Max        Max     Logfile Location                  Status\n                                   Time         (mins)        (mins)         Log        Logs\n                                                                            Files       Size\n----------------- ------------- ----------- -------------- ------------- ----------- ---------- --------------------------------- ------\ntech-support           now         08:37          60            30           100         -      flash:schedule/tech-support/      Success\n\n\nleaf1#bash ls /mnt/flash/schedule/tech-support\nleaf1_tech-support_2023-03-09.1337.log.gz  leaf1_tech-support_2023-03-10.0837.log.gz  leaf1_tech-support_2023-03-11.0337.log.gz\n</code></pre> <p>For Network Readiness for Use (NRFU) tests and to keep a comprehensive report of the system state before going live, ANTA provides a command-line interface that efficiently retrieves these files.</p>"},{"location":"cli/exec/#command-overview_2","title":"Command overview","text":"<pre><code>Usage: anta exec collect-tech-support [OPTIONS]\n\n  Collect scheduled tech-support from EOS devices.\n\nOptions:\n  -u, --username TEXT     Username to connect to EOS  [env var: ANTA_USERNAME;\n                          required]\n  -p, --password TEXT     Password to connect to EOS that must be provided. It\n                          can be prompted using '--prompt' option.  [env var:\n                          ANTA_PASSWORD]\n  --enable-password TEXT  Password to access EOS Privileged EXEC mode. It can\n                          be prompted using '--prompt' option. Requires '--\n                          enable' option.  [env var: ANTA_ENABLE_PASSWORD]\n  --enable                Some commands may require EOS Privileged EXEC mode.\n                          This option tries to access this mode before sending\n                          a command to the device.  [env var: ANTA_ENABLE]\n  -P, --prompt            Prompt for passwords if they are not provided.  [env\n                          var: ANTA_PROMPT]\n  --timeout FLOAT         Global API timeout. This value will be used for all\n                          devices.  [env var: ANTA_TIMEOUT; default: 30.0]\n  --insecure              Disable SSH Host Key validation.  [env var:\n                          ANTA_INSECURE]\n  --disable-cache         Disable cache globally.  [env var:\n                          ANTA_DISABLE_CACHE]\n  -i, --inventory FILE    Path to the inventory YAML file.  [env var:\n                          ANTA_INVENTORY; required]\n  --tags TEXT             List of tags using comma as separator:\n                          tag1,tag2,tag3.  [env var: ANTA_TAGS]\n  -o, --output PATH       Path for test catalog  [default: ./tech-support]\n  --latest INTEGER        Number of scheduled show-tech to retrieve\n  --configure             [DEPRECATED] Ensure devices have 'aaa authorization\n                          exec default local' configured (required for SCP on\n                          EOS). THIS WILL CHANGE THE CONFIGURATION OF YOUR\n                          NETWORK.\n  --help                  Show this message and exit.\n</code></pre> <p>Tip</p> <p><code>username</code>, <code>password</code>, <code>enable-password</code>, <code>enable</code>, <code>timeout</code> and <code>insecure</code> values are the same for all devices</p> <p>When executed, this command fetches tech-support files and downloads them locally into a device-specific subfolder within the designated folder. You can specify the output folder with the <code>--output</code> option.</p> <p>ANTA uses SCP to download files from devices and will not trust unknown SSH hosts by default. Add the SSH public keys of your devices to your <code>known_hosts</code> file or use the <code>anta --insecure</code> option to ignore SSH host keys validation.</p> <p>The configuration <code>aaa authorization exec default</code> must be present on devices to be able to use SCP.</p> <p>Caution</p> <p>Deprecation</p> <p>ANTA can automatically configure <code>aaa authorization exec default local</code> using the <code>anta exec collect-tech-support --configure</code> option but this option is deprecated and will be removed in ANTA 2.0.0.</p> <p>If you require specific AAA configuration for <code>aaa authorization exec default</code>, like <code>aaa authorization exec default none</code> or <code>aaa authorization exec default group tacacs+</code>, you will need to configure it manually.</p> <p>The <code>--latest</code> option allows retrieval of a specific number of the most recent tech-support files.</p> <p>Warning</p> <p>By default all the tech-support files present on the devices are retrieved.</p>"},{"location":"cli/exec/#example_2","title":"Example","text":"<pre><code>anta --insecure exec collect-tech-support\n[15:27:19] INFO     Connecting to devices...\nINFO     Copying '/mnt/flash/schedule/tech-support/spine1_tech-support_2023-06-09.1315.log.gz' from device spine1 to 'tech-support/spine1' locally\nINFO     Copying '/mnt/flash/schedule/tech-support/leaf3_tech-support_2023-06-09.1315.log.gz' from device leaf3 to 'tech-support/leaf3' locally\nINFO     Copying '/mnt/flash/schedule/tech-support/leaf1_tech-support_2023-06-09.1315.log.gz' from device leaf1 to 'tech-support/leaf1' locally\nINFO     Copying '/mnt/flash/schedule/tech-support/leaf2_tech-support_2023-06-09.1315.log.gz' from device leaf2 to 'tech-support/leaf2' locally\nINFO     Copying '/mnt/flash/schedule/tech-support/spine2_tech-support_2023-06-09.1315.log.gz' from device spine2 to 'tech-support/spine2' locally\nINFO     Copying '/mnt/flash/schedule/tech-support/leaf4_tech-support_2023-06-09.1315.log.gz' from device leaf4 to 'tech-support/leaf4' locally\nINFO     Collected 1 scheduled tech-support from leaf2\nINFO     Collected 1 scheduled tech-support from spine2\nINFO     Collected 1 scheduled tech-support from leaf3\nINFO     Collected 1 scheduled tech-support from spine1\nINFO     Collected 1 scheduled tech-support from leaf1\nINFO     Collected 1 scheduled tech-support from leaf4\n</code></pre> <p>The output folder structure is as follows:</p> <pre><code>tree tech-support/\ntech-support/\n\u251c\u2500\u2500 leaf1\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 leaf1_tech-support_2023-06-09.1315.log.gz\n\u251c\u2500\u2500 leaf2\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 leaf2_tech-support_2023-06-09.1315.log.gz\n\u251c\u2500\u2500 leaf3\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 leaf3_tech-support_2023-06-09.1315.log.gz\n\u251c\u2500\u2500 leaf4\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 leaf4_tech-support_2023-06-09.1315.log.gz\n\u251c\u2500\u2500 spine1\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 spine1_tech-support_2023-06-09.1315.log.gz\n\u2514\u2500\u2500 spine2\n    \u2514\u2500\u2500 spine2_tech-support_2023-06-09.1315.log.gz\n\n6 directories, 6 files\n</code></pre> <p>Each device has its own subdirectory containing the collected tech-support files.</p>"},{"location":"cli/get-inventory-information/","title":"Get Inventory Information","text":"<p>The ANTA CLI offers multiple commands to access data from your local inventory.</p>"},{"location":"cli/get-inventory-information/#list-devices-in-inventory","title":"List devices in inventory","text":"<p>This command will list all devices available in the inventory. Using the <code>--tags</code> option, you can filter this list to only include devices with specific tags (visit this page to learn more about tags). The <code>--connected</code> option allows to display only the devices where a connection has been established.</p>"},{"location":"cli/get-inventory-information/#command-overview","title":"Command overview","text":"<pre><code>Usage: anta get inventory [OPTIONS]\n\n  Show inventory loaded in ANTA.\n\nOptions:\n  -u, --username TEXT            Username to connect to EOS  [env var:\n                                 ANTA_USERNAME; required]\n  -p, --password TEXT            Password to connect to EOS that must be\n                                 provided. It can be prompted using '--prompt'\n                                 option.  [env var: ANTA_PASSWORD]\n  --enable-password TEXT         Password to access EOS Privileged EXEC mode.\n                                 It can be prompted using '--prompt' option.\n                                 Requires '--enable' option.  [env var:\n                                 ANTA_ENABLE_PASSWORD]\n  --enable                       Some commands may require EOS Privileged EXEC\n                                 mode. This option tries to access this mode\n                                 before sending a command to the device.  [env\n                                 var: ANTA_ENABLE]\n  -P, --prompt                   Prompt for passwords if they are not\n                                 provided.  [env var: ANTA_PROMPT]\n  --timeout FLOAT                Global API timeout. This value will be used\n                                 for all devices.  [env var: ANTA_TIMEOUT;\n                                 default: 30.0]\n  --insecure                     Disable SSH Host Key validation.  [env var:\n                                 ANTA_INSECURE]\n  --disable-cache                Disable cache globally.  [env var:\n                                 ANTA_DISABLE_CACHE]\n  -i, --inventory FILE           Path to the inventory YAML file.  [env var:\n                                 ANTA_INVENTORY; required]\n  --tags TEXT                    List of tags using comma as separator:\n                                 tag1,tag2,tag3.  [env var: ANTA_TAGS]\n  --connected / --not-connected  Display inventory after connection has been\n                                 created\n  --help                         Show this message and exit.\n</code></pre> <p>Tip</p> <p>By default, <code>anta get inventory</code> only provides information that doesn\u2019t rely on a device connection. If you are interested in obtaining connection-dependent details, like the hardware model, use the <code>--connected</code> option.</p>"},{"location":"cli/get-inventory-information/#example","title":"Example","text":"<p>Let\u2019s consider the following inventory:</p> <pre><code>---\nanta_inventory:\n  hosts:\n    - host: 172.20.20.101\n      name: DC1-SPINE1\n      tags: [\"SPINE\", \"DC1\"]\n\n    - host: 172.20.20.102\n      name: DC1-SPINE2\n      tags: [\"SPINE\", \"DC1\"]\n\n    - host: 172.20.20.111\n      name: DC1-LEAF1A\n      tags: [\"LEAF\", \"DC1\"]\n\n    - host: 172.20.20.112\n      name: DC1-LEAF1B\n      tags: [\"LEAF\", \"DC1\"]\n\n    - host: 172.20.20.121\n      name: DC1-BL1\n      tags: [\"BL\", \"DC1\"]\n\n    - host: 172.20.20.122\n      name: DC1-BL2\n      tags: [\"BL\", \"DC1\"]\n\n    - host: 172.20.20.201\n      name: DC2-SPINE1\n      tags: [\"SPINE\", \"DC2\"]\n\n    - host: 172.20.20.202\n      name: DC2-SPINE2\n      tags: [\"SPINE\", \"DC2\"]\n\n    - host: 172.20.20.211\n      name: DC2-LEAF1A\n      tags: [\"LEAF\", \"DC2\"]\n\n    - host: 172.20.20.212\n      name: DC2-LEAF1B\n      tags: [\"LEAF\", \"DC2\"]\n\n    - host: 172.20.20.221\n      name: DC2-BL1\n      tags: [\"BL\", \"DC2\"]\n\n    - host: 172.20.20.222\n      name: DC2-BL2\n      tags: [\"BL\", \"DC2\"]\n</code></pre> <p>To retrieve a comprehensive list of all devices along with their details, execute the following command. It will provide all the data loaded into the ANTA inventory from your inventory file.</p> <pre><code>$ anta get inventory --tags SPINE\nCurrent inventory content is:\n{\n    'DC1-SPINE1': AsyncEOSDevice(\n        name='DC1-SPINE1',\n        tags={'DC1-SPINE1', 'DC1', 'SPINE'},\n        hw_model=None,\n        is_online=False,\n        established=False,\n        disable_cache=False,\n        host='172.20.20.101',\n        eapi_port=443,\n        username='arista',\n        enable=False,\n        insecure=False\n    ),\n    'DC1-SPINE2': AsyncEOSDevice(\n        name='DC1-SPINE2',\n        tags={'DC1', 'SPINE', 'DC1-SPINE2'},\n        hw_model=None,\n        is_online=False,\n        established=False,\n        disable_cache=False,\n        host='172.20.20.102',\n        eapi_port=443,\n        username='arista',\n        enable=False,\n        insecure=False\n    ),\n    'DC2-SPINE1': AsyncEOSDevice(\n        name='DC2-SPINE1',\n        tags={'DC2', 'DC2-SPINE1', 'SPINE'},\n        hw_model=None,\n        is_online=False,\n        established=False,\n        disable_cache=False,\n        host='172.20.20.201',\n        eapi_port=443,\n        username='arista',\n        enable=False,\n        insecure=False\n    ),\n    'DC2-SPINE2': AsyncEOSDevice(\n        name='DC2-SPINE2',\n        tags={'DC2', 'DC2-SPINE2', 'SPINE'},\n        hw_model=None,\n        is_online=False,\n        established=False,\n        disable_cache=False,\n        host='172.20.20.202',\n        eapi_port=443,\n        username='arista',\n        enable=False,\n        insecure=False\n    )\n}\n</code></pre>"},{"location":"cli/get-tests/","title":"Get Tests Information","text":"<p><code>anta get tests</code> commands help you discover available tests in ANTA.</p>"},{"location":"cli/get-tests/#command-overview","title":"Command overview","text":"<pre><code>Usage: anta get tests [OPTIONS]\n\n  Show all builtin ANTA tests with an example output retrieved from each test\n  documentation.\n\nOptions:\n  --module TEXT  Filter tests by module name.  [default: anta.tests]\n  --test TEXT    Filter by specific test name. If module is specified,\n                 searches only within that module.\n  --short        Display test names without their inputs.\n  --count        Print only the number of tests found.\n  --help         Show this message and exit.\n</code></pre> <p>Tip</p> <p>By default, <code>anta get tests</code> will retrieve all tests available in ANTA.</p>"},{"location":"cli/get-tests/#examples","title":"Examples","text":""},{"location":"cli/get-tests/#default-usage","title":"Default usage","text":"anta get tests<pre><code>anta.tests.aaa:\n  - VerifyAcctConsoleMethods:\n      # Verifies the AAA accounting console method lists for different accounting types (system, exec, commands, dot1x).\n      methods:\n        - local\n        - none\n        - logging\n      types:\n        - system\n        - exec\n        - commands\n        - dot1x\n  - VerifyAcctDefaultMethods:\n      # Verifies the AAA accounting default method lists for different accounting types (system, exec, commands, dot1x).\n      methods:\n        - local\n        - none\n        - logging\n      types:\n        - system\n        - exec\n        - commands\n        - dot1x\n[...]\n</code></pre>"},{"location":"cli/get-tests/#module-usage","title":"Module usage","text":"<p>To retrieve all the tests from <code>anta.tests.stun</code>.</p> anta get tests --module anta.tests.stun<pre><code>anta.tests.stun:\n  - VerifyStunClient:\n      # Verifies STUN client settings, including local IP/port and optionally public IP/port.\n      stun_clients:\n        - source_address: 172.18.3.2\n          public_address: 172.18.3.21\n          source_port: 4500\n          public_port: 6006\n        - source_address: 100.64.3.2\n          public_address: 100.64.3.21\n          source_port: 4500\n          public_port: 6006\n  - VerifyStunServer:\n      # Verifies the STUN server status is enabled and running.\n</code></pre>"},{"location":"cli/get-tests/#test-usage","title":"Test usage","text":"anta get tests --test VerifyTacacsSourceIntf<pre><code>anta.tests.aaa:\n  - VerifyTacacsSourceIntf:\n      # Verifies TACACS source-interface for a specified VRF.\n      intf: Management0\n      vrf: MGMT\n</code></pre> <p>Tip</p> <p>You can filter tests by providing a prefix - ANTA will return all tests that start with your specified string.</p> anta get tests --test VerifyTacacs<pre><code>anta.tests.aaa:\n  - VerifyTacacsServerGroups:\n      # Verifies if the provided TACACS server group(s) are configured.\n      groups:\n        - TACACS-GROUP1\n        - TACACS-GROUP2\n  - VerifyTacacsServers:\n      # Verifies TACACS servers are configured for a specified VRF.\n      servers:\n        - 10.10.10.21\n        - 10.10.10.22\n      vrf: MGMT\n  - VerifyTacacsSourceIntf:\n      # Verifies TACACS source-interface for a specified VRF.\n      intf: Management0\n      vrf: MGMT\n</code></pre>"},{"location":"cli/get-tests/#count-the-tests","title":"Count the tests","text":"anta get tests --count<pre><code>There are 155 tests available in `anta.tests`.\n</code></pre>"},{"location":"cli/inv-from-ansible/","title":"Inventory from Ansible","text":"<p>In large setups, it might be beneficial to construct your inventory based on your Ansible inventory. The <code>from-ansible</code> entrypoint of the <code>get</code> command enables the user to create an ANTA inventory from Ansible.</p>"},{"location":"cli/inv-from-ansible/#command-overview","title":"Command overview","text":"<pre><code>$ anta get from-ansible --help\nUsage: anta get from-ansible [OPTIONS]\n\n  Build ANTA inventory from an ansible inventory YAML file.\n\n  NOTE: This command does not support inline vaulted variables. Make sure to\n  comment them out.\n\nOptions:\n  -o, --output FILE         Path to save inventory file  [env var:\n                            ANTA_INVENTORY; required]\n  --overwrite               Do not prompt when overriding current inventory\n                            [env var: ANTA_GET_FROM_ANSIBLE_OVERWRITE]\n  -g, --ansible-group TEXT  Ansible group to filter\n  --ansible-inventory FILE  Path to your ansible inventory file to read\n                            [required]\n  --help                    Show this message and exit.\n</code></pre> <p>Warning</p> <ul> <li> <p><code>anta get from-ansible</code> does not support inline vaulted variables, comment them out to generate your inventory.</p> </li> <li> <p>If the vaulted variable is necessary to build the inventory (e.g. <code>ansible_host</code>), it needs to be unvaulted for <code>from-ansible</code> command to work.\u201d</p> </li> <li> <p>The current implementation only considers devices directly attached to a specific Ansible group and does not support inheritance when using the <code>--ansible-group</code> option.</p> </li> </ul> <p>By default, if user does not provide <code>--output</code> file, anta will save output to configured anta inventory (<code>anta --inventory</code>). If the output file has content, anta will ask user to overwrite when running in interactive console. This mechanism can be controlled by triggers in case of CI usage: <code>--overwrite</code> to force anta to overwrite file. If not set, anta will exit</p>"},{"location":"cli/inv-from-ansible/#command-output","title":"Command output","text":"<p><code>host</code> value is coming from the <code>ansible_host</code> key in your inventory while <code>name</code> is the name you defined for your host. Below is an ansible inventory example used to generate previous inventory:</p> <pre><code>---\nall:\n  children:\n    endpoints:\n      hosts:\n        srv-pod01:\n          ansible_httpapi_port: 9023\n          ansible_port: 9023\n          ansible_host: 10.73.252.41\n          type: endpoint\n        srv-pod02:\n          ansible_httpapi_port: 9024\n          ansible_port: 9024\n          ansible_host: 10.73.252.42\n          type: endpoint\n        srv-pod03:\n          ansible_httpapi_port: 9025\n          ansible_port: 9025\n          ansible_host: 10.73.252.43\n          type: endpoint\n</code></pre> <p>The output is an inventory where the name of the container is added as a tag for each host:</p> <pre><code>anta_inventory:\n  hosts:\n  - host: 10.73.252.41\n    name: srv-pod01\n  - host: 10.73.252.42\n    name: srv-pod02\n  - host: 10.73.252.43\n    name: srv-pod03\n</code></pre>"},{"location":"cli/inv-from-cvp/","title":"Inventory from CVP","text":"<p>In large setups, it might be beneficial to construct your inventory based on CloudVision. The <code>from-cvp</code> entrypoint of the <code>get</code> command enables the user to create an ANTA inventory from CloudVision.</p> <p>Info</p> <p>The current implementation only works with on-premises CloudVision instances, not with CloudVision as a Service (CVaaS).</p>"},{"location":"cli/inv-from-cvp/#command-overview","title":"Command overview","text":"<pre><code>Usage: anta get from-cvp [OPTIONS]\n\n  Build ANTA inventory from CloudVision.\n\n  NOTE: Only username/password authentication is supported for on-premises CloudVision instances.\n  Token authentication for both on-premises and CloudVision as a Service (CVaaS) is not supported.\n\nOptions:\n  -o, --output FILE     Path to save inventory file  [env var: ANTA_INVENTORY;\n                        required]\n  --overwrite           Do not prompt when overriding current inventory  [env\n                        var: ANTA_GET_FROM_CVP_OVERWRITE]\n  -host, --host TEXT    CloudVision instance FQDN or IP  [required]\n  -u, --username TEXT   CloudVision username  [required]\n  -p, --password TEXT   CloudVision password  [required]\n  -c, --container TEXT  CloudVision container where devices are configured\n  --ignore-cert         By default connection to CV will use HTTPS\n                        certificate, set this flag to disable it  [env var:\n                        ANTA_GET_FROM_CVP_IGNORE_CERT]\n  --help                Show this message and exit.\n</code></pre> <p>The output is an inventory where the name of the container is added as a tag for each host:</p> <pre><code>anta_inventory:\n  hosts:\n  - host: 192.168.0.13\n    name: leaf2\n    tags:\n    - pod1\n  - host: 192.168.0.15\n    name: leaf4\n    tags:\n    - pod2\n</code></pre> <p>Warning</p> <p>The current implementation only considers devices directly attached to a specific container when using the <code>--cvp-container</code> option.</p>"},{"location":"cli/inv-from-cvp/#creating-an-inventory-from-multiple-containers","title":"Creating an inventory from multiple containers","text":"<p>If you need to create an inventory from multiple containers, you can use a bash command and then manually concatenate files to create a single inventory file:</p> <pre><code>$ for container in pod01 pod02 spines; do anta get from-cvp -ip &lt;cvp-ip&gt; -u cvpadmin -p cvpadmin -c $container -d test-inventory; done\n\n[12:25:35] INFO     Getting auth token from cvp.as73.inetsix.net for user tom\n[12:25:36] INFO     Creating inventory folder /home/tom/Projects/arista/network-test-automation/test-inventory\n           WARNING  Using the new api_token parameter. This will override usage of the cvaas_token parameter if both are provided. This is because api_token and cvaas_token parameters\n                    are for the same use case and api_token is more generic\n           INFO     Connected to CVP cvp.as73.inetsix.net\n\n\n[12:25:37] INFO     Getting auth token from cvp.as73.inetsix.net for user tom\n[12:25:38] WARNING  Using the new api_token parameter. This will override usage of the cvaas_token parameter if both are provided. This is because api_token and cvaas_token parameters\n                    are for the same use case and api_token is more generic\n           INFO     Connected to CVP cvp.as73.inetsix.net\n\n\n[12:25:38] INFO     Getting auth token from cvp.as73.inetsix.net for user tom\n[12:25:39] WARNING  Using the new api_token parameter. This will override usage of the cvaas_token parameter if both are provided. This is because api_token and cvaas_token parameters\n                    are for the same use case and api_token is more generic\n           INFO     Connected to CVP cvp.as73.inetsix.net\n\n           INFO     Inventory file has been created in /home/tom/Projects/arista/network-test-automation/test-inventory/inventory-spines.yml\n</code></pre>"},{"location":"cli/nrfu/","title":"NRFU","text":"<p>ANTA provides a set of commands for performing NRFU tests on devices. These commands are under the <code>anta nrfu</code> namespace and offer multiple output format options:</p> <ul> <li>Text report</li> <li>Table report</li> <li>JSON report</li> <li>Custom template report</li> <li>CSV report</li> <li>Markdown report</li> </ul>"},{"location":"cli/nrfu/#nrfu-command-overview","title":"NRFU Command overview","text":"<pre><code>$ anta nrfu --help\nUsage: anta nrfu [OPTIONS] COMMAND [ARGS]...\n\n  Run ANTA tests on selected inventory devices.\n\nOptions:\n  -u, --username TEXT             Username to connect to EOS  [env var:\n                                  ANTA_USERNAME; required]\n  -p, --password TEXT             Password to connect to EOS that must be\n                                  provided. It can be prompted using '--\n                                  prompt' option.  [env var: ANTA_PASSWORD]\n  --enable-password TEXT          Password to access EOS Privileged EXEC mode.\n                                  It can be prompted using '--prompt' option.\n                                  Requires '--enable' option.  [env var:\n                                  ANTA_ENABLE_PASSWORD]\n  --enable                        Some commands may require EOS Privileged\n                                  EXEC mode. This option tries to access this\n                                  mode before sending a command to the device.\n                                  [env var: ANTA_ENABLE]\n  -P, --prompt                    Prompt for passwords if they are not\n                                  provided.  [env var: ANTA_PROMPT]\n  --timeout FLOAT                 Global API timeout. This value will be used\n                                  for all devices.  [env var: ANTA_TIMEOUT;\n                                  default: 30.0]\n  --insecure                      Disable SSH Host Key validation.  [env var:\n                                  ANTA_INSECURE]\n  --disable-cache                 Disable cache globally.  [env var:\n                                  ANTA_DISABLE_CACHE]\n  -i, --inventory FILE            Path to the inventory YAML file.  [env var:\n                                  ANTA_INVENTORY; required]\n  --inventory-format [yaml|json]  Format of the inventory file, either 'yaml'\n                                  or 'json'  [env var: ANTA_INVENTORY_FORMAT]\n  --tags TEXT                     List of tags using comma as separator:\n                                  tag1,tag2,tag3.  [env var: ANTA_TAGS]\n  -c, --catalog FILE              Path to the test catalog file  [env var:\n                                  ANTA_CATALOG; required]\n  --catalog-format [yaml|json]    Format of the catalog file, either 'yaml' or\n                                  'json'  [env var: ANTA_CATALOG_FORMAT]\n  -d, --device TEXT               Run tests on a specific device. Can be\n                                  provided multiple times.\n  -t, --test TEXT                 Run a specific test. Can be provided\n                                  multiple times.\n  --ignore-status                 Exit code will always be 0.  [env var:\n                                  ANTA_NRFU_IGNORE_STATUS]\n  --ignore-error                  Exit code will be 0 if all tests succeeded\n                                  or 1 if any test failed.  [env var:\n                                  ANTA_NRFU_IGNORE_ERROR]\n  --hide [success|failure|error|skipped]\n                                  Hide results by type: success / failure /\n                                  error / skipped'.\n  --dry-run                       Run anta nrfu command but stop before\n                                  starting to execute the tests. Considers all\n                                  devices as connected.  [env var:\n                                  ANTA_NRFU_DRY_RUN]\n  --help                          Show this message and exit.\n\nCommands:\n  csv         ANTA command to check network state with CSV report.\n  json        ANTA command to check network state with JSON results.\n  md-report   ANTA command to check network state with Markdown report.\n  table       ANTA command to check network state with table results.\n  text        ANTA command to check network state with text results.\n  tpl-report  ANTA command to check network state with templated report.\n</code></pre> <p><code>username</code>, <code>password</code>, <code>enable-password</code>, <code>enable</code>, <code>timeout</code> and <code>insecure</code> values are the same for all devices</p> <p>All commands under the <code>anta nrfu</code> namespace require a catalog yaml file specified with the <code>--catalog</code> option and a device inventory file specified with the <code>--inventory</code> option.</p> <p>Tip</p> <p>Issuing the command <code>anta nrfu</code> will run <code>anta nrfu table</code> without any option.</p>"},{"location":"cli/nrfu/#tag-management","title":"Tag management","text":"<p>The <code>--tags</code> option can be used to target specific devices in your inventory and run only tests configured with this specific tags from your catalog. Refer to the dedicated page for more information.</p>"},{"location":"cli/nrfu/#device-and-test-filtering","title":"Device and test filtering","text":"<p>Options <code>--device</code> and <code>--test</code> can be used to target one or multiple devices and/or tests to run in your environment. The options can be repeated. Example: <code>anta nrfu --device leaf1a --device leaf1b --test VerifyUptime --test VerifyReloadCause</code>.</p>"},{"location":"cli/nrfu/#hide-results","title":"Hide results","text":"<p>Option <code>--hide</code> can be used to hide test results in the output or report file based on their status. The option can be repeated. Example: <code>anta nrfu --hide error --hide skipped</code>.</p>"},{"location":"cli/nrfu/#performing-nrfu-with-text-rendering","title":"Performing NRFU with text rendering","text":"<p>The <code>text</code> subcommand provides a straightforward text report for each test executed on all devices in your inventory.</p>"},{"location":"cli/nrfu/#command-overview","title":"Command overview","text":"<pre><code>$ anta nrfu text --help\nUsage: anta nrfu text [OPTIONS]\n\n  ANTA command to check network state with text results.\n\nOptions:\n  --help  Show this message and exit.\n</code></pre>"},{"location":"cli/nrfu/#example","title":"Example","text":"<pre><code>anta nrfu --device DC1-LEAF1A text\n</code></pre>"},{"location":"cli/nrfu/#performing-nrfu-with-table-rendering","title":"Performing NRFU with table rendering","text":"<p>The <code>table</code> command under the <code>anta nrfu</code> namespace offers a clear and organized table view of the test results, suitable for filtering. It also has its own set of options for better control over the output.</p>"},{"location":"cli/nrfu/#command-overview_1","title":"Command overview","text":"<pre><code>$ anta nrfu table --help\nUsage: anta nrfu table [OPTIONS]\n\n  ANTA command to check network state with table results.\n\nOptions:\n  --group-by [device|test]  Group result by test or device.\n  --help                    Show this message and exit.\n</code></pre> <p>The <code>--group-by</code> option show a summarized view of the test results per host or per test.</p>"},{"location":"cli/nrfu/#examples","title":"Examples","text":"<pre><code>anta nrfu --tags LEAF table\n</code></pre> <p>For larger setups, you can also group the results by host or test to get a summarized view:</p> <pre><code>anta nrfu table --group-by device\n</code></pre> <p></p> <pre><code>anta nrfu table --group-by test\n</code></pre> <p></p> <p>To get more specific information, it is possible to filter on a single device or a single test:</p> <pre><code>anta nrfu --device spine1 table\n</code></pre> <p></p> <pre><code>anta nrfu --test VerifyZeroTouch table\n</code></pre> <p></p>"},{"location":"cli/nrfu/#performing-nrfu-with-json-rendering","title":"Performing NRFU with JSON rendering","text":"<p>The JSON rendering command in NRFU testing will generate an output of all test results in JSON format.</p>"},{"location":"cli/nrfu/#command-overview_2","title":"Command overview","text":"<pre><code>$ anta nrfu json --help\nUsage: anta nrfu json [OPTIONS]\n\n  ANTA command to check network state with JSON results.\n\n  If no `--output` is specified, the output is printed to stdout.\n\nOptions:\n  -o, --output FILE  Path to save report as a JSON file  [env var:\n                     ANTA_NRFU_JSON_OUTPUT]\n  --help             Show this message and exit.\n</code></pre> <p>The <code>--output</code> option allows you to save the JSON report as a file. If specified, no output will be displayed in the terminal. This is useful for further processing or integration with other tools.</p>"},{"location":"cli/nrfu/#example_1","title":"Example","text":"<pre><code>anta nrfu --tags LEAF json\n</code></pre>"},{"location":"cli/nrfu/#performing-nrfu-and-saving-results-in-a-csv-file","title":"Performing NRFU and saving results in a CSV file","text":"<p>The <code>csv</code> command in NRFU testing is useful for generating a CSV file with all tests result. This file can be easily analyzed and filtered by operator for reporting purposes.</p>"},{"location":"cli/nrfu/#command-overview_3","title":"Command overview","text":"<pre><code>$ anta nrfu csv --help\nUsage: anta nrfu csv [OPTIONS]\n\n  ANTA command to check network state with CSV report.\n\nOptions:\n  --csv-output FILE  Path to save report as a CSV file  [env var:\n                     ANTA_NRFU_CSV_CSV_OUTPUT; required]\n  --help             Show this message and exit.\n</code></pre>"},{"location":"cli/nrfu/#example_2","title":"Example","text":""},{"location":"cli/nrfu/#performing-nrfu-and-saving-results-in-a-markdown-file","title":"Performing NRFU and saving results in a Markdown file","text":"<p>The <code>md-report</code> command in NRFU testing generates a comprehensive Markdown report containing various sections, including detailed statistics for devices and test categories.</p>"},{"location":"cli/nrfu/#command-overview_4","title":"Command overview","text":"<pre><code>$ anta nrfu md-report --help\nUsage: anta nrfu md-report [OPTIONS]\n\n  ANTA command to check network state with Markdown report.\n\nOptions:\n  --md-output FILE  Path to save the report as a Markdown file  [env var:\n                    ANTA_NRFU_MD_REPORT_MD_OUTPUT; required]\n  --help            Show this message and exit.\n</code></pre>"},{"location":"cli/nrfu/#example_3","title":"Example","text":""},{"location":"cli/nrfu/#performing-nrfu-with-custom-reports","title":"Performing NRFU with custom reports","text":"<p>ANTA offers a CLI option for creating custom reports. This leverages the Jinja2 template system, allowing you to tailor reports to your specific needs.</p>"},{"location":"cli/nrfu/#command-overview_5","title":"Command overview","text":"<pre><code>$ anta nrfu tpl-report --help\nUsage: anta nrfu tpl-report [OPTIONS]\n\n  ANTA command to check network state with templated report.\n\nOptions:\n  -tpl, --template FILE  Path to the template to use for the report  [env var:\n                         ANTA_NRFU_TPL_REPORT_TEMPLATE; required]\n  -o, --output FILE      Path to save report as a file  [env var:\n                         ANTA_NRFU_TPL_REPORT_OUTPUT]\n  --help                 Show this message and exit.\n</code></pre> <p>The <code>--template</code> option is used to specify the Jinja2 template file for generating the custom report.</p> <p>The <code>--output</code> option allows you to choose the path where the final report will be saved.</p>"},{"location":"cli/nrfu/#example_4","title":"Example","text":"<pre><code>anta nrfu --tags LEAF tpl-report --template ./custom_template.j2\n</code></pre> <p>The template <code>./custom_template.j2</code> is a simple Jinja2 template:</p> <pre><code>{% for d in data %}\n* {{ d.test }} is [green]{{ d.result | upper}}[/green] for {{ d.name }}\n{% endfor %}\n</code></pre> <p>The Jinja2 template has access to all <code>TestResult</code> elements and their values, as described in this documentation.</p> <p>You can also save the report result to a file using the <code>--output</code> option:</p> <pre><code>anta nrfu --tags LEAF tpl-report --template ./custom_template.j2 --output nrfu-tpl-report.txt\n</code></pre> <p>The resulting output might look like this:</p> <pre><code>cat nrfu-tpl-report.txt\n* VerifyMlagStatus is [green]SUCCESS[/green] for DC1-LEAF1A\n* VerifyMlagInterfaces is [green]SUCCESS[/green] for DC1-LEAF1A\n* VerifyMlagConfigSanity is [green]SUCCESS[/green] for DC1-LEAF1A\n* VerifyMlagReloadDelay is [green]SUCCESS[/green] for DC1-LEAF1A\n</code></pre>"},{"location":"cli/nrfu/#dry-run-mode","title":"Dry-run mode","text":"<p>It is possible to run <code>anta nrfu --dry-run</code> to execute ANTA up to the point where it should communicate with the network to execute the tests. When using <code>--dry-run</code>, all inventory devices are assumed to be online. This can be useful to check how many tests would be run using the catalog and inventory.</p> <p></p>"},{"location":"cli/overview/","title":"Overview","text":"<p>ANTA provides a powerful Command-Line Interface (CLI) to perform a wide range of operations. This document provides a comprehensive overview of ANTA CLI usage and its commands.</p> <p>ANTA can also be used as a Python library, allowing you to build your own tools based on it. Visit this page for more details.</p> <p>To start using the ANTA CLI, open your terminal and type <code>anta</code>.</p>"},{"location":"cli/overview/#invoking-anta-cli","title":"Invoking ANTA CLI","text":"<pre><code>$ anta --help\n$ anta --help\nUsage: anta [OPTIONS] COMMAND [ARGS]...\n\n  Arista Network Test Automation (ANTA) CLI.\n\nOptions:\n  --help                          Show this message and exit.\n  --version                       Show the version and exit.\n  --log-file FILE                 Send the logs to a file. If logging level is\n                                  DEBUG, only INFO or higher will be sent to\n                                  stdout.  [env var: ANTA_LOG_FILE]\n  -l, --log-level [CRITICAL|ERROR|WARNING|INFO|DEBUG]\n                                  ANTA logging level  [env var:\n                                  ANTA_LOG_LEVEL; default: INFO]\n\nCommands:\n  check  Commands to validate configuration files.\n  debug  Commands to execute EOS commands on remote devices.\n  exec   Commands to execute various scripts on EOS devices.\n  get    Commands to get information from or generate inventories.\n  nrfu   Run ANTA tests on selected inventory devices.\n</code></pre>"},{"location":"cli/overview/#anta-environment-variables","title":"ANTA environment variables","text":"<p>Certain parameters are required and can be either passed to the ANTA CLI or set as an environment variable (ENV VAR).</p> <p>To pass the parameters via the CLI:</p> <pre><code>anta nrfu -u admin -p arista123 -i inventory.yaml -c tests.yaml\n</code></pre> <p>To set them as environment variables:</p> <pre><code>export ANTA_USERNAME=admin\nexport ANTA_PASSWORD=arista123\nexport ANTA_INVENTORY=inventory.yml\nexport ANTA_CATALOG=tests.yml\n</code></pre> <p>Then, run the CLI without options:</p> <pre><code>anta nrfu\n</code></pre> <p>Note</p> <p>All environment variables may not be needed for every commands.</p> <p>Refer to <code>&lt;command&gt; --help</code> for the comprehensive environment variables names.</p> <p>Below are the environment variables usable with the <code>anta nrfu</code> command:</p> Variable Name Purpose Required Default ANTA_USERNAME The username to use in the inventory to connect to devices. Yes - ANTA_PASSWORD The password to use in the inventory to connect to devices. Yes - ANTA_INVENTORY The path to the inventory file. Yes - ANTA_CATALOG The path to the catalog file. Yes - ANTA_ENABLE_PASSWORD The optional enable password, when this variable is set, ANTA_ENABLE or <code>--enable</code> is required. No - ANTA_ENABLE Whether it is necessary to go to enable mode on devices. No False ANTA_PROMPT Prompt for passwords if they are not provided. No False ANTA_TIMEOUT The global timeout value for API calls. No 30.0 ANTA_INSECURE Whether or not using insecure mode when connecting to the EOS devices HTTP API. No False ANTA_DISABLE_CACHE A variable to disable caching for all ANTA tests (enabled by default). No False ANTA_INVENTORY_FORMAT Format of the inventory file. <code>json</code> or <code>yaml</code>. No <code>yaml</code> ANTA_CATALOG_FORMAT Format of the catalog file. <code>json</code> or <code>yaml</code>. No <code>yaml</code> ANTA_TAGS A list of tags to filter which tests to run on which devices. No - ANTA_NRFU_IGNORE_STATUS Exit code will always be 0. No False ANTA_NRFU_IGNORE_ERROR Exit code will be 0 if all tests succeeded or 1 if any test failed. No False ANTA_NRFU_DRY_RUN Run <code>anta nrfu</code> command but stop before running the tests. No False <p>Note</p> <p>Caching can be disabled with the global parameter <code>--disable-cache</code>. For more details about how caching is implemented in ANTA, please refer to Caching in ANTA.</p>"},{"location":"cli/overview/#anta-exit-codes","title":"ANTA Exit Codes","text":"<p>ANTA CLI utilizes the following exit codes:</p> <ul> <li><code>Exit code 0</code> - All tests passed successfully.</li> <li><code>Exit code 1</code> - An internal error occurred while executing ANTA.</li> <li><code>Exit code 2</code> - A usage error was raised.</li> <li><code>Exit code 3</code> - Tests were run, but at least one test returned an error.</li> <li><code>Exit code 4</code> - Tests were run, but at least one test returned a failure.</li> </ul> <p>To ignore the test status, use <code>anta nrfu --ignore-status</code>, and the exit code will always be 0.</p> <p>To ignore errors, use <code>anta nrfu --ignore-error</code>, and the exit code will be 0 if all tests succeeded or 1 if any test failed.</p>"},{"location":"cli/overview/#shell-completion","title":"Shell Completion","text":"<p>You can enable shell completion for the ANTA CLI:</p> ZSHBASH <p>If you use ZSH shell, add the following line in your <code>~/.zshrc</code>:</p> <pre><code>eval \"$(_ANTA_COMPLETE=zsh_source anta)\" &gt; /dev/null\n</code></pre> <p>With bash, add the following line in your <code>~/.bashrc</code>:</p> <pre><code>eval \"$(_ANTA_COMPLETE=bash_source anta)\" &gt; /dev/null\n</code></pre>"},{"location":"cli/tag-management/","title":"Tag Management","text":"<p>ANTA uses tags to define test-to-device mappings (tests run on devices with matching tags) and the <code>--tags</code> CLI option acts as a filter to execute specific test/device combinations.</p>"},{"location":"cli/tag-management/#defining-tags","title":"Defining tags","text":""},{"location":"cli/tag-management/#device-tags","title":"Device tags","text":"<p>Device tags can be defined in the inventory:</p> <pre><code>anta_inventory:\n  hosts:\n    - name: leaf1\n      host: leaf1.anta.arista.com\n      tags: [\"leaf\"]\n    - name: leaf2\n      host: leaf2.anta.arista.com\n      tags: [\"leaf\"]\n    - name: spine1\n      host: spine1.anta.arista.com\n      tags: [\"spine\"]\n</code></pre> <p>Each device also has its own name automatically added as a tag:</p> <pre><code>$ anta get inventory\nCurrent inventory content is:\n{\n    'leaf1': AsyncEOSDevice(\n        name='leaf1',\n        tags={'leaf', 'leaf1'},  &lt;--\n        [...]\n        host='leaf1.anta.arista.com',\n        [...]\n    ),\n    'leaf2': AsyncEOSDevice(\n        name='leaf2',\n        tags={'leaf', 'leaf2'},  &lt;--\n        [...]\n        host='leaf2.anta.arista.com',\n        [...]\n    ),\n    'spine1': AsyncEOSDevice(\n        name='spine1',\n        tags={'spine1', 'spine'},  &lt;--\n        [...]\n        host='spine1.anta.arista.com',\n        [...]\n    )\n}\n</code></pre>"},{"location":"cli/tag-management/#test-tags","title":"Test tags","text":"<p>Tags can be defined in the test catalog to restrict tests to tagged devices:</p> <pre><code>anta.tests.system:\n  - VerifyUptime:\n      minimum: 10\n      filters: tags: [spine]\n  - VerifyUptime:\n      minimum: 9\n      filters:\n        tags: [leaf]\n  - VerifyReloadCause:\n      filters:\n        tags: [spine, leaf]\n  - VerifyCoredump:\n  - VerifyAgentLogs:\n  - VerifyCPUUtilization:\n  - VerifyMemoryUtilization:\n  - VerifyFileSystemUtilization:\n  - VerifyNTP:\n\nanta.tests.mlag:\n  - VerifyMlagStatus:\n      filters:\n        tags: [leaf]\n\nanta.tests.interfaces:\n  - VerifyL3MTU:\n      mtu: 1500\n      filters:\n        tags: [spine]\n</code></pre> <p>Tip</p> <ul> <li> <p>A tag used to filter a test can also be a device name</p> </li> <li> <p>Use different input values for a specific test: Leverage tags to define different input values for a specific test. See the <code>VerifyUptime</code> example above.</p> </li> </ul>"},{"location":"cli/tag-management/#using-tags","title":"Using tags","text":"Command Description No <code>--tags</code> option Run all tests on all devices according to the <code>tag</code> definitions in your inventory and test catalog. Tests without tags are executed on all devices. <code>--tags leaf</code> Run all tests marked with the <code>leaf</code> tag on all devices configured with the <code>leaf</code> tag. All other tests are ignored. <code>--tags leaf,spine</code> Run all tests marked with the <code>leaf</code> tag on all devices configured with the <code>leaf</code> tag.Run all tests marked with the <code>spine</code> tag on all devices configured with the <code>spine</code> tag. All other tests are ignored."},{"location":"cli/tag-management/#examples","title":"Examples","text":"<p>The following examples use the inventory and test catalog defined above.</p>"},{"location":"cli/tag-management/#no-tags-option","title":"No <code>--tags</code> option","text":"<p>Tests without tags are run on all devices. Tests with tags will only run on devices with matching tags.</p> <pre><code>$ anta nrfu table --group-by device\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Settings \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 - ANTA Inventory contains 3 devices (AsyncEOSDevice) \u2502\n\u2502 - Tests catalog contains 11 tests                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n--- ANTA NRFU Run Information ---\nNumber of devices: 3 (3 established)\nTotal number of selected tests: 27\n---------------------------------\n                                            Summary per device\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Device \u2503 # of success \u2503 # of skipped \u2503 # of failure \u2503 # of errors \u2503 List of failed or error test cases \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 leaf1  \u2502 9            \u2502 0            \u2502 0            \u2502 0           \u2502                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 leaf2  \u2502 7            \u2502 1            \u2502 1            \u2502 0           \u2502 VerifyAgentLogs                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 spine1 \u2502 9            \u2502 0            \u2502 0            \u2502 0           \u2502                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"cli/tag-management/#single-tag","title":"Single tag","text":"<p>With a tag specified, only tests matching this tag will be run on matching devices.</p> <pre><code>$ anta nrfu --tags leaf text\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Settings \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 - ANTA Inventory contains 3 devices (AsyncEOSDevice) \u2502\n\u2502 - Tests catalog contains 11 tests                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n--- ANTA NRFU Run Information ---\nNumber of devices: 3 (2 established)\nTotal number of selected tests: 6\n---------------------------------\n\nleaf1 :: VerifyReloadCause :: SUCCESS\nleaf1 :: VerifyUptime :: SUCCESS\nleaf1 :: VerifyMlagStatus :: SUCCESS\nleaf2 :: VerifyReloadCause :: SUCCESS\nleaf2 :: VerifyUptime :: SUCCESS\nleaf2 :: VerifyMlagStatus :: SKIPPED (MLAG is disabled)\n</code></pre> <p>In this case, only <code>leaf</code> devices defined in the inventory are used to run tests marked with the <code>leaf</code> in the test catalog.</p>"},{"location":"cli/tag-management/#multiple-tags","title":"Multiple tags","text":"<p>It is possible to use multiple tags using the <code>--tags tag1,tag2</code> syntax.</p> <pre><code>$ anta nrfu --tags leaf,spine text\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Settings \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 - ANTA Inventory contains 3 devices (AsyncEOSDevice) \u2502\n\u2502 - Tests catalog contains 11 tests                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n--- ANTA NRFU Run Information ---\nNumber of devices: 3 (3 established)\nTotal number of selected tests: 15\n---------------------------------\n\nleaf1 :: VerifyReloadCause :: SUCCESS\nleaf1 :: VerifyMlagStatus :: SUCCESS\nleaf1 :: VerifyUptime :: SUCCESS\nleaf1 :: VerifyL3MTU :: SUCCESS\nleaf1 :: VerifyUptime :: SUCCESS\nleaf2 :: VerifyReloadCause :: SUCCESS\nleaf2 :: VerifyMlagStatus :: SKIPPED (MLAG is disabled)\nleaf2 :: VerifyUptime :: SUCCESS\nleaf2 :: VerifyL3MTU :: SUCCESS\nleaf2 :: VerifyUptime :: SUCCESS\nspine1 :: VerifyReloadCause :: SUCCESS\nspine1 :: VerifyMlagStatus :: SUCCESS\nspine1 :: VerifyUptime :: SUCCESS\nspine1 :: VerifyL3MTU :: SUCCESS\nspine1 :: VerifyUptime :: SUCCESS\n</code></pre>"},{"location":"cli/tag-management/#obtaining-all-configured-tags","title":"Obtaining all configured tags","text":"<p>As most ANTA commands accommodate tag filtering, this command is useful for enumerating all tags configured in the inventory. Running the <code>anta get tags</code> command will return a list of all tags configured in the inventory.</p>"},{"location":"cli/tag-management/#command-overview","title":"Command overview","text":"<pre><code>--8&lt;-- anta_get_tags_help.txt\n</code></pre>"},{"location":"cli/tag-management/#example","title":"Example","text":"<p>To get the list of all configured tags in the inventory, run the following command:</p> <pre><code>$ anta get tags\nTags found:\n[\n  \"leaf\",\n  \"leaf1\",\n  \"leaf2\",\n  \"spine\",\n  \"spine1\"\n]\n</code></pre>"}]}